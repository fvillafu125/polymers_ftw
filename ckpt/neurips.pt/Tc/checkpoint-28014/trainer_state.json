{
  "best_global_step": 20010,
  "best_metric": 0.0020028071012347937,
  "best_model_checkpoint": "ckpt/neurips.pt/Tc/checkpoint-20010",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 28014,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01249375312343828,
      "grad_norm": 6.312224864959717,
      "learning_rate": 4.993878060969516e-05,
      "loss": 0.0813,
      "step": 50
    },
    {
      "epoch": 0.02498750624687656,
      "grad_norm": 1.2056206464767456,
      "learning_rate": 4.987631184407796e-05,
      "loss": 0.0438,
      "step": 100
    },
    {
      "epoch": 0.037481259370314844,
      "grad_norm": 2.8671300411224365,
      "learning_rate": 4.981384307846077e-05,
      "loss": 0.0292,
      "step": 150
    },
    {
      "epoch": 0.04997501249375312,
      "grad_norm": 3.500213146209717,
      "learning_rate": 4.975137431284358e-05,
      "loss": 0.0291,
      "step": 200
    },
    {
      "epoch": 0.062468765617191405,
      "grad_norm": 5.867520809173584,
      "learning_rate": 4.9688905547226386e-05,
      "loss": 0.0491,
      "step": 250
    },
    {
      "epoch": 0.07496251874062969,
      "grad_norm": 1.8115986585617065,
      "learning_rate": 4.9626436781609195e-05,
      "loss": 0.0278,
      "step": 300
    },
    {
      "epoch": 0.08745627186406797,
      "grad_norm": 4.086695194244385,
      "learning_rate": 4.956396801599201e-05,
      "loss": 0.0212,
      "step": 350
    },
    {
      "epoch": 0.09995002498750624,
      "grad_norm": 1.9937783479690552,
      "learning_rate": 4.950149925037482e-05,
      "loss": 0.0304,
      "step": 400
    },
    {
      "epoch": 0.11244377811094453,
      "grad_norm": 5.062497138977051,
      "learning_rate": 4.943903048475763e-05,
      "loss": 0.0252,
      "step": 450
    },
    {
      "epoch": 0.12493753123438281,
      "grad_norm": 1.8786851167678833,
      "learning_rate": 4.937656171914043e-05,
      "loss": 0.0254,
      "step": 500
    },
    {
      "epoch": 0.1374312843578211,
      "grad_norm": 1.9751256704330444,
      "learning_rate": 4.931409295352324e-05,
      "loss": 0.0206,
      "step": 550
    },
    {
      "epoch": 0.14992503748125938,
      "grad_norm": 3.423582077026367,
      "learning_rate": 4.925162418790605e-05,
      "loss": 0.021,
      "step": 600
    },
    {
      "epoch": 0.16241879060469766,
      "grad_norm": 1.5686819553375244,
      "learning_rate": 4.9189155422288855e-05,
      "loss": 0.022,
      "step": 650
    },
    {
      "epoch": 0.17491254372813594,
      "grad_norm": 1.2592302560806274,
      "learning_rate": 4.9126686656671664e-05,
      "loss": 0.0202,
      "step": 700
    },
    {
      "epoch": 0.1874062968515742,
      "grad_norm": 5.568796634674072,
      "learning_rate": 4.906421789105447e-05,
      "loss": 0.0234,
      "step": 750
    },
    {
      "epoch": 0.19990004997501248,
      "grad_norm": 2.5328750610351562,
      "learning_rate": 4.900174912543729e-05,
      "loss": 0.0211,
      "step": 800
    },
    {
      "epoch": 0.21239380309845077,
      "grad_norm": 4.399670600891113,
      "learning_rate": 4.89392803598201e-05,
      "loss": 0.016,
      "step": 850
    },
    {
      "epoch": 0.22488755622188905,
      "grad_norm": 4.888381481170654,
      "learning_rate": 4.88768115942029e-05,
      "loss": 0.0226,
      "step": 900
    },
    {
      "epoch": 0.23738130934532733,
      "grad_norm": 3.1280102729797363,
      "learning_rate": 4.881434282858571e-05,
      "loss": 0.0173,
      "step": 950
    },
    {
      "epoch": 0.24987506246876562,
      "grad_norm": 2.855862617492676,
      "learning_rate": 4.8751874062968516e-05,
      "loss": 0.0316,
      "step": 1000
    },
    {
      "epoch": 0.2623688155922039,
      "grad_norm": 2.1616175174713135,
      "learning_rate": 4.8689405297351325e-05,
      "loss": 0.0188,
      "step": 1050
    },
    {
      "epoch": 0.2748625687156422,
      "grad_norm": 2.895878553390503,
      "learning_rate": 4.8626936531734134e-05,
      "loss": 0.0164,
      "step": 1100
    },
    {
      "epoch": 0.28735632183908044,
      "grad_norm": 2.941817045211792,
      "learning_rate": 4.856446776611694e-05,
      "loss": 0.0192,
      "step": 1150
    },
    {
      "epoch": 0.29985007496251875,
      "grad_norm": 1.2977616786956787,
      "learning_rate": 4.850199900049975e-05,
      "loss": 0.017,
      "step": 1200
    },
    {
      "epoch": 0.312343828085957,
      "grad_norm": 2.6009345054626465,
      "learning_rate": 4.8439530234882566e-05,
      "loss": 0.0175,
      "step": 1250
    },
    {
      "epoch": 0.3248375812093953,
      "grad_norm": 2.5296592712402344,
      "learning_rate": 4.8377061469265375e-05,
      "loss": 0.0171,
      "step": 1300
    },
    {
      "epoch": 0.3373313343328336,
      "grad_norm": 1.632485032081604,
      "learning_rate": 4.831459270364818e-05,
      "loss": 0.0171,
      "step": 1350
    },
    {
      "epoch": 0.3498250874562719,
      "grad_norm": 4.0033345222473145,
      "learning_rate": 4.8252123938030986e-05,
      "loss": 0.0257,
      "step": 1400
    },
    {
      "epoch": 0.36231884057971014,
      "grad_norm": 2.8596181869506836,
      "learning_rate": 4.8189655172413794e-05,
      "loss": 0.0147,
      "step": 1450
    },
    {
      "epoch": 0.3748125937031484,
      "grad_norm": 1.8743635416030884,
      "learning_rate": 4.81271864067966e-05,
      "loss": 0.0309,
      "step": 1500
    },
    {
      "epoch": 0.3873063468265867,
      "grad_norm": 3.790996789932251,
      "learning_rate": 4.806471764117941e-05,
      "loss": 0.0148,
      "step": 1550
    },
    {
      "epoch": 0.39980009995002497,
      "grad_norm": 5.655865669250488,
      "learning_rate": 4.800224887556222e-05,
      "loss": 0.0158,
      "step": 1600
    },
    {
      "epoch": 0.4122938530734633,
      "grad_norm": 1.5494496822357178,
      "learning_rate": 4.793978010994503e-05,
      "loss": 0.0194,
      "step": 1650
    },
    {
      "epoch": 0.42478760619690153,
      "grad_norm": 1.0983058214187622,
      "learning_rate": 4.787731134432784e-05,
      "loss": 0.026,
      "step": 1700
    },
    {
      "epoch": 0.43728135932033985,
      "grad_norm": 2.464763641357422,
      "learning_rate": 4.7814842578710646e-05,
      "loss": 0.0139,
      "step": 1750
    },
    {
      "epoch": 0.4497751124437781,
      "grad_norm": 3.3514857292175293,
      "learning_rate": 4.7752373813093455e-05,
      "loss": 0.0171,
      "step": 1800
    },
    {
      "epoch": 0.4622688655672164,
      "grad_norm": 0.8355218172073364,
      "learning_rate": 4.7689905047476264e-05,
      "loss": 0.0119,
      "step": 1850
    },
    {
      "epoch": 0.47476261869065467,
      "grad_norm": 2.711320638656616,
      "learning_rate": 4.762743628185907e-05,
      "loss": 0.0124,
      "step": 1900
    },
    {
      "epoch": 0.487256371814093,
      "grad_norm": 2.0634663105010986,
      "learning_rate": 4.756496751624188e-05,
      "loss": 0.0135,
      "step": 1950
    },
    {
      "epoch": 0.49975012493753124,
      "grad_norm": 0.9462367296218872,
      "learning_rate": 4.750249875062469e-05,
      "loss": 0.0159,
      "step": 2000
    },
    {
      "epoch": 0.5122438780609695,
      "grad_norm": 2.5407063961029053,
      "learning_rate": 4.74400299850075e-05,
      "loss": 0.0122,
      "step": 2050
    },
    {
      "epoch": 0.5247376311844077,
      "grad_norm": 1.6367571353912354,
      "learning_rate": 4.737756121939031e-05,
      "loss": 0.0163,
      "step": 2100
    },
    {
      "epoch": 0.5372313843078461,
      "grad_norm": 2.2189559936523438,
      "learning_rate": 4.7315092453773116e-05,
      "loss": 0.0148,
      "step": 2150
    },
    {
      "epoch": 0.5497251374312844,
      "grad_norm": 2.1010801792144775,
      "learning_rate": 4.7252623688155924e-05,
      "loss": 0.013,
      "step": 2200
    },
    {
      "epoch": 0.5622188905547226,
      "grad_norm": 2.2674636840820312,
      "learning_rate": 4.719015492253873e-05,
      "loss": 0.014,
      "step": 2250
    },
    {
      "epoch": 0.5747126436781609,
      "grad_norm": 1.2197097539901733,
      "learning_rate": 4.712768615692154e-05,
      "loss": 0.0116,
      "step": 2300
    },
    {
      "epoch": 0.5872063968015993,
      "grad_norm": 3.67559552192688,
      "learning_rate": 4.706521739130435e-05,
      "loss": 0.0146,
      "step": 2350
    },
    {
      "epoch": 0.5997001499250375,
      "grad_norm": 12.006609916687012,
      "learning_rate": 4.700274862568716e-05,
      "loss": 0.0301,
      "step": 2400
    },
    {
      "epoch": 0.6121939030484758,
      "grad_norm": 0.5720727443695068,
      "learning_rate": 4.694027986006997e-05,
      "loss": 0.0121,
      "step": 2450
    },
    {
      "epoch": 0.624687656171914,
      "grad_norm": 1.595648169517517,
      "learning_rate": 4.6877811094452777e-05,
      "loss": 0.0131,
      "step": 2500
    },
    {
      "epoch": 0.6371814092953523,
      "grad_norm": 1.4780017137527466,
      "learning_rate": 4.6815342328835585e-05,
      "loss": 0.0134,
      "step": 2550
    },
    {
      "epoch": 0.6496751624187906,
      "grad_norm": 1.4547780752182007,
      "learning_rate": 4.6752873563218394e-05,
      "loss": 0.0124,
      "step": 2600
    },
    {
      "epoch": 0.6621689155422289,
      "grad_norm": 1.6579742431640625,
      "learning_rate": 4.66904047976012e-05,
      "loss": 0.0114,
      "step": 2650
    },
    {
      "epoch": 0.6746626686656672,
      "grad_norm": 2.9011120796203613,
      "learning_rate": 4.662793603198401e-05,
      "loss": 0.0136,
      "step": 2700
    },
    {
      "epoch": 0.6871564217891054,
      "grad_norm": 1.9389357566833496,
      "learning_rate": 4.656546726636682e-05,
      "loss": 0.0124,
      "step": 2750
    },
    {
      "epoch": 0.6996501749125438,
      "grad_norm": 1.9439111948013306,
      "learning_rate": 4.650299850074963e-05,
      "loss": 0.0105,
      "step": 2800
    },
    {
      "epoch": 0.712143928035982,
      "grad_norm": 1.6612296104431152,
      "learning_rate": 4.644052973513244e-05,
      "loss": 0.0119,
      "step": 2850
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 0.8151309490203857,
      "learning_rate": 4.6378060969515246e-05,
      "loss": 0.0207,
      "step": 2900
    },
    {
      "epoch": 0.7371314342828585,
      "grad_norm": 0.8826169967651367,
      "learning_rate": 4.631559220389805e-05,
      "loss": 0.0114,
      "step": 2950
    },
    {
      "epoch": 0.7496251874062968,
      "grad_norm": 2.4290096759796143,
      "learning_rate": 4.6253123438280857e-05,
      "loss": 0.0111,
      "step": 3000
    },
    {
      "epoch": 0.7621189405297352,
      "grad_norm": 0.675841212272644,
      "learning_rate": 4.619065467266367e-05,
      "loss": 0.0097,
      "step": 3050
    },
    {
      "epoch": 0.7746126936531734,
      "grad_norm": 0.6818892955780029,
      "learning_rate": 4.612818590704648e-05,
      "loss": 0.0078,
      "step": 3100
    },
    {
      "epoch": 0.7871064467766117,
      "grad_norm": 0.6444903612136841,
      "learning_rate": 4.606571714142929e-05,
      "loss": 0.0115,
      "step": 3150
    },
    {
      "epoch": 0.7996001999000499,
      "grad_norm": 2.493208885192871,
      "learning_rate": 4.60032483758121e-05,
      "loss": 0.0076,
      "step": 3200
    },
    {
      "epoch": 0.8120939530234883,
      "grad_norm": 0.6769257187843323,
      "learning_rate": 4.594077961019491e-05,
      "loss": 0.0181,
      "step": 3250
    },
    {
      "epoch": 0.8245877061469266,
      "grad_norm": 2.9910240173339844,
      "learning_rate": 4.5878310844577715e-05,
      "loss": 0.0082,
      "step": 3300
    },
    {
      "epoch": 0.8370814592703648,
      "grad_norm": 1.8393542766571045,
      "learning_rate": 4.581584207896052e-05,
      "loss": 0.0107,
      "step": 3350
    },
    {
      "epoch": 0.8495752123938031,
      "grad_norm": 2.4550530910491943,
      "learning_rate": 4.5753373313343326e-05,
      "loss": 0.0101,
      "step": 3400
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.8230810165405273,
      "learning_rate": 4.5690904547726135e-05,
      "loss": 0.0095,
      "step": 3450
    },
    {
      "epoch": 0.8745627186406797,
      "grad_norm": 1.0653148889541626,
      "learning_rate": 4.562843578210895e-05,
      "loss": 0.0083,
      "step": 3500
    },
    {
      "epoch": 0.887056471764118,
      "grad_norm": 1.5085943937301636,
      "learning_rate": 4.556596701649176e-05,
      "loss": 0.0096,
      "step": 3550
    },
    {
      "epoch": 0.8995502248875562,
      "grad_norm": 1.9942761659622192,
      "learning_rate": 4.550349825087457e-05,
      "loss": 0.0111,
      "step": 3600
    },
    {
      "epoch": 0.9120439780109945,
      "grad_norm": 2.153306245803833,
      "learning_rate": 4.5441029485257376e-05,
      "loss": 0.0114,
      "step": 3650
    },
    {
      "epoch": 0.9245377311344328,
      "grad_norm": 1.911697506904602,
      "learning_rate": 4.5378560719640185e-05,
      "loss": 0.0096,
      "step": 3700
    },
    {
      "epoch": 0.9370314842578711,
      "grad_norm": 3.3119664192199707,
      "learning_rate": 4.5316091954022993e-05,
      "loss": 0.0098,
      "step": 3750
    },
    {
      "epoch": 0.9495252373813093,
      "grad_norm": 2.345182180404663,
      "learning_rate": 4.5253623188405795e-05,
      "loss": 0.0109,
      "step": 3800
    },
    {
      "epoch": 0.9620189905047476,
      "grad_norm": 0.6333037614822388,
      "learning_rate": 4.5191154422788604e-05,
      "loss": 0.0085,
      "step": 3850
    },
    {
      "epoch": 0.974512743628186,
      "grad_norm": 0.44535231590270996,
      "learning_rate": 4.512868565717141e-05,
      "loss": 0.0098,
      "step": 3900
    },
    {
      "epoch": 0.9870064967516242,
      "grad_norm": 1.4956209659576416,
      "learning_rate": 4.506621689155423e-05,
      "loss": 0.0078,
      "step": 3950
    },
    {
      "epoch": 0.9995002498750625,
      "grad_norm": 0.6598081588745117,
      "learning_rate": 4.500374812593704e-05,
      "loss": 0.009,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.004789364989846945,
      "eval_runtime": 2.713,
      "eval_samples_per_second": 593.442,
      "eval_steps_per_second": 74.457,
      "step": 4002
    },
    {
      "epoch": 1.0119940029985008,
      "grad_norm": 2.1726253032684326,
      "learning_rate": 4.4941279360319846e-05,
      "loss": 0.0087,
      "step": 4050
    },
    {
      "epoch": 1.024487756121939,
      "grad_norm": 1.7819780111312866,
      "learning_rate": 4.4878810594702654e-05,
      "loss": 0.0103,
      "step": 4100
    },
    {
      "epoch": 1.0369815092453774,
      "grad_norm": 1.2640975713729858,
      "learning_rate": 4.481634182908546e-05,
      "loss": 0.0095,
      "step": 4150
    },
    {
      "epoch": 1.0494752623688155,
      "grad_norm": 1.0046687126159668,
      "learning_rate": 4.4753873063468265e-05,
      "loss": 0.0078,
      "step": 4200
    },
    {
      "epoch": 1.0619690154922539,
      "grad_norm": 0.5196293592453003,
      "learning_rate": 4.4691404297851074e-05,
      "loss": 0.0188,
      "step": 4250
    },
    {
      "epoch": 1.0744627686156922,
      "grad_norm": 1.227694034576416,
      "learning_rate": 4.462893553223388e-05,
      "loss": 0.0069,
      "step": 4300
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 1.56533682346344,
      "learning_rate": 4.456646676661669e-05,
      "loss": 0.0104,
      "step": 4350
    },
    {
      "epoch": 1.0994502748625687,
      "grad_norm": 1.2668657302856445,
      "learning_rate": 4.45039980009995e-05,
      "loss": 0.0086,
      "step": 4400
    },
    {
      "epoch": 1.111944027986007,
      "grad_norm": 1.8022435903549194,
      "learning_rate": 4.4441529235382315e-05,
      "loss": 0.0083,
      "step": 4450
    },
    {
      "epoch": 1.1244377811094453,
      "grad_norm": 1.754470944404602,
      "learning_rate": 4.4379060469765124e-05,
      "loss": 0.0088,
      "step": 4500
    },
    {
      "epoch": 1.1369315342328836,
      "grad_norm": 1.2690297365188599,
      "learning_rate": 4.431659170414793e-05,
      "loss": 0.0097,
      "step": 4550
    },
    {
      "epoch": 1.1494252873563218,
      "grad_norm": 0.7271156907081604,
      "learning_rate": 4.4254122938530734e-05,
      "loss": 0.0074,
      "step": 4600
    },
    {
      "epoch": 1.1619190404797601,
      "grad_norm": 0.8961464166641235,
      "learning_rate": 4.419165417291354e-05,
      "loss": 0.0067,
      "step": 4650
    },
    {
      "epoch": 1.1744127936031985,
      "grad_norm": 3.2410857677459717,
      "learning_rate": 4.412918540729635e-05,
      "loss": 0.0262,
      "step": 4700
    },
    {
      "epoch": 1.1869065467266366,
      "grad_norm": 3.9292454719543457,
      "learning_rate": 4.406671664167916e-05,
      "loss": 0.0095,
      "step": 4750
    },
    {
      "epoch": 1.199400299850075,
      "grad_norm": 1.1966437101364136,
      "learning_rate": 4.400424787606197e-05,
      "loss": 0.007,
      "step": 4800
    },
    {
      "epoch": 1.2118940529735132,
      "grad_norm": 0.8260778188705444,
      "learning_rate": 4.394177911044478e-05,
      "loss": 0.0073,
      "step": 4850
    },
    {
      "epoch": 1.2243878060969515,
      "grad_norm": 2.54539155960083,
      "learning_rate": 4.387931034482759e-05,
      "loss": 0.0064,
      "step": 4900
    },
    {
      "epoch": 1.23688155922039,
      "grad_norm": 1.258065104484558,
      "learning_rate": 4.38168415792104e-05,
      "loss": 0.0056,
      "step": 4950
    },
    {
      "epoch": 1.249375312343828,
      "grad_norm": 1.0803890228271484,
      "learning_rate": 4.3754372813593204e-05,
      "loss": 0.0157,
      "step": 5000
    },
    {
      "epoch": 1.2618690654672664,
      "grad_norm": 1.9677447080612183,
      "learning_rate": 4.369190404797601e-05,
      "loss": 0.0068,
      "step": 5050
    },
    {
      "epoch": 1.2743628185907045,
      "grad_norm": 3.6474947929382324,
      "learning_rate": 4.362943528235882e-05,
      "loss": 0.0141,
      "step": 5100
    },
    {
      "epoch": 1.286856571714143,
      "grad_norm": 1.4508373737335205,
      "learning_rate": 4.356696651674163e-05,
      "loss": 0.007,
      "step": 5150
    },
    {
      "epoch": 1.2993503248375813,
      "grad_norm": 0.7648293972015381,
      "learning_rate": 4.350449775112444e-05,
      "loss": 0.0083,
      "step": 5200
    },
    {
      "epoch": 1.3118440779610194,
      "grad_norm": 1.6828947067260742,
      "learning_rate": 4.344202898550725e-05,
      "loss": 0.0063,
      "step": 5250
    },
    {
      "epoch": 1.3243378310844578,
      "grad_norm": 1.8866181373596191,
      "learning_rate": 4.3379560219890056e-05,
      "loss": 0.0063,
      "step": 5300
    },
    {
      "epoch": 1.336831584207896,
      "grad_norm": 1.903488278388977,
      "learning_rate": 4.331709145427287e-05,
      "loss": 0.0064,
      "step": 5350
    },
    {
      "epoch": 1.3493253373313343,
      "grad_norm": 1.7405844926834106,
      "learning_rate": 4.325462268865567e-05,
      "loss": 0.0053,
      "step": 5400
    },
    {
      "epoch": 1.3618190904547727,
      "grad_norm": 0.8601424098014832,
      "learning_rate": 4.319215392303848e-05,
      "loss": 0.0055,
      "step": 5450
    },
    {
      "epoch": 1.3743128435782108,
      "grad_norm": 0.47635841369628906,
      "learning_rate": 4.312968515742129e-05,
      "loss": 0.006,
      "step": 5500
    },
    {
      "epoch": 1.3868065967016492,
      "grad_norm": 0.6739533543586731,
      "learning_rate": 4.30672163918041e-05,
      "loss": 0.0067,
      "step": 5550
    },
    {
      "epoch": 1.3993003498250873,
      "grad_norm": 0.4738546311855316,
      "learning_rate": 4.300474762618691e-05,
      "loss": 0.0044,
      "step": 5600
    },
    {
      "epoch": 1.4117941029485257,
      "grad_norm": 0.8671789765357971,
      "learning_rate": 4.2942278860569717e-05,
      "loss": 0.0078,
      "step": 5650
    },
    {
      "epoch": 1.424287856071964,
      "grad_norm": 0.5185899138450623,
      "learning_rate": 4.2879810094952525e-05,
      "loss": 0.0069,
      "step": 5700
    },
    {
      "epoch": 1.4367816091954024,
      "grad_norm": 0.6377416253089905,
      "learning_rate": 4.2817341329335334e-05,
      "loss": 0.0044,
      "step": 5750
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 1.1477428674697876,
      "learning_rate": 4.275487256371814e-05,
      "loss": 0.0053,
      "step": 5800
    },
    {
      "epoch": 1.461769115442279,
      "grad_norm": 1.2287580966949463,
      "learning_rate": 4.269240379810095e-05,
      "loss": 0.0049,
      "step": 5850
    },
    {
      "epoch": 1.474262868565717,
      "grad_norm": 1.0249079465866089,
      "learning_rate": 4.262993503248376e-05,
      "loss": 0.0097,
      "step": 5900
    },
    {
      "epoch": 1.4867566216891555,
      "grad_norm": 0.6807969808578491,
      "learning_rate": 4.256746626686657e-05,
      "loss": 0.0065,
      "step": 5950
    },
    {
      "epoch": 1.4992503748125938,
      "grad_norm": 1.1658626794815063,
      "learning_rate": 4.250499750124938e-05,
      "loss": 0.0051,
      "step": 6000
    },
    {
      "epoch": 1.511744127936032,
      "grad_norm": 0.5859391689300537,
      "learning_rate": 4.2442528735632186e-05,
      "loss": 0.0052,
      "step": 6050
    },
    {
      "epoch": 1.5242378810594701,
      "grad_norm": 0.9345666170120239,
      "learning_rate": 4.2380059970014995e-05,
      "loss": 0.0044,
      "step": 6100
    },
    {
      "epoch": 1.5367316341829085,
      "grad_norm": 1.381780743598938,
      "learning_rate": 4.23175912043978e-05,
      "loss": 0.0058,
      "step": 6150
    },
    {
      "epoch": 1.5492253873063468,
      "grad_norm": 3.043295383453369,
      "learning_rate": 4.225512243878061e-05,
      "loss": 0.0162,
      "step": 6200
    },
    {
      "epoch": 1.5617191404297852,
      "grad_norm": 0.6903210878372192,
      "learning_rate": 4.219265367316342e-05,
      "loss": 0.0056,
      "step": 6250
    },
    {
      "epoch": 1.5742128935532234,
      "grad_norm": 0.41398268938064575,
      "learning_rate": 4.213018490754623e-05,
      "loss": 0.0081,
      "step": 6300
    },
    {
      "epoch": 1.5867066466766615,
      "grad_norm": 2.0643606185913086,
      "learning_rate": 4.206771614192904e-05,
      "loss": 0.0133,
      "step": 6350
    },
    {
      "epoch": 1.5992003998000999,
      "grad_norm": 1.6740602254867554,
      "learning_rate": 4.200524737631185e-05,
      "loss": 0.0052,
      "step": 6400
    },
    {
      "epoch": 1.6116941529235382,
      "grad_norm": 2.0308961868286133,
      "learning_rate": 4.1942778610694655e-05,
      "loss": 0.0063,
      "step": 6450
    },
    {
      "epoch": 1.6241879060469766,
      "grad_norm": 2.181459665298462,
      "learning_rate": 4.1880309845077464e-05,
      "loss": 0.0057,
      "step": 6500
    },
    {
      "epoch": 1.6366816591704147,
      "grad_norm": 1.8234437704086304,
      "learning_rate": 4.181784107946027e-05,
      "loss": 0.0069,
      "step": 6550
    },
    {
      "epoch": 1.6491754122938531,
      "grad_norm": 0.3572370707988739,
      "learning_rate": 4.175537231384308e-05,
      "loss": 0.0145,
      "step": 6600
    },
    {
      "epoch": 1.6616691654172913,
      "grad_norm": 0.537525475025177,
      "learning_rate": 4.169290354822589e-05,
      "loss": 0.0062,
      "step": 6650
    },
    {
      "epoch": 1.6741629185407296,
      "grad_norm": 1.4987943172454834,
      "learning_rate": 4.16304347826087e-05,
      "loss": 0.0054,
      "step": 6700
    },
    {
      "epoch": 1.686656671664168,
      "grad_norm": 0.9859936833381653,
      "learning_rate": 4.156796601699151e-05,
      "loss": 0.0059,
      "step": 6750
    },
    {
      "epoch": 1.6991504247876064,
      "grad_norm": 1.1259324550628662,
      "learning_rate": 4.1505497251374316e-05,
      "loss": 0.0059,
      "step": 6800
    },
    {
      "epoch": 1.7116441779110445,
      "grad_norm": 0.7556604743003845,
      "learning_rate": 4.1443028485757125e-05,
      "loss": 0.0064,
      "step": 6850
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 1.41274893283844,
      "learning_rate": 4.1380559720139933e-05,
      "loss": 0.0061,
      "step": 6900
    },
    {
      "epoch": 1.736631684157921,
      "grad_norm": 0.9117818474769592,
      "learning_rate": 4.131809095452274e-05,
      "loss": 0.0051,
      "step": 6950
    },
    {
      "epoch": 1.7491254372813594,
      "grad_norm": 0.6636679172515869,
      "learning_rate": 4.125562218890555e-05,
      "loss": 0.005,
      "step": 7000
    },
    {
      "epoch": 1.7616191904047978,
      "grad_norm": 0.5222653746604919,
      "learning_rate": 4.119315342328835e-05,
      "loss": 0.0051,
      "step": 7050
    },
    {
      "epoch": 1.774112943528236,
      "grad_norm": 1.5661249160766602,
      "learning_rate": 4.113068465767116e-05,
      "loss": 0.0152,
      "step": 7100
    },
    {
      "epoch": 1.786606696651674,
      "grad_norm": 0.633439302444458,
      "learning_rate": 4.106821589205398e-05,
      "loss": 0.0052,
      "step": 7150
    },
    {
      "epoch": 1.7991004497751124,
      "grad_norm": 1.9892381429672241,
      "learning_rate": 4.1005747126436786e-05,
      "loss": 0.0053,
      "step": 7200
    },
    {
      "epoch": 1.8115942028985508,
      "grad_norm": 1.0338701009750366,
      "learning_rate": 4.0943278360819594e-05,
      "loss": 0.0128,
      "step": 7250
    },
    {
      "epoch": 1.8240879560219891,
      "grad_norm": 0.7020848393440247,
      "learning_rate": 4.08808095952024e-05,
      "loss": 0.0045,
      "step": 7300
    },
    {
      "epoch": 1.8365817091454273,
      "grad_norm": 2.299654245376587,
      "learning_rate": 4.081834082958521e-05,
      "loss": 0.0045,
      "step": 7350
    },
    {
      "epoch": 1.8490754622688654,
      "grad_norm": 1.6705480813980103,
      "learning_rate": 4.075587206396802e-05,
      "loss": 0.0042,
      "step": 7400
    },
    {
      "epoch": 1.8615692153923038,
      "grad_norm": 0.6636860370635986,
      "learning_rate": 4.069340329835082e-05,
      "loss": 0.0047,
      "step": 7450
    },
    {
      "epoch": 1.8740629685157422,
      "grad_norm": 1.759121060371399,
      "learning_rate": 4.063093453273363e-05,
      "loss": 0.013,
      "step": 7500
    },
    {
      "epoch": 1.8865567216391805,
      "grad_norm": 1.0169074535369873,
      "learning_rate": 4.056846576711644e-05,
      "loss": 0.004,
      "step": 7550
    },
    {
      "epoch": 1.8990504747626187,
      "grad_norm": 1.9727025032043457,
      "learning_rate": 4.0505997001499255e-05,
      "loss": 0.0047,
      "step": 7600
    },
    {
      "epoch": 1.9115442278860568,
      "grad_norm": 0.2869306206703186,
      "learning_rate": 4.0443528235882064e-05,
      "loss": 0.0045,
      "step": 7650
    },
    {
      "epoch": 1.9240379810094952,
      "grad_norm": 1.6450607776641846,
      "learning_rate": 4.038105947026487e-05,
      "loss": 0.0045,
      "step": 7700
    },
    {
      "epoch": 1.9365317341329336,
      "grad_norm": 1.5389165878295898,
      "learning_rate": 4.031859070464768e-05,
      "loss": 0.0041,
      "step": 7750
    },
    {
      "epoch": 1.949025487256372,
      "grad_norm": 0.7357416152954102,
      "learning_rate": 4.025612193903049e-05,
      "loss": 0.0046,
      "step": 7800
    },
    {
      "epoch": 1.96151924037981,
      "grad_norm": 0.7186815738677979,
      "learning_rate": 4.019365317341329e-05,
      "loss": 0.0039,
      "step": 7850
    },
    {
      "epoch": 1.9740129935032482,
      "grad_norm": 0.34882983565330505,
      "learning_rate": 4.01311844077961e-05,
      "loss": 0.0161,
      "step": 7900
    },
    {
      "epoch": 1.9865067466266866,
      "grad_norm": 1.8473480939865112,
      "learning_rate": 4.006871564217891e-05,
      "loss": 0.0043,
      "step": 7950
    },
    {
      "epoch": 1.999000499750125,
      "grad_norm": 0.48129042983055115,
      "learning_rate": 4.000624687656172e-05,
      "loss": 0.0065,
      "step": 8000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0069345273077487946,
      "eval_runtime": 2.6892,
      "eval_samples_per_second": 598.695,
      "eval_steps_per_second": 75.116,
      "step": 8004
    },
    {
      "epoch": 2.0114942528735633,
      "grad_norm": 0.8705040216445923,
      "learning_rate": 3.9943778110944526e-05,
      "loss": 0.0038,
      "step": 8050
    },
    {
      "epoch": 2.0239880059970017,
      "grad_norm": 0.47046563029289246,
      "learning_rate": 3.988130934532734e-05,
      "loss": 0.0033,
      "step": 8100
    },
    {
      "epoch": 2.0364817591204396,
      "grad_norm": 0.824157178401947,
      "learning_rate": 3.981884057971015e-05,
      "loss": 0.0039,
      "step": 8150
    },
    {
      "epoch": 2.048975512243878,
      "grad_norm": 2.302203893661499,
      "learning_rate": 3.975637181409296e-05,
      "loss": 0.0048,
      "step": 8200
    },
    {
      "epoch": 2.0614692653673163,
      "grad_norm": 2.420708179473877,
      "learning_rate": 3.969390304847577e-05,
      "loss": 0.0056,
      "step": 8250
    },
    {
      "epoch": 2.0739630184907547,
      "grad_norm": 0.4139159023761749,
      "learning_rate": 3.963143428285857e-05,
      "loss": 0.004,
      "step": 8300
    },
    {
      "epoch": 2.086456771614193,
      "grad_norm": 0.6064297556877136,
      "learning_rate": 3.956896551724138e-05,
      "loss": 0.0053,
      "step": 8350
    },
    {
      "epoch": 2.098950524737631,
      "grad_norm": 0.576764702796936,
      "learning_rate": 3.950649675162419e-05,
      "loss": 0.0043,
      "step": 8400
    },
    {
      "epoch": 2.1114442778610694,
      "grad_norm": 0.31911593675613403,
      "learning_rate": 3.9444027986006996e-05,
      "loss": 0.0121,
      "step": 8450
    },
    {
      "epoch": 2.1239380309845077,
      "grad_norm": 0.8611418604850769,
      "learning_rate": 3.9381559220389804e-05,
      "loss": 0.0038,
      "step": 8500
    },
    {
      "epoch": 2.136431784107946,
      "grad_norm": 0.7824526429176331,
      "learning_rate": 3.931909045477262e-05,
      "loss": 0.0034,
      "step": 8550
    },
    {
      "epoch": 2.1489255372313845,
      "grad_norm": 0.41160982847213745,
      "learning_rate": 3.925662168915543e-05,
      "loss": 0.0031,
      "step": 8600
    },
    {
      "epoch": 2.1614192903548224,
      "grad_norm": 10.154025077819824,
      "learning_rate": 3.919415292353824e-05,
      "loss": 0.0132,
      "step": 8650
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.25864097476005554,
      "learning_rate": 3.913168415792104e-05,
      "loss": 0.0037,
      "step": 8700
    },
    {
      "epoch": 2.186406796601699,
      "grad_norm": 1.3815337419509888,
      "learning_rate": 3.906921539230385e-05,
      "loss": 0.0036,
      "step": 8750
    },
    {
      "epoch": 2.1989005497251375,
      "grad_norm": 0.6493897438049316,
      "learning_rate": 3.9006746626686657e-05,
      "loss": 0.0037,
      "step": 8800
    },
    {
      "epoch": 2.211394302848576,
      "grad_norm": 1.3967498540878296,
      "learning_rate": 3.8944277861069465e-05,
      "loss": 0.0055,
      "step": 8850
    },
    {
      "epoch": 2.223888055972014,
      "grad_norm": 0.9875578284263611,
      "learning_rate": 3.8881809095452274e-05,
      "loss": 0.0022,
      "step": 8900
    },
    {
      "epoch": 2.236381809095452,
      "grad_norm": 0.4458809196949005,
      "learning_rate": 3.881934032983508e-05,
      "loss": 0.004,
      "step": 8950
    },
    {
      "epoch": 2.2488755622188905,
      "grad_norm": 0.5827258825302124,
      "learning_rate": 3.87568715642179e-05,
      "loss": 0.0044,
      "step": 9000
    },
    {
      "epoch": 2.261369315342329,
      "grad_norm": 1.1301935911178589,
      "learning_rate": 3.869440279860071e-05,
      "loss": 0.0049,
      "step": 9050
    },
    {
      "epoch": 2.2738630684657672,
      "grad_norm": 1.4324134588241577,
      "learning_rate": 3.863193403298351e-05,
      "loss": 0.0047,
      "step": 9100
    },
    {
      "epoch": 2.286356821589205,
      "grad_norm": 0.3386005461215973,
      "learning_rate": 3.856946526736632e-05,
      "loss": 0.014,
      "step": 9150
    },
    {
      "epoch": 2.2988505747126435,
      "grad_norm": 0.5295233130455017,
      "learning_rate": 3.8506996501749126e-05,
      "loss": 0.0035,
      "step": 9200
    },
    {
      "epoch": 2.311344327836082,
      "grad_norm": 1.4566242694854736,
      "learning_rate": 3.8444527736131935e-05,
      "loss": 0.0033,
      "step": 9250
    },
    {
      "epoch": 2.3238380809595203,
      "grad_norm": 0.6573612093925476,
      "learning_rate": 3.838205897051474e-05,
      "loss": 0.0116,
      "step": 9300
    },
    {
      "epoch": 2.3363318340829586,
      "grad_norm": 0.7735643982887268,
      "learning_rate": 3.831959020489755e-05,
      "loss": 0.004,
      "step": 9350
    },
    {
      "epoch": 2.348825587206397,
      "grad_norm": 0.3414800465106964,
      "learning_rate": 3.825712143928036e-05,
      "loss": 0.0033,
      "step": 9400
    },
    {
      "epoch": 2.361319340329835,
      "grad_norm": 0.6397759914398193,
      "learning_rate": 3.819465267366317e-05,
      "loss": 0.0031,
      "step": 9450
    },
    {
      "epoch": 2.3738130934532733,
      "grad_norm": 1.9660999774932861,
      "learning_rate": 3.813218390804598e-05,
      "loss": 0.0041,
      "step": 9500
    },
    {
      "epoch": 2.3863068465767117,
      "grad_norm": 1.1710196733474731,
      "learning_rate": 3.806971514242879e-05,
      "loss": 0.0039,
      "step": 9550
    },
    {
      "epoch": 2.39880059970015,
      "grad_norm": 0.31465664505958557,
      "learning_rate": 3.8007246376811595e-05,
      "loss": 0.0031,
      "step": 9600
    },
    {
      "epoch": 2.4112943528235884,
      "grad_norm": 1.5988081693649292,
      "learning_rate": 3.7944777611194404e-05,
      "loss": 0.0034,
      "step": 9650
    },
    {
      "epoch": 2.4237881059470263,
      "grad_norm": 0.973689615726471,
      "learning_rate": 3.788230884557721e-05,
      "loss": 0.0042,
      "step": 9700
    },
    {
      "epoch": 2.4362818590704647,
      "grad_norm": 0.7019133567810059,
      "learning_rate": 3.781984007996002e-05,
      "loss": 0.004,
      "step": 9750
    },
    {
      "epoch": 2.448775612193903,
      "grad_norm": 0.6351796388626099,
      "learning_rate": 3.775737131434283e-05,
      "loss": 0.0127,
      "step": 9800
    },
    {
      "epoch": 2.4612693653173414,
      "grad_norm": 0.4099218547344208,
      "learning_rate": 3.769490254872564e-05,
      "loss": 0.0045,
      "step": 9850
    },
    {
      "epoch": 2.47376311844078,
      "grad_norm": 0.6521816253662109,
      "learning_rate": 3.763243378310845e-05,
      "loss": 0.003,
      "step": 9900
    },
    {
      "epoch": 2.4862568715642177,
      "grad_norm": 0.33161288499832153,
      "learning_rate": 3.7569965017491256e-05,
      "loss": 0.0116,
      "step": 9950
    },
    {
      "epoch": 2.498750624687656,
      "grad_norm": 0.21285438537597656,
      "learning_rate": 3.7507496251874065e-05,
      "loss": 0.0117,
      "step": 10000
    },
    {
      "epoch": 2.5112443778110944,
      "grad_norm": 0.5948212146759033,
      "learning_rate": 3.7445027486256874e-05,
      "loss": 0.0031,
      "step": 10050
    },
    {
      "epoch": 2.523738130934533,
      "grad_norm": 0.8577877879142761,
      "learning_rate": 3.738255872063968e-05,
      "loss": 0.0025,
      "step": 10100
    },
    {
      "epoch": 2.536231884057971,
      "grad_norm": 0.6205180287361145,
      "learning_rate": 3.732008995502249e-05,
      "loss": 0.0029,
      "step": 10150
    },
    {
      "epoch": 2.548725637181409,
      "grad_norm": 0.6997723579406738,
      "learning_rate": 3.72576211894053e-05,
      "loss": 0.0028,
      "step": 10200
    },
    {
      "epoch": 2.5612193903048475,
      "grad_norm": 0.9666504263877869,
      "learning_rate": 3.719515242378811e-05,
      "loss": 0.0129,
      "step": 10250
    },
    {
      "epoch": 2.573713143428286,
      "grad_norm": 1.5617183446884155,
      "learning_rate": 3.713268365817092e-05,
      "loss": 0.0041,
      "step": 10300
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 1.8205139636993408,
      "learning_rate": 3.7070214892553726e-05,
      "loss": 0.0042,
      "step": 10350
    },
    {
      "epoch": 2.5987006496751626,
      "grad_norm": 0.44661274552345276,
      "learning_rate": 3.7007746126936534e-05,
      "loss": 0.0035,
      "step": 10400
    },
    {
      "epoch": 2.611194402798601,
      "grad_norm": 0.6787466406822205,
      "learning_rate": 3.694527736131934e-05,
      "loss": 0.0028,
      "step": 10450
    },
    {
      "epoch": 2.623688155922039,
      "grad_norm": 1.1583361625671387,
      "learning_rate": 3.688280859570215e-05,
      "loss": 0.0027,
      "step": 10500
    },
    {
      "epoch": 2.6361819090454772,
      "grad_norm": 0.5257135629653931,
      "learning_rate": 3.682033983008496e-05,
      "loss": 0.0029,
      "step": 10550
    },
    {
      "epoch": 2.6486756621689156,
      "grad_norm": 0.2720324695110321,
      "learning_rate": 3.675787106446777e-05,
      "loss": 0.0109,
      "step": 10600
    },
    {
      "epoch": 2.661169415292354,
      "grad_norm": 0.9272398948669434,
      "learning_rate": 3.669540229885058e-05,
      "loss": 0.0038,
      "step": 10650
    },
    {
      "epoch": 2.673663168415792,
      "grad_norm": 0.44904613494873047,
      "learning_rate": 3.6632933533233386e-05,
      "loss": 0.0029,
      "step": 10700
    },
    {
      "epoch": 2.6861569215392302,
      "grad_norm": 1.0308042764663696,
      "learning_rate": 3.657046476761619e-05,
      "loss": 0.0032,
      "step": 10750
    },
    {
      "epoch": 2.6986506746626686,
      "grad_norm": 0.46158117055892944,
      "learning_rate": 3.6507996001999004e-05,
      "loss": 0.0041,
      "step": 10800
    },
    {
      "epoch": 2.711144427786107,
      "grad_norm": 0.7393142580986023,
      "learning_rate": 3.644552723638181e-05,
      "loss": 0.0032,
      "step": 10850
    },
    {
      "epoch": 2.7236381809095453,
      "grad_norm": 1.6746275424957275,
      "learning_rate": 3.638305847076462e-05,
      "loss": 0.0031,
      "step": 10900
    },
    {
      "epoch": 2.7361319340329837,
      "grad_norm": 0.7214917540550232,
      "learning_rate": 3.632058970514743e-05,
      "loss": 0.0027,
      "step": 10950
    },
    {
      "epoch": 2.7486256871564216,
      "grad_norm": 0.6038284301757812,
      "learning_rate": 3.625812093953024e-05,
      "loss": 0.0039,
      "step": 11000
    },
    {
      "epoch": 2.76111944027986,
      "grad_norm": 2.3381519317626953,
      "learning_rate": 3.619565217391305e-05,
      "loss": 0.0045,
      "step": 11050
    },
    {
      "epoch": 2.7736131934032984,
      "grad_norm": 3.025824546813965,
      "learning_rate": 3.6133183408295856e-05,
      "loss": 0.0041,
      "step": 11100
    },
    {
      "epoch": 2.7861069465267367,
      "grad_norm": 0.6253853440284729,
      "learning_rate": 3.607071464267866e-05,
      "loss": 0.0052,
      "step": 11150
    },
    {
      "epoch": 2.7986006996501747,
      "grad_norm": 0.3477432429790497,
      "learning_rate": 3.6008245877061466e-05,
      "loss": 0.0028,
      "step": 11200
    },
    {
      "epoch": 2.811094452773613,
      "grad_norm": 0.8873515129089355,
      "learning_rate": 3.594577711144428e-05,
      "loss": 0.0029,
      "step": 11250
    },
    {
      "epoch": 2.8235882058970514,
      "grad_norm": 0.3621152639389038,
      "learning_rate": 3.588330834582709e-05,
      "loss": 0.0046,
      "step": 11300
    },
    {
      "epoch": 2.8360819590204898,
      "grad_norm": 0.3499357998371124,
      "learning_rate": 3.58208395802099e-05,
      "loss": 0.0025,
      "step": 11350
    },
    {
      "epoch": 2.848575712143928,
      "grad_norm": 0.3979410231113434,
      "learning_rate": 3.575837081459271e-05,
      "loss": 0.0207,
      "step": 11400
    },
    {
      "epoch": 2.8610694652673665,
      "grad_norm": 1.0478579998016357,
      "learning_rate": 3.5695902048975517e-05,
      "loss": 0.0034,
      "step": 11450
    },
    {
      "epoch": 2.873563218390805,
      "grad_norm": 0.4208085238933563,
      "learning_rate": 3.5633433283358325e-05,
      "loss": 0.0022,
      "step": 11500
    },
    {
      "epoch": 2.886056971514243,
      "grad_norm": 0.8773317337036133,
      "learning_rate": 3.557096451774113e-05,
      "loss": 0.0042,
      "step": 11550
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 1.0404767990112305,
      "learning_rate": 3.5508495752123936e-05,
      "loss": 0.0029,
      "step": 11600
    },
    {
      "epoch": 2.9110444777611195,
      "grad_norm": 0.5824851989746094,
      "learning_rate": 3.5446026986506744e-05,
      "loss": 0.0027,
      "step": 11650
    },
    {
      "epoch": 2.923538230884558,
      "grad_norm": 0.4237886071205139,
      "learning_rate": 3.538355822088956e-05,
      "loss": 0.0022,
      "step": 11700
    },
    {
      "epoch": 2.936031984007996,
      "grad_norm": 0.42945972084999084,
      "learning_rate": 3.532108945527237e-05,
      "loss": 0.0032,
      "step": 11750
    },
    {
      "epoch": 2.948525737131434,
      "grad_norm": 0.9129598736763,
      "learning_rate": 3.525862068965518e-05,
      "loss": 0.0028,
      "step": 11800
    },
    {
      "epoch": 2.9610194902548725,
      "grad_norm": 2.0907726287841797,
      "learning_rate": 3.5196151924037986e-05,
      "loss": 0.0114,
      "step": 11850
    },
    {
      "epoch": 2.973513243378311,
      "grad_norm": 0.689822793006897,
      "learning_rate": 3.5133683158420795e-05,
      "loss": 0.0025,
      "step": 11900
    },
    {
      "epoch": 2.9860069965017493,
      "grad_norm": 0.5771703124046326,
      "learning_rate": 3.5071214392803597e-05,
      "loss": 0.0029,
      "step": 11950
    },
    {
      "epoch": 2.9985007496251876,
      "grad_norm": 0.6469007730484009,
      "learning_rate": 3.5008745627186405e-05,
      "loss": 0.0019,
      "step": 12000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.00242886645719409,
      "eval_runtime": 2.7163,
      "eval_samples_per_second": 592.725,
      "eval_steps_per_second": 74.367,
      "step": 12006
    },
    {
      "epoch": 3.0109945027486256,
      "grad_norm": 0.8839011192321777,
      "learning_rate": 3.4946276861569214e-05,
      "loss": 0.0022,
      "step": 12050
    },
    {
      "epoch": 3.023488255872064,
      "grad_norm": 0.4296039044857025,
      "learning_rate": 3.488380809595202e-05,
      "loss": 0.0018,
      "step": 12100
    },
    {
      "epoch": 3.0359820089955023,
      "grad_norm": 0.5651512742042542,
      "learning_rate": 3.482133933033483e-05,
      "loss": 0.003,
      "step": 12150
    },
    {
      "epoch": 3.0484757621189407,
      "grad_norm": 0.33352160453796387,
      "learning_rate": 3.475887056471765e-05,
      "loss": 0.0038,
      "step": 12200
    },
    {
      "epoch": 3.0609695152423786,
      "grad_norm": 0.9077199697494507,
      "learning_rate": 3.4696401799100455e-05,
      "loss": 0.0035,
      "step": 12250
    },
    {
      "epoch": 3.073463268365817,
      "grad_norm": 0.707865834236145,
      "learning_rate": 3.4633933033483264e-05,
      "loss": 0.0025,
      "step": 12300
    },
    {
      "epoch": 3.0859570214892553,
      "grad_norm": 0.8717777729034424,
      "learning_rate": 3.4571464267866066e-05,
      "loss": 0.003,
      "step": 12350
    },
    {
      "epoch": 3.0984507746126937,
      "grad_norm": 0.9547908306121826,
      "learning_rate": 3.4508995502248875e-05,
      "loss": 0.0026,
      "step": 12400
    },
    {
      "epoch": 3.110944527736132,
      "grad_norm": 0.24252356588840485,
      "learning_rate": 3.444652673663168e-05,
      "loss": 0.002,
      "step": 12450
    },
    {
      "epoch": 3.1234382808595704,
      "grad_norm": 0.5355746746063232,
      "learning_rate": 3.438405797101449e-05,
      "loss": 0.0023,
      "step": 12500
    },
    {
      "epoch": 3.1359320339830083,
      "grad_norm": 0.32901501655578613,
      "learning_rate": 3.43215892053973e-05,
      "loss": 0.0031,
      "step": 12550
    },
    {
      "epoch": 3.1484257871064467,
      "grad_norm": 0.8076605200767517,
      "learning_rate": 3.425912043978011e-05,
      "loss": 0.0028,
      "step": 12600
    },
    {
      "epoch": 3.160919540229885,
      "grad_norm": 0.4156164228916168,
      "learning_rate": 3.4196651674162925e-05,
      "loss": 0.0022,
      "step": 12650
    },
    {
      "epoch": 3.1734132933533234,
      "grad_norm": 0.3924374282360077,
      "learning_rate": 3.4134182908545733e-05,
      "loss": 0.0021,
      "step": 12700
    },
    {
      "epoch": 3.185907046476762,
      "grad_norm": 0.5169135928153992,
      "learning_rate": 3.4071714142928535e-05,
      "loss": 0.0038,
      "step": 12750
    },
    {
      "epoch": 3.1984007996001997,
      "grad_norm": 0.5958784222602844,
      "learning_rate": 3.4009245377311344e-05,
      "loss": 0.0034,
      "step": 12800
    },
    {
      "epoch": 3.210894552723638,
      "grad_norm": 0.657442569732666,
      "learning_rate": 3.394677661169415e-05,
      "loss": 0.0017,
      "step": 12850
    },
    {
      "epoch": 3.2233883058470765,
      "grad_norm": 0.25678688287734985,
      "learning_rate": 3.388430784607696e-05,
      "loss": 0.0022,
      "step": 12900
    },
    {
      "epoch": 3.235882058970515,
      "grad_norm": 0.6552765369415283,
      "learning_rate": 3.382183908045977e-05,
      "loss": 0.0027,
      "step": 12950
    },
    {
      "epoch": 3.248375812093953,
      "grad_norm": 0.610701858997345,
      "learning_rate": 3.375937031484258e-05,
      "loss": 0.0025,
      "step": 13000
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 1.2387738227844238,
      "learning_rate": 3.369690154922539e-05,
      "loss": 0.0025,
      "step": 13050
    },
    {
      "epoch": 3.2733633183408295,
      "grad_norm": 0.15108805894851685,
      "learning_rate": 3.36344327836082e-05,
      "loss": 0.003,
      "step": 13100
    },
    {
      "epoch": 3.285857071464268,
      "grad_norm": 0.7608789205551147,
      "learning_rate": 3.357196401799101e-05,
      "loss": 0.0022,
      "step": 13150
    },
    {
      "epoch": 3.2983508245877062,
      "grad_norm": 0.2338891625404358,
      "learning_rate": 3.3509495252373814e-05,
      "loss": 0.0028,
      "step": 13200
    },
    {
      "epoch": 3.3108445777111446,
      "grad_norm": 0.4370156526565552,
      "learning_rate": 3.344702648675662e-05,
      "loss": 0.01,
      "step": 13250
    },
    {
      "epoch": 3.3233383308345825,
      "grad_norm": 0.5858136415481567,
      "learning_rate": 3.338455772113943e-05,
      "loss": 0.0019,
      "step": 13300
    },
    {
      "epoch": 3.335832083958021,
      "grad_norm": 0.4819238781929016,
      "learning_rate": 3.332208895552224e-05,
      "loss": 0.0025,
      "step": 13350
    },
    {
      "epoch": 3.3483258370814593,
      "grad_norm": 0.0868532732129097,
      "learning_rate": 3.325962018990505e-05,
      "loss": 0.002,
      "step": 13400
    },
    {
      "epoch": 3.3608195902048976,
      "grad_norm": 0.6253899335861206,
      "learning_rate": 3.319715142428786e-05,
      "loss": 0.0021,
      "step": 13450
    },
    {
      "epoch": 3.373313343328336,
      "grad_norm": 0.2539798617362976,
      "learning_rate": 3.3134682658670666e-05,
      "loss": 0.0027,
      "step": 13500
    },
    {
      "epoch": 3.3858070964517744,
      "grad_norm": 0.3498704135417938,
      "learning_rate": 3.3072213893053474e-05,
      "loss": 0.0023,
      "step": 13550
    },
    {
      "epoch": 3.3983008495752123,
      "grad_norm": 2.477801561355591,
      "learning_rate": 3.300974512743628e-05,
      "loss": 0.004,
      "step": 13600
    },
    {
      "epoch": 3.4107946026986506,
      "grad_norm": 0.5063374638557434,
      "learning_rate": 3.294727636181909e-05,
      "loss": 0.0033,
      "step": 13650
    },
    {
      "epoch": 3.423288355822089,
      "grad_norm": 0.3279203772544861,
      "learning_rate": 3.28848075962019e-05,
      "loss": 0.0024,
      "step": 13700
    },
    {
      "epoch": 3.4357821089455274,
      "grad_norm": 0.2980031669139862,
      "learning_rate": 3.282233883058471e-05,
      "loss": 0.0022,
      "step": 13750
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 0.4501500427722931,
      "learning_rate": 3.275987006496752e-05,
      "loss": 0.0029,
      "step": 13800
    },
    {
      "epoch": 3.4607696151924037,
      "grad_norm": 0.6928590536117554,
      "learning_rate": 3.2697401299350326e-05,
      "loss": 0.0015,
      "step": 13850
    },
    {
      "epoch": 3.473263368315842,
      "grad_norm": 1.161917805671692,
      "learning_rate": 3.2634932533733135e-05,
      "loss": 0.0026,
      "step": 13900
    },
    {
      "epoch": 3.4857571214392804,
      "grad_norm": 0.679386556148529,
      "learning_rate": 3.2572463768115944e-05,
      "loss": 0.0034,
      "step": 13950
    },
    {
      "epoch": 3.4982508745627188,
      "grad_norm": 0.41419926285743713,
      "learning_rate": 3.250999500249875e-05,
      "loss": 0.0128,
      "step": 14000
    },
    {
      "epoch": 3.510744627686157,
      "grad_norm": 0.524882972240448,
      "learning_rate": 3.244752623688156e-05,
      "loss": 0.0021,
      "step": 14050
    },
    {
      "epoch": 3.523238380809595,
      "grad_norm": 0.14199236035346985,
      "learning_rate": 3.238505747126437e-05,
      "loss": 0.0027,
      "step": 14100
    },
    {
      "epoch": 3.5357321339330334,
      "grad_norm": 0.299393892288208,
      "learning_rate": 3.232258870564718e-05,
      "loss": 0.0107,
      "step": 14150
    },
    {
      "epoch": 3.548225887056472,
      "grad_norm": 0.0437539704144001,
      "learning_rate": 3.226011994002999e-05,
      "loss": 0.0103,
      "step": 14200
    },
    {
      "epoch": 3.56071964017991,
      "grad_norm": 0.5321473479270935,
      "learning_rate": 3.2197651174412796e-05,
      "loss": 0.003,
      "step": 14250
    },
    {
      "epoch": 3.573213393303348,
      "grad_norm": 0.26747825741767883,
      "learning_rate": 3.2135182408795604e-05,
      "loss": 0.002,
      "step": 14300
    },
    {
      "epoch": 3.5857071464267865,
      "grad_norm": 0.5776614546775818,
      "learning_rate": 3.207271364317841e-05,
      "loss": 0.0031,
      "step": 14350
    },
    {
      "epoch": 3.598200899550225,
      "grad_norm": 0.39348384737968445,
      "learning_rate": 3.201024487756122e-05,
      "loss": 0.0018,
      "step": 14400
    },
    {
      "epoch": 3.610694652673663,
      "grad_norm": 0.12610599398612976,
      "learning_rate": 3.194777611194403e-05,
      "loss": 0.011,
      "step": 14450
    },
    {
      "epoch": 3.6231884057971016,
      "grad_norm": 0.9272701740264893,
      "learning_rate": 3.188530734632684e-05,
      "loss": 0.0015,
      "step": 14500
    },
    {
      "epoch": 3.63568215892054,
      "grad_norm": 0.13367848098278046,
      "learning_rate": 3.182283858070965e-05,
      "loss": 0.0021,
      "step": 14550
    },
    {
      "epoch": 3.6481759120439783,
      "grad_norm": 0.48706015944480896,
      "learning_rate": 3.1760369815092457e-05,
      "loss": 0.0018,
      "step": 14600
    },
    {
      "epoch": 3.660669665167416,
      "grad_norm": 0.17238329350948334,
      "learning_rate": 3.1697901049475265e-05,
      "loss": 0.0133,
      "step": 14650
    },
    {
      "epoch": 3.6731634182908546,
      "grad_norm": 0.8406168818473816,
      "learning_rate": 3.1635432283858074e-05,
      "loss": 0.0027,
      "step": 14700
    },
    {
      "epoch": 3.685657171414293,
      "grad_norm": 0.3795815706253052,
      "learning_rate": 3.157296351824088e-05,
      "loss": 0.0113,
      "step": 14750
    },
    {
      "epoch": 3.698150924537731,
      "grad_norm": 0.8469248414039612,
      "learning_rate": 3.1510494752623684e-05,
      "loss": 0.002,
      "step": 14800
    },
    {
      "epoch": 3.7106446776611692,
      "grad_norm": 0.9731367230415344,
      "learning_rate": 3.144802598700649e-05,
      "loss": 0.0024,
      "step": 14850
    },
    {
      "epoch": 3.7231384307846076,
      "grad_norm": 0.4709452986717224,
      "learning_rate": 3.138555722138931e-05,
      "loss": 0.0017,
      "step": 14900
    },
    {
      "epoch": 3.735632183908046,
      "grad_norm": 0.7688578963279724,
      "learning_rate": 3.132308845577212e-05,
      "loss": 0.0022,
      "step": 14950
    },
    {
      "epoch": 3.7481259370314843,
      "grad_norm": 0.7015954852104187,
      "learning_rate": 3.1260619690154926e-05,
      "loss": 0.0017,
      "step": 15000
    },
    {
      "epoch": 3.7606196901549227,
      "grad_norm": 0.6097835898399353,
      "learning_rate": 3.1198150924537735e-05,
      "loss": 0.0024,
      "step": 15050
    },
    {
      "epoch": 3.773113443278361,
      "grad_norm": 1.0533638000488281,
      "learning_rate": 3.113568215892054e-05,
      "loss": 0.0025,
      "step": 15100
    },
    {
      "epoch": 3.785607196401799,
      "grad_norm": 0.5615659356117249,
      "learning_rate": 3.107321339330335e-05,
      "loss": 0.0021,
      "step": 15150
    },
    {
      "epoch": 3.7981009495252374,
      "grad_norm": 0.2950117886066437,
      "learning_rate": 3.1010744627686154e-05,
      "loss": 0.0103,
      "step": 15200
    },
    {
      "epoch": 3.8105947026486757,
      "grad_norm": 0.2502337098121643,
      "learning_rate": 3.094827586206896e-05,
      "loss": 0.0013,
      "step": 15250
    },
    {
      "epoch": 3.823088455772114,
      "grad_norm": 0.36405298113822937,
      "learning_rate": 3.088580709645177e-05,
      "loss": 0.0013,
      "step": 15300
    },
    {
      "epoch": 3.835582208895552,
      "grad_norm": 0.3957786560058594,
      "learning_rate": 3.082333833083459e-05,
      "loss": 0.0021,
      "step": 15350
    },
    {
      "epoch": 3.8480759620189904,
      "grad_norm": 0.2548372149467468,
      "learning_rate": 3.0760869565217395e-05,
      "loss": 0.0021,
      "step": 15400
    },
    {
      "epoch": 3.8605697151424287,
      "grad_norm": 0.15733788907527924,
      "learning_rate": 3.0698400799600204e-05,
      "loss": 0.0013,
      "step": 15450
    },
    {
      "epoch": 3.873063468265867,
      "grad_norm": 0.4386509358882904,
      "learning_rate": 3.063593203398301e-05,
      "loss": 0.0111,
      "step": 15500
    },
    {
      "epoch": 3.8855572213893055,
      "grad_norm": 0.599073588848114,
      "learning_rate": 3.057346326836582e-05,
      "loss": 0.0113,
      "step": 15550
    },
    {
      "epoch": 3.898050974512744,
      "grad_norm": 0.27499502897262573,
      "learning_rate": 3.051099450274863e-05,
      "loss": 0.0019,
      "step": 15600
    },
    {
      "epoch": 3.9105447276361818,
      "grad_norm": 0.38619428873062134,
      "learning_rate": 3.0448525737131432e-05,
      "loss": 0.0114,
      "step": 15650
    },
    {
      "epoch": 3.92303848075962,
      "grad_norm": 0.2885243892669678,
      "learning_rate": 3.0386056971514244e-05,
      "loss": 0.0023,
      "step": 15700
    },
    {
      "epoch": 3.9355322338830585,
      "grad_norm": 0.21494556963443756,
      "learning_rate": 3.0323588205897053e-05,
      "loss": 0.0016,
      "step": 15750
    },
    {
      "epoch": 3.948025987006497,
      "grad_norm": 0.4693526029586792,
      "learning_rate": 3.026111944027986e-05,
      "loss": 0.0019,
      "step": 15800
    },
    {
      "epoch": 3.960519740129935,
      "grad_norm": 0.16594626009464264,
      "learning_rate": 3.019865067466267e-05,
      "loss": 0.0116,
      "step": 15850
    },
    {
      "epoch": 3.973013493253373,
      "grad_norm": 0.2951127886772156,
      "learning_rate": 3.013618190904548e-05,
      "loss": 0.0015,
      "step": 15900
    },
    {
      "epoch": 3.9855072463768115,
      "grad_norm": 1.278440237045288,
      "learning_rate": 3.007371314342829e-05,
      "loss": 0.002,
      "step": 15950
    },
    {
      "epoch": 3.99800099950025,
      "grad_norm": 0.6301234364509583,
      "learning_rate": 3.00112443778111e-05,
      "loss": 0.0017,
      "step": 16000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.0024966264609247446,
      "eval_runtime": 2.7241,
      "eval_samples_per_second": 591.019,
      "eval_steps_per_second": 74.153,
      "step": 16008
    },
    {
      "epoch": 4.010494752623688,
      "grad_norm": 0.5052827596664429,
      "learning_rate": 2.99487756121939e-05,
      "loss": 0.0028,
      "step": 16050
    },
    {
      "epoch": 4.022988505747127,
      "grad_norm": 0.3450659513473511,
      "learning_rate": 2.988630684657671e-05,
      "loss": 0.0014,
      "step": 16100
    },
    {
      "epoch": 4.035482258870565,
      "grad_norm": 0.3728630542755127,
      "learning_rate": 2.9823838080959522e-05,
      "loss": 0.0018,
      "step": 16150
    },
    {
      "epoch": 4.047976011994003,
      "grad_norm": 0.3939385712146759,
      "learning_rate": 2.976136931534233e-05,
      "loss": 0.002,
      "step": 16200
    },
    {
      "epoch": 4.060469765117441,
      "grad_norm": 0.2719709873199463,
      "learning_rate": 2.969890054972514e-05,
      "loss": 0.0014,
      "step": 16250
    },
    {
      "epoch": 4.072963518240879,
      "grad_norm": 0.7116342186927795,
      "learning_rate": 2.9636431784107948e-05,
      "loss": 0.0027,
      "step": 16300
    },
    {
      "epoch": 4.085457271364318,
      "grad_norm": 0.26004984974861145,
      "learning_rate": 2.9573963018490757e-05,
      "loss": 0.0018,
      "step": 16350
    },
    {
      "epoch": 4.097951024487756,
      "grad_norm": 0.46501269936561584,
      "learning_rate": 2.9511494252873566e-05,
      "loss": 0.0018,
      "step": 16400
    },
    {
      "epoch": 4.110444777611194,
      "grad_norm": 0.5929214358329773,
      "learning_rate": 2.944902548725637e-05,
      "loss": 0.0017,
      "step": 16450
    },
    {
      "epoch": 4.122938530734633,
      "grad_norm": 0.1875474750995636,
      "learning_rate": 2.938655672163918e-05,
      "loss": 0.0015,
      "step": 16500
    },
    {
      "epoch": 4.135432283858071,
      "grad_norm": 0.5249295830726624,
      "learning_rate": 2.9324087956021988e-05,
      "loss": 0.0022,
      "step": 16550
    },
    {
      "epoch": 4.147926036981509,
      "grad_norm": 0.2427499145269394,
      "learning_rate": 2.92616191904048e-05,
      "loss": 0.002,
      "step": 16600
    },
    {
      "epoch": 4.160419790104948,
      "grad_norm": 0.4877086579799652,
      "learning_rate": 2.919915042478761e-05,
      "loss": 0.0013,
      "step": 16650
    },
    {
      "epoch": 4.172913543228386,
      "grad_norm": 0.3108214735984802,
      "learning_rate": 2.9136681659170418e-05,
      "loss": 0.0106,
      "step": 16700
    },
    {
      "epoch": 4.1854072963518245,
      "grad_norm": 0.18443864583969116,
      "learning_rate": 2.9074212893553226e-05,
      "loss": 0.0019,
      "step": 16750
    },
    {
      "epoch": 4.197901049475262,
      "grad_norm": 1.2259173393249512,
      "learning_rate": 2.9011744127936035e-05,
      "loss": 0.0021,
      "step": 16800
    },
    {
      "epoch": 4.2103948025987,
      "grad_norm": 0.8625140190124512,
      "learning_rate": 2.894927536231884e-05,
      "loss": 0.0012,
      "step": 16850
    },
    {
      "epoch": 4.222888555722139,
      "grad_norm": 0.3133280277252197,
      "learning_rate": 2.888680659670165e-05,
      "loss": 0.0016,
      "step": 16900
    },
    {
      "epoch": 4.235382308845577,
      "grad_norm": 0.66065913438797,
      "learning_rate": 2.8824337831084458e-05,
      "loss": 0.0025,
      "step": 16950
    },
    {
      "epoch": 4.2478760619690155,
      "grad_norm": 1.2794867753982544,
      "learning_rate": 2.8761869065467266e-05,
      "loss": 0.0019,
      "step": 17000
    },
    {
      "epoch": 4.260369815092454,
      "grad_norm": 0.34562385082244873,
      "learning_rate": 2.8699400299850075e-05,
      "loss": 0.0012,
      "step": 17050
    },
    {
      "epoch": 4.272863568215892,
      "grad_norm": 0.9638125896453857,
      "learning_rate": 2.8636931534232887e-05,
      "loss": 0.0019,
      "step": 17100
    },
    {
      "epoch": 4.285357321339331,
      "grad_norm": 0.2800893485546112,
      "learning_rate": 2.8574462768615696e-05,
      "loss": 0.0022,
      "step": 17150
    },
    {
      "epoch": 4.297851074462769,
      "grad_norm": 0.20424026250839233,
      "learning_rate": 2.8511994002998504e-05,
      "loss": 0.0106,
      "step": 17200
    },
    {
      "epoch": 4.310344827586207,
      "grad_norm": 0.4874563217163086,
      "learning_rate": 2.844952523738131e-05,
      "loss": 0.0102,
      "step": 17250
    },
    {
      "epoch": 4.322838580709645,
      "grad_norm": 0.287539005279541,
      "learning_rate": 2.838705647176412e-05,
      "loss": 0.0016,
      "step": 17300
    },
    {
      "epoch": 4.335332333833083,
      "grad_norm": 0.6066880822181702,
      "learning_rate": 2.8324587706146927e-05,
      "loss": 0.0016,
      "step": 17350
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.2903725504875183,
      "learning_rate": 2.8262118940529736e-05,
      "loss": 0.0021,
      "step": 17400
    },
    {
      "epoch": 4.36031984007996,
      "grad_norm": 0.2695006728172302,
      "learning_rate": 2.8199650174912544e-05,
      "loss": 0.0012,
      "step": 17450
    },
    {
      "epoch": 4.372813593203398,
      "grad_norm": 0.38602471351623535,
      "learning_rate": 2.8137181409295353e-05,
      "loss": 0.0015,
      "step": 17500
    },
    {
      "epoch": 4.385307346326837,
      "grad_norm": 0.30058553814888,
      "learning_rate": 2.8074712643678165e-05,
      "loss": 0.002,
      "step": 17550
    },
    {
      "epoch": 4.397801099450275,
      "grad_norm": 0.38388895988464355,
      "learning_rate": 2.8012243878060974e-05,
      "loss": 0.0018,
      "step": 17600
    },
    {
      "epoch": 4.410294852573713,
      "grad_norm": 0.23858259618282318,
      "learning_rate": 2.7949775112443776e-05,
      "loss": 0.002,
      "step": 17650
    },
    {
      "epoch": 4.422788605697152,
      "grad_norm": 0.5633940100669861,
      "learning_rate": 2.7887306346826584e-05,
      "loss": 0.0024,
      "step": 17700
    },
    {
      "epoch": 4.43528235882059,
      "grad_norm": 0.6825752854347229,
      "learning_rate": 2.7824837581209397e-05,
      "loss": 0.0027,
      "step": 17750
    },
    {
      "epoch": 4.447776111944028,
      "grad_norm": 0.7364340424537659,
      "learning_rate": 2.7762368815592205e-05,
      "loss": 0.0014,
      "step": 17800
    },
    {
      "epoch": 4.460269865067466,
      "grad_norm": 0.27846992015838623,
      "learning_rate": 2.7699900049975014e-05,
      "loss": 0.0023,
      "step": 17850
    },
    {
      "epoch": 4.472763618190904,
      "grad_norm": 0.4251120686531067,
      "learning_rate": 2.7637431284357823e-05,
      "loss": 0.0099,
      "step": 17900
    },
    {
      "epoch": 4.485257371314343,
      "grad_norm": 0.5546542406082153,
      "learning_rate": 2.757496251874063e-05,
      "loss": 0.0014,
      "step": 17950
    },
    {
      "epoch": 4.497751124437781,
      "grad_norm": 0.34240052103996277,
      "learning_rate": 2.7512493753123443e-05,
      "loss": 0.0113,
      "step": 18000
    },
    {
      "epoch": 4.510244877561219,
      "grad_norm": 0.4894225597381592,
      "learning_rate": 2.7450024987506252e-05,
      "loss": 0.0023,
      "step": 18050
    },
    {
      "epoch": 4.522738630684658,
      "grad_norm": 2.71199631690979,
      "learning_rate": 2.7387556221889054e-05,
      "loss": 0.0021,
      "step": 18100
    },
    {
      "epoch": 4.535232383808096,
      "grad_norm": 0.5510482788085938,
      "learning_rate": 2.7325087456271863e-05,
      "loss": 0.002,
      "step": 18150
    },
    {
      "epoch": 4.5477261369315345,
      "grad_norm": 0.40524131059646606,
      "learning_rate": 2.7262618690654675e-05,
      "loss": 0.0014,
      "step": 18200
    },
    {
      "epoch": 4.560219890054973,
      "grad_norm": 0.21142686903476715,
      "learning_rate": 2.7200149925037483e-05,
      "loss": 0.0014,
      "step": 18250
    },
    {
      "epoch": 4.57271364317841,
      "grad_norm": 0.2195136547088623,
      "learning_rate": 2.7137681159420292e-05,
      "loss": 0.0015,
      "step": 18300
    },
    {
      "epoch": 4.585207396301849,
      "grad_norm": 0.32127535343170166,
      "learning_rate": 2.70752123938031e-05,
      "loss": 0.0113,
      "step": 18350
    },
    {
      "epoch": 4.597701149425287,
      "grad_norm": 0.8309571146965027,
      "learning_rate": 2.701274362818591e-05,
      "loss": 0.0017,
      "step": 18400
    },
    {
      "epoch": 4.610194902548725,
      "grad_norm": 0.7242892980575562,
      "learning_rate": 2.6950274862568718e-05,
      "loss": 0.0015,
      "step": 18450
    },
    {
      "epoch": 4.622688655672164,
      "grad_norm": 0.44163885712623596,
      "learning_rate": 2.6887806096951523e-05,
      "loss": 0.0013,
      "step": 18500
    },
    {
      "epoch": 4.635182408795602,
      "grad_norm": 0.39178308844566345,
      "learning_rate": 2.6825337331334332e-05,
      "loss": 0.0035,
      "step": 18550
    },
    {
      "epoch": 4.6476761619190405,
      "grad_norm": 0.22831299901008606,
      "learning_rate": 2.676286856571714e-05,
      "loss": 0.0026,
      "step": 18600
    },
    {
      "epoch": 4.660169915042479,
      "grad_norm": 0.2898932099342346,
      "learning_rate": 2.6700399800099953e-05,
      "loss": 0.0024,
      "step": 18650
    },
    {
      "epoch": 4.672663668165917,
      "grad_norm": 0.4085114598274231,
      "learning_rate": 2.663793103448276e-05,
      "loss": 0.0019,
      "step": 18700
    },
    {
      "epoch": 4.685157421289356,
      "grad_norm": 0.1920028030872345,
      "learning_rate": 2.657546226886557e-05,
      "loss": 0.0014,
      "step": 18750
    },
    {
      "epoch": 4.697651174412794,
      "grad_norm": 0.5452795028686523,
      "learning_rate": 2.651299350324838e-05,
      "loss": 0.0015,
      "step": 18800
    },
    {
      "epoch": 4.710144927536232,
      "grad_norm": 0.19912225008010864,
      "learning_rate": 2.6450524737631187e-05,
      "loss": 0.0101,
      "step": 18850
    },
    {
      "epoch": 4.72263868065967,
      "grad_norm": 0.5033826231956482,
      "learning_rate": 2.6388055972013993e-05,
      "loss": 0.0018,
      "step": 18900
    },
    {
      "epoch": 4.735132433783108,
      "grad_norm": 0.3203108608722687,
      "learning_rate": 2.63255872063968e-05,
      "loss": 0.0201,
      "step": 18950
    },
    {
      "epoch": 4.747626186906547,
      "grad_norm": 0.5692335963249207,
      "learning_rate": 2.626311844077961e-05,
      "loss": 0.0022,
      "step": 19000
    },
    {
      "epoch": 4.760119940029985,
      "grad_norm": 0.35018783807754517,
      "learning_rate": 2.620064967516242e-05,
      "loss": 0.0025,
      "step": 19050
    },
    {
      "epoch": 4.772613693153423,
      "grad_norm": 0.22160010039806366,
      "learning_rate": 2.6138180909545227e-05,
      "loss": 0.0012,
      "step": 19100
    },
    {
      "epoch": 4.785107446276862,
      "grad_norm": 0.22507344186306,
      "learning_rate": 2.607571214392804e-05,
      "loss": 0.0021,
      "step": 19150
    },
    {
      "epoch": 4.7976011994003,
      "grad_norm": 0.7649863362312317,
      "learning_rate": 2.6013243378310848e-05,
      "loss": 0.0021,
      "step": 19200
    },
    {
      "epoch": 4.810094952523738,
      "grad_norm": 0.19663105905056,
      "learning_rate": 2.5950774612693657e-05,
      "loss": 0.0015,
      "step": 19250
    },
    {
      "epoch": 4.822588705647177,
      "grad_norm": 0.4171246290206909,
      "learning_rate": 2.5888305847076462e-05,
      "loss": 0.0099,
      "step": 19300
    },
    {
      "epoch": 4.835082458770614,
      "grad_norm": 0.29925796389579773,
      "learning_rate": 2.582583708145927e-05,
      "loss": 0.0022,
      "step": 19350
    },
    {
      "epoch": 4.847576211894053,
      "grad_norm": 0.26340100169181824,
      "learning_rate": 2.576336831584208e-05,
      "loss": 0.0107,
      "step": 19400
    },
    {
      "epoch": 4.860069965017491,
      "grad_norm": 0.21757081151008606,
      "learning_rate": 2.5700899550224888e-05,
      "loss": 0.0024,
      "step": 19450
    },
    {
      "epoch": 4.872563718140929,
      "grad_norm": 0.14723917841911316,
      "learning_rate": 2.5638430784607697e-05,
      "loss": 0.0017,
      "step": 19500
    },
    {
      "epoch": 4.885057471264368,
      "grad_norm": 0.32621631026268005,
      "learning_rate": 2.5575962018990506e-05,
      "loss": 0.0026,
      "step": 19550
    },
    {
      "epoch": 4.897551224387806,
      "grad_norm": 0.4668833315372467,
      "learning_rate": 2.5513493253373318e-05,
      "loss": 0.0023,
      "step": 19600
    },
    {
      "epoch": 4.9100449775112445,
      "grad_norm": 0.6068122386932373,
      "learning_rate": 2.5451024487756126e-05,
      "loss": 0.0015,
      "step": 19650
    },
    {
      "epoch": 4.922538730634683,
      "grad_norm": 0.2293003797531128,
      "learning_rate": 2.5388555722138928e-05,
      "loss": 0.0018,
      "step": 19700
    },
    {
      "epoch": 4.935032483758121,
      "grad_norm": 0.51124107837677,
      "learning_rate": 2.5326086956521737e-05,
      "loss": 0.0014,
      "step": 19750
    },
    {
      "epoch": 4.94752623688156,
      "grad_norm": 0.3080686032772064,
      "learning_rate": 2.526361819090455e-05,
      "loss": 0.0103,
      "step": 19800
    },
    {
      "epoch": 4.960019990004998,
      "grad_norm": 0.29680198431015015,
      "learning_rate": 2.5201149425287358e-05,
      "loss": 0.0014,
      "step": 19850
    },
    {
      "epoch": 4.972513743128435,
      "grad_norm": 0.2434380203485489,
      "learning_rate": 2.5138680659670166e-05,
      "loss": 0.002,
      "step": 19900
    },
    {
      "epoch": 4.985007496251874,
      "grad_norm": 0.34908315539360046,
      "learning_rate": 2.5076211894052975e-05,
      "loss": 0.0016,
      "step": 19950
    },
    {
      "epoch": 4.997501249375312,
      "grad_norm": 0.5679677724838257,
      "learning_rate": 2.5013743128435784e-05,
      "loss": 0.0017,
      "step": 20000
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.0020028071012347937,
      "eval_runtime": 2.6968,
      "eval_samples_per_second": 597.013,
      "eval_steps_per_second": 74.905,
      "step": 20010
    },
    {
      "epoch": 5.0099950024987505,
      "grad_norm": 0.399003803730011,
      "learning_rate": 2.4951274362818592e-05,
      "loss": 0.0015,
      "step": 20050
    },
    {
      "epoch": 5.022488755622189,
      "grad_norm": 0.5182840824127197,
      "learning_rate": 2.48888055972014e-05,
      "loss": 0.0018,
      "step": 20100
    },
    {
      "epoch": 5.034982508745627,
      "grad_norm": 0.84904545545578,
      "learning_rate": 2.482633683158421e-05,
      "loss": 0.0021,
      "step": 20150
    },
    {
      "epoch": 5.047476261869066,
      "grad_norm": 0.27017152309417725,
      "learning_rate": 2.4763868065967015e-05,
      "loss": 0.0015,
      "step": 20200
    },
    {
      "epoch": 5.059970014992504,
      "grad_norm": 0.031115610152482986,
      "learning_rate": 2.4701399300349827e-05,
      "loss": 0.0099,
      "step": 20250
    },
    {
      "epoch": 5.072463768115942,
      "grad_norm": 0.29028192162513733,
      "learning_rate": 2.4638930534732636e-05,
      "loss": 0.0023,
      "step": 20300
    },
    {
      "epoch": 5.084957521239381,
      "grad_norm": 0.532989501953125,
      "learning_rate": 2.4576461769115444e-05,
      "loss": 0.0027,
      "step": 20350
    },
    {
      "epoch": 5.097451274362818,
      "grad_norm": 0.25528043508529663,
      "learning_rate": 2.451399300349825e-05,
      "loss": 0.0019,
      "step": 20400
    },
    {
      "epoch": 5.109945027486257,
      "grad_norm": 0.42430397868156433,
      "learning_rate": 2.445152423788106e-05,
      "loss": 0.0021,
      "step": 20450
    },
    {
      "epoch": 5.122438780609695,
      "grad_norm": 0.22904300689697266,
      "learning_rate": 2.438905547226387e-05,
      "loss": 0.0015,
      "step": 20500
    },
    {
      "epoch": 5.134932533733133,
      "grad_norm": 0.41104695200920105,
      "learning_rate": 2.432658670664668e-05,
      "loss": 0.0013,
      "step": 20550
    },
    {
      "epoch": 5.147426286856572,
      "grad_norm": 0.275129497051239,
      "learning_rate": 2.4264117941029488e-05,
      "loss": 0.002,
      "step": 20600
    },
    {
      "epoch": 5.15992003998001,
      "grad_norm": 0.3669218420982361,
      "learning_rate": 2.4201649175412293e-05,
      "loss": 0.0014,
      "step": 20650
    },
    {
      "epoch": 5.172413793103448,
      "grad_norm": 0.31997475028038025,
      "learning_rate": 2.4139180409795105e-05,
      "loss": 0.002,
      "step": 20700
    },
    {
      "epoch": 5.184907546226887,
      "grad_norm": 0.3412492871284485,
      "learning_rate": 2.4076711644177914e-05,
      "loss": 0.0014,
      "step": 20750
    },
    {
      "epoch": 5.197401299350325,
      "grad_norm": 8.354032516479492,
      "learning_rate": 2.4014242878560723e-05,
      "loss": 0.0094,
      "step": 20800
    },
    {
      "epoch": 5.2098950524737635,
      "grad_norm": 0.19333815574645996,
      "learning_rate": 2.3951774112943528e-05,
      "loss": 0.0102,
      "step": 20850
    },
    {
      "epoch": 5.222388805597201,
      "grad_norm": 2.659928560256958,
      "learning_rate": 2.3889305347326337e-05,
      "loss": 0.0028,
      "step": 20900
    },
    {
      "epoch": 5.234882558720639,
      "grad_norm": 0.5814823508262634,
      "learning_rate": 2.382683658170915e-05,
      "loss": 0.0018,
      "step": 20950
    },
    {
      "epoch": 5.247376311844078,
      "grad_norm": 0.6346009969711304,
      "learning_rate": 2.3764367816091957e-05,
      "loss": 0.0103,
      "step": 21000
    },
    {
      "epoch": 5.259870064967516,
      "grad_norm": 0.281499981880188,
      "learning_rate": 2.3701899050474763e-05,
      "loss": 0.0014,
      "step": 21050
    },
    {
      "epoch": 5.2723638180909544,
      "grad_norm": 1.0000437498092651,
      "learning_rate": 2.363943028485757e-05,
      "loss": 0.0014,
      "step": 21100
    },
    {
      "epoch": 5.284857571214393,
      "grad_norm": 0.49573394656181335,
      "learning_rate": 2.357696151924038e-05,
      "loss": 0.0019,
      "step": 21150
    },
    {
      "epoch": 5.297351324337831,
      "grad_norm": 0.47409170866012573,
      "learning_rate": 2.3514492753623192e-05,
      "loss": 0.0016,
      "step": 21200
    },
    {
      "epoch": 5.3098450774612695,
      "grad_norm": 0.29704713821411133,
      "learning_rate": 2.3452023988005997e-05,
      "loss": 0.0019,
      "step": 21250
    },
    {
      "epoch": 5.322338830584708,
      "grad_norm": 0.8916493654251099,
      "learning_rate": 2.3389555222388806e-05,
      "loss": 0.0014,
      "step": 21300
    },
    {
      "epoch": 5.334832583708146,
      "grad_norm": 0.407839298248291,
      "learning_rate": 2.3327086456771615e-05,
      "loss": 0.0013,
      "step": 21350
    },
    {
      "epoch": 5.347326336831584,
      "grad_norm": 0.19390976428985596,
      "learning_rate": 2.3264617691154427e-05,
      "loss": 0.0017,
      "step": 21400
    },
    {
      "epoch": 5.359820089955022,
      "grad_norm": 0.3510603904724121,
      "learning_rate": 2.3202148925537232e-05,
      "loss": 0.0014,
      "step": 21450
    },
    {
      "epoch": 5.3723138430784605,
      "grad_norm": 0.40977582335472107,
      "learning_rate": 2.313968015992004e-05,
      "loss": 0.0019,
      "step": 21500
    },
    {
      "epoch": 5.384807596201899,
      "grad_norm": 0.9406090378761292,
      "learning_rate": 2.307721139430285e-05,
      "loss": 0.0013,
      "step": 21550
    },
    {
      "epoch": 5.397301349325337,
      "grad_norm": 0.1291268765926361,
      "learning_rate": 2.3014742628685658e-05,
      "loss": 0.0018,
      "step": 21600
    },
    {
      "epoch": 5.409795102448776,
      "grad_norm": 0.9847182631492615,
      "learning_rate": 2.2952273863068467e-05,
      "loss": 0.0018,
      "step": 21650
    },
    {
      "epoch": 5.422288855572214,
      "grad_norm": 0.5266324877738953,
      "learning_rate": 2.2889805097451275e-05,
      "loss": 0.0014,
      "step": 21700
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 0.24849587678909302,
      "learning_rate": 2.2827336331834084e-05,
      "loss": 0.0106,
      "step": 21750
    },
    {
      "epoch": 5.447276361819091,
      "grad_norm": 0.2495851218700409,
      "learning_rate": 2.2764867566216893e-05,
      "loss": 0.0015,
      "step": 21800
    },
    {
      "epoch": 5.459770114942529,
      "grad_norm": 0.5057253241539001,
      "learning_rate": 2.27023988005997e-05,
      "loss": 0.0018,
      "step": 21850
    },
    {
      "epoch": 5.472263868065967,
      "grad_norm": 0.330761194229126,
      "learning_rate": 2.263993003498251e-05,
      "loss": 0.0106,
      "step": 21900
    },
    {
      "epoch": 5.484757621189405,
      "grad_norm": 0.48194488883018494,
      "learning_rate": 2.257746126936532e-05,
      "loss": 0.0015,
      "step": 21950
    },
    {
      "epoch": 5.497251374312843,
      "grad_norm": 1.0455187559127808,
      "learning_rate": 2.2514992503748127e-05,
      "loss": 0.0014,
      "step": 22000
    },
    {
      "epoch": 5.509745127436282,
      "grad_norm": 0.4561727046966553,
      "learning_rate": 2.2452523738130936e-05,
      "loss": 0.002,
      "step": 22050
    },
    {
      "epoch": 5.52223888055972,
      "grad_norm": 0.23690764605998993,
      "learning_rate": 2.2390054972513745e-05,
      "loss": 0.0013,
      "step": 22100
    },
    {
      "epoch": 5.534732633683158,
      "grad_norm": 0.19069123268127441,
      "learning_rate": 2.2327586206896554e-05,
      "loss": 0.0018,
      "step": 22150
    },
    {
      "epoch": 5.547226386806597,
      "grad_norm": 0.1652805656194687,
      "learning_rate": 2.2265117441279362e-05,
      "loss": 0.0015,
      "step": 22200
    },
    {
      "epoch": 5.559720139930035,
      "grad_norm": 0.5528099536895752,
      "learning_rate": 2.2202648675662167e-05,
      "loss": 0.0028,
      "step": 22250
    },
    {
      "epoch": 5.5722138930534735,
      "grad_norm": 0.7103359699249268,
      "learning_rate": 2.214017991004498e-05,
      "loss": 0.0016,
      "step": 22300
    },
    {
      "epoch": 5.584707646176912,
      "grad_norm": 1.148163080215454,
      "learning_rate": 2.2077711144427788e-05,
      "loss": 0.0014,
      "step": 22350
    },
    {
      "epoch": 5.59720139930035,
      "grad_norm": 1.3516203165054321,
      "learning_rate": 2.2015242378810597e-05,
      "loss": 0.0019,
      "step": 22400
    },
    {
      "epoch": 5.609695152423788,
      "grad_norm": 0.35670143365859985,
      "learning_rate": 2.1952773613193402e-05,
      "loss": 0.0023,
      "step": 22450
    },
    {
      "epoch": 5.622188905547226,
      "grad_norm": 0.6354806423187256,
      "learning_rate": 2.189030484757621e-05,
      "loss": 0.0018,
      "step": 22500
    },
    {
      "epoch": 5.634682658670664,
      "grad_norm": 0.298797070980072,
      "learning_rate": 2.1827836081959023e-05,
      "loss": 0.0012,
      "step": 22550
    },
    {
      "epoch": 5.647176411794103,
      "grad_norm": 0.4194019138813019,
      "learning_rate": 2.176536731634183e-05,
      "loss": 0.0014,
      "step": 22600
    },
    {
      "epoch": 5.659670164917541,
      "grad_norm": 0.22380536794662476,
      "learning_rate": 2.1702898550724637e-05,
      "loss": 0.0014,
      "step": 22650
    },
    {
      "epoch": 5.6721639180409795,
      "grad_norm": 0.24309316277503967,
      "learning_rate": 2.1640429785107446e-05,
      "loss": 0.0012,
      "step": 22700
    },
    {
      "epoch": 5.684657671164418,
      "grad_norm": 0.3062015473842621,
      "learning_rate": 2.1577961019490254e-05,
      "loss": 0.0021,
      "step": 22750
    },
    {
      "epoch": 5.697151424287856,
      "grad_norm": 0.36194345355033875,
      "learning_rate": 2.1515492253873066e-05,
      "loss": 0.0026,
      "step": 22800
    },
    {
      "epoch": 5.709645177411295,
      "grad_norm": 0.26367050409317017,
      "learning_rate": 2.145302348825587e-05,
      "loss": 0.0089,
      "step": 22850
    },
    {
      "epoch": 5.722138930534733,
      "grad_norm": 0.8973719477653503,
      "learning_rate": 2.139055472263868e-05,
      "loss": 0.0013,
      "step": 22900
    },
    {
      "epoch": 5.734632683658171,
      "grad_norm": 0.4372415542602539,
      "learning_rate": 2.132808595702149e-05,
      "loss": 0.0013,
      "step": 22950
    },
    {
      "epoch": 5.747126436781609,
      "grad_norm": 0.2578306794166565,
      "learning_rate": 2.12656171914043e-05,
      "loss": 0.0098,
      "step": 23000
    },
    {
      "epoch": 5.759620189905047,
      "grad_norm": 0.8562420010566711,
      "learning_rate": 2.120314842578711e-05,
      "loss": 0.0023,
      "step": 23050
    },
    {
      "epoch": 5.772113943028486,
      "grad_norm": 0.47390666604042053,
      "learning_rate": 2.1140679660169915e-05,
      "loss": 0.0008,
      "step": 23100
    },
    {
      "epoch": 5.784607696151924,
      "grad_norm": 0.2877580523490906,
      "learning_rate": 2.1078210894552724e-05,
      "loss": 0.0011,
      "step": 23150
    },
    {
      "epoch": 5.797101449275362,
      "grad_norm": 0.8124470710754395,
      "learning_rate": 2.1015742128935532e-05,
      "loss": 0.0019,
      "step": 23200
    },
    {
      "epoch": 5.809595202398801,
      "grad_norm": 0.14234979450702667,
      "learning_rate": 2.0953273363318344e-05,
      "loss": 0.0012,
      "step": 23250
    },
    {
      "epoch": 5.822088955522239,
      "grad_norm": 0.2606046795845032,
      "learning_rate": 2.089080459770115e-05,
      "loss": 0.0103,
      "step": 23300
    },
    {
      "epoch": 5.834582708645677,
      "grad_norm": 0.4536517858505249,
      "learning_rate": 2.082833583208396e-05,
      "loss": 0.0023,
      "step": 23350
    },
    {
      "epoch": 5.847076461769116,
      "grad_norm": 0.36557677388191223,
      "learning_rate": 2.0765867066466767e-05,
      "loss": 0.0097,
      "step": 23400
    },
    {
      "epoch": 5.859570214892553,
      "grad_norm": 0.35073161125183105,
      "learning_rate": 2.0703398300849576e-05,
      "loss": 0.0097,
      "step": 23450
    },
    {
      "epoch": 5.872063968015992,
      "grad_norm": 1.212505578994751,
      "learning_rate": 2.0640929535232384e-05,
      "loss": 0.01,
      "step": 23500
    },
    {
      "epoch": 5.88455772113943,
      "grad_norm": 0.33884158730506897,
      "learning_rate": 2.0578460769615193e-05,
      "loss": 0.0011,
      "step": 23550
    },
    {
      "epoch": 5.897051474262868,
      "grad_norm": 0.7134022116661072,
      "learning_rate": 2.0515992003998002e-05,
      "loss": 0.0023,
      "step": 23600
    },
    {
      "epoch": 5.909545227386307,
      "grad_norm": 0.18816450238227844,
      "learning_rate": 2.045352323838081e-05,
      "loss": 0.0022,
      "step": 23650
    },
    {
      "epoch": 5.922038980509745,
      "grad_norm": 0.4975634515285492,
      "learning_rate": 2.039105447276362e-05,
      "loss": 0.0011,
      "step": 23700
    },
    {
      "epoch": 5.9345327336331835,
      "grad_norm": 0.562977135181427,
      "learning_rate": 2.0328585707146428e-05,
      "loss": 0.0027,
      "step": 23750
    },
    {
      "epoch": 5.947026486756622,
      "grad_norm": 0.429979145526886,
      "learning_rate": 2.0266116941529237e-05,
      "loss": 0.0015,
      "step": 23800
    },
    {
      "epoch": 5.95952023988006,
      "grad_norm": 0.2938435971736908,
      "learning_rate": 2.0203648175912045e-05,
      "loss": 0.0012,
      "step": 23850
    },
    {
      "epoch": 5.9720139930034986,
      "grad_norm": 0.32877930998802185,
      "learning_rate": 2.0141179410294854e-05,
      "loss": 0.0015,
      "step": 23900
    },
    {
      "epoch": 5.984507746126937,
      "grad_norm": 0.5389281511306763,
      "learning_rate": 2.0078710644677663e-05,
      "loss": 0.0017,
      "step": 23950
    },
    {
      "epoch": 5.997001499250375,
      "grad_norm": 0.20475345849990845,
      "learning_rate": 2.001624187906047e-05,
      "loss": 0.001,
      "step": 24000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.002123897895216942,
      "eval_runtime": 2.715,
      "eval_samples_per_second": 593.003,
      "eval_steps_per_second": 74.402,
      "step": 24012
    },
    {
      "epoch": 6.009495252373813,
      "grad_norm": 0.7242446541786194,
      "learning_rate": 1.995377311344328e-05,
      "loss": 0.0012,
      "step": 24050
    },
    {
      "epoch": 6.021989005497251,
      "grad_norm": 0.37561044096946716,
      "learning_rate": 1.9891304347826085e-05,
      "loss": 0.0019,
      "step": 24100
    },
    {
      "epoch": 6.0344827586206895,
      "grad_norm": 0.3947286307811737,
      "learning_rate": 1.9828835582208897e-05,
      "loss": 0.0013,
      "step": 24150
    },
    {
      "epoch": 6.046976511744128,
      "grad_norm": 0.323178768157959,
      "learning_rate": 1.9766366816591706e-05,
      "loss": 0.001,
      "step": 24200
    },
    {
      "epoch": 6.059470264867566,
      "grad_norm": 0.381226509809494,
      "learning_rate": 1.9703898050974515e-05,
      "loss": 0.0099,
      "step": 24250
    },
    {
      "epoch": 6.071964017991005,
      "grad_norm": 0.2593080401420593,
      "learning_rate": 1.964142928535732e-05,
      "loss": 0.0098,
      "step": 24300
    },
    {
      "epoch": 6.084457771114443,
      "grad_norm": 0.45071324706077576,
      "learning_rate": 1.9578960519740132e-05,
      "loss": 0.0011,
      "step": 24350
    },
    {
      "epoch": 6.096951524237881,
      "grad_norm": 0.728313684463501,
      "learning_rate": 1.951649175412294e-05,
      "loss": 0.0011,
      "step": 24400
    },
    {
      "epoch": 6.10944527736132,
      "grad_norm": 0.4066174328327179,
      "learning_rate": 1.945402298850575e-05,
      "loss": 0.0013,
      "step": 24450
    },
    {
      "epoch": 6.121939030484757,
      "grad_norm": 0.26154279708862305,
      "learning_rate": 1.9391554222888555e-05,
      "loss": 0.0012,
      "step": 24500
    },
    {
      "epoch": 6.1344327836081955,
      "grad_norm": 1.4961906671524048,
      "learning_rate": 1.9329085457271363e-05,
      "loss": 0.0015,
      "step": 24550
    },
    {
      "epoch": 6.146926536731634,
      "grad_norm": 0.6279833316802979,
      "learning_rate": 1.9266616691654175e-05,
      "loss": 0.0021,
      "step": 24600
    },
    {
      "epoch": 6.159420289855072,
      "grad_norm": 0.40069741010665894,
      "learning_rate": 1.9204147926036984e-05,
      "loss": 0.0019,
      "step": 24650
    },
    {
      "epoch": 6.171914042978511,
      "grad_norm": 0.509833812713623,
      "learning_rate": 1.914167916041979e-05,
      "loss": 0.0018,
      "step": 24700
    },
    {
      "epoch": 6.184407796101949,
      "grad_norm": 0.10713343322277069,
      "learning_rate": 1.9079210394802598e-05,
      "loss": 0.0019,
      "step": 24750
    },
    {
      "epoch": 6.196901549225387,
      "grad_norm": 0.291204571723938,
      "learning_rate": 1.9016741629185407e-05,
      "loss": 0.0012,
      "step": 24800
    },
    {
      "epoch": 6.209395302348826,
      "grad_norm": 0.8419649600982666,
      "learning_rate": 1.895427286356822e-05,
      "loss": 0.0017,
      "step": 24850
    },
    {
      "epoch": 6.221889055472264,
      "grad_norm": 0.23377151787281036,
      "learning_rate": 1.8891804097951024e-05,
      "loss": 0.0014,
      "step": 24900
    },
    {
      "epoch": 6.2343828085957025,
      "grad_norm": 0.5859711170196533,
      "learning_rate": 1.8829335332333833e-05,
      "loss": 0.0013,
      "step": 24950
    },
    {
      "epoch": 6.246876561719141,
      "grad_norm": 0.13552595674991608,
      "learning_rate": 1.876686656671664e-05,
      "loss": 0.0019,
      "step": 25000
    },
    {
      "epoch": 6.259370314842578,
      "grad_norm": 0.5303874015808105,
      "learning_rate": 1.8704397801099454e-05,
      "loss": 0.0014,
      "step": 25050
    },
    {
      "epoch": 6.271864067966017,
      "grad_norm": 0.5646317005157471,
      "learning_rate": 1.864192903548226e-05,
      "loss": 0.0094,
      "step": 25100
    },
    {
      "epoch": 6.284357821089455,
      "grad_norm": 0.8798695206642151,
      "learning_rate": 1.8579460269865067e-05,
      "loss": 0.0013,
      "step": 25150
    },
    {
      "epoch": 6.296851574212893,
      "grad_norm": 0.6392255425453186,
      "learning_rate": 1.8516991504247876e-05,
      "loss": 0.0014,
      "step": 25200
    },
    {
      "epoch": 6.309345327336332,
      "grad_norm": 0.2815510630607605,
      "learning_rate": 1.8454522738630685e-05,
      "loss": 0.0015,
      "step": 25250
    },
    {
      "epoch": 6.32183908045977,
      "grad_norm": 0.9147796034812927,
      "learning_rate": 1.8392053973013494e-05,
      "loss": 0.0018,
      "step": 25300
    },
    {
      "epoch": 6.3343328335832085,
      "grad_norm": 0.6522588729858398,
      "learning_rate": 1.8329585207396302e-05,
      "loss": 0.0014,
      "step": 25350
    },
    {
      "epoch": 6.346826586706647,
      "grad_norm": 0.18669196963310242,
      "learning_rate": 1.826711644177911e-05,
      "loss": 0.001,
      "step": 25400
    },
    {
      "epoch": 6.359320339830085,
      "grad_norm": 0.3155614733695984,
      "learning_rate": 1.820464767616192e-05,
      "loss": 0.0013,
      "step": 25450
    },
    {
      "epoch": 6.371814092953524,
      "grad_norm": 0.5199825167655945,
      "learning_rate": 1.8142178910544728e-05,
      "loss": 0.0014,
      "step": 25500
    },
    {
      "epoch": 6.384307846076961,
      "grad_norm": 0.8442807197570801,
      "learning_rate": 1.8079710144927537e-05,
      "loss": 0.0092,
      "step": 25550
    },
    {
      "epoch": 6.3968015992003995,
      "grad_norm": 0.2947741448879242,
      "learning_rate": 1.8017241379310346e-05,
      "loss": 0.0015,
      "step": 25600
    },
    {
      "epoch": 6.409295352323838,
      "grad_norm": 0.32593297958374023,
      "learning_rate": 1.7954772613693154e-05,
      "loss": 0.0013,
      "step": 25650
    },
    {
      "epoch": 6.421789105447276,
      "grad_norm": 0.14991216361522675,
      "learning_rate": 1.7892303848075963e-05,
      "loss": 0.0015,
      "step": 25700
    },
    {
      "epoch": 6.434282858570715,
      "grad_norm": 0.1508404165506363,
      "learning_rate": 1.782983508245877e-05,
      "loss": 0.0012,
      "step": 25750
    },
    {
      "epoch": 6.446776611694153,
      "grad_norm": 0.5064602494239807,
      "learning_rate": 1.776736631684158e-05,
      "loss": 0.0104,
      "step": 25800
    },
    {
      "epoch": 6.459270364817591,
      "grad_norm": 0.4416978657245636,
      "learning_rate": 1.770489755122439e-05,
      "loss": 0.002,
      "step": 25850
    },
    {
      "epoch": 6.47176411794103,
      "grad_norm": 0.9244464039802551,
      "learning_rate": 1.7642428785607198e-05,
      "loss": 0.0016,
      "step": 25900
    },
    {
      "epoch": 6.484257871064468,
      "grad_norm": 0.27588754892349243,
      "learning_rate": 1.7579960019990006e-05,
      "loss": 0.0016,
      "step": 25950
    },
    {
      "epoch": 6.496751624187906,
      "grad_norm": 0.32490912079811096,
      "learning_rate": 1.7517491254372815e-05,
      "loss": 0.0016,
      "step": 26000
    },
    {
      "epoch": 6.509245377311345,
      "grad_norm": 0.33253276348114014,
      "learning_rate": 1.7455022488755624e-05,
      "loss": 0.0017,
      "step": 26050
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.136769637465477,
      "learning_rate": 1.7392553723138432e-05,
      "loss": 0.0009,
      "step": 26100
    },
    {
      "epoch": 6.534232883558221,
      "grad_norm": 0.2623208463191986,
      "learning_rate": 1.7330084957521238e-05,
      "loss": 0.0025,
      "step": 26150
    },
    {
      "epoch": 6.546726636681659,
      "grad_norm": 0.33677464723587036,
      "learning_rate": 1.726761619190405e-05,
      "loss": 0.0015,
      "step": 26200
    },
    {
      "epoch": 6.559220389805097,
      "grad_norm": 0.5816773772239685,
      "learning_rate": 1.720514742628686e-05,
      "loss": 0.0012,
      "step": 26250
    },
    {
      "epoch": 6.571714142928536,
      "grad_norm": 0.28462862968444824,
      "learning_rate": 1.7142678660669667e-05,
      "loss": 0.0018,
      "step": 26300
    },
    {
      "epoch": 6.584207896051974,
      "grad_norm": 0.271314799785614,
      "learning_rate": 1.7080209895052472e-05,
      "loss": 0.0094,
      "step": 26350
    },
    {
      "epoch": 6.5967016491754125,
      "grad_norm": 0.13865871727466583,
      "learning_rate": 1.7017741129435284e-05,
      "loss": 0.0016,
      "step": 26400
    },
    {
      "epoch": 6.609195402298851,
      "grad_norm": 0.16577363014221191,
      "learning_rate": 1.6955272363818093e-05,
      "loss": 0.0013,
      "step": 26450
    },
    {
      "epoch": 6.621689155422289,
      "grad_norm": 0.23191876709461212,
      "learning_rate": 1.6892803598200902e-05,
      "loss": 0.0021,
      "step": 26500
    },
    {
      "epoch": 6.634182908545727,
      "grad_norm": 0.678479790687561,
      "learning_rate": 1.6830334832583707e-05,
      "loss": 0.0014,
      "step": 26550
    },
    {
      "epoch": 6.646676661669165,
      "grad_norm": 0.7463861107826233,
      "learning_rate": 1.6767866066966516e-05,
      "loss": 0.0017,
      "step": 26600
    },
    {
      "epoch": 6.659170414792603,
      "grad_norm": 0.25076404213905334,
      "learning_rate": 1.6705397301349328e-05,
      "loss": 0.002,
      "step": 26650
    },
    {
      "epoch": 6.671664167916042,
      "grad_norm": 0.9079283475875854,
      "learning_rate": 1.6642928535732137e-05,
      "loss": 0.0014,
      "step": 26700
    },
    {
      "epoch": 6.68415792103948,
      "grad_norm": 0.21132631599903107,
      "learning_rate": 1.6580459770114942e-05,
      "loss": 0.0014,
      "step": 26750
    },
    {
      "epoch": 6.6966516741629185,
      "grad_norm": 0.2828294634819031,
      "learning_rate": 1.651799100449775e-05,
      "loss": 0.0018,
      "step": 26800
    },
    {
      "epoch": 6.709145427286357,
      "grad_norm": 0.29625776410102844,
      "learning_rate": 1.645552223888056e-05,
      "loss": 0.0017,
      "step": 26850
    },
    {
      "epoch": 6.721639180409795,
      "grad_norm": 0.20550964772701263,
      "learning_rate": 1.639305347326337e-05,
      "loss": 0.001,
      "step": 26900
    },
    {
      "epoch": 6.734132933533234,
      "grad_norm": 0.3034921884536743,
      "learning_rate": 1.6330584707646177e-05,
      "loss": 0.0012,
      "step": 26950
    },
    {
      "epoch": 6.746626686656672,
      "grad_norm": 0.7928681969642639,
      "learning_rate": 1.6268115942028985e-05,
      "loss": 0.0021,
      "step": 27000
    },
    {
      "epoch": 6.75912043978011,
      "grad_norm": 0.38489845395088196,
      "learning_rate": 1.6205647176411794e-05,
      "loss": 0.0026,
      "step": 27050
    },
    {
      "epoch": 6.771614192903549,
      "grad_norm": 0.3773840665817261,
      "learning_rate": 1.6143178410794606e-05,
      "loss": 0.0013,
      "step": 27100
    },
    {
      "epoch": 6.784107946026986,
      "grad_norm": 0.48764652013778687,
      "learning_rate": 1.608070964517741e-05,
      "loss": 0.0018,
      "step": 27150
    },
    {
      "epoch": 6.796601699150425,
      "grad_norm": 0.9453148245811462,
      "learning_rate": 1.601824087956022e-05,
      "loss": 0.0011,
      "step": 27200
    },
    {
      "epoch": 6.809095452273863,
      "grad_norm": 0.21596576273441315,
      "learning_rate": 1.595577211394303e-05,
      "loss": 0.0013,
      "step": 27250
    },
    {
      "epoch": 6.821589205397301,
      "grad_norm": 0.16214071214199066,
      "learning_rate": 1.5893303348325837e-05,
      "loss": 0.0011,
      "step": 27300
    },
    {
      "epoch": 6.83408295852074,
      "grad_norm": 0.7985557913780212,
      "learning_rate": 1.5830834582708646e-05,
      "loss": 0.0027,
      "step": 27350
    },
    {
      "epoch": 6.846576711644178,
      "grad_norm": 0.3545474708080292,
      "learning_rate": 1.5768365817091455e-05,
      "loss": 0.0094,
      "step": 27400
    },
    {
      "epoch": 6.859070464767616,
      "grad_norm": 0.32259494066238403,
      "learning_rate": 1.5705897051474263e-05,
      "loss": 0.0013,
      "step": 27450
    },
    {
      "epoch": 6.871564217891055,
      "grad_norm": 0.2135905772447586,
      "learning_rate": 1.5643428285857072e-05,
      "loss": 0.0014,
      "step": 27500
    },
    {
      "epoch": 6.884057971014493,
      "grad_norm": 0.36625638604164124,
      "learning_rate": 1.558095952023988e-05,
      "loss": 0.0018,
      "step": 27550
    },
    {
      "epoch": 6.896551724137931,
      "grad_norm": 0.8694561123847961,
      "learning_rate": 1.551849075462269e-05,
      "loss": 0.0022,
      "step": 27600
    },
    {
      "epoch": 6.909045477261369,
      "grad_norm": 0.3174442648887634,
      "learning_rate": 1.5456021989005498e-05,
      "loss": 0.0019,
      "step": 27650
    },
    {
      "epoch": 6.921539230384807,
      "grad_norm": 0.22896669805049896,
      "learning_rate": 1.5393553223388307e-05,
      "loss": 0.0173,
      "step": 27700
    },
    {
      "epoch": 6.934032983508246,
      "grad_norm": 0.29848554730415344,
      "learning_rate": 1.5331084457771115e-05,
      "loss": 0.0093,
      "step": 27750
    },
    {
      "epoch": 6.946526736631684,
      "grad_norm": 0.7093002796173096,
      "learning_rate": 1.5268615692153924e-05,
      "loss": 0.0017,
      "step": 27800
    },
    {
      "epoch": 6.959020489755122,
      "grad_norm": 0.7054869532585144,
      "learning_rate": 1.5206146926536733e-05,
      "loss": 0.0085,
      "step": 27850
    },
    {
      "epoch": 6.971514242878561,
      "grad_norm": 0.33319076895713806,
      "learning_rate": 1.5143678160919541e-05,
      "loss": 0.0088,
      "step": 27900
    },
    {
      "epoch": 6.984007996001999,
      "grad_norm": 0.23646502196788788,
      "learning_rate": 1.508120939530235e-05,
      "loss": 0.0012,
      "step": 27950
    },
    {
      "epoch": 6.9965017491254375,
      "grad_norm": 0.48660808801651,
      "learning_rate": 1.5018740629685157e-05,
      "loss": 0.0011,
      "step": 28000
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.00288850674405694,
      "eval_runtime": 2.7169,
      "eval_samples_per_second": 592.591,
      "eval_steps_per_second": 74.35,
      "step": 28014
    }
  ],
  "logging_steps": 50,
  "max_steps": 40020,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2403222651440936e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
