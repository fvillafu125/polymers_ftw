{
  "best_global_step": 20010,
  "best_metric": 0.0018607978709042072,
  "best_model_checkpoint": "ckpt/neurips.pt/Tc/checkpoint-20010",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 28014,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01249375312343828,
      "grad_norm": 1.9133175611495972,
      "learning_rate": 4.993878060969516e-05,
      "loss": 0.035,
      "step": 50
    },
    {
      "epoch": 0.02498750624687656,
      "grad_norm": 1.933656930923462,
      "learning_rate": 4.987631184407796e-05,
      "loss": 0.037,
      "step": 100
    },
    {
      "epoch": 0.037481259370314844,
      "grad_norm": 1.3932268619537354,
      "learning_rate": 4.981384307846077e-05,
      "loss": 0.0273,
      "step": 150
    },
    {
      "epoch": 0.04997501249375312,
      "grad_norm": 5.764231204986572,
      "learning_rate": 4.975137431284358e-05,
      "loss": 0.0345,
      "step": 200
    },
    {
      "epoch": 0.062468765617191405,
      "grad_norm": 2.9389665126800537,
      "learning_rate": 4.9688905547226386e-05,
      "loss": 0.0289,
      "step": 250
    },
    {
      "epoch": 0.07496251874062969,
      "grad_norm": 6.887885570526123,
      "learning_rate": 4.9626436781609195e-05,
      "loss": 0.0286,
      "step": 300
    },
    {
      "epoch": 0.08745627186406797,
      "grad_norm": 2.2052431106567383,
      "learning_rate": 4.956396801599201e-05,
      "loss": 0.0218,
      "step": 350
    },
    {
      "epoch": 0.09995002498750624,
      "grad_norm": 3.405109405517578,
      "learning_rate": 4.950149925037482e-05,
      "loss": 0.0284,
      "step": 400
    },
    {
      "epoch": 0.11244377811094453,
      "grad_norm": 3.3912148475646973,
      "learning_rate": 4.943903048475763e-05,
      "loss": 0.0223,
      "step": 450
    },
    {
      "epoch": 0.12493753123438281,
      "grad_norm": 2.984694480895996,
      "learning_rate": 4.937656171914043e-05,
      "loss": 0.0195,
      "step": 500
    },
    {
      "epoch": 0.1374312843578211,
      "grad_norm": 2.4279847145080566,
      "learning_rate": 4.931409295352324e-05,
      "loss": 0.0211,
      "step": 550
    },
    {
      "epoch": 0.14992503748125938,
      "grad_norm": 0.9834805130958557,
      "learning_rate": 4.925162418790605e-05,
      "loss": 0.0221,
      "step": 600
    },
    {
      "epoch": 0.16241879060469766,
      "grad_norm": 1.9082144498825073,
      "learning_rate": 4.9189155422288855e-05,
      "loss": 0.021,
      "step": 650
    },
    {
      "epoch": 0.17491254372813594,
      "grad_norm": 3.8997225761413574,
      "learning_rate": 4.9126686656671664e-05,
      "loss": 0.0178,
      "step": 700
    },
    {
      "epoch": 0.1874062968515742,
      "grad_norm": 5.050921440124512,
      "learning_rate": 4.906421789105447e-05,
      "loss": 0.0184,
      "step": 750
    },
    {
      "epoch": 0.19990004997501248,
      "grad_norm": 4.129705905914307,
      "learning_rate": 4.900174912543729e-05,
      "loss": 0.0279,
      "step": 800
    },
    {
      "epoch": 0.21239380309845077,
      "grad_norm": 0.7925758361816406,
      "learning_rate": 4.89392803598201e-05,
      "loss": 0.0155,
      "step": 850
    },
    {
      "epoch": 0.22488755622188905,
      "grad_norm": 2.2642810344696045,
      "learning_rate": 4.88768115942029e-05,
      "loss": 0.0178,
      "step": 900
    },
    {
      "epoch": 0.23738130934532733,
      "grad_norm": 1.5251641273498535,
      "learning_rate": 4.881434282858571e-05,
      "loss": 0.0167,
      "step": 950
    },
    {
      "epoch": 0.24987506246876562,
      "grad_norm": 3.351388931274414,
      "learning_rate": 4.8751874062968516e-05,
      "loss": 0.0286,
      "step": 1000
    },
    {
      "epoch": 0.2623688155922039,
      "grad_norm": 1.7065006494522095,
      "learning_rate": 4.8689405297351325e-05,
      "loss": 0.0177,
      "step": 1050
    },
    {
      "epoch": 0.2748625687156422,
      "grad_norm": 3.2866015434265137,
      "learning_rate": 4.8626936531734134e-05,
      "loss": 0.0199,
      "step": 1100
    },
    {
      "epoch": 0.28735632183908044,
      "grad_norm": 1.0570125579833984,
      "learning_rate": 4.856446776611694e-05,
      "loss": 0.0175,
      "step": 1150
    },
    {
      "epoch": 0.29985007496251875,
      "grad_norm": 1.523733139038086,
      "learning_rate": 4.850199900049975e-05,
      "loss": 0.0163,
      "step": 1200
    },
    {
      "epoch": 0.312343828085957,
      "grad_norm": 2.531222105026245,
      "learning_rate": 4.8439530234882566e-05,
      "loss": 0.0225,
      "step": 1250
    },
    {
      "epoch": 0.3248375812093953,
      "grad_norm": 2.839601516723633,
      "learning_rate": 4.8377061469265375e-05,
      "loss": 0.0183,
      "step": 1300
    },
    {
      "epoch": 0.3373313343328336,
      "grad_norm": 1.389274001121521,
      "learning_rate": 4.831459270364818e-05,
      "loss": 0.0141,
      "step": 1350
    },
    {
      "epoch": 0.3498250874562719,
      "grad_norm": 3.168907642364502,
      "learning_rate": 4.8252123938030986e-05,
      "loss": 0.0253,
      "step": 1400
    },
    {
      "epoch": 0.36231884057971014,
      "grad_norm": 2.415294885635376,
      "learning_rate": 4.8189655172413794e-05,
      "loss": 0.013,
      "step": 1450
    },
    {
      "epoch": 0.3748125937031484,
      "grad_norm": 1.0336939096450806,
      "learning_rate": 4.81271864067966e-05,
      "loss": 0.0335,
      "step": 1500
    },
    {
      "epoch": 0.3873063468265867,
      "grad_norm": 2.70975661277771,
      "learning_rate": 4.806471764117941e-05,
      "loss": 0.0126,
      "step": 1550
    },
    {
      "epoch": 0.39980009995002497,
      "grad_norm": 0.7390902638435364,
      "learning_rate": 4.800224887556222e-05,
      "loss": 0.0126,
      "step": 1600
    },
    {
      "epoch": 0.4122938530734633,
      "grad_norm": 1.2705174684524536,
      "learning_rate": 4.793978010994503e-05,
      "loss": 0.0148,
      "step": 1650
    },
    {
      "epoch": 0.42478760619690153,
      "grad_norm": 2.0221173763275146,
      "learning_rate": 4.787731134432784e-05,
      "loss": 0.0252,
      "step": 1700
    },
    {
      "epoch": 0.43728135932033985,
      "grad_norm": 1.5104533433914185,
      "learning_rate": 4.7814842578710646e-05,
      "loss": 0.0158,
      "step": 1750
    },
    {
      "epoch": 0.4497751124437781,
      "grad_norm": 2.4823830127716064,
      "learning_rate": 4.7752373813093455e-05,
      "loss": 0.0173,
      "step": 1800
    },
    {
      "epoch": 0.4622688655672164,
      "grad_norm": 1.0127735137939453,
      "learning_rate": 4.7689905047476264e-05,
      "loss": 0.0154,
      "step": 1850
    },
    {
      "epoch": 0.47476261869065467,
      "grad_norm": 2.0855603218078613,
      "learning_rate": 4.762743628185907e-05,
      "loss": 0.0129,
      "step": 1900
    },
    {
      "epoch": 0.487256371814093,
      "grad_norm": 2.821049213409424,
      "learning_rate": 4.756496751624188e-05,
      "loss": 0.0146,
      "step": 1950
    },
    {
      "epoch": 0.49975012493753124,
      "grad_norm": 1.3597303628921509,
      "learning_rate": 4.750249875062469e-05,
      "loss": 0.0173,
      "step": 2000
    },
    {
      "epoch": 0.5122438780609695,
      "grad_norm": 2.9448599815368652,
      "learning_rate": 4.74400299850075e-05,
      "loss": 0.0105,
      "step": 2050
    },
    {
      "epoch": 0.5247376311844077,
      "grad_norm": 1.6546869277954102,
      "learning_rate": 4.737756121939031e-05,
      "loss": 0.0108,
      "step": 2100
    },
    {
      "epoch": 0.5372313843078461,
      "grad_norm": 3.674354076385498,
      "learning_rate": 4.7315092453773116e-05,
      "loss": 0.0116,
      "step": 2150
    },
    {
      "epoch": 0.5497251374312844,
      "grad_norm": 0.5594280958175659,
      "learning_rate": 4.7252623688155924e-05,
      "loss": 0.014,
      "step": 2200
    },
    {
      "epoch": 0.5622188905547226,
      "grad_norm": 3.1787941455841064,
      "learning_rate": 4.719015492253873e-05,
      "loss": 0.014,
      "step": 2250
    },
    {
      "epoch": 0.5747126436781609,
      "grad_norm": 2.7477757930755615,
      "learning_rate": 4.712768615692154e-05,
      "loss": 0.012,
      "step": 2300
    },
    {
      "epoch": 0.5872063968015993,
      "grad_norm": 1.4748663902282715,
      "learning_rate": 4.706521739130435e-05,
      "loss": 0.0135,
      "step": 2350
    },
    {
      "epoch": 0.5997001499250375,
      "grad_norm": Infinity,
      "learning_rate": 4.700274862568716e-05,
      "loss": 0.0329,
      "step": 2400
    },
    {
      "epoch": 0.6121939030484758,
      "grad_norm": 0.9019086360931396,
      "learning_rate": 4.694027986006997e-05,
      "loss": 0.0114,
      "step": 2450
    },
    {
      "epoch": 0.624687656171914,
      "grad_norm": 1.1890219449996948,
      "learning_rate": 4.6877811094452777e-05,
      "loss": 0.0131,
      "step": 2500
    },
    {
      "epoch": 0.6371814092953523,
      "grad_norm": 0.8005285263061523,
      "learning_rate": 4.6815342328835585e-05,
      "loss": 0.0093,
      "step": 2550
    },
    {
      "epoch": 0.6496751624187906,
      "grad_norm": 1.1513750553131104,
      "learning_rate": 4.6752873563218394e-05,
      "loss": 0.0148,
      "step": 2600
    },
    {
      "epoch": 0.6621689155422289,
      "grad_norm": 2.326296329498291,
      "learning_rate": 4.66904047976012e-05,
      "loss": 0.0114,
      "step": 2650
    },
    {
      "epoch": 0.6746626686656672,
      "grad_norm": 2.4659652709960938,
      "learning_rate": 4.662793603198401e-05,
      "loss": 0.0088,
      "step": 2700
    },
    {
      "epoch": 0.6871564217891054,
      "grad_norm": 1.1390248537063599,
      "learning_rate": 4.656546726636682e-05,
      "loss": 0.0089,
      "step": 2750
    },
    {
      "epoch": 0.6996501749125438,
      "grad_norm": 2.195314645767212,
      "learning_rate": 4.650299850074963e-05,
      "loss": 0.009,
      "step": 2800
    },
    {
      "epoch": 0.712143928035982,
      "grad_norm": 0.6950820088386536,
      "learning_rate": 4.644052973513244e-05,
      "loss": 0.01,
      "step": 2850
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 1.1514028310775757,
      "learning_rate": 4.6378060969515246e-05,
      "loss": 0.0197,
      "step": 2900
    },
    {
      "epoch": 0.7371314342828585,
      "grad_norm": 1.7703018188476562,
      "learning_rate": 4.631559220389805e-05,
      "loss": 0.0071,
      "step": 2950
    },
    {
      "epoch": 0.7496251874062968,
      "grad_norm": 0.5157099366188049,
      "learning_rate": 4.6253123438280857e-05,
      "loss": 0.0132,
      "step": 3000
    },
    {
      "epoch": 0.7621189405297352,
      "grad_norm": 0.6826083660125732,
      "learning_rate": 4.619065467266367e-05,
      "loss": 0.0082,
      "step": 3050
    },
    {
      "epoch": 0.7746126936531734,
      "grad_norm": 1.278374195098877,
      "learning_rate": 4.612818590704648e-05,
      "loss": 0.0092,
      "step": 3100
    },
    {
      "epoch": 0.7871064467766117,
      "grad_norm": 0.8601912260055542,
      "learning_rate": 4.606571714142929e-05,
      "loss": 0.0078,
      "step": 3150
    },
    {
      "epoch": 0.7996001999000499,
      "grad_norm": 1.5492274761199951,
      "learning_rate": 4.60032483758121e-05,
      "loss": 0.0069,
      "step": 3200
    },
    {
      "epoch": 0.8120939530234883,
      "grad_norm": 2.532534122467041,
      "learning_rate": 4.594077961019491e-05,
      "loss": 0.0257,
      "step": 3250
    },
    {
      "epoch": 0.8245877061469266,
      "grad_norm": 0.3699701726436615,
      "learning_rate": 4.5878310844577715e-05,
      "loss": 0.0119,
      "step": 3300
    },
    {
      "epoch": 0.8370814592703648,
      "grad_norm": 1.5041016340255737,
      "learning_rate": 4.581584207896052e-05,
      "loss": 0.0085,
      "step": 3350
    },
    {
      "epoch": 0.8495752123938031,
      "grad_norm": 1.0724314451217651,
      "learning_rate": 4.5753373313343326e-05,
      "loss": 0.0108,
      "step": 3400
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 1.5918314456939697,
      "learning_rate": 4.5690904547726135e-05,
      "loss": 0.0103,
      "step": 3450
    },
    {
      "epoch": 0.8745627186406797,
      "grad_norm": 1.4010614156723022,
      "learning_rate": 4.562843578210895e-05,
      "loss": 0.0069,
      "step": 3500
    },
    {
      "epoch": 0.887056471764118,
      "grad_norm": 0.9417255520820618,
      "learning_rate": 4.556596701649176e-05,
      "loss": 0.0079,
      "step": 3550
    },
    {
      "epoch": 0.8995502248875562,
      "grad_norm": 0.7142592072486877,
      "learning_rate": 4.550349825087457e-05,
      "loss": 0.0072,
      "step": 3600
    },
    {
      "epoch": 0.9120439780109945,
      "grad_norm": 1.0443415641784668,
      "learning_rate": 4.5441029485257376e-05,
      "loss": 0.0083,
      "step": 3650
    },
    {
      "epoch": 0.9245377311344328,
      "grad_norm": 1.7821247577667236,
      "learning_rate": 4.5378560719640185e-05,
      "loss": 0.0071,
      "step": 3700
    },
    {
      "epoch": 0.9370314842578711,
      "grad_norm": 2.6674258708953857,
      "learning_rate": 4.5316091954022993e-05,
      "loss": 0.0097,
      "step": 3750
    },
    {
      "epoch": 0.9495252373813093,
      "grad_norm": 3.365302801132202,
      "learning_rate": 4.5253623188405795e-05,
      "loss": 0.0135,
      "step": 3800
    },
    {
      "epoch": 0.9620189905047476,
      "grad_norm": 0.7859903573989868,
      "learning_rate": 4.5191154422788604e-05,
      "loss": 0.0078,
      "step": 3850
    },
    {
      "epoch": 0.974512743628186,
      "grad_norm": 2.045598030090332,
      "learning_rate": 4.512868565717141e-05,
      "loss": 0.008,
      "step": 3900
    },
    {
      "epoch": 0.9870064967516242,
      "grad_norm": 0.7717111706733704,
      "learning_rate": 4.506621689155423e-05,
      "loss": 0.0125,
      "step": 3950
    },
    {
      "epoch": 0.9995002498750625,
      "grad_norm": 1.850124716758728,
      "learning_rate": 4.500374812593704e-05,
      "loss": 0.0103,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.00929073803126812,
      "eval_runtime": 2.7501,
      "eval_samples_per_second": 585.428,
      "eval_steps_per_second": 73.451,
      "step": 4002
    },
    {
      "epoch": 1.0119940029985008,
      "grad_norm": 1.8832769393920898,
      "learning_rate": 4.4941279360319846e-05,
      "loss": 0.0109,
      "step": 4050
    },
    {
      "epoch": 1.024487756121939,
      "grad_norm": 1.261102318763733,
      "learning_rate": 4.4878810594702654e-05,
      "loss": 0.0073,
      "step": 4100
    },
    {
      "epoch": 1.0369815092453774,
      "grad_norm": 1.2061355113983154,
      "learning_rate": 4.481634182908546e-05,
      "loss": 0.0093,
      "step": 4150
    },
    {
      "epoch": 1.0494752623688155,
      "grad_norm": 1.0212680101394653,
      "learning_rate": 4.4753873063468265e-05,
      "loss": 0.0071,
      "step": 4200
    },
    {
      "epoch": 1.0619690154922539,
      "grad_norm": 1.8663156032562256,
      "learning_rate": 4.4691404297851074e-05,
      "loss": 0.0176,
      "step": 4250
    },
    {
      "epoch": 1.0744627686156922,
      "grad_norm": 0.5866253972053528,
      "learning_rate": 4.462893553223388e-05,
      "loss": 0.0081,
      "step": 4300
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 2.3767271041870117,
      "learning_rate": 4.456646676661669e-05,
      "loss": 0.0076,
      "step": 4350
    },
    {
      "epoch": 1.0994502748625687,
      "grad_norm": 1.4971096515655518,
      "learning_rate": 4.45039980009995e-05,
      "loss": 0.0062,
      "step": 4400
    },
    {
      "epoch": 1.111944027986007,
      "grad_norm": 2.2803256511688232,
      "learning_rate": 4.4441529235382315e-05,
      "loss": 0.0082,
      "step": 4450
    },
    {
      "epoch": 1.1244377811094453,
      "grad_norm": 0.35923177003860474,
      "learning_rate": 4.4379060469765124e-05,
      "loss": 0.0068,
      "step": 4500
    },
    {
      "epoch": 1.1369315342328836,
      "grad_norm": 0.5986681580543518,
      "learning_rate": 4.431659170414793e-05,
      "loss": 0.0062,
      "step": 4550
    },
    {
      "epoch": 1.1494252873563218,
      "grad_norm": 1.7388111352920532,
      "learning_rate": 4.4254122938530734e-05,
      "loss": 0.0057,
      "step": 4600
    },
    {
      "epoch": 1.1619190404797601,
      "grad_norm": 1.950104832649231,
      "learning_rate": 4.419165417291354e-05,
      "loss": 0.008,
      "step": 4650
    },
    {
      "epoch": 1.1744127936031985,
      "grad_norm": 2.5653419494628906,
      "learning_rate": 4.412918540729635e-05,
      "loss": 0.0229,
      "step": 4700
    },
    {
      "epoch": 1.1869065467266366,
      "grad_norm": 1.216827154159546,
      "learning_rate": 4.406671664167916e-05,
      "loss": 0.007,
      "step": 4750
    },
    {
      "epoch": 1.199400299850075,
      "grad_norm": 2.1503915786743164,
      "learning_rate": 4.400424787606197e-05,
      "loss": 0.0095,
      "step": 4800
    },
    {
      "epoch": 1.2118940529735132,
      "grad_norm": 1.2702133655548096,
      "learning_rate": 4.394177911044478e-05,
      "loss": 0.0063,
      "step": 4850
    },
    {
      "epoch": 1.2243878060969515,
      "grad_norm": 1.6786092519760132,
      "learning_rate": 4.387931034482759e-05,
      "loss": 0.0065,
      "step": 4900
    },
    {
      "epoch": 1.23688155922039,
      "grad_norm": 2.773257255554199,
      "learning_rate": 4.38168415792104e-05,
      "loss": 0.0074,
      "step": 4950
    },
    {
      "epoch": 1.249375312343828,
      "grad_norm": 1.243179202079773,
      "learning_rate": 4.3754372813593204e-05,
      "loss": 0.0169,
      "step": 5000
    },
    {
      "epoch": 1.2618690654672664,
      "grad_norm": 1.0713765621185303,
      "learning_rate": 4.369190404797601e-05,
      "loss": 0.0061,
      "step": 5050
    },
    {
      "epoch": 1.2743628185907045,
      "grad_norm": 4.793112754821777,
      "learning_rate": 4.362943528235882e-05,
      "loss": 0.0173,
      "step": 5100
    },
    {
      "epoch": 1.286856571714143,
      "grad_norm": 0.4649578928947449,
      "learning_rate": 4.356696651674163e-05,
      "loss": 0.0081,
      "step": 5150
    },
    {
      "epoch": 1.2993503248375813,
      "grad_norm": 1.509839415550232,
      "learning_rate": 4.350449775112444e-05,
      "loss": 0.0055,
      "step": 5200
    },
    {
      "epoch": 1.3118440779610194,
      "grad_norm": 2.055250644683838,
      "learning_rate": 4.344202898550725e-05,
      "loss": 0.0081,
      "step": 5250
    },
    {
      "epoch": 1.3243378310844578,
      "grad_norm": 2.3131439685821533,
      "learning_rate": 4.3379560219890056e-05,
      "loss": 0.0061,
      "step": 5300
    },
    {
      "epoch": 1.336831584207896,
      "grad_norm": 1.2029616832733154,
      "learning_rate": 4.331709145427287e-05,
      "loss": 0.0057,
      "step": 5350
    },
    {
      "epoch": 1.3493253373313343,
      "grad_norm": 0.950776994228363,
      "learning_rate": 4.325462268865567e-05,
      "loss": 0.0048,
      "step": 5400
    },
    {
      "epoch": 1.3618190904547727,
      "grad_norm": 0.7988550066947937,
      "learning_rate": 4.319215392303848e-05,
      "loss": 0.0065,
      "step": 5450
    },
    {
      "epoch": 1.3743128435782108,
      "grad_norm": 1.60272216796875,
      "learning_rate": 4.312968515742129e-05,
      "loss": 0.0065,
      "step": 5500
    },
    {
      "epoch": 1.3868065967016492,
      "grad_norm": 0.7051938772201538,
      "learning_rate": 4.30672163918041e-05,
      "loss": 0.007,
      "step": 5550
    },
    {
      "epoch": 1.3993003498250873,
      "grad_norm": 2.486192226409912,
      "learning_rate": 4.300474762618691e-05,
      "loss": 0.0055,
      "step": 5600
    },
    {
      "epoch": 1.4117941029485257,
      "grad_norm": 2.7546019554138184,
      "learning_rate": 4.2942278860569717e-05,
      "loss": 0.0068,
      "step": 5650
    },
    {
      "epoch": 1.424287856071964,
      "grad_norm": 2.688344955444336,
      "learning_rate": 4.2879810094952525e-05,
      "loss": 0.0066,
      "step": 5700
    },
    {
      "epoch": 1.4367816091954024,
      "grad_norm": 0.5050407648086548,
      "learning_rate": 4.2817341329335334e-05,
      "loss": 0.0055,
      "step": 5750
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 2.8783915042877197,
      "learning_rate": 4.275487256371814e-05,
      "loss": 0.0059,
      "step": 5800
    },
    {
      "epoch": 1.461769115442279,
      "grad_norm": 0.20093250274658203,
      "learning_rate": 4.269240379810095e-05,
      "loss": 0.004,
      "step": 5850
    },
    {
      "epoch": 1.474262868565717,
      "grad_norm": 2.107262134552002,
      "learning_rate": 4.262993503248376e-05,
      "loss": 0.0066,
      "step": 5900
    },
    {
      "epoch": 1.4867566216891555,
      "grad_norm": 1.620782494544983,
      "learning_rate": 4.256746626686657e-05,
      "loss": 0.0059,
      "step": 5950
    },
    {
      "epoch": 1.4992503748125938,
      "grad_norm": 0.45846787095069885,
      "learning_rate": 4.250499750124938e-05,
      "loss": 0.004,
      "step": 6000
    },
    {
      "epoch": 1.511744127936032,
      "grad_norm": 1.2849383354187012,
      "learning_rate": 4.2442528735632186e-05,
      "loss": 0.0048,
      "step": 6050
    },
    {
      "epoch": 1.5242378810594701,
      "grad_norm": 0.8918518424034119,
      "learning_rate": 4.2380059970014995e-05,
      "loss": 0.0047,
      "step": 6100
    },
    {
      "epoch": 1.5367316341829085,
      "grad_norm": 0.8156757354736328,
      "learning_rate": 4.23175912043978e-05,
      "loss": 0.0051,
      "step": 6150
    },
    {
      "epoch": 1.5492253873063468,
      "grad_norm": 0.14887097477912903,
      "learning_rate": 4.225512243878061e-05,
      "loss": 0.0158,
      "step": 6200
    },
    {
      "epoch": 1.5617191404297852,
      "grad_norm": 0.5342129468917847,
      "learning_rate": 4.219265367316342e-05,
      "loss": 0.0058,
      "step": 6250
    },
    {
      "epoch": 1.5742128935532234,
      "grad_norm": 1.9833035469055176,
      "learning_rate": 4.213018490754623e-05,
      "loss": 0.006,
      "step": 6300
    },
    {
      "epoch": 1.5867066466766615,
      "grad_norm": 2.1378114223480225,
      "learning_rate": 4.206771614192904e-05,
      "loss": 0.0135,
      "step": 6350
    },
    {
      "epoch": 1.5992003998000999,
      "grad_norm": 1.5784876346588135,
      "learning_rate": 4.200524737631185e-05,
      "loss": 0.0054,
      "step": 6400
    },
    {
      "epoch": 1.6116941529235382,
      "grad_norm": 0.9982662796974182,
      "learning_rate": 4.1942778610694655e-05,
      "loss": 0.004,
      "step": 6450
    },
    {
      "epoch": 1.6241879060469766,
      "grad_norm": 1.3440639972686768,
      "learning_rate": 4.1880309845077464e-05,
      "loss": 0.0049,
      "step": 6500
    },
    {
      "epoch": 1.6366816591704147,
      "grad_norm": 1.303795576095581,
      "learning_rate": 4.181784107946027e-05,
      "loss": 0.0048,
      "step": 6550
    },
    {
      "epoch": 1.6491754122938531,
      "grad_norm": 0.551557719707489,
      "learning_rate": 4.175537231384308e-05,
      "loss": 0.015,
      "step": 6600
    },
    {
      "epoch": 1.6616691654172913,
      "grad_norm": 0.4552532136440277,
      "learning_rate": 4.169290354822589e-05,
      "loss": 0.0063,
      "step": 6650
    },
    {
      "epoch": 1.6741629185407296,
      "grad_norm": 1.969494342803955,
      "learning_rate": 4.16304347826087e-05,
      "loss": 0.0057,
      "step": 6700
    },
    {
      "epoch": 1.686656671664168,
      "grad_norm": 1.1327660083770752,
      "learning_rate": 4.156796601699151e-05,
      "loss": 0.0052,
      "step": 6750
    },
    {
      "epoch": 1.6991504247876064,
      "grad_norm": 0.9423850178718567,
      "learning_rate": 4.1505497251374316e-05,
      "loss": 0.0074,
      "step": 6800
    },
    {
      "epoch": 1.7116441779110445,
      "grad_norm": 0.47388753294944763,
      "learning_rate": 4.1443028485757125e-05,
      "loss": 0.0036,
      "step": 6850
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 1.8009240627288818,
      "learning_rate": 4.1380559720139933e-05,
      "loss": 0.0059,
      "step": 6900
    },
    {
      "epoch": 1.736631684157921,
      "grad_norm": 1.3671345710754395,
      "learning_rate": 4.131809095452274e-05,
      "loss": 0.0054,
      "step": 6950
    },
    {
      "epoch": 1.7491254372813594,
      "grad_norm": 0.43499818444252014,
      "learning_rate": 4.125562218890555e-05,
      "loss": 0.0033,
      "step": 7000
    },
    {
      "epoch": 1.7616191904047978,
      "grad_norm": 0.6845595836639404,
      "learning_rate": 4.119315342328835e-05,
      "loss": 0.0042,
      "step": 7050
    },
    {
      "epoch": 1.774112943528236,
      "grad_norm": 1.2007741928100586,
      "learning_rate": 4.113068465767116e-05,
      "loss": 0.0146,
      "step": 7100
    },
    {
      "epoch": 1.786606696651674,
      "grad_norm": 2.1100494861602783,
      "learning_rate": 4.106821589205398e-05,
      "loss": 0.0057,
      "step": 7150
    },
    {
      "epoch": 1.7991004497751124,
      "grad_norm": 1.400044560432434,
      "learning_rate": 4.1005747126436786e-05,
      "loss": 0.0052,
      "step": 7200
    },
    {
      "epoch": 1.8115942028985508,
      "grad_norm": 1.050148844718933,
      "learning_rate": 4.0943278360819594e-05,
      "loss": 0.0131,
      "step": 7250
    },
    {
      "epoch": 1.8240879560219891,
      "grad_norm": 0.647339403629303,
      "learning_rate": 4.08808095952024e-05,
      "loss": 0.0056,
      "step": 7300
    },
    {
      "epoch": 1.8365817091454273,
      "grad_norm": 0.8534316420555115,
      "learning_rate": 4.081834082958521e-05,
      "loss": 0.0046,
      "step": 7350
    },
    {
      "epoch": 1.8490754622688654,
      "grad_norm": 1.9255216121673584,
      "learning_rate": 4.075587206396802e-05,
      "loss": 0.0052,
      "step": 7400
    },
    {
      "epoch": 1.8615692153923038,
      "grad_norm": 2.046457290649414,
      "learning_rate": 4.069340329835082e-05,
      "loss": 0.0053,
      "step": 7450
    },
    {
      "epoch": 1.8740629685157422,
      "grad_norm": 1.083852767944336,
      "learning_rate": 4.063093453273363e-05,
      "loss": 0.0127,
      "step": 7500
    },
    {
      "epoch": 1.8865567216391805,
      "grad_norm": 0.40154513716697693,
      "learning_rate": 4.056846576711644e-05,
      "loss": 0.0027,
      "step": 7550
    },
    {
      "epoch": 1.8990504747626187,
      "grad_norm": 2.6340315341949463,
      "learning_rate": 4.0505997001499255e-05,
      "loss": 0.0041,
      "step": 7600
    },
    {
      "epoch": 1.9115442278860568,
      "grad_norm": 0.6126173138618469,
      "learning_rate": 4.0443528235882064e-05,
      "loss": 0.0046,
      "step": 7650
    },
    {
      "epoch": 1.9240379810094952,
      "grad_norm": 0.8993630409240723,
      "learning_rate": 4.038105947026487e-05,
      "loss": 0.006,
      "step": 7700
    },
    {
      "epoch": 1.9365317341329336,
      "grad_norm": 0.8166562914848328,
      "learning_rate": 4.031859070464768e-05,
      "loss": 0.0036,
      "step": 7750
    },
    {
      "epoch": 1.949025487256372,
      "grad_norm": 0.6642404794692993,
      "learning_rate": 4.025612193903049e-05,
      "loss": 0.0034,
      "step": 7800
    },
    {
      "epoch": 1.96151924037981,
      "grad_norm": 1.9637364149093628,
      "learning_rate": 4.019365317341329e-05,
      "loss": 0.0037,
      "step": 7850
    },
    {
      "epoch": 1.9740129935032482,
      "grad_norm": 0.3329135775566101,
      "learning_rate": 4.01311844077961e-05,
      "loss": 0.0124,
      "step": 7900
    },
    {
      "epoch": 1.9865067466266866,
      "grad_norm": 0.7956482768058777,
      "learning_rate": 4.006871564217891e-05,
      "loss": 0.0039,
      "step": 7950
    },
    {
      "epoch": 1.999000499750125,
      "grad_norm": 0.5045437812805176,
      "learning_rate": 4.000624687656172e-05,
      "loss": 0.0063,
      "step": 8000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0034655772615224123,
      "eval_runtime": 2.7321,
      "eval_samples_per_second": 589.299,
      "eval_steps_per_second": 73.937,
      "step": 8004
    },
    {
      "epoch": 2.0114942528735633,
      "grad_norm": 0.38383495807647705,
      "learning_rate": 3.9943778110944526e-05,
      "loss": 0.0034,
      "step": 8050
    },
    {
      "epoch": 2.0239880059970017,
      "grad_norm": 1.5022354125976562,
      "learning_rate": 3.988130934532734e-05,
      "loss": 0.0042,
      "step": 8100
    },
    {
      "epoch": 2.0364817591204396,
      "grad_norm": 0.6706172823905945,
      "learning_rate": 3.981884057971015e-05,
      "loss": 0.0029,
      "step": 8150
    },
    {
      "epoch": 2.048975512243878,
      "grad_norm": 2.2144882678985596,
      "learning_rate": 3.975637181409296e-05,
      "loss": 0.0047,
      "step": 8200
    },
    {
      "epoch": 2.0614692653673163,
      "grad_norm": 0.6712347269058228,
      "learning_rate": 3.969390304847577e-05,
      "loss": 0.0028,
      "step": 8250
    },
    {
      "epoch": 2.0739630184907547,
      "grad_norm": 0.6288363337516785,
      "learning_rate": 3.963143428285857e-05,
      "loss": 0.0035,
      "step": 8300
    },
    {
      "epoch": 2.086456771614193,
      "grad_norm": 0.5394971370697021,
      "learning_rate": 3.956896551724138e-05,
      "loss": 0.0044,
      "step": 8350
    },
    {
      "epoch": 2.098950524737631,
      "grad_norm": 0.7050229907035828,
      "learning_rate": 3.950649675162419e-05,
      "loss": 0.0031,
      "step": 8400
    },
    {
      "epoch": 2.1114442778610694,
      "grad_norm": 0.540313720703125,
      "learning_rate": 3.9444027986006996e-05,
      "loss": 0.011,
      "step": 8450
    },
    {
      "epoch": 2.1239380309845077,
      "grad_norm": 2.247985363006592,
      "learning_rate": 3.9381559220389804e-05,
      "loss": 0.0034,
      "step": 8500
    },
    {
      "epoch": 2.136431784107946,
      "grad_norm": 0.8688861131668091,
      "learning_rate": 3.931909045477262e-05,
      "loss": 0.0033,
      "step": 8550
    },
    {
      "epoch": 2.1489255372313845,
      "grad_norm": 0.6871092319488525,
      "learning_rate": 3.925662168915543e-05,
      "loss": 0.0032,
      "step": 8600
    },
    {
      "epoch": 2.1614192903548224,
      "grad_norm": NaN,
      "learning_rate": 3.919415292353824e-05,
      "loss": 0.0129,
      "step": 8650
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.5276443958282471,
      "learning_rate": 3.913168415792104e-05,
      "loss": 0.0029,
      "step": 8700
    },
    {
      "epoch": 2.186406796601699,
      "grad_norm": 0.2630939781665802,
      "learning_rate": 3.906921539230385e-05,
      "loss": 0.0033,
      "step": 8750
    },
    {
      "epoch": 2.1989005497251375,
      "grad_norm": 0.766602635383606,
      "learning_rate": 3.9006746626686657e-05,
      "loss": 0.0034,
      "step": 8800
    },
    {
      "epoch": 2.211394302848576,
      "grad_norm": 2.383399486541748,
      "learning_rate": 3.8944277861069465e-05,
      "loss": 0.0054,
      "step": 8850
    },
    {
      "epoch": 2.223888055972014,
      "grad_norm": 0.2596574127674103,
      "learning_rate": 3.8881809095452274e-05,
      "loss": 0.003,
      "step": 8900
    },
    {
      "epoch": 2.236381809095452,
      "grad_norm": 0.6499922871589661,
      "learning_rate": 3.881934032983508e-05,
      "loss": 0.0031,
      "step": 8950
    },
    {
      "epoch": 2.2488755622188905,
      "grad_norm": 0.9767376780509949,
      "learning_rate": 3.87568715642179e-05,
      "loss": 0.0035,
      "step": 9000
    },
    {
      "epoch": 2.261369315342329,
      "grad_norm": 1.654689908027649,
      "learning_rate": 3.869440279860071e-05,
      "loss": 0.0048,
      "step": 9050
    },
    {
      "epoch": 2.2738630684657672,
      "grad_norm": 1.5934033393859863,
      "learning_rate": 3.863193403298351e-05,
      "loss": 0.0045,
      "step": 9100
    },
    {
      "epoch": 2.286356821589205,
      "grad_norm": 0.686957836151123,
      "learning_rate": 3.856946526736632e-05,
      "loss": 0.0137,
      "step": 9150
    },
    {
      "epoch": 2.2988505747126435,
      "grad_norm": 0.5009754300117493,
      "learning_rate": 3.8506996501749126e-05,
      "loss": 0.0042,
      "step": 9200
    },
    {
      "epoch": 2.311344327836082,
      "grad_norm": 0.9907544851303101,
      "learning_rate": 3.8444527736131935e-05,
      "loss": 0.0028,
      "step": 9250
    },
    {
      "epoch": 2.3238380809595203,
      "grad_norm": 0.416152685880661,
      "learning_rate": 3.838205897051474e-05,
      "loss": 0.0112,
      "step": 9300
    },
    {
      "epoch": 2.3363318340829586,
      "grad_norm": 0.510959804058075,
      "learning_rate": 3.831959020489755e-05,
      "loss": 0.0041,
      "step": 9350
    },
    {
      "epoch": 2.348825587206397,
      "grad_norm": 0.6579998135566711,
      "learning_rate": 3.825712143928036e-05,
      "loss": 0.0036,
      "step": 9400
    },
    {
      "epoch": 2.361319340329835,
      "grad_norm": 0.6599454879760742,
      "learning_rate": 3.819465267366317e-05,
      "loss": 0.0034,
      "step": 9450
    },
    {
      "epoch": 2.3738130934532733,
      "grad_norm": 0.9922193884849548,
      "learning_rate": 3.813218390804598e-05,
      "loss": 0.0032,
      "step": 9500
    },
    {
      "epoch": 2.3863068465767117,
      "grad_norm": 0.47418150305747986,
      "learning_rate": 3.806971514242879e-05,
      "loss": 0.0034,
      "step": 9550
    },
    {
      "epoch": 2.39880059970015,
      "grad_norm": 0.5291637182235718,
      "learning_rate": 3.8007246376811595e-05,
      "loss": 0.0032,
      "step": 9600
    },
    {
      "epoch": 2.4112943528235884,
      "grad_norm": 0.4351147711277008,
      "learning_rate": 3.7944777611194404e-05,
      "loss": 0.003,
      "step": 9650
    },
    {
      "epoch": 2.4237881059470263,
      "grad_norm": 1.0975327491760254,
      "learning_rate": 3.788230884557721e-05,
      "loss": 0.0046,
      "step": 9700
    },
    {
      "epoch": 2.4362818590704647,
      "grad_norm": 0.5226255059242249,
      "learning_rate": 3.781984007996002e-05,
      "loss": 0.0044,
      "step": 9750
    },
    {
      "epoch": 2.448775612193903,
      "grad_norm": 0.6187398433685303,
      "learning_rate": 3.775737131434283e-05,
      "loss": 0.0132,
      "step": 9800
    },
    {
      "epoch": 2.4612693653173414,
      "grad_norm": 0.2898483872413635,
      "learning_rate": 3.769490254872564e-05,
      "loss": 0.0043,
      "step": 9850
    },
    {
      "epoch": 2.47376311844078,
      "grad_norm": 0.55823814868927,
      "learning_rate": 3.763243378310845e-05,
      "loss": 0.0035,
      "step": 9900
    },
    {
      "epoch": 2.4862568715642177,
      "grad_norm": 0.2883625328540802,
      "learning_rate": 3.7569965017491256e-05,
      "loss": 0.0112,
      "step": 9950
    },
    {
      "epoch": 2.498750624687656,
      "grad_norm": 0.5325047969818115,
      "learning_rate": 3.7507496251874065e-05,
      "loss": 0.0118,
      "step": 10000
    },
    {
      "epoch": 2.5112443778110944,
      "grad_norm": 0.7446795105934143,
      "learning_rate": 3.7445027486256874e-05,
      "loss": 0.0033,
      "step": 10050
    },
    {
      "epoch": 2.523738130934533,
      "grad_norm": 0.6893144249916077,
      "learning_rate": 3.738255872063968e-05,
      "loss": 0.0028,
      "step": 10100
    },
    {
      "epoch": 2.536231884057971,
      "grad_norm": 0.701102077960968,
      "learning_rate": 3.732008995502249e-05,
      "loss": 0.0033,
      "step": 10150
    },
    {
      "epoch": 2.548725637181409,
      "grad_norm": 0.5875473022460938,
      "learning_rate": 3.72576211894053e-05,
      "loss": 0.0027,
      "step": 10200
    },
    {
      "epoch": 2.5612193903048475,
      "grad_norm": 0.5441356301307678,
      "learning_rate": 3.719515242378811e-05,
      "loss": 0.0118,
      "step": 10250
    },
    {
      "epoch": 2.573713143428286,
      "grad_norm": 0.7066912055015564,
      "learning_rate": 3.713268365817092e-05,
      "loss": 0.0031,
      "step": 10300
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 0.3546716272830963,
      "learning_rate": 3.7070214892553726e-05,
      "loss": 0.0039,
      "step": 10350
    },
    {
      "epoch": 2.5987006496751626,
      "grad_norm": 0.21157632768154144,
      "learning_rate": 3.7007746126936534e-05,
      "loss": 0.0024,
      "step": 10400
    },
    {
      "epoch": 2.611194402798601,
      "grad_norm": 0.5572110414505005,
      "learning_rate": 3.694527736131934e-05,
      "loss": 0.0022,
      "step": 10450
    },
    {
      "epoch": 2.623688155922039,
      "grad_norm": 0.4283684194087982,
      "learning_rate": 3.688280859570215e-05,
      "loss": 0.0023,
      "step": 10500
    },
    {
      "epoch": 2.6361819090454772,
      "grad_norm": 1.050291895866394,
      "learning_rate": 3.682033983008496e-05,
      "loss": 0.0032,
      "step": 10550
    },
    {
      "epoch": 2.6486756621689156,
      "grad_norm": 0.4255851209163666,
      "learning_rate": 3.675787106446777e-05,
      "loss": 0.0115,
      "step": 10600
    },
    {
      "epoch": 2.661169415292354,
      "grad_norm": 0.5570421814918518,
      "learning_rate": 3.669540229885058e-05,
      "loss": 0.0034,
      "step": 10650
    },
    {
      "epoch": 2.673663168415792,
      "grad_norm": 0.7445876598358154,
      "learning_rate": 3.6632933533233386e-05,
      "loss": 0.0027,
      "step": 10700
    },
    {
      "epoch": 2.6861569215392302,
      "grad_norm": 0.8102554082870483,
      "learning_rate": 3.657046476761619e-05,
      "loss": 0.0037,
      "step": 10750
    },
    {
      "epoch": 2.6986506746626686,
      "grad_norm": 0.3571840524673462,
      "learning_rate": 3.6507996001999004e-05,
      "loss": 0.004,
      "step": 10800
    },
    {
      "epoch": 2.711144427786107,
      "grad_norm": 0.2970544993877411,
      "learning_rate": 3.644552723638181e-05,
      "loss": 0.0027,
      "step": 10850
    },
    {
      "epoch": 2.7236381809095453,
      "grad_norm": 1.1554492712020874,
      "learning_rate": 3.638305847076462e-05,
      "loss": 0.003,
      "step": 10900
    },
    {
      "epoch": 2.7361319340329837,
      "grad_norm": 0.6444098949432373,
      "learning_rate": 3.632058970514743e-05,
      "loss": 0.0029,
      "step": 10950
    },
    {
      "epoch": 2.7486256871564216,
      "grad_norm": 0.5823017358779907,
      "learning_rate": 3.625812093953024e-05,
      "loss": 0.003,
      "step": 11000
    },
    {
      "epoch": 2.76111944027986,
      "grad_norm": 1.1182780265808105,
      "learning_rate": 3.619565217391305e-05,
      "loss": 0.0038,
      "step": 11050
    },
    {
      "epoch": 2.7736131934032984,
      "grad_norm": 1.8369500637054443,
      "learning_rate": 3.6133183408295856e-05,
      "loss": 0.003,
      "step": 11100
    },
    {
      "epoch": 2.7861069465267367,
      "grad_norm": 0.22848740220069885,
      "learning_rate": 3.607071464267866e-05,
      "loss": 0.0039,
      "step": 11150
    },
    {
      "epoch": 2.7986006996501747,
      "grad_norm": 0.6479471325874329,
      "learning_rate": 3.6008245877061466e-05,
      "loss": 0.002,
      "step": 11200
    },
    {
      "epoch": 2.811094452773613,
      "grad_norm": 0.5966682434082031,
      "learning_rate": 3.594577711144428e-05,
      "loss": 0.0025,
      "step": 11250
    },
    {
      "epoch": 2.8235882058970514,
      "grad_norm": 0.2568841576576233,
      "learning_rate": 3.588330834582709e-05,
      "loss": 0.0036,
      "step": 11300
    },
    {
      "epoch": 2.8360819590204898,
      "grad_norm": 0.5992873907089233,
      "learning_rate": 3.58208395802099e-05,
      "loss": 0.0029,
      "step": 11350
    },
    {
      "epoch": 2.848575712143928,
      "grad_norm": 0.3542286455631256,
      "learning_rate": 3.575837081459271e-05,
      "loss": 0.0201,
      "step": 11400
    },
    {
      "epoch": 2.8610694652673665,
      "grad_norm": 1.1398005485534668,
      "learning_rate": 3.5695902048975517e-05,
      "loss": 0.0032,
      "step": 11450
    },
    {
      "epoch": 2.873563218390805,
      "grad_norm": 0.9454771876335144,
      "learning_rate": 3.5633433283358325e-05,
      "loss": 0.0034,
      "step": 11500
    },
    {
      "epoch": 2.886056971514243,
      "grad_norm": 0.4576091170310974,
      "learning_rate": 3.557096451774113e-05,
      "loss": 0.004,
      "step": 11550
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 1.0456477403640747,
      "learning_rate": 3.5508495752123936e-05,
      "loss": 0.0028,
      "step": 11600
    },
    {
      "epoch": 2.9110444777611195,
      "grad_norm": 1.1964759826660156,
      "learning_rate": 3.5446026986506744e-05,
      "loss": 0.0028,
      "step": 11650
    },
    {
      "epoch": 2.923538230884558,
      "grad_norm": 0.14211435616016388,
      "learning_rate": 3.538355822088956e-05,
      "loss": 0.0021,
      "step": 11700
    },
    {
      "epoch": 2.936031984007996,
      "grad_norm": 0.4079819321632385,
      "learning_rate": 3.532108945527237e-05,
      "loss": 0.0037,
      "step": 11750
    },
    {
      "epoch": 2.948525737131434,
      "grad_norm": 1.0407803058624268,
      "learning_rate": 3.525862068965518e-05,
      "loss": 0.0031,
      "step": 11800
    },
    {
      "epoch": 2.9610194902548725,
      "grad_norm": 0.7981908917427063,
      "learning_rate": 3.5196151924037986e-05,
      "loss": 0.0114,
      "step": 11850
    },
    {
      "epoch": 2.973513243378311,
      "grad_norm": 0.5626279711723328,
      "learning_rate": 3.5133683158420795e-05,
      "loss": 0.0022,
      "step": 11900
    },
    {
      "epoch": 2.9860069965017493,
      "grad_norm": 0.3354646563529968,
      "learning_rate": 3.5071214392803597e-05,
      "loss": 0.0024,
      "step": 11950
    },
    {
      "epoch": 2.9985007496251876,
      "grad_norm": 0.2706742286682129,
      "learning_rate": 3.5008745627186405e-05,
      "loss": 0.0017,
      "step": 12000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0022541291546076536,
      "eval_runtime": 2.7464,
      "eval_samples_per_second": 586.212,
      "eval_steps_per_second": 73.55,
      "step": 12006
    },
    {
      "epoch": 3.0109945027486256,
      "grad_norm": 1.1217405796051025,
      "learning_rate": 3.4946276861569214e-05,
      "loss": 0.0015,
      "step": 12050
    },
    {
      "epoch": 3.023488255872064,
      "grad_norm": 0.6906899809837341,
      "learning_rate": 3.488380809595202e-05,
      "loss": 0.0022,
      "step": 12100
    },
    {
      "epoch": 3.0359820089955023,
      "grad_norm": 0.9962279796600342,
      "learning_rate": 3.482133933033483e-05,
      "loss": 0.0023,
      "step": 12150
    },
    {
      "epoch": 3.0484757621189407,
      "grad_norm": 0.18719059228897095,
      "learning_rate": 3.475887056471765e-05,
      "loss": 0.0032,
      "step": 12200
    },
    {
      "epoch": 3.0609695152423786,
      "grad_norm": 1.121614694595337,
      "learning_rate": 3.4696401799100455e-05,
      "loss": 0.0034,
      "step": 12250
    },
    {
      "epoch": 3.073463268365817,
      "grad_norm": 1.1395511627197266,
      "learning_rate": 3.4633933033483264e-05,
      "loss": 0.0022,
      "step": 12300
    },
    {
      "epoch": 3.0859570214892553,
      "grad_norm": 1.0118911266326904,
      "learning_rate": 3.4571464267866066e-05,
      "loss": 0.0033,
      "step": 12350
    },
    {
      "epoch": 3.0984507746126937,
      "grad_norm": 1.4607136249542236,
      "learning_rate": 3.4508995502248875e-05,
      "loss": 0.0031,
      "step": 12400
    },
    {
      "epoch": 3.110944527736132,
      "grad_norm": 0.41595134139060974,
      "learning_rate": 3.444652673663168e-05,
      "loss": 0.0019,
      "step": 12450
    },
    {
      "epoch": 3.1234382808595704,
      "grad_norm": 0.6696957349777222,
      "learning_rate": 3.438405797101449e-05,
      "loss": 0.0023,
      "step": 12500
    },
    {
      "epoch": 3.1359320339830083,
      "grad_norm": 0.48479145765304565,
      "learning_rate": 3.43215892053973e-05,
      "loss": 0.0028,
      "step": 12550
    },
    {
      "epoch": 3.1484257871064467,
      "grad_norm": 0.55162113904953,
      "learning_rate": 3.425912043978011e-05,
      "loss": 0.0026,
      "step": 12600
    },
    {
      "epoch": 3.160919540229885,
      "grad_norm": 0.2847103178501129,
      "learning_rate": 3.4196651674162925e-05,
      "loss": 0.002,
      "step": 12650
    },
    {
      "epoch": 3.1734132933533234,
      "grad_norm": 1.009155511856079,
      "learning_rate": 3.4134182908545733e-05,
      "loss": 0.0022,
      "step": 12700
    },
    {
      "epoch": 3.185907046476762,
      "grad_norm": 0.38015782833099365,
      "learning_rate": 3.4071714142928535e-05,
      "loss": 0.003,
      "step": 12750
    },
    {
      "epoch": 3.1984007996001997,
      "grad_norm": 0.6968423128128052,
      "learning_rate": 3.4009245377311344e-05,
      "loss": 0.0033,
      "step": 12800
    },
    {
      "epoch": 3.210894552723638,
      "grad_norm": 0.5640507936477661,
      "learning_rate": 3.394677661169415e-05,
      "loss": 0.0022,
      "step": 12850
    },
    {
      "epoch": 3.2233883058470765,
      "grad_norm": 0.5278831124305725,
      "learning_rate": 3.388430784607696e-05,
      "loss": 0.0021,
      "step": 12900
    },
    {
      "epoch": 3.235882058970515,
      "grad_norm": 0.36937960982322693,
      "learning_rate": 3.382183908045977e-05,
      "loss": 0.0027,
      "step": 12950
    },
    {
      "epoch": 3.248375812093953,
      "grad_norm": 0.4396139681339264,
      "learning_rate": 3.375937031484258e-05,
      "loss": 0.0026,
      "step": 13000
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 1.2568261623382568,
      "learning_rate": 3.369690154922539e-05,
      "loss": 0.0022,
      "step": 13050
    },
    {
      "epoch": 3.2733633183408295,
      "grad_norm": 0.515576958656311,
      "learning_rate": 3.36344327836082e-05,
      "loss": 0.003,
      "step": 13100
    },
    {
      "epoch": 3.285857071464268,
      "grad_norm": 0.5702576637268066,
      "learning_rate": 3.357196401799101e-05,
      "loss": 0.0015,
      "step": 13150
    },
    {
      "epoch": 3.2983508245877062,
      "grad_norm": 0.1758413016796112,
      "learning_rate": 3.3509495252373814e-05,
      "loss": 0.0024,
      "step": 13200
    },
    {
      "epoch": 3.3108445777111446,
      "grad_norm": 0.38156139850616455,
      "learning_rate": 3.344702648675662e-05,
      "loss": 0.0101,
      "step": 13250
    },
    {
      "epoch": 3.3233383308345825,
      "grad_norm": 0.7744289040565491,
      "learning_rate": 3.338455772113943e-05,
      "loss": 0.0019,
      "step": 13300
    },
    {
      "epoch": 3.335832083958021,
      "grad_norm": 0.117373526096344,
      "learning_rate": 3.332208895552224e-05,
      "loss": 0.0022,
      "step": 13350
    },
    {
      "epoch": 3.3483258370814593,
      "grad_norm": 0.29035520553588867,
      "learning_rate": 3.325962018990505e-05,
      "loss": 0.002,
      "step": 13400
    },
    {
      "epoch": 3.3608195902048976,
      "grad_norm": 0.1966048628091812,
      "learning_rate": 3.319715142428786e-05,
      "loss": 0.0021,
      "step": 13450
    },
    {
      "epoch": 3.373313343328336,
      "grad_norm": 0.4565640985965729,
      "learning_rate": 3.3134682658670666e-05,
      "loss": 0.0025,
      "step": 13500
    },
    {
      "epoch": 3.3858070964517744,
      "grad_norm": 0.3368772268295288,
      "learning_rate": 3.3072213893053474e-05,
      "loss": 0.0021,
      "step": 13550
    },
    {
      "epoch": 3.3983008495752123,
      "grad_norm": 2.2295172214508057,
      "learning_rate": 3.300974512743628e-05,
      "loss": 0.0035,
      "step": 13600
    },
    {
      "epoch": 3.4107946026986506,
      "grad_norm": 0.48495155572891235,
      "learning_rate": 3.294727636181909e-05,
      "loss": 0.0031,
      "step": 13650
    },
    {
      "epoch": 3.423288355822089,
      "grad_norm": 0.297807514667511,
      "learning_rate": 3.28848075962019e-05,
      "loss": 0.0024,
      "step": 13700
    },
    {
      "epoch": 3.4357821089455274,
      "grad_norm": 0.5607819557189941,
      "learning_rate": 3.282233883058471e-05,
      "loss": 0.002,
      "step": 13750
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 0.6631056666374207,
      "learning_rate": 3.275987006496752e-05,
      "loss": 0.0027,
      "step": 13800
    },
    {
      "epoch": 3.4607696151924037,
      "grad_norm": 0.5187460780143738,
      "learning_rate": 3.2697401299350326e-05,
      "loss": 0.0017,
      "step": 13850
    },
    {
      "epoch": 3.473263368315842,
      "grad_norm": 1.1950639486312866,
      "learning_rate": 3.2634932533733135e-05,
      "loss": 0.0024,
      "step": 13900
    },
    {
      "epoch": 3.4857571214392804,
      "grad_norm": 1.0810868740081787,
      "learning_rate": 3.2572463768115944e-05,
      "loss": 0.0029,
      "step": 13950
    },
    {
      "epoch": 3.4982508745627188,
      "grad_norm": 0.5835714936256409,
      "learning_rate": 3.250999500249875e-05,
      "loss": 0.0123,
      "step": 14000
    },
    {
      "epoch": 3.510744627686157,
      "grad_norm": 0.7182209491729736,
      "learning_rate": 3.244752623688156e-05,
      "loss": 0.0021,
      "step": 14050
    },
    {
      "epoch": 3.523238380809595,
      "grad_norm": 0.4651585519313812,
      "learning_rate": 3.238505747126437e-05,
      "loss": 0.0028,
      "step": 14100
    },
    {
      "epoch": 3.5357321339330334,
      "grad_norm": 0.5467664003372192,
      "learning_rate": 3.232258870564718e-05,
      "loss": 0.011,
      "step": 14150
    },
    {
      "epoch": 3.548225887056472,
      "grad_norm": 0.20427604019641876,
      "learning_rate": 3.226011994002999e-05,
      "loss": 0.0105,
      "step": 14200
    },
    {
      "epoch": 3.56071964017991,
      "grad_norm": 0.451993852853775,
      "learning_rate": 3.2197651174412796e-05,
      "loss": 0.0022,
      "step": 14250
    },
    {
      "epoch": 3.573213393303348,
      "grad_norm": 0.3381006121635437,
      "learning_rate": 3.2135182408795604e-05,
      "loss": 0.0019,
      "step": 14300
    },
    {
      "epoch": 3.5857071464267865,
      "grad_norm": 0.6293882131576538,
      "learning_rate": 3.207271364317841e-05,
      "loss": 0.0031,
      "step": 14350
    },
    {
      "epoch": 3.598200899550225,
      "grad_norm": 0.5989000201225281,
      "learning_rate": 3.201024487756122e-05,
      "loss": 0.0018,
      "step": 14400
    },
    {
      "epoch": 3.610694652673663,
      "grad_norm": 0.5757220387458801,
      "learning_rate": 3.194777611194403e-05,
      "loss": 0.0101,
      "step": 14450
    },
    {
      "epoch": 3.6231884057971016,
      "grad_norm": 0.8303162455558777,
      "learning_rate": 3.188530734632684e-05,
      "loss": 0.0017,
      "step": 14500
    },
    {
      "epoch": 3.63568215892054,
      "grad_norm": 0.46191126108169556,
      "learning_rate": 3.182283858070965e-05,
      "loss": 0.0022,
      "step": 14550
    },
    {
      "epoch": 3.6481759120439783,
      "grad_norm": 0.2905195951461792,
      "learning_rate": 3.1760369815092457e-05,
      "loss": 0.0018,
      "step": 14600
    },
    {
      "epoch": 3.660669665167416,
      "grad_norm": 0.36909055709838867,
      "learning_rate": 3.1697901049475265e-05,
      "loss": 0.0114,
      "step": 14650
    },
    {
      "epoch": 3.6731634182908546,
      "grad_norm": 0.4065990447998047,
      "learning_rate": 3.1635432283858074e-05,
      "loss": 0.0021,
      "step": 14700
    },
    {
      "epoch": 3.685657171414293,
      "grad_norm": 0.23165263235569,
      "learning_rate": 3.157296351824088e-05,
      "loss": 0.0113,
      "step": 14750
    },
    {
      "epoch": 3.698150924537731,
      "grad_norm": 0.4292662441730499,
      "learning_rate": 3.1510494752623684e-05,
      "loss": 0.0019,
      "step": 14800
    },
    {
      "epoch": 3.7106446776611692,
      "grad_norm": 1.2942652702331543,
      "learning_rate": 3.144802598700649e-05,
      "loss": 0.0024,
      "step": 14850
    },
    {
      "epoch": 3.7231384307846076,
      "grad_norm": 0.3021031618118286,
      "learning_rate": 3.138555722138931e-05,
      "loss": 0.0014,
      "step": 14900
    },
    {
      "epoch": 3.735632183908046,
      "grad_norm": 0.519334614276886,
      "learning_rate": 3.132308845577212e-05,
      "loss": 0.0021,
      "step": 14950
    },
    {
      "epoch": 3.7481259370314843,
      "grad_norm": 0.27235284447669983,
      "learning_rate": 3.1260619690154926e-05,
      "loss": 0.0015,
      "step": 15000
    },
    {
      "epoch": 3.7606196901549227,
      "grad_norm": 0.5451032519340515,
      "learning_rate": 3.1198150924537735e-05,
      "loss": 0.0023,
      "step": 15050
    },
    {
      "epoch": 3.773113443278361,
      "grad_norm": 0.7487869262695312,
      "learning_rate": 3.113568215892054e-05,
      "loss": 0.0024,
      "step": 15100
    },
    {
      "epoch": 3.785607196401799,
      "grad_norm": 0.5136009454727173,
      "learning_rate": 3.107321339330335e-05,
      "loss": 0.0019,
      "step": 15150
    },
    {
      "epoch": 3.7981009495252374,
      "grad_norm": 0.34884533286094666,
      "learning_rate": 3.1010744627686154e-05,
      "loss": 0.0103,
      "step": 15200
    },
    {
      "epoch": 3.8105947026486757,
      "grad_norm": 0.3317354917526245,
      "learning_rate": 3.094827586206896e-05,
      "loss": 0.0015,
      "step": 15250
    },
    {
      "epoch": 3.823088455772114,
      "grad_norm": 0.583215057849884,
      "learning_rate": 3.088580709645177e-05,
      "loss": 0.0012,
      "step": 15300
    },
    {
      "epoch": 3.835582208895552,
      "grad_norm": 0.37877166271209717,
      "learning_rate": 3.082333833083459e-05,
      "loss": 0.0022,
      "step": 15350
    },
    {
      "epoch": 3.8480759620189904,
      "grad_norm": 0.1797676831483841,
      "learning_rate": 3.0760869565217395e-05,
      "loss": 0.002,
      "step": 15400
    },
    {
      "epoch": 3.8605697151424287,
      "grad_norm": 0.09913458675146103,
      "learning_rate": 3.0698400799600204e-05,
      "loss": 0.0014,
      "step": 15450
    },
    {
      "epoch": 3.873063468265867,
      "grad_norm": 0.34765610098838806,
      "learning_rate": 3.063593203398301e-05,
      "loss": 0.011,
      "step": 15500
    },
    {
      "epoch": 3.8855572213893055,
      "grad_norm": 0.5369486212730408,
      "learning_rate": 3.057346326836582e-05,
      "loss": 0.0107,
      "step": 15550
    },
    {
      "epoch": 3.898050974512744,
      "grad_norm": 0.9028950333595276,
      "learning_rate": 3.051099450274863e-05,
      "loss": 0.0019,
      "step": 15600
    },
    {
      "epoch": 3.9105447276361818,
      "grad_norm": 0.8640379309654236,
      "learning_rate": 3.0448525737131432e-05,
      "loss": 0.0108,
      "step": 15650
    },
    {
      "epoch": 3.92303848075962,
      "grad_norm": 0.32553014159202576,
      "learning_rate": 3.0386056971514244e-05,
      "loss": 0.0021,
      "step": 15700
    },
    {
      "epoch": 3.9355322338830585,
      "grad_norm": 0.14628960192203522,
      "learning_rate": 3.0323588205897053e-05,
      "loss": 0.0014,
      "step": 15750
    },
    {
      "epoch": 3.948025987006497,
      "grad_norm": 0.41630855202674866,
      "learning_rate": 3.026111944027986e-05,
      "loss": 0.0017,
      "step": 15800
    },
    {
      "epoch": 3.960519740129935,
      "grad_norm": 0.04468926042318344,
      "learning_rate": 3.019865067466267e-05,
      "loss": 0.0118,
      "step": 15850
    },
    {
      "epoch": 3.973013493253373,
      "grad_norm": 0.25054943561553955,
      "learning_rate": 3.013618190904548e-05,
      "loss": 0.0012,
      "step": 15900
    },
    {
      "epoch": 3.9855072463768115,
      "grad_norm": 1.163680911064148,
      "learning_rate": 3.007371314342829e-05,
      "loss": 0.0019,
      "step": 15950
    },
    {
      "epoch": 3.99800099950025,
      "grad_norm": 0.2907456159591675,
      "learning_rate": 3.00112443778111e-05,
      "loss": 0.0015,
      "step": 16000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.002077060518786311,
      "eval_runtime": 2.765,
      "eval_samples_per_second": 582.273,
      "eval_steps_per_second": 73.055,
      "step": 16008
    },
    {
      "epoch": 4.010494752623688,
      "grad_norm": 0.4885829985141754,
      "learning_rate": 2.99487756121939e-05,
      "loss": 0.0027,
      "step": 16050
    },
    {
      "epoch": 4.022988505747127,
      "grad_norm": 0.5749664902687073,
      "learning_rate": 2.988630684657671e-05,
      "loss": 0.0015,
      "step": 16100
    },
    {
      "epoch": 4.035482258870565,
      "grad_norm": 0.3425399363040924,
      "learning_rate": 2.9823838080959522e-05,
      "loss": 0.0018,
      "step": 16150
    },
    {
      "epoch": 4.047976011994003,
      "grad_norm": 0.20342779159545898,
      "learning_rate": 2.976136931534233e-05,
      "loss": 0.0016,
      "step": 16200
    },
    {
      "epoch": 4.060469765117441,
      "grad_norm": 0.24257519841194153,
      "learning_rate": 2.969890054972514e-05,
      "loss": 0.0014,
      "step": 16250
    },
    {
      "epoch": 4.072963518240879,
      "grad_norm": 0.6455493569374084,
      "learning_rate": 2.9636431784107948e-05,
      "loss": 0.0022,
      "step": 16300
    },
    {
      "epoch": 4.085457271364318,
      "grad_norm": 0.2438666820526123,
      "learning_rate": 2.9573963018490757e-05,
      "loss": 0.0018,
      "step": 16350
    },
    {
      "epoch": 4.097951024487756,
      "grad_norm": 0.6773192882537842,
      "learning_rate": 2.9511494252873566e-05,
      "loss": 0.0018,
      "step": 16400
    },
    {
      "epoch": 4.110444777611194,
      "grad_norm": 0.5036067962646484,
      "learning_rate": 2.944902548725637e-05,
      "loss": 0.0015,
      "step": 16450
    },
    {
      "epoch": 4.122938530734633,
      "grad_norm": 0.25140580534935,
      "learning_rate": 2.938655672163918e-05,
      "loss": 0.0016,
      "step": 16500
    },
    {
      "epoch": 4.135432283858071,
      "grad_norm": 0.7222632169723511,
      "learning_rate": 2.9324087956021988e-05,
      "loss": 0.002,
      "step": 16550
    },
    {
      "epoch": 4.147926036981509,
      "grad_norm": 0.2841150760650635,
      "learning_rate": 2.92616191904048e-05,
      "loss": 0.002,
      "step": 16600
    },
    {
      "epoch": 4.160419790104948,
      "grad_norm": 0.4333117604255676,
      "learning_rate": 2.919915042478761e-05,
      "loss": 0.0014,
      "step": 16650
    },
    {
      "epoch": 4.172913543228386,
      "grad_norm": 0.3884117305278778,
      "learning_rate": 2.9136681659170418e-05,
      "loss": 0.0103,
      "step": 16700
    },
    {
      "epoch": 4.1854072963518245,
      "grad_norm": 0.11436428874731064,
      "learning_rate": 2.9074212893553226e-05,
      "loss": 0.0014,
      "step": 16750
    },
    {
      "epoch": 4.197901049475262,
      "grad_norm": 1.1358578205108643,
      "learning_rate": 2.9011744127936035e-05,
      "loss": 0.0018,
      "step": 16800
    },
    {
      "epoch": 4.2103948025987,
      "grad_norm": 0.5458881855010986,
      "learning_rate": 2.894927536231884e-05,
      "loss": 0.0012,
      "step": 16850
    },
    {
      "epoch": 4.222888555722139,
      "grad_norm": 0.3208983242511749,
      "learning_rate": 2.888680659670165e-05,
      "loss": 0.0017,
      "step": 16900
    },
    {
      "epoch": 4.235382308845577,
      "grad_norm": 0.7339029908180237,
      "learning_rate": 2.8824337831084458e-05,
      "loss": 0.0023,
      "step": 16950
    },
    {
      "epoch": 4.2478760619690155,
      "grad_norm": 0.8207383155822754,
      "learning_rate": 2.8761869065467266e-05,
      "loss": 0.0018,
      "step": 17000
    },
    {
      "epoch": 4.260369815092454,
      "grad_norm": 0.3985726237297058,
      "learning_rate": 2.8699400299850075e-05,
      "loss": 0.0012,
      "step": 17050
    },
    {
      "epoch": 4.272863568215892,
      "grad_norm": 0.8618625402450562,
      "learning_rate": 2.8636931534232887e-05,
      "loss": 0.0015,
      "step": 17100
    },
    {
      "epoch": 4.285357321339331,
      "grad_norm": 0.2466159462928772,
      "learning_rate": 2.8574462768615696e-05,
      "loss": 0.0022,
      "step": 17150
    },
    {
      "epoch": 4.297851074462769,
      "grad_norm": 0.24821992218494415,
      "learning_rate": 2.8511994002998504e-05,
      "loss": 0.0097,
      "step": 17200
    },
    {
      "epoch": 4.310344827586207,
      "grad_norm": 0.5048270225524902,
      "learning_rate": 2.844952523738131e-05,
      "loss": 0.0093,
      "step": 17250
    },
    {
      "epoch": 4.322838580709645,
      "grad_norm": 0.2908315658569336,
      "learning_rate": 2.838705647176412e-05,
      "loss": 0.0015,
      "step": 17300
    },
    {
      "epoch": 4.335332333833083,
      "grad_norm": 0.5198988914489746,
      "learning_rate": 2.8324587706146927e-05,
      "loss": 0.002,
      "step": 17350
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.4866836667060852,
      "learning_rate": 2.8262118940529736e-05,
      "loss": 0.0018,
      "step": 17400
    },
    {
      "epoch": 4.36031984007996,
      "grad_norm": 0.2396235466003418,
      "learning_rate": 2.8199650174912544e-05,
      "loss": 0.0011,
      "step": 17450
    },
    {
      "epoch": 4.372813593203398,
      "grad_norm": 0.6152860522270203,
      "learning_rate": 2.8137181409295353e-05,
      "loss": 0.0016,
      "step": 17500
    },
    {
      "epoch": 4.385307346326837,
      "grad_norm": 0.12409406900405884,
      "learning_rate": 2.8074712643678165e-05,
      "loss": 0.0019,
      "step": 17550
    },
    {
      "epoch": 4.397801099450275,
      "grad_norm": 0.2070084810256958,
      "learning_rate": 2.8012243878060974e-05,
      "loss": 0.0015,
      "step": 17600
    },
    {
      "epoch": 4.410294852573713,
      "grad_norm": 0.135434091091156,
      "learning_rate": 2.7949775112443776e-05,
      "loss": 0.0018,
      "step": 17650
    },
    {
      "epoch": 4.422788605697152,
      "grad_norm": 0.5157265663146973,
      "learning_rate": 2.7887306346826584e-05,
      "loss": 0.0022,
      "step": 17700
    },
    {
      "epoch": 4.43528235882059,
      "grad_norm": 0.7271838784217834,
      "learning_rate": 2.7824837581209397e-05,
      "loss": 0.0027,
      "step": 17750
    },
    {
      "epoch": 4.447776111944028,
      "grad_norm": 0.5659842491149902,
      "learning_rate": 2.7762368815592205e-05,
      "loss": 0.0013,
      "step": 17800
    },
    {
      "epoch": 4.460269865067466,
      "grad_norm": 0.4800907373428345,
      "learning_rate": 2.7699900049975014e-05,
      "loss": 0.0017,
      "step": 17850
    },
    {
      "epoch": 4.472763618190904,
      "grad_norm": 0.362212598323822,
      "learning_rate": 2.7637431284357823e-05,
      "loss": 0.0097,
      "step": 17900
    },
    {
      "epoch": 4.485257371314343,
      "grad_norm": 0.2150537371635437,
      "learning_rate": 2.757496251874063e-05,
      "loss": 0.0014,
      "step": 17950
    },
    {
      "epoch": 4.497751124437781,
      "grad_norm": 0.5576764941215515,
      "learning_rate": 2.7512493753123443e-05,
      "loss": 0.0109,
      "step": 18000
    },
    {
      "epoch": 4.510244877561219,
      "grad_norm": 0.2776055335998535,
      "learning_rate": 2.7450024987506252e-05,
      "loss": 0.0022,
      "step": 18050
    },
    {
      "epoch": 4.522738630684658,
      "grad_norm": 2.1985065937042236,
      "learning_rate": 2.7387556221889054e-05,
      "loss": 0.0016,
      "step": 18100
    },
    {
      "epoch": 4.535232383808096,
      "grad_norm": 0.26108264923095703,
      "learning_rate": 2.7325087456271863e-05,
      "loss": 0.0017,
      "step": 18150
    },
    {
      "epoch": 4.5477261369315345,
      "grad_norm": 0.5795332789421082,
      "learning_rate": 2.7262618690654675e-05,
      "loss": 0.0014,
      "step": 18200
    },
    {
      "epoch": 4.560219890054973,
      "grad_norm": 0.1478613168001175,
      "learning_rate": 2.7200149925037483e-05,
      "loss": 0.0013,
      "step": 18250
    },
    {
      "epoch": 4.57271364317841,
      "grad_norm": 0.196795254945755,
      "learning_rate": 2.7137681159420292e-05,
      "loss": 0.0016,
      "step": 18300
    },
    {
      "epoch": 4.585207396301849,
      "grad_norm": 0.5037466287612915,
      "learning_rate": 2.70752123938031e-05,
      "loss": 0.0106,
      "step": 18350
    },
    {
      "epoch": 4.597701149425287,
      "grad_norm": 0.7877110242843628,
      "learning_rate": 2.701274362818591e-05,
      "loss": 0.0017,
      "step": 18400
    },
    {
      "epoch": 4.610194902548725,
      "grad_norm": 0.5155628323554993,
      "learning_rate": 2.6950274862568718e-05,
      "loss": 0.0014,
      "step": 18450
    },
    {
      "epoch": 4.622688655672164,
      "grad_norm": 0.28755736351013184,
      "learning_rate": 2.6887806096951523e-05,
      "loss": 0.0012,
      "step": 18500
    },
    {
      "epoch": 4.635182408795602,
      "grad_norm": 0.7124711275100708,
      "learning_rate": 2.6825337331334332e-05,
      "loss": 0.003,
      "step": 18550
    },
    {
      "epoch": 4.6476761619190405,
      "grad_norm": 0.12837399542331696,
      "learning_rate": 2.676286856571714e-05,
      "loss": 0.0019,
      "step": 18600
    },
    {
      "epoch": 4.660169915042479,
      "grad_norm": 0.6213203072547913,
      "learning_rate": 2.6700399800099953e-05,
      "loss": 0.0024,
      "step": 18650
    },
    {
      "epoch": 4.672663668165917,
      "grad_norm": 0.7588539719581604,
      "learning_rate": 2.663793103448276e-05,
      "loss": 0.002,
      "step": 18700
    },
    {
      "epoch": 4.685157421289356,
      "grad_norm": 0.2957099676132202,
      "learning_rate": 2.657546226886557e-05,
      "loss": 0.0014,
      "step": 18750
    },
    {
      "epoch": 4.697651174412794,
      "grad_norm": 0.4438987076282501,
      "learning_rate": 2.651299350324838e-05,
      "loss": 0.0015,
      "step": 18800
    },
    {
      "epoch": 4.710144927536232,
      "grad_norm": 0.21671505272388458,
      "learning_rate": 2.6450524737631187e-05,
      "loss": 0.0095,
      "step": 18850
    },
    {
      "epoch": 4.72263868065967,
      "grad_norm": 0.19356203079223633,
      "learning_rate": 2.6388055972013993e-05,
      "loss": 0.0016,
      "step": 18900
    },
    {
      "epoch": 4.735132433783108,
      "grad_norm": 0.36932218074798584,
      "learning_rate": 2.63255872063968e-05,
      "loss": 0.0186,
      "step": 18950
    },
    {
      "epoch": 4.747626186906547,
      "grad_norm": 0.4449436664581299,
      "learning_rate": 2.626311844077961e-05,
      "loss": 0.0021,
      "step": 19000
    },
    {
      "epoch": 4.760119940029985,
      "grad_norm": 0.37664875388145447,
      "learning_rate": 2.620064967516242e-05,
      "loss": 0.0021,
      "step": 19050
    },
    {
      "epoch": 4.772613693153423,
      "grad_norm": 0.2766917645931244,
      "learning_rate": 2.6138180909545227e-05,
      "loss": 0.0014,
      "step": 19100
    },
    {
      "epoch": 4.785107446276862,
      "grad_norm": 0.4255990982055664,
      "learning_rate": 2.607571214392804e-05,
      "loss": 0.0023,
      "step": 19150
    },
    {
      "epoch": 4.7976011994003,
      "grad_norm": 0.8925712704658508,
      "learning_rate": 2.6013243378310848e-05,
      "loss": 0.0021,
      "step": 19200
    },
    {
      "epoch": 4.810094952523738,
      "grad_norm": 0.27761876583099365,
      "learning_rate": 2.5950774612693657e-05,
      "loss": 0.0013,
      "step": 19250
    },
    {
      "epoch": 4.822588705647177,
      "grad_norm": 0.31842556595802307,
      "learning_rate": 2.5888305847076462e-05,
      "loss": 0.0088,
      "step": 19300
    },
    {
      "epoch": 4.835082458770614,
      "grad_norm": 0.1808752417564392,
      "learning_rate": 2.582583708145927e-05,
      "loss": 0.0019,
      "step": 19350
    },
    {
      "epoch": 4.847576211894053,
      "grad_norm": 0.09593085199594498,
      "learning_rate": 2.576336831584208e-05,
      "loss": 0.0099,
      "step": 19400
    },
    {
      "epoch": 4.860069965017491,
      "grad_norm": 0.22156590223312378,
      "learning_rate": 2.5700899550224888e-05,
      "loss": 0.0021,
      "step": 19450
    },
    {
      "epoch": 4.872563718140929,
      "grad_norm": 0.07492522150278091,
      "learning_rate": 2.5638430784607697e-05,
      "loss": 0.0017,
      "step": 19500
    },
    {
      "epoch": 4.885057471264368,
      "grad_norm": 0.36194705963134766,
      "learning_rate": 2.5575962018990506e-05,
      "loss": 0.0026,
      "step": 19550
    },
    {
      "epoch": 4.897551224387806,
      "grad_norm": 0.4071160852909088,
      "learning_rate": 2.5513493253373318e-05,
      "loss": 0.0024,
      "step": 19600
    },
    {
      "epoch": 4.9100449775112445,
      "grad_norm": 0.618546187877655,
      "learning_rate": 2.5451024487756126e-05,
      "loss": 0.0015,
      "step": 19650
    },
    {
      "epoch": 4.922538730634683,
      "grad_norm": 0.20294959843158722,
      "learning_rate": 2.5388555722138928e-05,
      "loss": 0.0015,
      "step": 19700
    },
    {
      "epoch": 4.935032483758121,
      "grad_norm": 0.33970722556114197,
      "learning_rate": 2.5326086956521737e-05,
      "loss": 0.0014,
      "step": 19750
    },
    {
      "epoch": 4.94752623688156,
      "grad_norm": 0.3041898310184479,
      "learning_rate": 2.526361819090455e-05,
      "loss": 0.0102,
      "step": 19800
    },
    {
      "epoch": 4.960019990004998,
      "grad_norm": 0.1604199856519699,
      "learning_rate": 2.5201149425287358e-05,
      "loss": 0.0014,
      "step": 19850
    },
    {
      "epoch": 4.972513743128435,
      "grad_norm": 0.1981007158756256,
      "learning_rate": 2.5138680659670166e-05,
      "loss": 0.0016,
      "step": 19900
    },
    {
      "epoch": 4.985007496251874,
      "grad_norm": 0.21741318702697754,
      "learning_rate": 2.5076211894052975e-05,
      "loss": 0.0017,
      "step": 19950
    },
    {
      "epoch": 4.997501249375312,
      "grad_norm": 0.3653919994831085,
      "learning_rate": 2.5013743128435784e-05,
      "loss": 0.0016,
      "step": 20000
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.0018607978709042072,
      "eval_runtime": 2.7399,
      "eval_samples_per_second": 587.606,
      "eval_steps_per_second": 73.724,
      "step": 20010
    },
    {
      "epoch": 5.0099950024987505,
      "grad_norm": 0.35603222250938416,
      "learning_rate": 2.4951274362818592e-05,
      "loss": 0.0015,
      "step": 20050
    },
    {
      "epoch": 5.022488755622189,
      "grad_norm": 0.38964414596557617,
      "learning_rate": 2.48888055972014e-05,
      "loss": 0.0016,
      "step": 20100
    },
    {
      "epoch": 5.034982508745627,
      "grad_norm": 0.7746419906616211,
      "learning_rate": 2.482633683158421e-05,
      "loss": 0.0021,
      "step": 20150
    },
    {
      "epoch": 5.047476261869066,
      "grad_norm": 0.4240291714668274,
      "learning_rate": 2.4763868065967015e-05,
      "loss": 0.0014,
      "step": 20200
    },
    {
      "epoch": 5.059970014992504,
      "grad_norm": 0.2740279734134674,
      "learning_rate": 2.4701399300349827e-05,
      "loss": 0.0088,
      "step": 20250
    },
    {
      "epoch": 5.072463768115942,
      "grad_norm": 0.4742564857006073,
      "learning_rate": 2.4638930534732636e-05,
      "loss": 0.0021,
      "step": 20300
    },
    {
      "epoch": 5.084957521239381,
      "grad_norm": 0.3944348096847534,
      "learning_rate": 2.4576461769115444e-05,
      "loss": 0.0023,
      "step": 20350
    },
    {
      "epoch": 5.097451274362818,
      "grad_norm": 0.25598442554473877,
      "learning_rate": 2.451399300349825e-05,
      "loss": 0.0014,
      "step": 20400
    },
    {
      "epoch": 5.109945027486257,
      "grad_norm": 0.3388799726963043,
      "learning_rate": 2.445152423788106e-05,
      "loss": 0.0018,
      "step": 20450
    },
    {
      "epoch": 5.122438780609695,
      "grad_norm": 0.29730936884880066,
      "learning_rate": 2.438905547226387e-05,
      "loss": 0.0015,
      "step": 20500
    },
    {
      "epoch": 5.134932533733133,
      "grad_norm": 0.24375547468662262,
      "learning_rate": 2.432658670664668e-05,
      "loss": 0.0013,
      "step": 20550
    },
    {
      "epoch": 5.147426286856572,
      "grad_norm": 0.3513745665550232,
      "learning_rate": 2.4264117941029488e-05,
      "loss": 0.002,
      "step": 20600
    },
    {
      "epoch": 5.15992003998001,
      "grad_norm": 0.23975886404514313,
      "learning_rate": 2.4201649175412293e-05,
      "loss": 0.0013,
      "step": 20650
    },
    {
      "epoch": 5.172413793103448,
      "grad_norm": 0.04578281566500664,
      "learning_rate": 2.4139180409795105e-05,
      "loss": 0.0017,
      "step": 20700
    },
    {
      "epoch": 5.184907546226887,
      "grad_norm": 0.3588160574436188,
      "learning_rate": 2.4076711644177914e-05,
      "loss": 0.0014,
      "step": 20750
    },
    {
      "epoch": 5.197401299350325,
      "grad_norm": 8.786974906921387,
      "learning_rate": 2.4014242878560723e-05,
      "loss": 0.0091,
      "step": 20800
    },
    {
      "epoch": 5.2098950524737635,
      "grad_norm": 0.12771372497081757,
      "learning_rate": 2.3951774112943528e-05,
      "loss": 0.0097,
      "step": 20850
    },
    {
      "epoch": 5.222388805597201,
      "grad_norm": 2.540168285369873,
      "learning_rate": 2.3889305347326337e-05,
      "loss": 0.0026,
      "step": 20900
    },
    {
      "epoch": 5.234882558720639,
      "grad_norm": 0.5260195732116699,
      "learning_rate": 2.382683658170915e-05,
      "loss": 0.0019,
      "step": 20950
    },
    {
      "epoch": 5.247376311844078,
      "grad_norm": 0.7449161410331726,
      "learning_rate": 2.3764367816091957e-05,
      "loss": 0.0099,
      "step": 21000
    },
    {
      "epoch": 5.259870064967516,
      "grad_norm": 0.22156517207622528,
      "learning_rate": 2.3701899050474763e-05,
      "loss": 0.0013,
      "step": 21050
    },
    {
      "epoch": 5.2723638180909544,
      "grad_norm": 1.0389269590377808,
      "learning_rate": 2.363943028485757e-05,
      "loss": 0.0013,
      "step": 21100
    },
    {
      "epoch": 5.284857571214393,
      "grad_norm": 0.33155557513237,
      "learning_rate": 2.357696151924038e-05,
      "loss": 0.0018,
      "step": 21150
    },
    {
      "epoch": 5.297351324337831,
      "grad_norm": 0.5679362416267395,
      "learning_rate": 2.3514492753623192e-05,
      "loss": 0.0012,
      "step": 21200
    },
    {
      "epoch": 5.3098450774612695,
      "grad_norm": 0.4160667359828949,
      "learning_rate": 2.3452023988005997e-05,
      "loss": 0.0017,
      "step": 21250
    },
    {
      "epoch": 5.322338830584708,
      "grad_norm": 0.5343022346496582,
      "learning_rate": 2.3389555222388806e-05,
      "loss": 0.0014,
      "step": 21300
    },
    {
      "epoch": 5.334832583708146,
      "grad_norm": 0.5154708027839661,
      "learning_rate": 2.3327086456771615e-05,
      "loss": 0.0012,
      "step": 21350
    },
    {
      "epoch": 5.347326336831584,
      "grad_norm": 0.1890668123960495,
      "learning_rate": 2.3264617691154427e-05,
      "loss": 0.0017,
      "step": 21400
    },
    {
      "epoch": 5.359820089955022,
      "grad_norm": 0.22828200459480286,
      "learning_rate": 2.3202148925537232e-05,
      "loss": 0.0012,
      "step": 21450
    },
    {
      "epoch": 5.3723138430784605,
      "grad_norm": 0.17620089650154114,
      "learning_rate": 2.313968015992004e-05,
      "loss": 0.0016,
      "step": 21500
    },
    {
      "epoch": 5.384807596201899,
      "grad_norm": 0.7094060182571411,
      "learning_rate": 2.307721139430285e-05,
      "loss": 0.0012,
      "step": 21550
    },
    {
      "epoch": 5.397301349325337,
      "grad_norm": 0.17648263275623322,
      "learning_rate": 2.3014742628685658e-05,
      "loss": 0.0017,
      "step": 21600
    },
    {
      "epoch": 5.409795102448776,
      "grad_norm": 0.775696873664856,
      "learning_rate": 2.2952273863068467e-05,
      "loss": 0.0016,
      "step": 21650
    },
    {
      "epoch": 5.422288855572214,
      "grad_norm": 0.20228728652000427,
      "learning_rate": 2.2889805097451275e-05,
      "loss": 0.0012,
      "step": 21700
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 0.7267294526100159,
      "learning_rate": 2.2827336331834084e-05,
      "loss": 0.0101,
      "step": 21750
    },
    {
      "epoch": 5.447276361819091,
      "grad_norm": 0.08265694975852966,
      "learning_rate": 2.2764867566216893e-05,
      "loss": 0.0015,
      "step": 21800
    },
    {
      "epoch": 5.459770114942529,
      "grad_norm": 0.5977702736854553,
      "learning_rate": 2.27023988005997e-05,
      "loss": 0.0019,
      "step": 21850
    },
    {
      "epoch": 5.472263868065967,
      "grad_norm": 0.11811158061027527,
      "learning_rate": 2.263993003498251e-05,
      "loss": 0.011,
      "step": 21900
    },
    {
      "epoch": 5.484757621189405,
      "grad_norm": 0.6659576296806335,
      "learning_rate": 2.257746126936532e-05,
      "loss": 0.0013,
      "step": 21950
    },
    {
      "epoch": 5.497251374312843,
      "grad_norm": 0.9218317866325378,
      "learning_rate": 2.2514992503748127e-05,
      "loss": 0.0012,
      "step": 22000
    },
    {
      "epoch": 5.509745127436282,
      "grad_norm": 0.3940066695213318,
      "learning_rate": 2.2452523738130936e-05,
      "loss": 0.0018,
      "step": 22050
    },
    {
      "epoch": 5.52223888055972,
      "grad_norm": 0.405282586812973,
      "learning_rate": 2.2390054972513745e-05,
      "loss": 0.0012,
      "step": 22100
    },
    {
      "epoch": 5.534732633683158,
      "grad_norm": 0.14706654846668243,
      "learning_rate": 2.2327586206896554e-05,
      "loss": 0.0018,
      "step": 22150
    },
    {
      "epoch": 5.547226386806597,
      "grad_norm": 0.17886725068092346,
      "learning_rate": 2.2265117441279362e-05,
      "loss": 0.0012,
      "step": 22200
    },
    {
      "epoch": 5.559720139930035,
      "grad_norm": 0.7201084494590759,
      "learning_rate": 2.2202648675662167e-05,
      "loss": 0.0025,
      "step": 22250
    },
    {
      "epoch": 5.5722138930534735,
      "grad_norm": 0.81156325340271,
      "learning_rate": 2.214017991004498e-05,
      "loss": 0.0015,
      "step": 22300
    },
    {
      "epoch": 5.584707646176912,
      "grad_norm": 1.23674738407135,
      "learning_rate": 2.2077711144427788e-05,
      "loss": 0.0014,
      "step": 22350
    },
    {
      "epoch": 5.59720139930035,
      "grad_norm": 1.1354142427444458,
      "learning_rate": 2.2015242378810597e-05,
      "loss": 0.0017,
      "step": 22400
    },
    {
      "epoch": 5.609695152423788,
      "grad_norm": 0.3004049062728882,
      "learning_rate": 2.1952773613193402e-05,
      "loss": 0.002,
      "step": 22450
    },
    {
      "epoch": 5.622188905547226,
      "grad_norm": 0.49940159916877747,
      "learning_rate": 2.189030484757621e-05,
      "loss": 0.0018,
      "step": 22500
    },
    {
      "epoch": 5.634682658670664,
      "grad_norm": 0.2560460865497589,
      "learning_rate": 2.1827836081959023e-05,
      "loss": 0.001,
      "step": 22550
    },
    {
      "epoch": 5.647176411794103,
      "grad_norm": 0.4213408827781677,
      "learning_rate": 2.176536731634183e-05,
      "loss": 0.0014,
      "step": 22600
    },
    {
      "epoch": 5.659670164917541,
      "grad_norm": 0.059006113559007645,
      "learning_rate": 2.1702898550724637e-05,
      "loss": 0.0013,
      "step": 22650
    },
    {
      "epoch": 5.6721639180409795,
      "grad_norm": 0.24123750627040863,
      "learning_rate": 2.1640429785107446e-05,
      "loss": 0.0013,
      "step": 22700
    },
    {
      "epoch": 5.684657671164418,
      "grad_norm": 0.3242149353027344,
      "learning_rate": 2.1577961019490254e-05,
      "loss": 0.002,
      "step": 22750
    },
    {
      "epoch": 5.697151424287856,
      "grad_norm": 0.2897719740867615,
      "learning_rate": 2.1515492253873066e-05,
      "loss": 0.0022,
      "step": 22800
    },
    {
      "epoch": 5.709645177411295,
      "grad_norm": 0.2957974970340729,
      "learning_rate": 2.145302348825587e-05,
      "loss": 0.0084,
      "step": 22850
    },
    {
      "epoch": 5.722138930534733,
      "grad_norm": 1.0834579467773438,
      "learning_rate": 2.139055472263868e-05,
      "loss": 0.0011,
      "step": 22900
    },
    {
      "epoch": 5.734632683658171,
      "grad_norm": 0.5410255193710327,
      "learning_rate": 2.132808595702149e-05,
      "loss": 0.0013,
      "step": 22950
    },
    {
      "epoch": 5.747126436781609,
      "grad_norm": 0.22208212316036224,
      "learning_rate": 2.12656171914043e-05,
      "loss": 0.0088,
      "step": 23000
    },
    {
      "epoch": 5.759620189905047,
      "grad_norm": 1.3244127035140991,
      "learning_rate": 2.120314842578711e-05,
      "loss": 0.0018,
      "step": 23050
    },
    {
      "epoch": 5.772113943028486,
      "grad_norm": 0.40885257720947266,
      "learning_rate": 2.1140679660169915e-05,
      "loss": 0.0007,
      "step": 23100
    },
    {
      "epoch": 5.784607696151924,
      "grad_norm": 0.15947797894477844,
      "learning_rate": 2.1078210894552724e-05,
      "loss": 0.001,
      "step": 23150
    },
    {
      "epoch": 5.797101449275362,
      "grad_norm": 0.8932924270629883,
      "learning_rate": 2.1015742128935532e-05,
      "loss": 0.0019,
      "step": 23200
    },
    {
      "epoch": 5.809595202398801,
      "grad_norm": 0.4085087776184082,
      "learning_rate": 2.0953273363318344e-05,
      "loss": 0.0013,
      "step": 23250
    },
    {
      "epoch": 5.822088955522239,
      "grad_norm": 0.31988632678985596,
      "learning_rate": 2.089080459770115e-05,
      "loss": 0.0098,
      "step": 23300
    },
    {
      "epoch": 5.834582708645677,
      "grad_norm": 0.26225602626800537,
      "learning_rate": 2.082833583208396e-05,
      "loss": 0.0021,
      "step": 23350
    },
    {
      "epoch": 5.847076461769116,
      "grad_norm": 0.26205146312713623,
      "learning_rate": 2.0765867066466767e-05,
      "loss": 0.0087,
      "step": 23400
    },
    {
      "epoch": 5.859570214892553,
      "grad_norm": 0.28385767340660095,
      "learning_rate": 2.0703398300849576e-05,
      "loss": 0.0098,
      "step": 23450
    },
    {
      "epoch": 5.872063968015992,
      "grad_norm": 1.1266165971755981,
      "learning_rate": 2.0640929535232384e-05,
      "loss": 0.0103,
      "step": 23500
    },
    {
      "epoch": 5.88455772113943,
      "grad_norm": 0.3023083508014679,
      "learning_rate": 2.0578460769615193e-05,
      "loss": 0.0011,
      "step": 23550
    },
    {
      "epoch": 5.897051474262868,
      "grad_norm": 0.5754231810569763,
      "learning_rate": 2.0515992003998002e-05,
      "loss": 0.0019,
      "step": 23600
    },
    {
      "epoch": 5.909545227386307,
      "grad_norm": 0.4982847273349762,
      "learning_rate": 2.045352323838081e-05,
      "loss": 0.0019,
      "step": 23650
    },
    {
      "epoch": 5.922038980509745,
      "grad_norm": 0.3979637324810028,
      "learning_rate": 2.039105447276362e-05,
      "loss": 0.0014,
      "step": 23700
    },
    {
      "epoch": 5.9345327336331835,
      "grad_norm": 0.40103858709335327,
      "learning_rate": 2.0328585707146428e-05,
      "loss": 0.0024,
      "step": 23750
    },
    {
      "epoch": 5.947026486756622,
      "grad_norm": 0.054040633141994476,
      "learning_rate": 2.0266116941529237e-05,
      "loss": 0.0012,
      "step": 23800
    },
    {
      "epoch": 5.95952023988006,
      "grad_norm": 0.24567431211471558,
      "learning_rate": 2.0203648175912045e-05,
      "loss": 0.0011,
      "step": 23850
    },
    {
      "epoch": 5.9720139930034986,
      "grad_norm": 0.372048556804657,
      "learning_rate": 2.0141179410294854e-05,
      "loss": 0.0014,
      "step": 23900
    },
    {
      "epoch": 5.984507746126937,
      "grad_norm": 0.5215389728546143,
      "learning_rate": 2.0078710644677663e-05,
      "loss": 0.0017,
      "step": 23950
    },
    {
      "epoch": 5.997001499250375,
      "grad_norm": 0.16764283180236816,
      "learning_rate": 2.001624187906047e-05,
      "loss": 0.001,
      "step": 24000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.0019261781126260757,
      "eval_runtime": 2.7301,
      "eval_samples_per_second": 589.718,
      "eval_steps_per_second": 73.989,
      "step": 24012
    },
    {
      "epoch": 6.009495252373813,
      "grad_norm": 0.4588807225227356,
      "learning_rate": 1.995377311344328e-05,
      "loss": 0.0011,
      "step": 24050
    },
    {
      "epoch": 6.021989005497251,
      "grad_norm": 0.4003659188747406,
      "learning_rate": 1.9891304347826085e-05,
      "loss": 0.0017,
      "step": 24100
    },
    {
      "epoch": 6.0344827586206895,
      "grad_norm": 0.21980752050876617,
      "learning_rate": 1.9828835582208897e-05,
      "loss": 0.0011,
      "step": 24150
    },
    {
      "epoch": 6.046976511744128,
      "grad_norm": 0.3390009105205536,
      "learning_rate": 1.9766366816591706e-05,
      "loss": 0.0009,
      "step": 24200
    },
    {
      "epoch": 6.059470264867566,
      "grad_norm": 0.35201647877693176,
      "learning_rate": 1.9703898050974515e-05,
      "loss": 0.0089,
      "step": 24250
    },
    {
      "epoch": 6.071964017991005,
      "grad_norm": 0.20592659711837769,
      "learning_rate": 1.964142928535732e-05,
      "loss": 0.0095,
      "step": 24300
    },
    {
      "epoch": 6.084457771114443,
      "grad_norm": 0.24339476227760315,
      "learning_rate": 1.9578960519740132e-05,
      "loss": 0.001,
      "step": 24350
    },
    {
      "epoch": 6.096951524237881,
      "grad_norm": 0.5619897246360779,
      "learning_rate": 1.951649175412294e-05,
      "loss": 0.001,
      "step": 24400
    },
    {
      "epoch": 6.10944527736132,
      "grad_norm": 0.20959195494651794,
      "learning_rate": 1.945402298850575e-05,
      "loss": 0.0013,
      "step": 24450
    },
    {
      "epoch": 6.121939030484757,
      "grad_norm": 0.2649342715740204,
      "learning_rate": 1.9391554222888555e-05,
      "loss": 0.0012,
      "step": 24500
    },
    {
      "epoch": 6.1344327836081955,
      "grad_norm": 0.8381179571151733,
      "learning_rate": 1.9329085457271363e-05,
      "loss": 0.0012,
      "step": 24550
    },
    {
      "epoch": 6.146926536731634,
      "grad_norm": 0.601198136806488,
      "learning_rate": 1.9266616691654175e-05,
      "loss": 0.002,
      "step": 24600
    },
    {
      "epoch": 6.159420289855072,
      "grad_norm": 0.37591686844825745,
      "learning_rate": 1.9204147926036984e-05,
      "loss": 0.0017,
      "step": 24650
    },
    {
      "epoch": 6.171914042978511,
      "grad_norm": 0.27825817465782166,
      "learning_rate": 1.914167916041979e-05,
      "loss": 0.0018,
      "step": 24700
    },
    {
      "epoch": 6.184407796101949,
      "grad_norm": 0.1588863581418991,
      "learning_rate": 1.9079210394802598e-05,
      "loss": 0.0018,
      "step": 24750
    },
    {
      "epoch": 6.196901549225387,
      "grad_norm": 0.41219404339790344,
      "learning_rate": 1.9016741629185407e-05,
      "loss": 0.0012,
      "step": 24800
    },
    {
      "epoch": 6.209395302348826,
      "grad_norm": 0.6346722841262817,
      "learning_rate": 1.895427286356822e-05,
      "loss": 0.0016,
      "step": 24850
    },
    {
      "epoch": 6.221889055472264,
      "grad_norm": 0.25825726985931396,
      "learning_rate": 1.8891804097951024e-05,
      "loss": 0.0012,
      "step": 24900
    },
    {
      "epoch": 6.2343828085957025,
      "grad_norm": 0.30831748247146606,
      "learning_rate": 1.8829335332333833e-05,
      "loss": 0.0011,
      "step": 24950
    },
    {
      "epoch": 6.246876561719141,
      "grad_norm": 0.15258972346782684,
      "learning_rate": 1.876686656671664e-05,
      "loss": 0.0016,
      "step": 25000
    },
    {
      "epoch": 6.259370314842578,
      "grad_norm": 0.5451982021331787,
      "learning_rate": 1.8704397801099454e-05,
      "loss": 0.0013,
      "step": 25050
    },
    {
      "epoch": 6.271864067966017,
      "grad_norm": 0.5031073093414307,
      "learning_rate": 1.864192903548226e-05,
      "loss": 0.0091,
      "step": 25100
    },
    {
      "epoch": 6.284357821089455,
      "grad_norm": 0.6856794357299805,
      "learning_rate": 1.8579460269865067e-05,
      "loss": 0.0013,
      "step": 25150
    },
    {
      "epoch": 6.296851574212893,
      "grad_norm": 0.6248753070831299,
      "learning_rate": 1.8516991504247876e-05,
      "loss": 0.0014,
      "step": 25200
    },
    {
      "epoch": 6.309345327336332,
      "grad_norm": 0.18465234339237213,
      "learning_rate": 1.8454522738630685e-05,
      "loss": 0.0014,
      "step": 25250
    },
    {
      "epoch": 6.32183908045977,
      "grad_norm": 0.8350297808647156,
      "learning_rate": 1.8392053973013494e-05,
      "loss": 0.0015,
      "step": 25300
    },
    {
      "epoch": 6.3343328335832085,
      "grad_norm": 0.5505244731903076,
      "learning_rate": 1.8329585207396302e-05,
      "loss": 0.0012,
      "step": 25350
    },
    {
      "epoch": 6.346826586706647,
      "grad_norm": 0.2279614806175232,
      "learning_rate": 1.826711644177911e-05,
      "loss": 0.0009,
      "step": 25400
    },
    {
      "epoch": 6.359320339830085,
      "grad_norm": 0.26423752307891846,
      "learning_rate": 1.820464767616192e-05,
      "loss": 0.0012,
      "step": 25450
    },
    {
      "epoch": 6.371814092953524,
      "grad_norm": 0.1766151785850525,
      "learning_rate": 1.8142178910544728e-05,
      "loss": 0.0012,
      "step": 25500
    },
    {
      "epoch": 6.384307846076961,
      "grad_norm": 0.7057377099990845,
      "learning_rate": 1.8079710144927537e-05,
      "loss": 0.0081,
      "step": 25550
    },
    {
      "epoch": 6.3968015992003995,
      "grad_norm": 0.17762160301208496,
      "learning_rate": 1.8017241379310346e-05,
      "loss": 0.0014,
      "step": 25600
    },
    {
      "epoch": 6.409295352323838,
      "grad_norm": 0.14875534176826477,
      "learning_rate": 1.7954772613693154e-05,
      "loss": 0.0012,
      "step": 25650
    },
    {
      "epoch": 6.421789105447276,
      "grad_norm": 0.34112459421157837,
      "learning_rate": 1.7892303848075963e-05,
      "loss": 0.0014,
      "step": 25700
    },
    {
      "epoch": 6.434282858570715,
      "grad_norm": 0.19252823293209076,
      "learning_rate": 1.782983508245877e-05,
      "loss": 0.0012,
      "step": 25750
    },
    {
      "epoch": 6.446776611694153,
      "grad_norm": 0.29949209094047546,
      "learning_rate": 1.776736631684158e-05,
      "loss": 0.0097,
      "step": 25800
    },
    {
      "epoch": 6.459270364817591,
      "grad_norm": 0.17030081152915955,
      "learning_rate": 1.770489755122439e-05,
      "loss": 0.0018,
      "step": 25850
    },
    {
      "epoch": 6.47176411794103,
      "grad_norm": 0.9666052460670471,
      "learning_rate": 1.7642428785607198e-05,
      "loss": 0.0015,
      "step": 25900
    },
    {
      "epoch": 6.484257871064468,
      "grad_norm": 0.14174872636795044,
      "learning_rate": 1.7579960019990006e-05,
      "loss": 0.0015,
      "step": 25950
    },
    {
      "epoch": 6.496751624187906,
      "grad_norm": 0.31908079981803894,
      "learning_rate": 1.7517491254372815e-05,
      "loss": 0.0013,
      "step": 26000
    },
    {
      "epoch": 6.509245377311345,
      "grad_norm": 0.29863348603248596,
      "learning_rate": 1.7455022488755624e-05,
      "loss": 0.0015,
      "step": 26050
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.23066604137420654,
      "learning_rate": 1.7392553723138432e-05,
      "loss": 0.0009,
      "step": 26100
    },
    {
      "epoch": 6.534232883558221,
      "grad_norm": 0.2300112247467041,
      "learning_rate": 1.7330084957521238e-05,
      "loss": 0.002,
      "step": 26150
    },
    {
      "epoch": 6.546726636681659,
      "grad_norm": 0.19520407915115356,
      "learning_rate": 1.726761619190405e-05,
      "loss": 0.0012,
      "step": 26200
    },
    {
      "epoch": 6.559220389805097,
      "grad_norm": 0.6515663862228394,
      "learning_rate": 1.720514742628686e-05,
      "loss": 0.0011,
      "step": 26250
    },
    {
      "epoch": 6.571714142928536,
      "grad_norm": 0.4347301125526428,
      "learning_rate": 1.7142678660669667e-05,
      "loss": 0.0019,
      "step": 26300
    },
    {
      "epoch": 6.584207896051974,
      "grad_norm": 0.352024108171463,
      "learning_rate": 1.7080209895052472e-05,
      "loss": 0.0095,
      "step": 26350
    },
    {
      "epoch": 6.5967016491754125,
      "grad_norm": 0.14800822734832764,
      "learning_rate": 1.7017741129435284e-05,
      "loss": 0.0015,
      "step": 26400
    },
    {
      "epoch": 6.609195402298851,
      "grad_norm": 0.2196005880832672,
      "learning_rate": 1.6955272363818093e-05,
      "loss": 0.0013,
      "step": 26450
    },
    {
      "epoch": 6.621689155422289,
      "grad_norm": 0.38522326946258545,
      "learning_rate": 1.6892803598200902e-05,
      "loss": 0.0019,
      "step": 26500
    },
    {
      "epoch": 6.634182908545727,
      "grad_norm": 0.7244999408721924,
      "learning_rate": 1.6830334832583707e-05,
      "loss": 0.0012,
      "step": 26550
    },
    {
      "epoch": 6.646676661669165,
      "grad_norm": 0.43913111090660095,
      "learning_rate": 1.6767866066966516e-05,
      "loss": 0.0015,
      "step": 26600
    },
    {
      "epoch": 6.659170414792603,
      "grad_norm": 0.3724846839904785,
      "learning_rate": 1.6705397301349328e-05,
      "loss": 0.0018,
      "step": 26650
    },
    {
      "epoch": 6.671664167916042,
      "grad_norm": 0.9801084399223328,
      "learning_rate": 1.6642928535732137e-05,
      "loss": 0.0013,
      "step": 26700
    },
    {
      "epoch": 6.68415792103948,
      "grad_norm": 0.30212849378585815,
      "learning_rate": 1.6580459770114942e-05,
      "loss": 0.0013,
      "step": 26750
    },
    {
      "epoch": 6.6966516741629185,
      "grad_norm": 0.20648878812789917,
      "learning_rate": 1.651799100449775e-05,
      "loss": 0.0015,
      "step": 26800
    },
    {
      "epoch": 6.709145427286357,
      "grad_norm": 0.3399299085140228,
      "learning_rate": 1.645552223888056e-05,
      "loss": 0.0014,
      "step": 26850
    },
    {
      "epoch": 6.721639180409795,
      "grad_norm": 0.21010127663612366,
      "learning_rate": 1.639305347326337e-05,
      "loss": 0.001,
      "step": 26900
    },
    {
      "epoch": 6.734132933533234,
      "grad_norm": 0.31759363412857056,
      "learning_rate": 1.6330584707646177e-05,
      "loss": 0.0012,
      "step": 26950
    },
    {
      "epoch": 6.746626686656672,
      "grad_norm": 0.7728597521781921,
      "learning_rate": 1.6268115942028985e-05,
      "loss": 0.0015,
      "step": 27000
    },
    {
      "epoch": 6.75912043978011,
      "grad_norm": 0.34328821301460266,
      "learning_rate": 1.6205647176411794e-05,
      "loss": 0.002,
      "step": 27050
    },
    {
      "epoch": 6.771614192903549,
      "grad_norm": 0.3312665522098541,
      "learning_rate": 1.6143178410794606e-05,
      "loss": 0.0012,
      "step": 27100
    },
    {
      "epoch": 6.784107946026986,
      "grad_norm": 0.548848569393158,
      "learning_rate": 1.608070964517741e-05,
      "loss": 0.0019,
      "step": 27150
    },
    {
      "epoch": 6.796601699150425,
      "grad_norm": 0.6766266226768494,
      "learning_rate": 1.601824087956022e-05,
      "loss": 0.001,
      "step": 27200
    },
    {
      "epoch": 6.809095452273863,
      "grad_norm": 0.3851863741874695,
      "learning_rate": 1.595577211394303e-05,
      "loss": 0.0012,
      "step": 27250
    },
    {
      "epoch": 6.821589205397301,
      "grad_norm": 0.18560537695884705,
      "learning_rate": 1.5893303348325837e-05,
      "loss": 0.0011,
      "step": 27300
    },
    {
      "epoch": 6.83408295852074,
      "grad_norm": 0.7805370092391968,
      "learning_rate": 1.5830834582708646e-05,
      "loss": 0.0026,
      "step": 27350
    },
    {
      "epoch": 6.846576711644178,
      "grad_norm": 0.3143867552280426,
      "learning_rate": 1.5768365817091455e-05,
      "loss": 0.009,
      "step": 27400
    },
    {
      "epoch": 6.859070464767616,
      "grad_norm": 0.16577230393886566,
      "learning_rate": 1.5705897051474263e-05,
      "loss": 0.0012,
      "step": 27450
    },
    {
      "epoch": 6.871564217891055,
      "grad_norm": 0.28989285230636597,
      "learning_rate": 1.5643428285857072e-05,
      "loss": 0.0015,
      "step": 27500
    },
    {
      "epoch": 6.884057971014493,
      "grad_norm": 0.14475305378437042,
      "learning_rate": 1.558095952023988e-05,
      "loss": 0.0016,
      "step": 27550
    },
    {
      "epoch": 6.896551724137931,
      "grad_norm": 0.8361651301383972,
      "learning_rate": 1.551849075462269e-05,
      "loss": 0.0019,
      "step": 27600
    },
    {
      "epoch": 6.909045477261369,
      "grad_norm": 0.5288302898406982,
      "learning_rate": 1.5456021989005498e-05,
      "loss": 0.0017,
      "step": 27650
    },
    {
      "epoch": 6.921539230384807,
      "grad_norm": 0.31309911608695984,
      "learning_rate": 1.5393553223388307e-05,
      "loss": 0.0166,
      "step": 27700
    },
    {
      "epoch": 6.934032983508246,
      "grad_norm": 0.1271297037601471,
      "learning_rate": 1.5331084457771115e-05,
      "loss": 0.0083,
      "step": 27750
    },
    {
      "epoch": 6.946526736631684,
      "grad_norm": 1.1848986148834229,
      "learning_rate": 1.5268615692153924e-05,
      "loss": 0.0014,
      "step": 27800
    },
    {
      "epoch": 6.959020489755122,
      "grad_norm": 0.5017361044883728,
      "learning_rate": 1.5206146926536733e-05,
      "loss": 0.0073,
      "step": 27850
    },
    {
      "epoch": 6.971514242878561,
      "grad_norm": 0.38068488240242004,
      "learning_rate": 1.5143678160919541e-05,
      "loss": 0.0079,
      "step": 27900
    },
    {
      "epoch": 6.984007996001999,
      "grad_norm": 0.03555773198604584,
      "learning_rate": 1.508120939530235e-05,
      "loss": 0.0012,
      "step": 27950
    },
    {
      "epoch": 6.9965017491254375,
      "grad_norm": 0.23229239881038666,
      "learning_rate": 1.5018740629685157e-05,
      "loss": 0.0011,
      "step": 28000
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.002879020757973194,
      "eval_runtime": 2.7556,
      "eval_samples_per_second": 584.255,
      "eval_steps_per_second": 73.304,
      "step": 28014
    }
  ],
  "logging_steps": 50,
  "max_steps": 40020,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2118032572387112e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
