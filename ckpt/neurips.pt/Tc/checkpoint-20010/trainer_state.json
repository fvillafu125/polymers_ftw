{
  "best_global_step": 20010,
  "best_metric": 0.001990102929994464,
  "best_model_checkpoint": "ckpt/neurips.pt/Tc/checkpoint-20010",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 20010,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01249375312343828,
      "grad_norm": 2.335559606552124,
      "learning_rate": 4.993878060969516e-05,
      "loss": 0.0529,
      "step": 50
    },
    {
      "epoch": 0.02498750624687656,
      "grad_norm": 8.572004318237305,
      "learning_rate": 4.987631184407796e-05,
      "loss": 0.0424,
      "step": 100
    },
    {
      "epoch": 0.037481259370314844,
      "grad_norm": 9.43557071685791,
      "learning_rate": 4.981384307846077e-05,
      "loss": 0.0324,
      "step": 150
    },
    {
      "epoch": 0.04997501249375312,
      "grad_norm": 8.924070358276367,
      "learning_rate": 4.975137431284358e-05,
      "loss": 0.0285,
      "step": 200
    },
    {
      "epoch": 0.062468765617191405,
      "grad_norm": 1.5846986770629883,
      "learning_rate": 4.9688905547226386e-05,
      "loss": 0.0381,
      "step": 250
    },
    {
      "epoch": 0.07496251874062969,
      "grad_norm": 4.185199737548828,
      "learning_rate": 4.9626436781609195e-05,
      "loss": 0.0262,
      "step": 300
    },
    {
      "epoch": 0.08745627186406797,
      "grad_norm": 2.2390806674957275,
      "learning_rate": 4.956396801599201e-05,
      "loss": 0.0233,
      "step": 350
    },
    {
      "epoch": 0.09995002498750624,
      "grad_norm": 5.624087333679199,
      "learning_rate": 4.950149925037482e-05,
      "loss": 0.0299,
      "step": 400
    },
    {
      "epoch": 0.11244377811094453,
      "grad_norm": 3.012333631515503,
      "learning_rate": 4.943903048475763e-05,
      "loss": 0.0309,
      "step": 450
    },
    {
      "epoch": 0.12493753123438281,
      "grad_norm": 3.231595039367676,
      "learning_rate": 4.937656171914043e-05,
      "loss": 0.0249,
      "step": 500
    },
    {
      "epoch": 0.1374312843578211,
      "grad_norm": 2.435840129852295,
      "learning_rate": 4.931409295352324e-05,
      "loss": 0.0202,
      "step": 550
    },
    {
      "epoch": 0.14992503748125938,
      "grad_norm": 2.5662035942077637,
      "learning_rate": 4.925162418790605e-05,
      "loss": 0.0211,
      "step": 600
    },
    {
      "epoch": 0.16241879060469766,
      "grad_norm": 0.8626339435577393,
      "learning_rate": 4.9189155422288855e-05,
      "loss": 0.0187,
      "step": 650
    },
    {
      "epoch": 0.17491254372813594,
      "grad_norm": 3.785350799560547,
      "learning_rate": 4.9126686656671664e-05,
      "loss": 0.0252,
      "step": 700
    },
    {
      "epoch": 0.1874062968515742,
      "grad_norm": 3.63316011428833,
      "learning_rate": 4.906421789105447e-05,
      "loss": 0.0221,
      "step": 750
    },
    {
      "epoch": 0.19990004997501248,
      "grad_norm": 2.9594011306762695,
      "learning_rate": 4.900174912543729e-05,
      "loss": 0.023,
      "step": 800
    },
    {
      "epoch": 0.21239380309845077,
      "grad_norm": 1.6913821697235107,
      "learning_rate": 4.89392803598201e-05,
      "loss": 0.0194,
      "step": 850
    },
    {
      "epoch": 0.22488755622188905,
      "grad_norm": 2.100555419921875,
      "learning_rate": 4.88768115942029e-05,
      "loss": 0.0229,
      "step": 900
    },
    {
      "epoch": 0.23738130934532733,
      "grad_norm": 2.5200819969177246,
      "learning_rate": 4.881434282858571e-05,
      "loss": 0.0199,
      "step": 950
    },
    {
      "epoch": 0.24987506246876562,
      "grad_norm": 2.173670530319214,
      "learning_rate": 4.8751874062968516e-05,
      "loss": 0.0246,
      "step": 1000
    },
    {
      "epoch": 0.2623688155922039,
      "grad_norm": 5.528991222381592,
      "learning_rate": 4.8689405297351325e-05,
      "loss": 0.0176,
      "step": 1050
    },
    {
      "epoch": 0.2748625687156422,
      "grad_norm": 2.1097235679626465,
      "learning_rate": 4.8626936531734134e-05,
      "loss": 0.022,
      "step": 1100
    },
    {
      "epoch": 0.28735632183908044,
      "grad_norm": 3.4513142108917236,
      "learning_rate": 4.856446776611694e-05,
      "loss": 0.0163,
      "step": 1150
    },
    {
      "epoch": 0.29985007496251875,
      "grad_norm": 1.4732003211975098,
      "learning_rate": 4.850199900049975e-05,
      "loss": 0.0165,
      "step": 1200
    },
    {
      "epoch": 0.312343828085957,
      "grad_norm": 3.071027994155884,
      "learning_rate": 4.8439530234882566e-05,
      "loss": 0.0169,
      "step": 1250
    },
    {
      "epoch": 0.3248375812093953,
      "grad_norm": 1.791897177696228,
      "learning_rate": 4.8377061469265375e-05,
      "loss": 0.0154,
      "step": 1300
    },
    {
      "epoch": 0.3373313343328336,
      "grad_norm": 4.648906230926514,
      "learning_rate": 4.831459270364818e-05,
      "loss": 0.016,
      "step": 1350
    },
    {
      "epoch": 0.3498250874562719,
      "grad_norm": 1.9345132112503052,
      "learning_rate": 4.8252123938030986e-05,
      "loss": 0.0288,
      "step": 1400
    },
    {
      "epoch": 0.36231884057971014,
      "grad_norm": 3.0896036624908447,
      "learning_rate": 4.8189655172413794e-05,
      "loss": 0.0228,
      "step": 1450
    },
    {
      "epoch": 0.3748125937031484,
      "grad_norm": 2.342803478240967,
      "learning_rate": 4.81271864067966e-05,
      "loss": 0.0313,
      "step": 1500
    },
    {
      "epoch": 0.3873063468265867,
      "grad_norm": 2.290196418762207,
      "learning_rate": 4.806471764117941e-05,
      "loss": 0.0169,
      "step": 1550
    },
    {
      "epoch": 0.39980009995002497,
      "grad_norm": 1.5695827007293701,
      "learning_rate": 4.800224887556222e-05,
      "loss": 0.012,
      "step": 1600
    },
    {
      "epoch": 0.4122938530734633,
      "grad_norm": 3.6518213748931885,
      "learning_rate": 4.793978010994503e-05,
      "loss": 0.0162,
      "step": 1650
    },
    {
      "epoch": 0.42478760619690153,
      "grad_norm": 3.409005880355835,
      "learning_rate": 4.787731134432784e-05,
      "loss": 0.0213,
      "step": 1700
    },
    {
      "epoch": 0.43728135932033985,
      "grad_norm": 1.533514380455017,
      "learning_rate": 4.7814842578710646e-05,
      "loss": 0.0134,
      "step": 1750
    },
    {
      "epoch": 0.4497751124437781,
      "grad_norm": 2.8577563762664795,
      "learning_rate": 4.7752373813093455e-05,
      "loss": 0.014,
      "step": 1800
    },
    {
      "epoch": 0.4622688655672164,
      "grad_norm": 2.8161439895629883,
      "learning_rate": 4.7689905047476264e-05,
      "loss": 0.0154,
      "step": 1850
    },
    {
      "epoch": 0.47476261869065467,
      "grad_norm": 0.5287413597106934,
      "learning_rate": 4.762743628185907e-05,
      "loss": 0.0173,
      "step": 1900
    },
    {
      "epoch": 0.487256371814093,
      "grad_norm": 0.3928965628147125,
      "learning_rate": 4.756496751624188e-05,
      "loss": 0.0129,
      "step": 1950
    },
    {
      "epoch": 0.49975012493753124,
      "grad_norm": 4.011432647705078,
      "learning_rate": 4.750249875062469e-05,
      "loss": 0.019,
      "step": 2000
    },
    {
      "epoch": 0.5122438780609695,
      "grad_norm": 2.816331148147583,
      "learning_rate": 4.74400299850075e-05,
      "loss": 0.011,
      "step": 2050
    },
    {
      "epoch": 0.5247376311844077,
      "grad_norm": 3.0954430103302,
      "learning_rate": 4.737756121939031e-05,
      "loss": 0.0149,
      "step": 2100
    },
    {
      "epoch": 0.5372313843078461,
      "grad_norm": 1.5645662546157837,
      "learning_rate": 4.7315092453773116e-05,
      "loss": 0.0117,
      "step": 2150
    },
    {
      "epoch": 0.5497251374312844,
      "grad_norm": 1.9123655557632446,
      "learning_rate": 4.7252623688155924e-05,
      "loss": 0.0129,
      "step": 2200
    },
    {
      "epoch": 0.5622188905547226,
      "grad_norm": 3.9661264419555664,
      "learning_rate": 4.719015492253873e-05,
      "loss": 0.013,
      "step": 2250
    },
    {
      "epoch": 0.5747126436781609,
      "grad_norm": 3.5023953914642334,
      "learning_rate": 4.712768615692154e-05,
      "loss": 0.0136,
      "step": 2300
    },
    {
      "epoch": 0.5872063968015993,
      "grad_norm": 1.1273047924041748,
      "learning_rate": 4.706521739130435e-05,
      "loss": 0.0122,
      "step": 2350
    },
    {
      "epoch": 0.5997001499250375,
      "grad_norm": 11.94385814666748,
      "learning_rate": 4.700274862568716e-05,
      "loss": 0.0258,
      "step": 2400
    },
    {
      "epoch": 0.6121939030484758,
      "grad_norm": 1.9441065788269043,
      "learning_rate": 4.694027986006997e-05,
      "loss": 0.0128,
      "step": 2450
    },
    {
      "epoch": 0.624687656171914,
      "grad_norm": 1.4785915613174438,
      "learning_rate": 4.6877811094452777e-05,
      "loss": 0.0126,
      "step": 2500
    },
    {
      "epoch": 0.6371814092953523,
      "grad_norm": 3.3063974380493164,
      "learning_rate": 4.6815342328835585e-05,
      "loss": 0.013,
      "step": 2550
    },
    {
      "epoch": 0.6496751624187906,
      "grad_norm": 1.2478185892105103,
      "learning_rate": 4.6752873563218394e-05,
      "loss": 0.01,
      "step": 2600
    },
    {
      "epoch": 0.6621689155422289,
      "grad_norm": 1.9125919342041016,
      "learning_rate": 4.66904047976012e-05,
      "loss": 0.0129,
      "step": 2650
    },
    {
      "epoch": 0.6746626686656672,
      "grad_norm": 0.6957934498786926,
      "learning_rate": 4.662793603198401e-05,
      "loss": 0.008,
      "step": 2700
    },
    {
      "epoch": 0.6871564217891054,
      "grad_norm": 1.2272651195526123,
      "learning_rate": 4.656546726636682e-05,
      "loss": 0.0105,
      "step": 2750
    },
    {
      "epoch": 0.6996501749125438,
      "grad_norm": 2.4249162673950195,
      "learning_rate": 4.650299850074963e-05,
      "loss": 0.0106,
      "step": 2800
    },
    {
      "epoch": 0.712143928035982,
      "grad_norm": 1.228910207748413,
      "learning_rate": 4.644052973513244e-05,
      "loss": 0.0108,
      "step": 2850
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 1.0577844381332397,
      "learning_rate": 4.6378060969515246e-05,
      "loss": 0.018,
      "step": 2900
    },
    {
      "epoch": 0.7371314342828585,
      "grad_norm": 0.911592423915863,
      "learning_rate": 4.631559220389805e-05,
      "loss": 0.0095,
      "step": 2950
    },
    {
      "epoch": 0.7496251874062968,
      "grad_norm": 2.285515785217285,
      "learning_rate": 4.6253123438280857e-05,
      "loss": 0.0077,
      "step": 3000
    },
    {
      "epoch": 0.7621189405297352,
      "grad_norm": 2.8276116847991943,
      "learning_rate": 4.619065467266367e-05,
      "loss": 0.0091,
      "step": 3050
    },
    {
      "epoch": 0.7746126936531734,
      "grad_norm": 2.4575181007385254,
      "learning_rate": 4.612818590704648e-05,
      "loss": 0.0104,
      "step": 3100
    },
    {
      "epoch": 0.7871064467766117,
      "grad_norm": 1.0029231309890747,
      "learning_rate": 4.606571714142929e-05,
      "loss": 0.0102,
      "step": 3150
    },
    {
      "epoch": 0.7996001999000499,
      "grad_norm": 0.525682806968689,
      "learning_rate": 4.60032483758121e-05,
      "loss": 0.0081,
      "step": 3200
    },
    {
      "epoch": 0.8120939530234883,
      "grad_norm": 1.0679235458374023,
      "learning_rate": 4.594077961019491e-05,
      "loss": 0.0192,
      "step": 3250
    },
    {
      "epoch": 0.8245877061469266,
      "grad_norm": 4.114838600158691,
      "learning_rate": 4.5878310844577715e-05,
      "loss": 0.0082,
      "step": 3300
    },
    {
      "epoch": 0.8370814592703648,
      "grad_norm": 2.6292736530303955,
      "learning_rate": 4.581584207896052e-05,
      "loss": 0.008,
      "step": 3350
    },
    {
      "epoch": 0.8495752123938031,
      "grad_norm": 5.624800682067871,
      "learning_rate": 4.5753373313343326e-05,
      "loss": 0.0098,
      "step": 3400
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 1.2573599815368652,
      "learning_rate": 4.5690904547726135e-05,
      "loss": 0.0127,
      "step": 3450
    },
    {
      "epoch": 0.8745627186406797,
      "grad_norm": 1.2537202835083008,
      "learning_rate": 4.562843578210895e-05,
      "loss": 0.007,
      "step": 3500
    },
    {
      "epoch": 0.887056471764118,
      "grad_norm": 0.5413388013839722,
      "learning_rate": 4.556596701649176e-05,
      "loss": 0.0096,
      "step": 3550
    },
    {
      "epoch": 0.8995502248875562,
      "grad_norm": 1.7800203561782837,
      "learning_rate": 4.550349825087457e-05,
      "loss": 0.0069,
      "step": 3600
    },
    {
      "epoch": 0.9120439780109945,
      "grad_norm": 0.6673161387443542,
      "learning_rate": 4.5441029485257376e-05,
      "loss": 0.0126,
      "step": 3650
    },
    {
      "epoch": 0.9245377311344328,
      "grad_norm": 0.8415715098381042,
      "learning_rate": 4.5378560719640185e-05,
      "loss": 0.0075,
      "step": 3700
    },
    {
      "epoch": 0.9370314842578711,
      "grad_norm": 2.151606798171997,
      "learning_rate": 4.5316091954022993e-05,
      "loss": 0.0107,
      "step": 3750
    },
    {
      "epoch": 0.9495252373813093,
      "grad_norm": 1.8335821628570557,
      "learning_rate": 4.5253623188405795e-05,
      "loss": 0.01,
      "step": 3800
    },
    {
      "epoch": 0.9620189905047476,
      "grad_norm": 1.2664393186569214,
      "learning_rate": 4.5191154422788604e-05,
      "loss": 0.0083,
      "step": 3850
    },
    {
      "epoch": 0.974512743628186,
      "grad_norm": 2.8100953102111816,
      "learning_rate": 4.512868565717141e-05,
      "loss": 0.0088,
      "step": 3900
    },
    {
      "epoch": 0.9870064967516242,
      "grad_norm": 2.5937249660491943,
      "learning_rate": 4.506621689155423e-05,
      "loss": 0.007,
      "step": 3950
    },
    {
      "epoch": 0.9995002498750625,
      "grad_norm": 1.6043825149536133,
      "learning_rate": 4.500374812593704e-05,
      "loss": 0.0073,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.007149092853069305,
      "eval_runtime": 2.7459,
      "eval_samples_per_second": 586.323,
      "eval_steps_per_second": 73.564,
      "step": 4002
    },
    {
      "epoch": 1.0119940029985008,
      "grad_norm": 2.261805534362793,
      "learning_rate": 4.4941279360319846e-05,
      "loss": 0.0089,
      "step": 4050
    },
    {
      "epoch": 1.024487756121939,
      "grad_norm": 0.9935632944107056,
      "learning_rate": 4.4878810594702654e-05,
      "loss": 0.0076,
      "step": 4100
    },
    {
      "epoch": 1.0369815092453774,
      "grad_norm": 3.394289016723633,
      "learning_rate": 4.481634182908546e-05,
      "loss": 0.0075,
      "step": 4150
    },
    {
      "epoch": 1.0494752623688155,
      "grad_norm": 2.7446093559265137,
      "learning_rate": 4.4753873063468265e-05,
      "loss": 0.0092,
      "step": 4200
    },
    {
      "epoch": 1.0619690154922539,
      "grad_norm": 1.7840230464935303,
      "learning_rate": 4.4691404297851074e-05,
      "loss": 0.0182,
      "step": 4250
    },
    {
      "epoch": 1.0744627686156922,
      "grad_norm": 0.33769553899765015,
      "learning_rate": 4.462893553223388e-05,
      "loss": 0.0087,
      "step": 4300
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 2.3640336990356445,
      "learning_rate": 4.456646676661669e-05,
      "loss": 0.0069,
      "step": 4350
    },
    {
      "epoch": 1.0994502748625687,
      "grad_norm": 0.9695983529090881,
      "learning_rate": 4.45039980009995e-05,
      "loss": 0.0076,
      "step": 4400
    },
    {
      "epoch": 1.111944027986007,
      "grad_norm": 1.4596434831619263,
      "learning_rate": 4.4441529235382315e-05,
      "loss": 0.0087,
      "step": 4450
    },
    {
      "epoch": 1.1244377811094453,
      "grad_norm": 1.1148813962936401,
      "learning_rate": 4.4379060469765124e-05,
      "loss": 0.0074,
      "step": 4500
    },
    {
      "epoch": 1.1369315342328836,
      "grad_norm": 0.5761957764625549,
      "learning_rate": 4.431659170414793e-05,
      "loss": 0.0064,
      "step": 4550
    },
    {
      "epoch": 1.1494252873563218,
      "grad_norm": 2.9781947135925293,
      "learning_rate": 4.4254122938530734e-05,
      "loss": 0.0066,
      "step": 4600
    },
    {
      "epoch": 1.1619190404797601,
      "grad_norm": 1.8655775785446167,
      "learning_rate": 4.419165417291354e-05,
      "loss": 0.0054,
      "step": 4650
    },
    {
      "epoch": 1.1744127936031985,
      "grad_norm": 0.2816058099269867,
      "learning_rate": 4.412918540729635e-05,
      "loss": 0.0238,
      "step": 4700
    },
    {
      "epoch": 1.1869065467266366,
      "grad_norm": 0.5050441026687622,
      "learning_rate": 4.406671664167916e-05,
      "loss": 0.0078,
      "step": 4750
    },
    {
      "epoch": 1.199400299850075,
      "grad_norm": 0.7940661907196045,
      "learning_rate": 4.400424787606197e-05,
      "loss": 0.007,
      "step": 4800
    },
    {
      "epoch": 1.2118940529735132,
      "grad_norm": 0.3668041527271271,
      "learning_rate": 4.394177911044478e-05,
      "loss": 0.0056,
      "step": 4850
    },
    {
      "epoch": 1.2243878060969515,
      "grad_norm": 0.44042888283729553,
      "learning_rate": 4.387931034482759e-05,
      "loss": 0.0068,
      "step": 4900
    },
    {
      "epoch": 1.23688155922039,
      "grad_norm": 1.7501776218414307,
      "learning_rate": 4.38168415792104e-05,
      "loss": 0.0058,
      "step": 4950
    },
    {
      "epoch": 1.249375312343828,
      "grad_norm": 0.35300490260124207,
      "learning_rate": 4.3754372813593204e-05,
      "loss": 0.0151,
      "step": 5000
    },
    {
      "epoch": 1.2618690654672664,
      "grad_norm": 0.5901088118553162,
      "learning_rate": 4.369190404797601e-05,
      "loss": 0.0068,
      "step": 5050
    },
    {
      "epoch": 1.2743628185907045,
      "grad_norm": 3.8506414890289307,
      "learning_rate": 4.362943528235882e-05,
      "loss": 0.0157,
      "step": 5100
    },
    {
      "epoch": 1.286856571714143,
      "grad_norm": 1.830001950263977,
      "learning_rate": 4.356696651674163e-05,
      "loss": 0.0077,
      "step": 5150
    },
    {
      "epoch": 1.2993503248375813,
      "grad_norm": 2.0049993991851807,
      "learning_rate": 4.350449775112444e-05,
      "loss": 0.0057,
      "step": 5200
    },
    {
      "epoch": 1.3118440779610194,
      "grad_norm": 1.32647705078125,
      "learning_rate": 4.344202898550725e-05,
      "loss": 0.0077,
      "step": 5250
    },
    {
      "epoch": 1.3243378310844578,
      "grad_norm": 1.1246845722198486,
      "learning_rate": 4.3379560219890056e-05,
      "loss": 0.0068,
      "step": 5300
    },
    {
      "epoch": 1.336831584207896,
      "grad_norm": 0.6418613195419312,
      "learning_rate": 4.331709145427287e-05,
      "loss": 0.0047,
      "step": 5350
    },
    {
      "epoch": 1.3493253373313343,
      "grad_norm": 0.4619443416595459,
      "learning_rate": 4.325462268865567e-05,
      "loss": 0.0053,
      "step": 5400
    },
    {
      "epoch": 1.3618190904547727,
      "grad_norm": 0.7802700996398926,
      "learning_rate": 4.319215392303848e-05,
      "loss": 0.0068,
      "step": 5450
    },
    {
      "epoch": 1.3743128435782108,
      "grad_norm": 1.031113862991333,
      "learning_rate": 4.312968515742129e-05,
      "loss": 0.0056,
      "step": 5500
    },
    {
      "epoch": 1.3868065967016492,
      "grad_norm": 0.4140602946281433,
      "learning_rate": 4.30672163918041e-05,
      "loss": 0.0052,
      "step": 5550
    },
    {
      "epoch": 1.3993003498250873,
      "grad_norm": 0.49785518646240234,
      "learning_rate": 4.300474762618691e-05,
      "loss": 0.005,
      "step": 5600
    },
    {
      "epoch": 1.4117941029485257,
      "grad_norm": 2.862901210784912,
      "learning_rate": 4.2942278860569717e-05,
      "loss": 0.007,
      "step": 5650
    },
    {
      "epoch": 1.424287856071964,
      "grad_norm": 1.3966909646987915,
      "learning_rate": 4.2879810094952525e-05,
      "loss": 0.0061,
      "step": 5700
    },
    {
      "epoch": 1.4367816091954024,
      "grad_norm": 0.5831520557403564,
      "learning_rate": 4.2817341329335334e-05,
      "loss": 0.005,
      "step": 5750
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 1.179548740386963,
      "learning_rate": 4.275487256371814e-05,
      "loss": 0.0062,
      "step": 5800
    },
    {
      "epoch": 1.461769115442279,
      "grad_norm": 0.45467105507850647,
      "learning_rate": 4.269240379810095e-05,
      "loss": 0.0065,
      "step": 5850
    },
    {
      "epoch": 1.474262868565717,
      "grad_norm": 1.4755946397781372,
      "learning_rate": 4.262993503248376e-05,
      "loss": 0.0078,
      "step": 5900
    },
    {
      "epoch": 1.4867566216891555,
      "grad_norm": 0.3905999958515167,
      "learning_rate": 4.256746626686657e-05,
      "loss": 0.0057,
      "step": 5950
    },
    {
      "epoch": 1.4992503748125938,
      "grad_norm": 0.5759466290473938,
      "learning_rate": 4.250499750124938e-05,
      "loss": 0.0049,
      "step": 6000
    },
    {
      "epoch": 1.511744127936032,
      "grad_norm": 0.6852695941925049,
      "learning_rate": 4.2442528735632186e-05,
      "loss": 0.0045,
      "step": 6050
    },
    {
      "epoch": 1.5242378810594701,
      "grad_norm": 0.9512091875076294,
      "learning_rate": 4.2380059970014995e-05,
      "loss": 0.0043,
      "step": 6100
    },
    {
      "epoch": 1.5367316341829085,
      "grad_norm": 0.44135308265686035,
      "learning_rate": 4.23175912043978e-05,
      "loss": 0.0052,
      "step": 6150
    },
    {
      "epoch": 1.5492253873063468,
      "grad_norm": 1.104840636253357,
      "learning_rate": 4.225512243878061e-05,
      "loss": 0.0138,
      "step": 6200
    },
    {
      "epoch": 1.5617191404297852,
      "grad_norm": 0.7042425274848938,
      "learning_rate": 4.219265367316342e-05,
      "loss": 0.0077,
      "step": 6250
    },
    {
      "epoch": 1.5742128935532234,
      "grad_norm": 0.5532925724983215,
      "learning_rate": 4.213018490754623e-05,
      "loss": 0.0047,
      "step": 6300
    },
    {
      "epoch": 1.5867066466766615,
      "grad_norm": 0.8350709676742554,
      "learning_rate": 4.206771614192904e-05,
      "loss": 0.013,
      "step": 6350
    },
    {
      "epoch": 1.5992003998000999,
      "grad_norm": 0.9690572023391724,
      "learning_rate": 4.200524737631185e-05,
      "loss": 0.0045,
      "step": 6400
    },
    {
      "epoch": 1.6116941529235382,
      "grad_norm": 1.6346694231033325,
      "learning_rate": 4.1942778610694655e-05,
      "loss": 0.0053,
      "step": 6450
    },
    {
      "epoch": 1.6241879060469766,
      "grad_norm": 1.458579659461975,
      "learning_rate": 4.1880309845077464e-05,
      "loss": 0.0053,
      "step": 6500
    },
    {
      "epoch": 1.6366816591704147,
      "grad_norm": 2.574336528778076,
      "learning_rate": 4.181784107946027e-05,
      "loss": 0.0058,
      "step": 6550
    },
    {
      "epoch": 1.6491754122938531,
      "grad_norm": 0.22699251770973206,
      "learning_rate": 4.175537231384308e-05,
      "loss": 0.0136,
      "step": 6600
    },
    {
      "epoch": 1.6616691654172913,
      "grad_norm": 1.979857325553894,
      "learning_rate": 4.169290354822589e-05,
      "loss": 0.007,
      "step": 6650
    },
    {
      "epoch": 1.6741629185407296,
      "grad_norm": 1.7310863733291626,
      "learning_rate": 4.16304347826087e-05,
      "loss": 0.0055,
      "step": 6700
    },
    {
      "epoch": 1.686656671664168,
      "grad_norm": 0.4305567145347595,
      "learning_rate": 4.156796601699151e-05,
      "loss": 0.0051,
      "step": 6750
    },
    {
      "epoch": 1.6991504247876064,
      "grad_norm": 0.6674104928970337,
      "learning_rate": 4.1505497251374316e-05,
      "loss": 0.0069,
      "step": 6800
    },
    {
      "epoch": 1.7116441779110445,
      "grad_norm": 2.4113688468933105,
      "learning_rate": 4.1443028485757125e-05,
      "loss": 0.0046,
      "step": 6850
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.9410276412963867,
      "learning_rate": 4.1380559720139933e-05,
      "loss": 0.0063,
      "step": 6900
    },
    {
      "epoch": 1.736631684157921,
      "grad_norm": 2.449333906173706,
      "learning_rate": 4.131809095452274e-05,
      "loss": 0.0055,
      "step": 6950
    },
    {
      "epoch": 1.7491254372813594,
      "grad_norm": 0.7450024485588074,
      "learning_rate": 4.125562218890555e-05,
      "loss": 0.0056,
      "step": 7000
    },
    {
      "epoch": 1.7616191904047978,
      "grad_norm": 1.4529714584350586,
      "learning_rate": 4.119315342328835e-05,
      "loss": 0.0051,
      "step": 7050
    },
    {
      "epoch": 1.774112943528236,
      "grad_norm": 1.1974622011184692,
      "learning_rate": 4.113068465767116e-05,
      "loss": 0.0143,
      "step": 7100
    },
    {
      "epoch": 1.786606696651674,
      "grad_norm": 0.42269402742385864,
      "learning_rate": 4.106821589205398e-05,
      "loss": 0.0056,
      "step": 7150
    },
    {
      "epoch": 1.7991004497751124,
      "grad_norm": 1.4024074077606201,
      "learning_rate": 4.1005747126436786e-05,
      "loss": 0.0058,
      "step": 7200
    },
    {
      "epoch": 1.8115942028985508,
      "grad_norm": 1.148937702178955,
      "learning_rate": 4.0943278360819594e-05,
      "loss": 0.0132,
      "step": 7250
    },
    {
      "epoch": 1.8240879560219891,
      "grad_norm": 0.47474828362464905,
      "learning_rate": 4.08808095952024e-05,
      "loss": 0.0037,
      "step": 7300
    },
    {
      "epoch": 1.8365817091454273,
      "grad_norm": 1.4606823921203613,
      "learning_rate": 4.081834082958521e-05,
      "loss": 0.0036,
      "step": 7350
    },
    {
      "epoch": 1.8490754622688654,
      "grad_norm": 0.19062720239162445,
      "learning_rate": 4.075587206396802e-05,
      "loss": 0.0038,
      "step": 7400
    },
    {
      "epoch": 1.8615692153923038,
      "grad_norm": 1.6398369073867798,
      "learning_rate": 4.069340329835082e-05,
      "loss": 0.0043,
      "step": 7450
    },
    {
      "epoch": 1.8740629685157422,
      "grad_norm": 0.47065332531929016,
      "learning_rate": 4.063093453273363e-05,
      "loss": 0.0127,
      "step": 7500
    },
    {
      "epoch": 1.8865567216391805,
      "grad_norm": 0.5316793322563171,
      "learning_rate": 4.056846576711644e-05,
      "loss": 0.0034,
      "step": 7550
    },
    {
      "epoch": 1.8990504747626187,
      "grad_norm": 2.0938172340393066,
      "learning_rate": 4.0505997001499255e-05,
      "loss": 0.0051,
      "step": 7600
    },
    {
      "epoch": 1.9115442278860568,
      "grad_norm": 0.4372985064983368,
      "learning_rate": 4.0443528235882064e-05,
      "loss": 0.0043,
      "step": 7650
    },
    {
      "epoch": 1.9240379810094952,
      "grad_norm": 1.1568485498428345,
      "learning_rate": 4.038105947026487e-05,
      "loss": 0.0045,
      "step": 7700
    },
    {
      "epoch": 1.9365317341329336,
      "grad_norm": 0.9622429013252258,
      "learning_rate": 4.031859070464768e-05,
      "loss": 0.0038,
      "step": 7750
    },
    {
      "epoch": 1.949025487256372,
      "grad_norm": 0.9094247221946716,
      "learning_rate": 4.025612193903049e-05,
      "loss": 0.0042,
      "step": 7800
    },
    {
      "epoch": 1.96151924037981,
      "grad_norm": 1.2414062023162842,
      "learning_rate": 4.019365317341329e-05,
      "loss": 0.0035,
      "step": 7850
    },
    {
      "epoch": 1.9740129935032482,
      "grad_norm": 0.5933390259742737,
      "learning_rate": 4.01311844077961e-05,
      "loss": 0.0135,
      "step": 7900
    },
    {
      "epoch": 1.9865067466266866,
      "grad_norm": 1.8463411331176758,
      "learning_rate": 4.006871564217891e-05,
      "loss": 0.0038,
      "step": 7950
    },
    {
      "epoch": 1.999000499750125,
      "grad_norm": 0.5901612043380737,
      "learning_rate": 4.000624687656172e-05,
      "loss": 0.0048,
      "step": 8000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0027881888672709465,
      "eval_runtime": 2.7546,
      "eval_samples_per_second": 584.468,
      "eval_steps_per_second": 73.331,
      "step": 8004
    },
    {
      "epoch": 2.0114942528735633,
      "grad_norm": 2.110703229904175,
      "learning_rate": 3.9943778110944526e-05,
      "loss": 0.0045,
      "step": 8050
    },
    {
      "epoch": 2.0239880059970017,
      "grad_norm": 1.3177490234375,
      "learning_rate": 3.988130934532734e-05,
      "loss": 0.0034,
      "step": 8100
    },
    {
      "epoch": 2.0364817591204396,
      "grad_norm": 1.9390496015548706,
      "learning_rate": 3.981884057971015e-05,
      "loss": 0.0036,
      "step": 8150
    },
    {
      "epoch": 2.048975512243878,
      "grad_norm": 1.5528302192687988,
      "learning_rate": 3.975637181409296e-05,
      "loss": 0.0064,
      "step": 8200
    },
    {
      "epoch": 2.0614692653673163,
      "grad_norm": 0.4489792585372925,
      "learning_rate": 3.969390304847577e-05,
      "loss": 0.0035,
      "step": 8250
    },
    {
      "epoch": 2.0739630184907547,
      "grad_norm": 0.5247868299484253,
      "learning_rate": 3.963143428285857e-05,
      "loss": 0.004,
      "step": 8300
    },
    {
      "epoch": 2.086456771614193,
      "grad_norm": 0.5876080393791199,
      "learning_rate": 3.956896551724138e-05,
      "loss": 0.0051,
      "step": 8350
    },
    {
      "epoch": 2.098950524737631,
      "grad_norm": 0.8317049741744995,
      "learning_rate": 3.950649675162419e-05,
      "loss": 0.0037,
      "step": 8400
    },
    {
      "epoch": 2.1114442778610694,
      "grad_norm": 1.1913264989852905,
      "learning_rate": 3.9444027986006996e-05,
      "loss": 0.0114,
      "step": 8450
    },
    {
      "epoch": 2.1239380309845077,
      "grad_norm": 0.3660529553890228,
      "learning_rate": 3.9381559220389804e-05,
      "loss": 0.003,
      "step": 8500
    },
    {
      "epoch": 2.136431784107946,
      "grad_norm": 1.24347984790802,
      "learning_rate": 3.931909045477262e-05,
      "loss": 0.0031,
      "step": 8550
    },
    {
      "epoch": 2.1489255372313845,
      "grad_norm": 0.4590812921524048,
      "learning_rate": 3.925662168915543e-05,
      "loss": 0.0034,
      "step": 8600
    },
    {
      "epoch": 2.1614192903548224,
      "grad_norm": 10.862173080444336,
      "learning_rate": 3.919415292353824e-05,
      "loss": 0.0133,
      "step": 8650
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.6683733463287354,
      "learning_rate": 3.913168415792104e-05,
      "loss": 0.0038,
      "step": 8700
    },
    {
      "epoch": 2.186406796601699,
      "grad_norm": 0.8068392872810364,
      "learning_rate": 3.906921539230385e-05,
      "loss": 0.0033,
      "step": 8750
    },
    {
      "epoch": 2.1989005497251375,
      "grad_norm": 0.5808517932891846,
      "learning_rate": 3.9006746626686657e-05,
      "loss": 0.0034,
      "step": 8800
    },
    {
      "epoch": 2.211394302848576,
      "grad_norm": 2.0403354167938232,
      "learning_rate": 3.8944277861069465e-05,
      "loss": 0.005,
      "step": 8850
    },
    {
      "epoch": 2.223888055972014,
      "grad_norm": 0.6614881157875061,
      "learning_rate": 3.8881809095452274e-05,
      "loss": 0.0032,
      "step": 8900
    },
    {
      "epoch": 2.236381809095452,
      "grad_norm": 1.0152533054351807,
      "learning_rate": 3.881934032983508e-05,
      "loss": 0.0039,
      "step": 8950
    },
    {
      "epoch": 2.2488755622188905,
      "grad_norm": 0.29711928963661194,
      "learning_rate": 3.87568715642179e-05,
      "loss": 0.0047,
      "step": 9000
    },
    {
      "epoch": 2.261369315342329,
      "grad_norm": 0.8475896120071411,
      "learning_rate": 3.869440279860071e-05,
      "loss": 0.0038,
      "step": 9050
    },
    {
      "epoch": 2.2738630684657672,
      "grad_norm": 0.9723670482635498,
      "learning_rate": 3.863193403298351e-05,
      "loss": 0.0041,
      "step": 9100
    },
    {
      "epoch": 2.286356821589205,
      "grad_norm": 0.7497878670692444,
      "learning_rate": 3.856946526736632e-05,
      "loss": 0.0135,
      "step": 9150
    },
    {
      "epoch": 2.2988505747126435,
      "grad_norm": 1.43092679977417,
      "learning_rate": 3.8506996501749126e-05,
      "loss": 0.004,
      "step": 9200
    },
    {
      "epoch": 2.311344327836082,
      "grad_norm": 2.039660930633545,
      "learning_rate": 3.8444527736131935e-05,
      "loss": 0.0027,
      "step": 9250
    },
    {
      "epoch": 2.3238380809595203,
      "grad_norm": 0.7958629131317139,
      "learning_rate": 3.838205897051474e-05,
      "loss": 0.0109,
      "step": 9300
    },
    {
      "epoch": 2.3363318340829586,
      "grad_norm": 1.3751217126846313,
      "learning_rate": 3.831959020489755e-05,
      "loss": 0.0053,
      "step": 9350
    },
    {
      "epoch": 2.348825587206397,
      "grad_norm": 0.5057019591331482,
      "learning_rate": 3.825712143928036e-05,
      "loss": 0.0038,
      "step": 9400
    },
    {
      "epoch": 2.361319340329835,
      "grad_norm": 0.6358141303062439,
      "learning_rate": 3.819465267366317e-05,
      "loss": 0.0029,
      "step": 9450
    },
    {
      "epoch": 2.3738130934532733,
      "grad_norm": 0.44129103422164917,
      "learning_rate": 3.813218390804598e-05,
      "loss": 0.004,
      "step": 9500
    },
    {
      "epoch": 2.3863068465767117,
      "grad_norm": 1.0424126386642456,
      "learning_rate": 3.806971514242879e-05,
      "loss": 0.0035,
      "step": 9550
    },
    {
      "epoch": 2.39880059970015,
      "grad_norm": 0.4789566397666931,
      "learning_rate": 3.8007246376811595e-05,
      "loss": 0.0049,
      "step": 9600
    },
    {
      "epoch": 2.4112943528235884,
      "grad_norm": 0.3429378867149353,
      "learning_rate": 3.7944777611194404e-05,
      "loss": 0.0031,
      "step": 9650
    },
    {
      "epoch": 2.4237881059470263,
      "grad_norm": 2.687239408493042,
      "learning_rate": 3.788230884557721e-05,
      "loss": 0.005,
      "step": 9700
    },
    {
      "epoch": 2.4362818590704647,
      "grad_norm": 0.780177652835846,
      "learning_rate": 3.781984007996002e-05,
      "loss": 0.0046,
      "step": 9750
    },
    {
      "epoch": 2.448775612193903,
      "grad_norm": 1.7584015130996704,
      "learning_rate": 3.775737131434283e-05,
      "loss": 0.0141,
      "step": 9800
    },
    {
      "epoch": 2.4612693653173414,
      "grad_norm": 0.41670626401901245,
      "learning_rate": 3.769490254872564e-05,
      "loss": 0.0049,
      "step": 9850
    },
    {
      "epoch": 2.47376311844078,
      "grad_norm": 0.355093389749527,
      "learning_rate": 3.763243378310845e-05,
      "loss": 0.0037,
      "step": 9900
    },
    {
      "epoch": 2.4862568715642177,
      "grad_norm": 0.45728036761283875,
      "learning_rate": 3.7569965017491256e-05,
      "loss": 0.0116,
      "step": 9950
    },
    {
      "epoch": 2.498750624687656,
      "grad_norm": 0.4358747601509094,
      "learning_rate": 3.7507496251874065e-05,
      "loss": 0.0114,
      "step": 10000
    },
    {
      "epoch": 2.5112443778110944,
      "grad_norm": 0.6014099717140198,
      "learning_rate": 3.7445027486256874e-05,
      "loss": 0.0032,
      "step": 10050
    },
    {
      "epoch": 2.523738130934533,
      "grad_norm": 0.3647141754627228,
      "learning_rate": 3.738255872063968e-05,
      "loss": 0.0029,
      "step": 10100
    },
    {
      "epoch": 2.536231884057971,
      "grad_norm": 0.5184563398361206,
      "learning_rate": 3.732008995502249e-05,
      "loss": 0.0036,
      "step": 10150
    },
    {
      "epoch": 2.548725637181409,
      "grad_norm": 0.5529182553291321,
      "learning_rate": 3.72576211894053e-05,
      "loss": 0.0026,
      "step": 10200
    },
    {
      "epoch": 2.5612193903048475,
      "grad_norm": 0.5068908929824829,
      "learning_rate": 3.719515242378811e-05,
      "loss": 0.0129,
      "step": 10250
    },
    {
      "epoch": 2.573713143428286,
      "grad_norm": 0.6751011610031128,
      "learning_rate": 3.713268365817092e-05,
      "loss": 0.0034,
      "step": 10300
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 1.0544683933258057,
      "learning_rate": 3.7070214892553726e-05,
      "loss": 0.0036,
      "step": 10350
    },
    {
      "epoch": 2.5987006496751626,
      "grad_norm": 0.723371684551239,
      "learning_rate": 3.7007746126936534e-05,
      "loss": 0.0029,
      "step": 10400
    },
    {
      "epoch": 2.611194402798601,
      "grad_norm": 0.35819119215011597,
      "learning_rate": 3.694527736131934e-05,
      "loss": 0.0021,
      "step": 10450
    },
    {
      "epoch": 2.623688155922039,
      "grad_norm": 0.9663382768630981,
      "learning_rate": 3.688280859570215e-05,
      "loss": 0.0023,
      "step": 10500
    },
    {
      "epoch": 2.6361819090454772,
      "grad_norm": 0.41533592343330383,
      "learning_rate": 3.682033983008496e-05,
      "loss": 0.0039,
      "step": 10550
    },
    {
      "epoch": 2.6486756621689156,
      "grad_norm": 0.21763180196285248,
      "learning_rate": 3.675787106446777e-05,
      "loss": 0.01,
      "step": 10600
    },
    {
      "epoch": 2.661169415292354,
      "grad_norm": 0.7744922637939453,
      "learning_rate": 3.669540229885058e-05,
      "loss": 0.003,
      "step": 10650
    },
    {
      "epoch": 2.673663168415792,
      "grad_norm": 0.26243239641189575,
      "learning_rate": 3.6632933533233386e-05,
      "loss": 0.003,
      "step": 10700
    },
    {
      "epoch": 2.6861569215392302,
      "grad_norm": 0.5429682731628418,
      "learning_rate": 3.657046476761619e-05,
      "loss": 0.0033,
      "step": 10750
    },
    {
      "epoch": 2.6986506746626686,
      "grad_norm": 0.2720491290092468,
      "learning_rate": 3.6507996001999004e-05,
      "loss": 0.0041,
      "step": 10800
    },
    {
      "epoch": 2.711144427786107,
      "grad_norm": 0.31106317043304443,
      "learning_rate": 3.644552723638181e-05,
      "loss": 0.003,
      "step": 10850
    },
    {
      "epoch": 2.7236381809095453,
      "grad_norm": 1.5165534019470215,
      "learning_rate": 3.638305847076462e-05,
      "loss": 0.0031,
      "step": 10900
    },
    {
      "epoch": 2.7361319340329837,
      "grad_norm": 0.663182258605957,
      "learning_rate": 3.632058970514743e-05,
      "loss": 0.0026,
      "step": 10950
    },
    {
      "epoch": 2.7486256871564216,
      "grad_norm": 0.704440176486969,
      "learning_rate": 3.625812093953024e-05,
      "loss": 0.0031,
      "step": 11000
    },
    {
      "epoch": 2.76111944027986,
      "grad_norm": 1.5029302835464478,
      "learning_rate": 3.619565217391305e-05,
      "loss": 0.0043,
      "step": 11050
    },
    {
      "epoch": 2.7736131934032984,
      "grad_norm": 2.6205971240997314,
      "learning_rate": 3.6133183408295856e-05,
      "loss": 0.003,
      "step": 11100
    },
    {
      "epoch": 2.7861069465267367,
      "grad_norm": 0.488799512386322,
      "learning_rate": 3.607071464267866e-05,
      "loss": 0.0039,
      "step": 11150
    },
    {
      "epoch": 2.7986006996501747,
      "grad_norm": 0.6691004633903503,
      "learning_rate": 3.6008245877061466e-05,
      "loss": 0.0026,
      "step": 11200
    },
    {
      "epoch": 2.811094452773613,
      "grad_norm": 0.8262212872505188,
      "learning_rate": 3.594577711144428e-05,
      "loss": 0.0024,
      "step": 11250
    },
    {
      "epoch": 2.8235882058970514,
      "grad_norm": 0.2953413128852844,
      "learning_rate": 3.588330834582709e-05,
      "loss": 0.0036,
      "step": 11300
    },
    {
      "epoch": 2.8360819590204898,
      "grad_norm": 0.3664480149745941,
      "learning_rate": 3.58208395802099e-05,
      "loss": 0.0032,
      "step": 11350
    },
    {
      "epoch": 2.848575712143928,
      "grad_norm": 0.17517973482608795,
      "learning_rate": 3.575837081459271e-05,
      "loss": 0.0199,
      "step": 11400
    },
    {
      "epoch": 2.8610694652673665,
      "grad_norm": 1.3166871070861816,
      "learning_rate": 3.5695902048975517e-05,
      "loss": 0.0036,
      "step": 11450
    },
    {
      "epoch": 2.873563218390805,
      "grad_norm": 0.19056953489780426,
      "learning_rate": 3.5633433283358325e-05,
      "loss": 0.0026,
      "step": 11500
    },
    {
      "epoch": 2.886056971514243,
      "grad_norm": 0.8186119198799133,
      "learning_rate": 3.557096451774113e-05,
      "loss": 0.0042,
      "step": 11550
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 1.1452590227127075,
      "learning_rate": 3.5508495752123936e-05,
      "loss": 0.0028,
      "step": 11600
    },
    {
      "epoch": 2.9110444777611195,
      "grad_norm": 0.5051024556159973,
      "learning_rate": 3.5446026986506744e-05,
      "loss": 0.003,
      "step": 11650
    },
    {
      "epoch": 2.923538230884558,
      "grad_norm": 0.45269548892974854,
      "learning_rate": 3.538355822088956e-05,
      "loss": 0.0024,
      "step": 11700
    },
    {
      "epoch": 2.936031984007996,
      "grad_norm": 0.9127236604690552,
      "learning_rate": 3.532108945527237e-05,
      "loss": 0.0035,
      "step": 11750
    },
    {
      "epoch": 2.948525737131434,
      "grad_norm": 0.6780264973640442,
      "learning_rate": 3.525862068965518e-05,
      "loss": 0.003,
      "step": 11800
    },
    {
      "epoch": 2.9610194902548725,
      "grad_norm": 1.0034399032592773,
      "learning_rate": 3.5196151924037986e-05,
      "loss": 0.0109,
      "step": 11850
    },
    {
      "epoch": 2.973513243378311,
      "grad_norm": 0.2643139064311981,
      "learning_rate": 3.5133683158420795e-05,
      "loss": 0.0022,
      "step": 11900
    },
    {
      "epoch": 2.9860069965017493,
      "grad_norm": 0.21657292544841766,
      "learning_rate": 3.5071214392803597e-05,
      "loss": 0.0031,
      "step": 11950
    },
    {
      "epoch": 2.9985007496251876,
      "grad_norm": 0.6518586277961731,
      "learning_rate": 3.5008745627186405e-05,
      "loss": 0.0019,
      "step": 12000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0024946408811956644,
      "eval_runtime": 2.7626,
      "eval_samples_per_second": 582.787,
      "eval_steps_per_second": 73.12,
      "step": 12006
    },
    {
      "epoch": 3.0109945027486256,
      "grad_norm": 0.7763864398002625,
      "learning_rate": 3.4946276861569214e-05,
      "loss": 0.0021,
      "step": 12050
    },
    {
      "epoch": 3.023488255872064,
      "grad_norm": 1.2040084600448608,
      "learning_rate": 3.488380809595202e-05,
      "loss": 0.0018,
      "step": 12100
    },
    {
      "epoch": 3.0359820089955023,
      "grad_norm": 0.7883752584457397,
      "learning_rate": 3.482133933033483e-05,
      "loss": 0.0022,
      "step": 12150
    },
    {
      "epoch": 3.0484757621189407,
      "grad_norm": 0.989355742931366,
      "learning_rate": 3.475887056471765e-05,
      "loss": 0.0049,
      "step": 12200
    },
    {
      "epoch": 3.0609695152423786,
      "grad_norm": 0.8813035488128662,
      "learning_rate": 3.4696401799100455e-05,
      "loss": 0.0037,
      "step": 12250
    },
    {
      "epoch": 3.073463268365817,
      "grad_norm": 1.7592684030532837,
      "learning_rate": 3.4633933033483264e-05,
      "loss": 0.0026,
      "step": 12300
    },
    {
      "epoch": 3.0859570214892553,
      "grad_norm": 1.0881154537200928,
      "learning_rate": 3.4571464267866066e-05,
      "loss": 0.0033,
      "step": 12350
    },
    {
      "epoch": 3.0984507746126937,
      "grad_norm": 0.8270717859268188,
      "learning_rate": 3.4508995502248875e-05,
      "loss": 0.0032,
      "step": 12400
    },
    {
      "epoch": 3.110944527736132,
      "grad_norm": 0.2692236602306366,
      "learning_rate": 3.444652673663168e-05,
      "loss": 0.0021,
      "step": 12450
    },
    {
      "epoch": 3.1234382808595704,
      "grad_norm": 0.7797172665596008,
      "learning_rate": 3.438405797101449e-05,
      "loss": 0.0025,
      "step": 12500
    },
    {
      "epoch": 3.1359320339830083,
      "grad_norm": 0.14700311422348022,
      "learning_rate": 3.43215892053973e-05,
      "loss": 0.0032,
      "step": 12550
    },
    {
      "epoch": 3.1484257871064467,
      "grad_norm": 0.23413382470607758,
      "learning_rate": 3.425912043978011e-05,
      "loss": 0.0028,
      "step": 12600
    },
    {
      "epoch": 3.160919540229885,
      "grad_norm": 0.5794180035591125,
      "learning_rate": 3.4196651674162925e-05,
      "loss": 0.002,
      "step": 12650
    },
    {
      "epoch": 3.1734132933533234,
      "grad_norm": 0.4195002615451813,
      "learning_rate": 3.4134182908545733e-05,
      "loss": 0.0023,
      "step": 12700
    },
    {
      "epoch": 3.185907046476762,
      "grad_norm": 0.5761920809745789,
      "learning_rate": 3.4071714142928535e-05,
      "loss": 0.0038,
      "step": 12750
    },
    {
      "epoch": 3.1984007996001997,
      "grad_norm": 0.6406518220901489,
      "learning_rate": 3.4009245377311344e-05,
      "loss": 0.0033,
      "step": 12800
    },
    {
      "epoch": 3.210894552723638,
      "grad_norm": 0.4754709005355835,
      "learning_rate": 3.394677661169415e-05,
      "loss": 0.0019,
      "step": 12850
    },
    {
      "epoch": 3.2233883058470765,
      "grad_norm": 0.7894298434257507,
      "learning_rate": 3.388430784607696e-05,
      "loss": 0.0026,
      "step": 12900
    },
    {
      "epoch": 3.235882058970515,
      "grad_norm": 0.39113688468933105,
      "learning_rate": 3.382183908045977e-05,
      "loss": 0.0026,
      "step": 12950
    },
    {
      "epoch": 3.248375812093953,
      "grad_norm": 0.48459282517433167,
      "learning_rate": 3.375937031484258e-05,
      "loss": 0.0026,
      "step": 13000
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 0.8394240736961365,
      "learning_rate": 3.369690154922539e-05,
      "loss": 0.0028,
      "step": 13050
    },
    {
      "epoch": 3.2733633183408295,
      "grad_norm": 0.7180854082107544,
      "learning_rate": 3.36344327836082e-05,
      "loss": 0.003,
      "step": 13100
    },
    {
      "epoch": 3.285857071464268,
      "grad_norm": 0.336820513010025,
      "learning_rate": 3.357196401799101e-05,
      "loss": 0.0021,
      "step": 13150
    },
    {
      "epoch": 3.2983508245877062,
      "grad_norm": 0.4079352915287018,
      "learning_rate": 3.3509495252373814e-05,
      "loss": 0.0025,
      "step": 13200
    },
    {
      "epoch": 3.3108445777111446,
      "grad_norm": 0.6905260682106018,
      "learning_rate": 3.344702648675662e-05,
      "loss": 0.011,
      "step": 13250
    },
    {
      "epoch": 3.3233383308345825,
      "grad_norm": 0.16048766672611237,
      "learning_rate": 3.338455772113943e-05,
      "loss": 0.0021,
      "step": 13300
    },
    {
      "epoch": 3.335832083958021,
      "grad_norm": 0.4227273166179657,
      "learning_rate": 3.332208895552224e-05,
      "loss": 0.0024,
      "step": 13350
    },
    {
      "epoch": 3.3483258370814593,
      "grad_norm": 0.19814106822013855,
      "learning_rate": 3.325962018990505e-05,
      "loss": 0.0018,
      "step": 13400
    },
    {
      "epoch": 3.3608195902048976,
      "grad_norm": 0.15166983008384705,
      "learning_rate": 3.319715142428786e-05,
      "loss": 0.0017,
      "step": 13450
    },
    {
      "epoch": 3.373313343328336,
      "grad_norm": 0.25106915831565857,
      "learning_rate": 3.3134682658670666e-05,
      "loss": 0.0025,
      "step": 13500
    },
    {
      "epoch": 3.3858070964517744,
      "grad_norm": 0.39849796891212463,
      "learning_rate": 3.3072213893053474e-05,
      "loss": 0.002,
      "step": 13550
    },
    {
      "epoch": 3.3983008495752123,
      "grad_norm": 2.5109386444091797,
      "learning_rate": 3.300974512743628e-05,
      "loss": 0.0041,
      "step": 13600
    },
    {
      "epoch": 3.4107946026986506,
      "grad_norm": 0.5400182008743286,
      "learning_rate": 3.294727636181909e-05,
      "loss": 0.0035,
      "step": 13650
    },
    {
      "epoch": 3.423288355822089,
      "grad_norm": 0.19341127574443817,
      "learning_rate": 3.28848075962019e-05,
      "loss": 0.0023,
      "step": 13700
    },
    {
      "epoch": 3.4357821089455274,
      "grad_norm": 0.6206735968589783,
      "learning_rate": 3.282233883058471e-05,
      "loss": 0.0021,
      "step": 13750
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 0.6570516228675842,
      "learning_rate": 3.275987006496752e-05,
      "loss": 0.0027,
      "step": 13800
    },
    {
      "epoch": 3.4607696151924037,
      "grad_norm": 0.2741740942001343,
      "learning_rate": 3.2697401299350326e-05,
      "loss": 0.0018,
      "step": 13850
    },
    {
      "epoch": 3.473263368315842,
      "grad_norm": 0.8799149394035339,
      "learning_rate": 3.2634932533733135e-05,
      "loss": 0.0024,
      "step": 13900
    },
    {
      "epoch": 3.4857571214392804,
      "grad_norm": 0.8686944246292114,
      "learning_rate": 3.2572463768115944e-05,
      "loss": 0.0031,
      "step": 13950
    },
    {
      "epoch": 3.4982508745627188,
      "grad_norm": 0.26212266087532043,
      "learning_rate": 3.250999500249875e-05,
      "loss": 0.0129,
      "step": 14000
    },
    {
      "epoch": 3.510744627686157,
      "grad_norm": 0.5678194165229797,
      "learning_rate": 3.244752623688156e-05,
      "loss": 0.0022,
      "step": 14050
    },
    {
      "epoch": 3.523238380809595,
      "grad_norm": 0.3194292485713959,
      "learning_rate": 3.238505747126437e-05,
      "loss": 0.0032,
      "step": 14100
    },
    {
      "epoch": 3.5357321339330334,
      "grad_norm": 0.6224895119667053,
      "learning_rate": 3.232258870564718e-05,
      "loss": 0.0117,
      "step": 14150
    },
    {
      "epoch": 3.548225887056472,
      "grad_norm": 0.29384705424308777,
      "learning_rate": 3.226011994002999e-05,
      "loss": 0.0102,
      "step": 14200
    },
    {
      "epoch": 3.56071964017991,
      "grad_norm": 0.23347409069538116,
      "learning_rate": 3.2197651174412796e-05,
      "loss": 0.0024,
      "step": 14250
    },
    {
      "epoch": 3.573213393303348,
      "grad_norm": 0.31567737460136414,
      "learning_rate": 3.2135182408795604e-05,
      "loss": 0.0017,
      "step": 14300
    },
    {
      "epoch": 3.5857071464267865,
      "grad_norm": 0.2658277153968811,
      "learning_rate": 3.207271364317841e-05,
      "loss": 0.003,
      "step": 14350
    },
    {
      "epoch": 3.598200899550225,
      "grad_norm": 0.3993993401527405,
      "learning_rate": 3.201024487756122e-05,
      "loss": 0.002,
      "step": 14400
    },
    {
      "epoch": 3.610694652673663,
      "grad_norm": 0.507768988609314,
      "learning_rate": 3.194777611194403e-05,
      "loss": 0.0102,
      "step": 14450
    },
    {
      "epoch": 3.6231884057971016,
      "grad_norm": 0.35179799795150757,
      "learning_rate": 3.188530734632684e-05,
      "loss": 0.002,
      "step": 14500
    },
    {
      "epoch": 3.63568215892054,
      "grad_norm": 0.4665483832359314,
      "learning_rate": 3.182283858070965e-05,
      "loss": 0.0019,
      "step": 14550
    },
    {
      "epoch": 3.6481759120439783,
      "grad_norm": 0.15081684291362762,
      "learning_rate": 3.1760369815092457e-05,
      "loss": 0.002,
      "step": 14600
    },
    {
      "epoch": 3.660669665167416,
      "grad_norm": 0.4847014844417572,
      "learning_rate": 3.1697901049475265e-05,
      "loss": 0.0122,
      "step": 14650
    },
    {
      "epoch": 3.6731634182908546,
      "grad_norm": 0.9404488205909729,
      "learning_rate": 3.1635432283858074e-05,
      "loss": 0.002,
      "step": 14700
    },
    {
      "epoch": 3.685657171414293,
      "grad_norm": 0.2901507019996643,
      "learning_rate": 3.157296351824088e-05,
      "loss": 0.011,
      "step": 14750
    },
    {
      "epoch": 3.698150924537731,
      "grad_norm": 0.38725417852401733,
      "learning_rate": 3.1510494752623684e-05,
      "loss": 0.0017,
      "step": 14800
    },
    {
      "epoch": 3.7106446776611692,
      "grad_norm": 1.7500827312469482,
      "learning_rate": 3.144802598700649e-05,
      "loss": 0.0022,
      "step": 14850
    },
    {
      "epoch": 3.7231384307846076,
      "grad_norm": 0.2622620463371277,
      "learning_rate": 3.138555722138931e-05,
      "loss": 0.0013,
      "step": 14900
    },
    {
      "epoch": 3.735632183908046,
      "grad_norm": 0.8012122511863708,
      "learning_rate": 3.132308845577212e-05,
      "loss": 0.0022,
      "step": 14950
    },
    {
      "epoch": 3.7481259370314843,
      "grad_norm": 0.44576403498649597,
      "learning_rate": 3.1260619690154926e-05,
      "loss": 0.0016,
      "step": 15000
    },
    {
      "epoch": 3.7606196901549227,
      "grad_norm": 0.3453305661678314,
      "learning_rate": 3.1198150924537735e-05,
      "loss": 0.0024,
      "step": 15050
    },
    {
      "epoch": 3.773113443278361,
      "grad_norm": 0.3839314877986908,
      "learning_rate": 3.113568215892054e-05,
      "loss": 0.0022,
      "step": 15100
    },
    {
      "epoch": 3.785607196401799,
      "grad_norm": 0.3816084861755371,
      "learning_rate": 3.107321339330335e-05,
      "loss": 0.0019,
      "step": 15150
    },
    {
      "epoch": 3.7981009495252374,
      "grad_norm": 0.27902355790138245,
      "learning_rate": 3.1010744627686154e-05,
      "loss": 0.0107,
      "step": 15200
    },
    {
      "epoch": 3.8105947026486757,
      "grad_norm": 0.31009432673454285,
      "learning_rate": 3.094827586206896e-05,
      "loss": 0.0016,
      "step": 15250
    },
    {
      "epoch": 3.823088455772114,
      "grad_norm": 0.15624137222766876,
      "learning_rate": 3.088580709645177e-05,
      "loss": 0.0012,
      "step": 15300
    },
    {
      "epoch": 3.835582208895552,
      "grad_norm": 0.42205771803855896,
      "learning_rate": 3.082333833083459e-05,
      "loss": 0.0021,
      "step": 15350
    },
    {
      "epoch": 3.8480759620189904,
      "grad_norm": 0.46713942289352417,
      "learning_rate": 3.0760869565217395e-05,
      "loss": 0.0021,
      "step": 15400
    },
    {
      "epoch": 3.8605697151424287,
      "grad_norm": 0.25104668736457825,
      "learning_rate": 3.0698400799600204e-05,
      "loss": 0.0014,
      "step": 15450
    },
    {
      "epoch": 3.873063468265867,
      "grad_norm": 0.2690243721008301,
      "learning_rate": 3.063593203398301e-05,
      "loss": 0.0112,
      "step": 15500
    },
    {
      "epoch": 3.8855572213893055,
      "grad_norm": 0.4302823841571808,
      "learning_rate": 3.057346326836582e-05,
      "loss": 0.0112,
      "step": 15550
    },
    {
      "epoch": 3.898050974512744,
      "grad_norm": 0.3798835277557373,
      "learning_rate": 3.051099450274863e-05,
      "loss": 0.002,
      "step": 15600
    },
    {
      "epoch": 3.9105447276361818,
      "grad_norm": 0.45278915762901306,
      "learning_rate": 3.0448525737131432e-05,
      "loss": 0.0117,
      "step": 15650
    },
    {
      "epoch": 3.92303848075962,
      "grad_norm": 0.38064315915107727,
      "learning_rate": 3.0386056971514244e-05,
      "loss": 0.0019,
      "step": 15700
    },
    {
      "epoch": 3.9355322338830585,
      "grad_norm": 0.2555163502693176,
      "learning_rate": 3.0323588205897053e-05,
      "loss": 0.0016,
      "step": 15750
    },
    {
      "epoch": 3.948025987006497,
      "grad_norm": 0.7814239263534546,
      "learning_rate": 3.026111944027986e-05,
      "loss": 0.0022,
      "step": 15800
    },
    {
      "epoch": 3.960519740129935,
      "grad_norm": 0.38094305992126465,
      "learning_rate": 3.019865067466267e-05,
      "loss": 0.0117,
      "step": 15850
    },
    {
      "epoch": 3.973013493253373,
      "grad_norm": 0.3508739173412323,
      "learning_rate": 3.013618190904548e-05,
      "loss": 0.0015,
      "step": 15900
    },
    {
      "epoch": 3.9855072463768115,
      "grad_norm": 1.5378669500350952,
      "learning_rate": 3.007371314342829e-05,
      "loss": 0.002,
      "step": 15950
    },
    {
      "epoch": 3.99800099950025,
      "grad_norm": 0.26530447602272034,
      "learning_rate": 3.00112443778111e-05,
      "loss": 0.0016,
      "step": 16000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.002305123955011368,
      "eval_runtime": 2.7689,
      "eval_samples_per_second": 581.468,
      "eval_steps_per_second": 72.954,
      "step": 16008
    },
    {
      "epoch": 4.010494752623688,
      "grad_norm": 0.2671017646789551,
      "learning_rate": 2.99487756121939e-05,
      "loss": 0.0028,
      "step": 16050
    },
    {
      "epoch": 4.022988505747127,
      "grad_norm": 0.5001603364944458,
      "learning_rate": 2.988630684657671e-05,
      "loss": 0.0014,
      "step": 16100
    },
    {
      "epoch": 4.035482258870565,
      "grad_norm": 0.6819108128547668,
      "learning_rate": 2.9823838080959522e-05,
      "loss": 0.0018,
      "step": 16150
    },
    {
      "epoch": 4.047976011994003,
      "grad_norm": 0.2579785883426666,
      "learning_rate": 2.976136931534233e-05,
      "loss": 0.0021,
      "step": 16200
    },
    {
      "epoch": 4.060469765117441,
      "grad_norm": 0.34076589345932007,
      "learning_rate": 2.969890054972514e-05,
      "loss": 0.0014,
      "step": 16250
    },
    {
      "epoch": 4.072963518240879,
      "grad_norm": 0.5764089822769165,
      "learning_rate": 2.9636431784107948e-05,
      "loss": 0.0026,
      "step": 16300
    },
    {
      "epoch": 4.085457271364318,
      "grad_norm": 0.18948346376419067,
      "learning_rate": 2.9573963018490757e-05,
      "loss": 0.002,
      "step": 16350
    },
    {
      "epoch": 4.097951024487756,
      "grad_norm": 0.35411742329597473,
      "learning_rate": 2.9511494252873566e-05,
      "loss": 0.0018,
      "step": 16400
    },
    {
      "epoch": 4.110444777611194,
      "grad_norm": 0.5724332928657532,
      "learning_rate": 2.944902548725637e-05,
      "loss": 0.0017,
      "step": 16450
    },
    {
      "epoch": 4.122938530734633,
      "grad_norm": 0.23945948481559753,
      "learning_rate": 2.938655672163918e-05,
      "loss": 0.0016,
      "step": 16500
    },
    {
      "epoch": 4.135432283858071,
      "grad_norm": 0.6964576840400696,
      "learning_rate": 2.9324087956021988e-05,
      "loss": 0.002,
      "step": 16550
    },
    {
      "epoch": 4.147926036981509,
      "grad_norm": 0.3056860566139221,
      "learning_rate": 2.92616191904048e-05,
      "loss": 0.002,
      "step": 16600
    },
    {
      "epoch": 4.160419790104948,
      "grad_norm": 0.546505868434906,
      "learning_rate": 2.919915042478761e-05,
      "loss": 0.0013,
      "step": 16650
    },
    {
      "epoch": 4.172913543228386,
      "grad_norm": 0.3145294785499573,
      "learning_rate": 2.9136681659170418e-05,
      "loss": 0.0108,
      "step": 16700
    },
    {
      "epoch": 4.1854072963518245,
      "grad_norm": 0.21033428609371185,
      "learning_rate": 2.9074212893553226e-05,
      "loss": 0.0017,
      "step": 16750
    },
    {
      "epoch": 4.197901049475262,
      "grad_norm": 1.296306848526001,
      "learning_rate": 2.9011744127936035e-05,
      "loss": 0.0022,
      "step": 16800
    },
    {
      "epoch": 4.2103948025987,
      "grad_norm": 1.0938868522644043,
      "learning_rate": 2.894927536231884e-05,
      "loss": 0.0014,
      "step": 16850
    },
    {
      "epoch": 4.222888555722139,
      "grad_norm": 0.3625146448612213,
      "learning_rate": 2.888680659670165e-05,
      "loss": 0.0015,
      "step": 16900
    },
    {
      "epoch": 4.235382308845577,
      "grad_norm": 0.7591845989227295,
      "learning_rate": 2.8824337831084458e-05,
      "loss": 0.0026,
      "step": 16950
    },
    {
      "epoch": 4.2478760619690155,
      "grad_norm": 1.0693342685699463,
      "learning_rate": 2.8761869065467266e-05,
      "loss": 0.0018,
      "step": 17000
    },
    {
      "epoch": 4.260369815092454,
      "grad_norm": 0.29648280143737793,
      "learning_rate": 2.8699400299850075e-05,
      "loss": 0.0012,
      "step": 17050
    },
    {
      "epoch": 4.272863568215892,
      "grad_norm": 0.97114098072052,
      "learning_rate": 2.8636931534232887e-05,
      "loss": 0.0019,
      "step": 17100
    },
    {
      "epoch": 4.285357321339331,
      "grad_norm": 0.7348019480705261,
      "learning_rate": 2.8574462768615696e-05,
      "loss": 0.0023,
      "step": 17150
    },
    {
      "epoch": 4.297851074462769,
      "grad_norm": 0.2720157206058502,
      "learning_rate": 2.8511994002998504e-05,
      "loss": 0.0103,
      "step": 17200
    },
    {
      "epoch": 4.310344827586207,
      "grad_norm": 0.4539388120174408,
      "learning_rate": 2.844952523738131e-05,
      "loss": 0.0098,
      "step": 17250
    },
    {
      "epoch": 4.322838580709645,
      "grad_norm": 0.2669612169265747,
      "learning_rate": 2.838705647176412e-05,
      "loss": 0.0014,
      "step": 17300
    },
    {
      "epoch": 4.335332333833083,
      "grad_norm": 0.21009625494480133,
      "learning_rate": 2.8324587706146927e-05,
      "loss": 0.0019,
      "step": 17350
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.2955389618873596,
      "learning_rate": 2.8262118940529736e-05,
      "loss": 0.0018,
      "step": 17400
    },
    {
      "epoch": 4.36031984007996,
      "grad_norm": 0.3275904357433319,
      "learning_rate": 2.8199650174912544e-05,
      "loss": 0.0011,
      "step": 17450
    },
    {
      "epoch": 4.372813593203398,
      "grad_norm": 0.6559923887252808,
      "learning_rate": 2.8137181409295353e-05,
      "loss": 0.0014,
      "step": 17500
    },
    {
      "epoch": 4.385307346326837,
      "grad_norm": 0.7786923050880432,
      "learning_rate": 2.8074712643678165e-05,
      "loss": 0.002,
      "step": 17550
    },
    {
      "epoch": 4.397801099450275,
      "grad_norm": 0.17093132436275482,
      "learning_rate": 2.8012243878060974e-05,
      "loss": 0.0016,
      "step": 17600
    },
    {
      "epoch": 4.410294852573713,
      "grad_norm": 0.17718088626861572,
      "learning_rate": 2.7949775112443776e-05,
      "loss": 0.0019,
      "step": 17650
    },
    {
      "epoch": 4.422788605697152,
      "grad_norm": 0.4723742604255676,
      "learning_rate": 2.7887306346826584e-05,
      "loss": 0.0024,
      "step": 17700
    },
    {
      "epoch": 4.43528235882059,
      "grad_norm": 0.3212125301361084,
      "learning_rate": 2.7824837581209397e-05,
      "loss": 0.0026,
      "step": 17750
    },
    {
      "epoch": 4.447776111944028,
      "grad_norm": 0.6785303950309753,
      "learning_rate": 2.7762368815592205e-05,
      "loss": 0.0012,
      "step": 17800
    },
    {
      "epoch": 4.460269865067466,
      "grad_norm": 0.3290292024612427,
      "learning_rate": 2.7699900049975014e-05,
      "loss": 0.0016,
      "step": 17850
    },
    {
      "epoch": 4.472763618190904,
      "grad_norm": 0.31732767820358276,
      "learning_rate": 2.7637431284357823e-05,
      "loss": 0.0095,
      "step": 17900
    },
    {
      "epoch": 4.485257371314343,
      "grad_norm": 0.3511275351047516,
      "learning_rate": 2.757496251874063e-05,
      "loss": 0.0015,
      "step": 17950
    },
    {
      "epoch": 4.497751124437781,
      "grad_norm": 0.7338486313819885,
      "learning_rate": 2.7512493753123443e-05,
      "loss": 0.0113,
      "step": 18000
    },
    {
      "epoch": 4.510244877561219,
      "grad_norm": 0.4021763801574707,
      "learning_rate": 2.7450024987506252e-05,
      "loss": 0.0024,
      "step": 18050
    },
    {
      "epoch": 4.522738630684658,
      "grad_norm": 2.596308708190918,
      "learning_rate": 2.7387556221889054e-05,
      "loss": 0.0019,
      "step": 18100
    },
    {
      "epoch": 4.535232383808096,
      "grad_norm": 0.8799206614494324,
      "learning_rate": 2.7325087456271863e-05,
      "loss": 0.0019,
      "step": 18150
    },
    {
      "epoch": 4.5477261369315345,
      "grad_norm": 0.23239588737487793,
      "learning_rate": 2.7262618690654675e-05,
      "loss": 0.0012,
      "step": 18200
    },
    {
      "epoch": 4.560219890054973,
      "grad_norm": 0.2688590884208679,
      "learning_rate": 2.7200149925037483e-05,
      "loss": 0.0013,
      "step": 18250
    },
    {
      "epoch": 4.57271364317841,
      "grad_norm": 0.3170832693576813,
      "learning_rate": 2.7137681159420292e-05,
      "loss": 0.0014,
      "step": 18300
    },
    {
      "epoch": 4.585207396301849,
      "grad_norm": 0.27907925844192505,
      "learning_rate": 2.70752123938031e-05,
      "loss": 0.0111,
      "step": 18350
    },
    {
      "epoch": 4.597701149425287,
      "grad_norm": 0.499309778213501,
      "learning_rate": 2.701274362818591e-05,
      "loss": 0.0015,
      "step": 18400
    },
    {
      "epoch": 4.610194902548725,
      "grad_norm": 0.5611559152603149,
      "learning_rate": 2.6950274862568718e-05,
      "loss": 0.0014,
      "step": 18450
    },
    {
      "epoch": 4.622688655672164,
      "grad_norm": 0.3618391752243042,
      "learning_rate": 2.6887806096951523e-05,
      "loss": 0.0013,
      "step": 18500
    },
    {
      "epoch": 4.635182408795602,
      "grad_norm": 0.5256654620170593,
      "learning_rate": 2.6825337331334332e-05,
      "loss": 0.0029,
      "step": 18550
    },
    {
      "epoch": 4.6476761619190405,
      "grad_norm": 0.09185861796140671,
      "learning_rate": 2.676286856571714e-05,
      "loss": 0.002,
      "step": 18600
    },
    {
      "epoch": 4.660169915042479,
      "grad_norm": 0.18409672379493713,
      "learning_rate": 2.6700399800099953e-05,
      "loss": 0.0025,
      "step": 18650
    },
    {
      "epoch": 4.672663668165917,
      "grad_norm": 0.23882511258125305,
      "learning_rate": 2.663793103448276e-05,
      "loss": 0.0018,
      "step": 18700
    },
    {
      "epoch": 4.685157421289356,
      "grad_norm": 0.49891555309295654,
      "learning_rate": 2.657546226886557e-05,
      "loss": 0.0012,
      "step": 18750
    },
    {
      "epoch": 4.697651174412794,
      "grad_norm": 0.45649266242980957,
      "learning_rate": 2.651299350324838e-05,
      "loss": 0.0013,
      "step": 18800
    },
    {
      "epoch": 4.710144927536232,
      "grad_norm": 0.3271957337856293,
      "learning_rate": 2.6450524737631187e-05,
      "loss": 0.0106,
      "step": 18850
    },
    {
      "epoch": 4.72263868065967,
      "grad_norm": 0.20380055904388428,
      "learning_rate": 2.6388055972013993e-05,
      "loss": 0.0014,
      "step": 18900
    },
    {
      "epoch": 4.735132433783108,
      "grad_norm": 0.29942750930786133,
      "learning_rate": 2.63255872063968e-05,
      "loss": 0.0192,
      "step": 18950
    },
    {
      "epoch": 4.747626186906547,
      "grad_norm": 0.5998938083648682,
      "learning_rate": 2.626311844077961e-05,
      "loss": 0.0024,
      "step": 19000
    },
    {
      "epoch": 4.760119940029985,
      "grad_norm": 0.3739696443080902,
      "learning_rate": 2.620064967516242e-05,
      "loss": 0.0025,
      "step": 19050
    },
    {
      "epoch": 4.772613693153423,
      "grad_norm": 0.5305472016334534,
      "learning_rate": 2.6138180909545227e-05,
      "loss": 0.0014,
      "step": 19100
    },
    {
      "epoch": 4.785107446276862,
      "grad_norm": 0.36551547050476074,
      "learning_rate": 2.607571214392804e-05,
      "loss": 0.0022,
      "step": 19150
    },
    {
      "epoch": 4.7976011994003,
      "grad_norm": 0.6880522966384888,
      "learning_rate": 2.6013243378310848e-05,
      "loss": 0.0024,
      "step": 19200
    },
    {
      "epoch": 4.810094952523738,
      "grad_norm": 0.32118409872055054,
      "learning_rate": 2.5950774612693657e-05,
      "loss": 0.0015,
      "step": 19250
    },
    {
      "epoch": 4.822588705647177,
      "grad_norm": 0.47469455003738403,
      "learning_rate": 2.5888305847076462e-05,
      "loss": 0.0094,
      "step": 19300
    },
    {
      "epoch": 4.835082458770614,
      "grad_norm": 0.34857022762298584,
      "learning_rate": 2.582583708145927e-05,
      "loss": 0.002,
      "step": 19350
    },
    {
      "epoch": 4.847576211894053,
      "grad_norm": 0.1746581345796585,
      "learning_rate": 2.576336831584208e-05,
      "loss": 0.0102,
      "step": 19400
    },
    {
      "epoch": 4.860069965017491,
      "grad_norm": 0.31930992007255554,
      "learning_rate": 2.5700899550224888e-05,
      "loss": 0.0025,
      "step": 19450
    },
    {
      "epoch": 4.872563718140929,
      "grad_norm": 0.257129043340683,
      "learning_rate": 2.5638430784607697e-05,
      "loss": 0.0017,
      "step": 19500
    },
    {
      "epoch": 4.885057471264368,
      "grad_norm": 0.4253997206687927,
      "learning_rate": 2.5575962018990506e-05,
      "loss": 0.0026,
      "step": 19550
    },
    {
      "epoch": 4.897551224387806,
      "grad_norm": 0.21372447907924652,
      "learning_rate": 2.5513493253373318e-05,
      "loss": 0.0026,
      "step": 19600
    },
    {
      "epoch": 4.9100449775112445,
      "grad_norm": 0.3412089943885803,
      "learning_rate": 2.5451024487756126e-05,
      "loss": 0.0015,
      "step": 19650
    },
    {
      "epoch": 4.922538730634683,
      "grad_norm": 0.5852280855178833,
      "learning_rate": 2.5388555722138928e-05,
      "loss": 0.0017,
      "step": 19700
    },
    {
      "epoch": 4.935032483758121,
      "grad_norm": 0.3148009181022644,
      "learning_rate": 2.5326086956521737e-05,
      "loss": 0.0012,
      "step": 19750
    },
    {
      "epoch": 4.94752623688156,
      "grad_norm": 0.29683956503868103,
      "learning_rate": 2.526361819090455e-05,
      "loss": 0.0104,
      "step": 19800
    },
    {
      "epoch": 4.960019990004998,
      "grad_norm": 0.13843460381031036,
      "learning_rate": 2.5201149425287358e-05,
      "loss": 0.0013,
      "step": 19850
    },
    {
      "epoch": 4.972513743128435,
      "grad_norm": 0.23785480856895447,
      "learning_rate": 2.5138680659670166e-05,
      "loss": 0.0019,
      "step": 19900
    },
    {
      "epoch": 4.985007496251874,
      "grad_norm": 0.2950192987918854,
      "learning_rate": 2.5076211894052975e-05,
      "loss": 0.0018,
      "step": 19950
    },
    {
      "epoch": 4.997501249375312,
      "grad_norm": 0.34142932295799255,
      "learning_rate": 2.5013743128435784e-05,
      "loss": 0.0015,
      "step": 20000
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.001990102929994464,
      "eval_runtime": 2.7576,
      "eval_samples_per_second": 583.851,
      "eval_steps_per_second": 73.253,
      "step": 20010
    }
  ],
  "logging_steps": 50,
  "max_steps": 40020,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8655737551705080.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
