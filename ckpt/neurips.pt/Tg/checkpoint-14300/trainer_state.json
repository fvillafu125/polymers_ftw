{
  "best_global_step": 12870,
  "best_metric": 0.005201386287808418,
  "best_model_checkpoint": "ckpt/neurips.pt/Tg/checkpoint-12870",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 14300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03496503496503497,
      "grad_norm": 3.5962233543395996,
      "learning_rate": 4.9828671328671335e-05,
      "loss": 0.087,
      "step": 50
    },
    {
      "epoch": 0.06993006993006994,
      "grad_norm": 1.2394009828567505,
      "learning_rate": 4.9653846153846155e-05,
      "loss": 0.0432,
      "step": 100
    },
    {
      "epoch": 0.1048951048951049,
      "grad_norm": 3.4165244102478027,
      "learning_rate": 4.947902097902098e-05,
      "loss": 0.0444,
      "step": 150
    },
    {
      "epoch": 0.13986013986013987,
      "grad_norm": 3.7350618839263916,
      "learning_rate": 4.930419580419581e-05,
      "loss": 0.0471,
      "step": 200
    },
    {
      "epoch": 0.17482517482517482,
      "grad_norm": 2.327638864517212,
      "learning_rate": 4.912937062937063e-05,
      "loss": 0.0398,
      "step": 250
    },
    {
      "epoch": 0.2097902097902098,
      "grad_norm": 0.6795595288276672,
      "learning_rate": 4.8954545454545456e-05,
      "loss": 0.0352,
      "step": 300
    },
    {
      "epoch": 0.24475524475524477,
      "grad_norm": 8.108631134033203,
      "learning_rate": 4.877972027972028e-05,
      "loss": 0.0353,
      "step": 350
    },
    {
      "epoch": 0.27972027972027974,
      "grad_norm": 1.4673593044281006,
      "learning_rate": 4.860489510489511e-05,
      "loss": 0.0343,
      "step": 400
    },
    {
      "epoch": 0.3146853146853147,
      "grad_norm": 3.797416925430298,
      "learning_rate": 4.843006993006993e-05,
      "loss": 0.0351,
      "step": 450
    },
    {
      "epoch": 0.34965034965034963,
      "grad_norm": 1.7753621339797974,
      "learning_rate": 4.8255244755244756e-05,
      "loss": 0.0376,
      "step": 500
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 3.021496295928955,
      "learning_rate": 4.808041958041958e-05,
      "loss": 0.0356,
      "step": 550
    },
    {
      "epoch": 0.4195804195804196,
      "grad_norm": 3.469139337539673,
      "learning_rate": 4.79055944055944e-05,
      "loss": 0.0403,
      "step": 600
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 2.9484596252441406,
      "learning_rate": 4.7730769230769236e-05,
      "loss": 0.0422,
      "step": 650
    },
    {
      "epoch": 0.48951048951048953,
      "grad_norm": 3.1926236152648926,
      "learning_rate": 4.7555944055944056e-05,
      "loss": 0.0287,
      "step": 700
    },
    {
      "epoch": 0.5244755244755245,
      "grad_norm": 4.826956748962402,
      "learning_rate": 4.738111888111888e-05,
      "loss": 0.0278,
      "step": 750
    },
    {
      "epoch": 0.5594405594405595,
      "grad_norm": 2.631345272064209,
      "learning_rate": 4.720629370629371e-05,
      "loss": 0.028,
      "step": 800
    },
    {
      "epoch": 0.5944055944055944,
      "grad_norm": 2.2883572578430176,
      "learning_rate": 4.703146853146853e-05,
      "loss": 0.0269,
      "step": 850
    },
    {
      "epoch": 0.6293706293706294,
      "grad_norm": 1.87671959400177,
      "learning_rate": 4.685664335664336e-05,
      "loss": 0.0296,
      "step": 900
    },
    {
      "epoch": 0.6643356643356644,
      "grad_norm": 5.934523105621338,
      "learning_rate": 4.6681818181818184e-05,
      "loss": 0.0283,
      "step": 950
    },
    {
      "epoch": 0.6993006993006993,
      "grad_norm": 2.4252517223358154,
      "learning_rate": 4.650699300699301e-05,
      "loss": 0.0243,
      "step": 1000
    },
    {
      "epoch": 0.7342657342657343,
      "grad_norm": 1.5441030263900757,
      "learning_rate": 4.633216783216783e-05,
      "loss": 0.0313,
      "step": 1050
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 2.435507297515869,
      "learning_rate": 4.6157342657342664e-05,
      "loss": 0.0335,
      "step": 1100
    },
    {
      "epoch": 0.8041958041958042,
      "grad_norm": 2.707592010498047,
      "learning_rate": 4.5982517482517484e-05,
      "loss": 0.0255,
      "step": 1150
    },
    {
      "epoch": 0.8391608391608392,
      "grad_norm": 1.812294602394104,
      "learning_rate": 4.580769230769231e-05,
      "loss": 0.0226,
      "step": 1200
    },
    {
      "epoch": 0.8741258741258742,
      "grad_norm": 3.386195421218872,
      "learning_rate": 4.563286713286714e-05,
      "loss": 0.0311,
      "step": 1250
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 1.9406899213790894,
      "learning_rate": 4.545804195804196e-05,
      "loss": 0.0331,
      "step": 1300
    },
    {
      "epoch": 0.9440559440559441,
      "grad_norm": 2.946239948272705,
      "learning_rate": 4.5283216783216785e-05,
      "loss": 0.0275,
      "step": 1350
    },
    {
      "epoch": 0.9790209790209791,
      "grad_norm": 3.634138345718384,
      "learning_rate": 4.510839160839161e-05,
      "loss": 0.0252,
      "step": 1400
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.01219189167022705,
      "eval_runtime": 1.2226,
      "eval_samples_per_second": 561.12,
      "eval_steps_per_second": 70.344,
      "step": 1430
    },
    {
      "epoch": 1.013986013986014,
      "grad_norm": 3.0170435905456543,
      "learning_rate": 4.493356643356644e-05,
      "loss": 0.0245,
      "step": 1450
    },
    {
      "epoch": 1.048951048951049,
      "grad_norm": 3.8279898166656494,
      "learning_rate": 4.475874125874126e-05,
      "loss": 0.0246,
      "step": 1500
    },
    {
      "epoch": 1.083916083916084,
      "grad_norm": 2.210859537124634,
      "learning_rate": 4.458391608391609e-05,
      "loss": 0.0242,
      "step": 1550
    },
    {
      "epoch": 1.118881118881119,
      "grad_norm": 1.0446231365203857,
      "learning_rate": 4.440909090909091e-05,
      "loss": 0.0239,
      "step": 1600
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 1.9877249002456665,
      "learning_rate": 4.423426573426573e-05,
      "loss": 0.0203,
      "step": 1650
    },
    {
      "epoch": 1.1888111888111887,
      "grad_norm": 4.311221599578857,
      "learning_rate": 4.4059440559440565e-05,
      "loss": 0.0312,
      "step": 1700
    },
    {
      "epoch": 1.2237762237762237,
      "grad_norm": 1.5352747440338135,
      "learning_rate": 4.3884615384615385e-05,
      "loss": 0.0236,
      "step": 1750
    },
    {
      "epoch": 1.2587412587412588,
      "grad_norm": 6.564160346984863,
      "learning_rate": 4.370979020979021e-05,
      "loss": 0.0297,
      "step": 1800
    },
    {
      "epoch": 1.2937062937062938,
      "grad_norm": 6.558581352233887,
      "learning_rate": 4.353496503496504e-05,
      "loss": 0.0248,
      "step": 1850
    },
    {
      "epoch": 1.3286713286713288,
      "grad_norm": 3.0144917964935303,
      "learning_rate": 4.3360139860139866e-05,
      "loss": 0.0229,
      "step": 1900
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 1.6514121294021606,
      "learning_rate": 4.3185314685314686e-05,
      "loss": 0.0267,
      "step": 1950
    },
    {
      "epoch": 1.3986013986013985,
      "grad_norm": 3.821683883666992,
      "learning_rate": 4.301048951048951e-05,
      "loss": 0.0198,
      "step": 2000
    },
    {
      "epoch": 1.4335664335664335,
      "grad_norm": 4.260939598083496,
      "learning_rate": 4.283566433566434e-05,
      "loss": 0.0267,
      "step": 2050
    },
    {
      "epoch": 1.4685314685314685,
      "grad_norm": 3.697751998901367,
      "learning_rate": 4.266083916083916e-05,
      "loss": 0.0292,
      "step": 2100
    },
    {
      "epoch": 1.5034965034965035,
      "grad_norm": 1.6036778688430786,
      "learning_rate": 4.2486013986013986e-05,
      "loss": 0.0229,
      "step": 2150
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 2.198725700378418,
      "learning_rate": 4.231118881118881e-05,
      "loss": 0.0179,
      "step": 2200
    },
    {
      "epoch": 1.5734265734265733,
      "grad_norm": 3.84104323387146,
      "learning_rate": 4.213636363636364e-05,
      "loss": 0.0234,
      "step": 2250
    },
    {
      "epoch": 1.6083916083916083,
      "grad_norm": 1.2657324075698853,
      "learning_rate": 4.196153846153847e-05,
      "loss": 0.0201,
      "step": 2300
    },
    {
      "epoch": 1.6433566433566433,
      "grad_norm": 2.179591655731201,
      "learning_rate": 4.178671328671329e-05,
      "loss": 0.023,
      "step": 2350
    },
    {
      "epoch": 1.6783216783216783,
      "grad_norm": 2.8417625427246094,
      "learning_rate": 4.1611888111888113e-05,
      "loss": 0.021,
      "step": 2400
    },
    {
      "epoch": 1.7132867132867133,
      "grad_norm": 1.6576318740844727,
      "learning_rate": 4.143706293706294e-05,
      "loss": 0.0197,
      "step": 2450
    },
    {
      "epoch": 1.7482517482517483,
      "grad_norm": 1.9588673114776611,
      "learning_rate": 4.126223776223777e-05,
      "loss": 0.0218,
      "step": 2500
    },
    {
      "epoch": 1.7832167832167833,
      "grad_norm": 1.0468381643295288,
      "learning_rate": 4.108741258741259e-05,
      "loss": 0.0208,
      "step": 2550
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 2.2679483890533447,
      "learning_rate": 4.0912587412587414e-05,
      "loss": 0.0181,
      "step": 2600
    },
    {
      "epoch": 1.8531468531468531,
      "grad_norm": 2.23065447807312,
      "learning_rate": 4.073776223776224e-05,
      "loss": 0.0224,
      "step": 2650
    },
    {
      "epoch": 1.8881118881118881,
      "grad_norm": 1.3603510856628418,
      "learning_rate": 4.056293706293707e-05,
      "loss": 0.0231,
      "step": 2700
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 6.474457740783691,
      "learning_rate": 4.038811188811189e-05,
      "loss": 0.0177,
      "step": 2750
    },
    {
      "epoch": 1.958041958041958,
      "grad_norm": 1.5898845195770264,
      "learning_rate": 4.0213286713286714e-05,
      "loss": 0.0202,
      "step": 2800
    },
    {
      "epoch": 1.993006993006993,
      "grad_norm": 3.135498523712158,
      "learning_rate": 4.003846153846154e-05,
      "loss": 0.0178,
      "step": 2850
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.008410128764808178,
      "eval_runtime": 1.2041,
      "eval_samples_per_second": 569.701,
      "eval_steps_per_second": 71.42,
      "step": 2860
    },
    {
      "epoch": 2.027972027972028,
      "grad_norm": 3.129290819168091,
      "learning_rate": 3.986363636363636e-05,
      "loss": 0.0211,
      "step": 2900
    },
    {
      "epoch": 2.062937062937063,
      "grad_norm": 1.9091567993164062,
      "learning_rate": 3.9688811188811195e-05,
      "loss": 0.0278,
      "step": 2950
    },
    {
      "epoch": 2.097902097902098,
      "grad_norm": 2.815141439437866,
      "learning_rate": 3.9513986013986015e-05,
      "loss": 0.0209,
      "step": 3000
    },
    {
      "epoch": 2.132867132867133,
      "grad_norm": 1.9948331117630005,
      "learning_rate": 3.933916083916084e-05,
      "loss": 0.0204,
      "step": 3050
    },
    {
      "epoch": 2.167832167832168,
      "grad_norm": 5.186739921569824,
      "learning_rate": 3.916433566433567e-05,
      "loss": 0.0198,
      "step": 3100
    },
    {
      "epoch": 2.202797202797203,
      "grad_norm": 2.3478636741638184,
      "learning_rate": 3.898951048951049e-05,
      "loss": 0.0175,
      "step": 3150
    },
    {
      "epoch": 2.237762237762238,
      "grad_norm": 4.462832450866699,
      "learning_rate": 3.8814685314685315e-05,
      "loss": 0.0246,
      "step": 3200
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 2.665193557739258,
      "learning_rate": 3.863986013986014e-05,
      "loss": 0.0235,
      "step": 3250
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 5.096268653869629,
      "learning_rate": 3.846503496503497e-05,
      "loss": 0.0153,
      "step": 3300
    },
    {
      "epoch": 2.3426573426573425,
      "grad_norm": 1.28212308883667,
      "learning_rate": 3.829020979020979e-05,
      "loss": 0.0174,
      "step": 3350
    },
    {
      "epoch": 2.3776223776223775,
      "grad_norm": 2.267091989517212,
      "learning_rate": 3.811538461538462e-05,
      "loss": 0.0199,
      "step": 3400
    },
    {
      "epoch": 2.4125874125874125,
      "grad_norm": 1.6941921710968018,
      "learning_rate": 3.794055944055944e-05,
      "loss": 0.0161,
      "step": 3450
    },
    {
      "epoch": 2.4475524475524475,
      "grad_norm": 1.508358359336853,
      "learning_rate": 3.776573426573426e-05,
      "loss": 0.0156,
      "step": 3500
    },
    {
      "epoch": 2.4825174825174825,
      "grad_norm": 1.4200388193130493,
      "learning_rate": 3.7590909090909096e-05,
      "loss": 0.0155,
      "step": 3550
    },
    {
      "epoch": 2.5174825174825175,
      "grad_norm": 3.282604455947876,
      "learning_rate": 3.7416083916083916e-05,
      "loss": 0.0188,
      "step": 3600
    },
    {
      "epoch": 2.5524475524475525,
      "grad_norm": 1.9655207395553589,
      "learning_rate": 3.724125874125874e-05,
      "loss": 0.0182,
      "step": 3650
    },
    {
      "epoch": 2.5874125874125875,
      "grad_norm": 7.397812366485596,
      "learning_rate": 3.706643356643357e-05,
      "loss": 0.0208,
      "step": 3700
    },
    {
      "epoch": 2.6223776223776225,
      "grad_norm": 3.9736015796661377,
      "learning_rate": 3.6891608391608396e-05,
      "loss": 0.0214,
      "step": 3750
    },
    {
      "epoch": 2.6573426573426575,
      "grad_norm": 1.9525562524795532,
      "learning_rate": 3.6716783216783216e-05,
      "loss": 0.0176,
      "step": 3800
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 1.5037317276000977,
      "learning_rate": 3.654195804195804e-05,
      "loss": 0.0146,
      "step": 3850
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 2.1082465648651123,
      "learning_rate": 3.636713286713287e-05,
      "loss": 0.0152,
      "step": 3900
    },
    {
      "epoch": 2.762237762237762,
      "grad_norm": 4.101151466369629,
      "learning_rate": 3.619230769230769e-05,
      "loss": 0.0186,
      "step": 3950
    },
    {
      "epoch": 2.797202797202797,
      "grad_norm": 4.250270843505859,
      "learning_rate": 3.6017482517482524e-05,
      "loss": 0.0151,
      "step": 4000
    },
    {
      "epoch": 2.832167832167832,
      "grad_norm": 1.1014633178710938,
      "learning_rate": 3.5842657342657344e-05,
      "loss": 0.0191,
      "step": 4050
    },
    {
      "epoch": 2.867132867132867,
      "grad_norm": 1.1629124879837036,
      "learning_rate": 3.566783216783217e-05,
      "loss": 0.0185,
      "step": 4100
    },
    {
      "epoch": 2.902097902097902,
      "grad_norm": 2.394188165664673,
      "learning_rate": 3.5493006993007e-05,
      "loss": 0.0178,
      "step": 4150
    },
    {
      "epoch": 2.937062937062937,
      "grad_norm": 1.9901858568191528,
      "learning_rate": 3.5318181818181824e-05,
      "loss": 0.0135,
      "step": 4200
    },
    {
      "epoch": 2.972027972027972,
      "grad_norm": 4.008172035217285,
      "learning_rate": 3.5143356643356644e-05,
      "loss": 0.0173,
      "step": 4250
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.008797364309430122,
      "eval_runtime": 1.2,
      "eval_samples_per_second": 571.652,
      "eval_steps_per_second": 71.665,
      "step": 4290
    },
    {
      "epoch": 3.006993006993007,
      "grad_norm": 2.5232629776000977,
      "learning_rate": 3.496853146853147e-05,
      "loss": 0.015,
      "step": 4300
    },
    {
      "epoch": 3.041958041958042,
      "grad_norm": 2.206047534942627,
      "learning_rate": 3.47937062937063e-05,
      "loss": 0.017,
      "step": 4350
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.8291898965835571,
      "learning_rate": 3.461888111888112e-05,
      "loss": 0.0126,
      "step": 4400
    },
    {
      "epoch": 3.111888111888112,
      "grad_norm": 0.9381358027458191,
      "learning_rate": 3.4444055944055945e-05,
      "loss": 0.0173,
      "step": 4450
    },
    {
      "epoch": 3.1468531468531467,
      "grad_norm": 2.699129343032837,
      "learning_rate": 3.426923076923077e-05,
      "loss": 0.0145,
      "step": 4500
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 4.166013240814209,
      "learning_rate": 3.40944055944056e-05,
      "loss": 0.0162,
      "step": 4550
    },
    {
      "epoch": 3.2167832167832167,
      "grad_norm": 1.2083091735839844,
      "learning_rate": 3.391958041958042e-05,
      "loss": 0.0159,
      "step": 4600
    },
    {
      "epoch": 3.2517482517482517,
      "grad_norm": 3.3760976791381836,
      "learning_rate": 3.3744755244755245e-05,
      "loss": 0.0153,
      "step": 4650
    },
    {
      "epoch": 3.2867132867132867,
      "grad_norm": 0.8938230872154236,
      "learning_rate": 3.356993006993007e-05,
      "loss": 0.0185,
      "step": 4700
    },
    {
      "epoch": 3.3216783216783217,
      "grad_norm": 0.995498776435852,
      "learning_rate": 3.339510489510489e-05,
      "loss": 0.0137,
      "step": 4750
    },
    {
      "epoch": 3.3566433566433567,
      "grad_norm": 1.0400500297546387,
      "learning_rate": 3.3220279720279725e-05,
      "loss": 0.0177,
      "step": 4800
    },
    {
      "epoch": 3.3916083916083917,
      "grad_norm": 3.626720428466797,
      "learning_rate": 3.3045454545454545e-05,
      "loss": 0.0173,
      "step": 4850
    },
    {
      "epoch": 3.4265734265734267,
      "grad_norm": 3.2018160820007324,
      "learning_rate": 3.287062937062937e-05,
      "loss": 0.0165,
      "step": 4900
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 3.346242904663086,
      "learning_rate": 3.26958041958042e-05,
      "loss": 0.0181,
      "step": 4950
    },
    {
      "epoch": 3.4965034965034967,
      "grad_norm": 1.6435402631759644,
      "learning_rate": 3.252097902097902e-05,
      "loss": 0.0186,
      "step": 5000
    },
    {
      "epoch": 3.5314685314685317,
      "grad_norm": 1.1705124378204346,
      "learning_rate": 3.2346153846153846e-05,
      "loss": 0.0162,
      "step": 5050
    },
    {
      "epoch": 3.5664335664335667,
      "grad_norm": 1.1618640422821045,
      "learning_rate": 3.217132867132867e-05,
      "loss": 0.0132,
      "step": 5100
    },
    {
      "epoch": 3.6013986013986012,
      "grad_norm": 1.940451979637146,
      "learning_rate": 3.19965034965035e-05,
      "loss": 0.0126,
      "step": 5150
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 1.678357720375061,
      "learning_rate": 3.182167832167832e-05,
      "loss": 0.0153,
      "step": 5200
    },
    {
      "epoch": 3.6713286713286712,
      "grad_norm": 1.1717268228530884,
      "learning_rate": 3.164685314685315e-05,
      "loss": 0.0147,
      "step": 5250
    },
    {
      "epoch": 3.7062937062937062,
      "grad_norm": 1.28753662109375,
      "learning_rate": 3.147202797202797e-05,
      "loss": 0.0106,
      "step": 5300
    },
    {
      "epoch": 3.7412587412587412,
      "grad_norm": 1.8785336017608643,
      "learning_rate": 3.12972027972028e-05,
      "loss": 0.0149,
      "step": 5350
    },
    {
      "epoch": 3.7762237762237763,
      "grad_norm": 1.274349331855774,
      "learning_rate": 3.112237762237763e-05,
      "loss": 0.0154,
      "step": 5400
    },
    {
      "epoch": 3.8111888111888113,
      "grad_norm": 1.6175428628921509,
      "learning_rate": 3.094755244755245e-05,
      "loss": 0.0137,
      "step": 5450
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 3.339273452758789,
      "learning_rate": 3.0772727272727273e-05,
      "loss": 0.0146,
      "step": 5500
    },
    {
      "epoch": 3.8811188811188813,
      "grad_norm": 0.8996143937110901,
      "learning_rate": 3.05979020979021e-05,
      "loss": 0.0171,
      "step": 5550
    },
    {
      "epoch": 3.916083916083916,
      "grad_norm": 3.8262312412261963,
      "learning_rate": 3.0423076923076927e-05,
      "loss": 0.014,
      "step": 5600
    },
    {
      "epoch": 3.951048951048951,
      "grad_norm": 2.1537396907806396,
      "learning_rate": 3.024825174825175e-05,
      "loss": 0.0158,
      "step": 5650
    },
    {
      "epoch": 3.986013986013986,
      "grad_norm": 1.813408374786377,
      "learning_rate": 3.0073426573426577e-05,
      "loss": 0.0138,
      "step": 5700
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.00765204755589366,
      "eval_runtime": 1.2076,
      "eval_samples_per_second": 568.076,
      "eval_steps_per_second": 71.217,
      "step": 5720
    },
    {
      "epoch": 4.020979020979021,
      "grad_norm": 1.903613805770874,
      "learning_rate": 2.98986013986014e-05,
      "loss": 0.0143,
      "step": 5750
    },
    {
      "epoch": 4.055944055944056,
      "grad_norm": 2.657620906829834,
      "learning_rate": 2.9723776223776224e-05,
      "loss": 0.0132,
      "step": 5800
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 2.1362357139587402,
      "learning_rate": 2.954895104895105e-05,
      "loss": 0.0151,
      "step": 5850
    },
    {
      "epoch": 4.125874125874126,
      "grad_norm": 0.9810961484909058,
      "learning_rate": 2.9374125874125874e-05,
      "loss": 0.0134,
      "step": 5900
    },
    {
      "epoch": 4.160839160839161,
      "grad_norm": 3.2459025382995605,
      "learning_rate": 2.91993006993007e-05,
      "loss": 0.0114,
      "step": 5950
    },
    {
      "epoch": 4.195804195804196,
      "grad_norm": 1.9538275003433228,
      "learning_rate": 2.9024475524475525e-05,
      "loss": 0.0122,
      "step": 6000
    },
    {
      "epoch": 4.230769230769231,
      "grad_norm": 1.379030704498291,
      "learning_rate": 2.8849650349650355e-05,
      "loss": 0.0181,
      "step": 6050
    },
    {
      "epoch": 4.265734265734266,
      "grad_norm": 2.287947654724121,
      "learning_rate": 2.8674825174825175e-05,
      "loss": 0.0105,
      "step": 6100
    },
    {
      "epoch": 4.300699300699301,
      "grad_norm": 3.1913163661956787,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0128,
      "step": 6150
    },
    {
      "epoch": 4.335664335664336,
      "grad_norm": 1.4818966388702393,
      "learning_rate": 2.832517482517483e-05,
      "loss": 0.0144,
      "step": 6200
    },
    {
      "epoch": 4.370629370629371,
      "grad_norm": 2.203270673751831,
      "learning_rate": 2.815034965034965e-05,
      "loss": 0.0125,
      "step": 6250
    },
    {
      "epoch": 4.405594405594406,
      "grad_norm": 3.9279024600982666,
      "learning_rate": 2.797552447552448e-05,
      "loss": 0.0107,
      "step": 6300
    },
    {
      "epoch": 4.440559440559441,
      "grad_norm": 2.3596951961517334,
      "learning_rate": 2.7800699300699302e-05,
      "loss": 0.0134,
      "step": 6350
    },
    {
      "epoch": 4.475524475524476,
      "grad_norm": 1.7866309881210327,
      "learning_rate": 2.762587412587413e-05,
      "loss": 0.0134,
      "step": 6400
    },
    {
      "epoch": 4.510489510489511,
      "grad_norm": 1.3344838619232178,
      "learning_rate": 2.7451048951048952e-05,
      "loss": 0.0146,
      "step": 6450
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.8667528629302979,
      "learning_rate": 2.7276223776223776e-05,
      "loss": 0.0113,
      "step": 6500
    },
    {
      "epoch": 4.58041958041958,
      "grad_norm": 2.454257011413574,
      "learning_rate": 2.7101398601398602e-05,
      "loss": 0.0094,
      "step": 6550
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 1.2574687004089355,
      "learning_rate": 2.6926573426573426e-05,
      "loss": 0.012,
      "step": 6600
    },
    {
      "epoch": 4.65034965034965,
      "grad_norm": 2.076496124267578,
      "learning_rate": 2.6751748251748253e-05,
      "loss": 0.0139,
      "step": 6650
    },
    {
      "epoch": 4.685314685314685,
      "grad_norm": 4.545418739318848,
      "learning_rate": 2.6576923076923076e-05,
      "loss": 0.0131,
      "step": 6700
    },
    {
      "epoch": 4.72027972027972,
      "grad_norm": 1.2313916683197021,
      "learning_rate": 2.6402097902097906e-05,
      "loss": 0.0109,
      "step": 6750
    },
    {
      "epoch": 4.755244755244755,
      "grad_norm": 2.3668198585510254,
      "learning_rate": 2.622727272727273e-05,
      "loss": 0.0121,
      "step": 6800
    },
    {
      "epoch": 4.79020979020979,
      "grad_norm": 1.2000209093093872,
      "learning_rate": 2.6052447552447556e-05,
      "loss": 0.0117,
      "step": 6850
    },
    {
      "epoch": 4.825174825174825,
      "grad_norm": 2.4168601036071777,
      "learning_rate": 2.587762237762238e-05,
      "loss": 0.013,
      "step": 6900
    },
    {
      "epoch": 4.86013986013986,
      "grad_norm": 0.7163248062133789,
      "learning_rate": 2.5702797202797203e-05,
      "loss": 0.0099,
      "step": 6950
    },
    {
      "epoch": 4.895104895104895,
      "grad_norm": 1.5648514032363892,
      "learning_rate": 2.552797202797203e-05,
      "loss": 0.0112,
      "step": 7000
    },
    {
      "epoch": 4.93006993006993,
      "grad_norm": 1.4699987173080444,
      "learning_rate": 2.5353146853146853e-05,
      "loss": 0.0115,
      "step": 7050
    },
    {
      "epoch": 4.965034965034965,
      "grad_norm": 1.3571370840072632,
      "learning_rate": 2.517832167832168e-05,
      "loss": 0.0108,
      "step": 7100
    },
    {
      "epoch": 5.0,
      "grad_norm": 6.825443267822266,
      "learning_rate": 2.5003496503496504e-05,
      "loss": 0.0141,
      "step": 7150
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.007025942672044039,
      "eval_runtime": 1.2192,
      "eval_samples_per_second": 562.649,
      "eval_steps_per_second": 70.536,
      "step": 7150
    },
    {
      "epoch": 5.034965034965035,
      "grad_norm": 0.6832647919654846,
      "learning_rate": 2.482867132867133e-05,
      "loss": 0.0089,
      "step": 7200
    },
    {
      "epoch": 5.06993006993007,
      "grad_norm": 1.4172111749649048,
      "learning_rate": 2.4653846153846154e-05,
      "loss": 0.0127,
      "step": 7250
    },
    {
      "epoch": 5.104895104895105,
      "grad_norm": 2.0852155685424805,
      "learning_rate": 2.447902097902098e-05,
      "loss": 0.0119,
      "step": 7300
    },
    {
      "epoch": 5.13986013986014,
      "grad_norm": 1.9654544591903687,
      "learning_rate": 2.4304195804195808e-05,
      "loss": 0.0145,
      "step": 7350
    },
    {
      "epoch": 5.174825174825175,
      "grad_norm": 1.6835676431655884,
      "learning_rate": 2.412937062937063e-05,
      "loss": 0.0097,
      "step": 7400
    },
    {
      "epoch": 5.20979020979021,
      "grad_norm": 1.174317717552185,
      "learning_rate": 2.3954545454545454e-05,
      "loss": 0.0097,
      "step": 7450
    },
    {
      "epoch": 5.244755244755245,
      "grad_norm": 3.002455234527588,
      "learning_rate": 2.377972027972028e-05,
      "loss": 0.0152,
      "step": 7500
    },
    {
      "epoch": 5.27972027972028,
      "grad_norm": 0.8919787406921387,
      "learning_rate": 2.3604895104895105e-05,
      "loss": 0.0106,
      "step": 7550
    },
    {
      "epoch": 5.314685314685315,
      "grad_norm": 1.3035866022109985,
      "learning_rate": 2.343006993006993e-05,
      "loss": 0.0106,
      "step": 7600
    },
    {
      "epoch": 5.34965034965035,
      "grad_norm": 2.4203083515167236,
      "learning_rate": 2.3255244755244758e-05,
      "loss": 0.0133,
      "step": 7650
    },
    {
      "epoch": 5.384615384615385,
      "grad_norm": 1.1820505857467651,
      "learning_rate": 2.308041958041958e-05,
      "loss": 0.0121,
      "step": 7700
    },
    {
      "epoch": 5.41958041958042,
      "grad_norm": 2.5418975353240967,
      "learning_rate": 2.290559440559441e-05,
      "loss": 0.0125,
      "step": 7750
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 1.2767155170440674,
      "learning_rate": 2.2730769230769232e-05,
      "loss": 0.0113,
      "step": 7800
    },
    {
      "epoch": 5.489510489510489,
      "grad_norm": 2.0219428539276123,
      "learning_rate": 2.2555944055944055e-05,
      "loss": 0.0116,
      "step": 7850
    },
    {
      "epoch": 5.524475524475524,
      "grad_norm": 2.0816757678985596,
      "learning_rate": 2.2381118881118882e-05,
      "loss": 0.011,
      "step": 7900
    },
    {
      "epoch": 5.559440559440559,
      "grad_norm": 1.637687087059021,
      "learning_rate": 2.2206293706293705e-05,
      "loss": 0.0099,
      "step": 7950
    },
    {
      "epoch": 5.594405594405594,
      "grad_norm": 1.5753933191299438,
      "learning_rate": 2.2031468531468532e-05,
      "loss": 0.0099,
      "step": 8000
    },
    {
      "epoch": 5.629370629370629,
      "grad_norm": 1.0148577690124512,
      "learning_rate": 2.185664335664336e-05,
      "loss": 0.0084,
      "step": 8050
    },
    {
      "epoch": 5.664335664335664,
      "grad_norm": 0.8493289947509766,
      "learning_rate": 2.1681818181818182e-05,
      "loss": 0.0117,
      "step": 8100
    },
    {
      "epoch": 5.699300699300699,
      "grad_norm": 2.973630428314209,
      "learning_rate": 2.150699300699301e-05,
      "loss": 0.0137,
      "step": 8150
    },
    {
      "epoch": 5.734265734265734,
      "grad_norm": 1.2518047094345093,
      "learning_rate": 2.1332167832167833e-05,
      "loss": 0.013,
      "step": 8200
    },
    {
      "epoch": 5.769230769230769,
      "grad_norm": 0.7279820442199707,
      "learning_rate": 2.1157342657342656e-05,
      "loss": 0.0143,
      "step": 8250
    },
    {
      "epoch": 5.804195804195804,
      "grad_norm": 1.233426809310913,
      "learning_rate": 2.0982517482517483e-05,
      "loss": 0.0141,
      "step": 8300
    },
    {
      "epoch": 5.839160839160839,
      "grad_norm": 1.0092250108718872,
      "learning_rate": 2.080769230769231e-05,
      "loss": 0.0088,
      "step": 8350
    },
    {
      "epoch": 5.874125874125874,
      "grad_norm": 2.110337972640991,
      "learning_rate": 2.0632867132867133e-05,
      "loss": 0.0121,
      "step": 8400
    },
    {
      "epoch": 5.909090909090909,
      "grad_norm": 2.855153799057007,
      "learning_rate": 2.045804195804196e-05,
      "loss": 0.0148,
      "step": 8450
    },
    {
      "epoch": 5.944055944055944,
      "grad_norm": 1.6348929405212402,
      "learning_rate": 2.0283216783216787e-05,
      "loss": 0.0124,
      "step": 8500
    },
    {
      "epoch": 5.979020979020979,
      "grad_norm": 0.4442886710166931,
      "learning_rate": 2.010839160839161e-05,
      "loss": 0.0114,
      "step": 8550
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.00543545838445425,
      "eval_runtime": 1.2067,
      "eval_samples_per_second": 568.498,
      "eval_steps_per_second": 71.269,
      "step": 8580
    },
    {
      "epoch": 6.013986013986014,
      "grad_norm": 2.4407291412353516,
      "learning_rate": 1.9933566433566434e-05,
      "loss": 0.0154,
      "step": 8600
    },
    {
      "epoch": 6.048951048951049,
      "grad_norm": 0.8673116564750671,
      "learning_rate": 1.975874125874126e-05,
      "loss": 0.0115,
      "step": 8650
    },
    {
      "epoch": 6.083916083916084,
      "grad_norm": 2.725827693939209,
      "learning_rate": 1.9583916083916084e-05,
      "loss": 0.0131,
      "step": 8700
    },
    {
      "epoch": 6.118881118881119,
      "grad_norm": 1.829023838043213,
      "learning_rate": 1.940909090909091e-05,
      "loss": 0.0101,
      "step": 8750
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 1.3325598239898682,
      "learning_rate": 1.9234265734265734e-05,
      "loss": 0.0096,
      "step": 8800
    },
    {
      "epoch": 6.188811188811189,
      "grad_norm": 1.7070753574371338,
      "learning_rate": 1.905944055944056e-05,
      "loss": 0.0099,
      "step": 8850
    },
    {
      "epoch": 6.223776223776224,
      "grad_norm": 2.334136486053467,
      "learning_rate": 1.8884615384615388e-05,
      "loss": 0.0118,
      "step": 8900
    },
    {
      "epoch": 6.258741258741258,
      "grad_norm": 1.2704005241394043,
      "learning_rate": 1.870979020979021e-05,
      "loss": 0.0101,
      "step": 8950
    },
    {
      "epoch": 6.293706293706293,
      "grad_norm": 3.0066816806793213,
      "learning_rate": 1.8534965034965034e-05,
      "loss": 0.0099,
      "step": 9000
    },
    {
      "epoch": 6.328671328671328,
      "grad_norm": 1.0735242366790771,
      "learning_rate": 1.836013986013986e-05,
      "loss": 0.0116,
      "step": 9050
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 1.8186533451080322,
      "learning_rate": 1.8185314685314685e-05,
      "loss": 0.0112,
      "step": 9100
    },
    {
      "epoch": 6.398601398601398,
      "grad_norm": 1.4024666547775269,
      "learning_rate": 1.801048951048951e-05,
      "loss": 0.0098,
      "step": 9150
    },
    {
      "epoch": 6.433566433566433,
      "grad_norm": 1.3309276103973389,
      "learning_rate": 1.7835664335664338e-05,
      "loss": 0.011,
      "step": 9200
    },
    {
      "epoch": 6.468531468531468,
      "grad_norm": 1.2853258848190308,
      "learning_rate": 1.766083916083916e-05,
      "loss": 0.0111,
      "step": 9250
    },
    {
      "epoch": 6.503496503496503,
      "grad_norm": 2.3912105560302734,
      "learning_rate": 1.748601398601399e-05,
      "loss": 0.0117,
      "step": 9300
    },
    {
      "epoch": 6.538461538461538,
      "grad_norm": 0.8383838534355164,
      "learning_rate": 1.7311188811188812e-05,
      "loss": 0.0096,
      "step": 9350
    },
    {
      "epoch": 6.573426573426573,
      "grad_norm": 0.7358822226524353,
      "learning_rate": 1.7136363636363635e-05,
      "loss": 0.0103,
      "step": 9400
    },
    {
      "epoch": 6.608391608391608,
      "grad_norm": 0.5553351044654846,
      "learning_rate": 1.6961538461538462e-05,
      "loss": 0.0086,
      "step": 9450
    },
    {
      "epoch": 6.643356643356643,
      "grad_norm": 0.6752291321754456,
      "learning_rate": 1.678671328671329e-05,
      "loss": 0.0089,
      "step": 9500
    },
    {
      "epoch": 6.678321678321678,
      "grad_norm": 2.9900119304656982,
      "learning_rate": 1.6611888111888112e-05,
      "loss": 0.0085,
      "step": 9550
    },
    {
      "epoch": 6.713286713286713,
      "grad_norm": 1.548688530921936,
      "learning_rate": 1.643706293706294e-05,
      "loss": 0.011,
      "step": 9600
    },
    {
      "epoch": 6.748251748251748,
      "grad_norm": 2.2218828201293945,
      "learning_rate": 1.6262237762237766e-05,
      "loss": 0.0109,
      "step": 9650
    },
    {
      "epoch": 6.783216783216783,
      "grad_norm": 1.2750542163848877,
      "learning_rate": 1.6087412587412586e-05,
      "loss": 0.0086,
      "step": 9700
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 2.300675392150879,
      "learning_rate": 1.5912587412587413e-05,
      "loss": 0.0091,
      "step": 9750
    },
    {
      "epoch": 6.853146853146853,
      "grad_norm": 1.678925633430481,
      "learning_rate": 1.573776223776224e-05,
      "loss": 0.0093,
      "step": 9800
    },
    {
      "epoch": 6.888111888111888,
      "grad_norm": 0.9693863391876221,
      "learning_rate": 1.5562937062937063e-05,
      "loss": 0.0088,
      "step": 9850
    },
    {
      "epoch": 6.923076923076923,
      "grad_norm": 1.0263047218322754,
      "learning_rate": 1.538811188811189e-05,
      "loss": 0.0094,
      "step": 9900
    },
    {
      "epoch": 6.958041958041958,
      "grad_norm": 2.4348502159118652,
      "learning_rate": 1.5213286713286715e-05,
      "loss": 0.0094,
      "step": 9950
    },
    {
      "epoch": 6.993006993006993,
      "grad_norm": 0.6298532485961914,
      "learning_rate": 1.503846153846154e-05,
      "loss": 0.0089,
      "step": 10000
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.008498728275299072,
      "eval_runtime": 1.2031,
      "eval_samples_per_second": 570.197,
      "eval_steps_per_second": 71.482,
      "step": 10010
    },
    {
      "epoch": 7.027972027972028,
      "grad_norm": 1.9528594017028809,
      "learning_rate": 1.4863636363636365e-05,
      "loss": 0.0131,
      "step": 10050
    },
    {
      "epoch": 7.062937062937063,
      "grad_norm": 1.4509317874908447,
      "learning_rate": 1.4688811188811188e-05,
      "loss": 0.0089,
      "step": 10100
    },
    {
      "epoch": 7.0979020979020975,
      "grad_norm": 1.7938159704208374,
      "learning_rate": 1.4513986013986014e-05,
      "loss": 0.0126,
      "step": 10150
    },
    {
      "epoch": 7.1328671328671325,
      "grad_norm": 0.4233759343624115,
      "learning_rate": 1.433916083916084e-05,
      "loss": 0.0097,
      "step": 10200
    },
    {
      "epoch": 7.1678321678321675,
      "grad_norm": 1.0252841711044312,
      "learning_rate": 1.4164335664335665e-05,
      "loss": 0.0097,
      "step": 10250
    },
    {
      "epoch": 7.2027972027972025,
      "grad_norm": 3.058821678161621,
      "learning_rate": 1.398951048951049e-05,
      "loss": 0.0093,
      "step": 10300
    },
    {
      "epoch": 7.2377622377622375,
      "grad_norm": Infinity,
      "learning_rate": 1.3814685314685316e-05,
      "loss": 0.0087,
      "step": 10350
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 0.8942460417747498,
      "learning_rate": 1.3639860139860142e-05,
      "loss": 0.0098,
      "step": 10400
    },
    {
      "epoch": 7.3076923076923075,
      "grad_norm": 1.1543389558792114,
      "learning_rate": 1.3465034965034964e-05,
      "loss": 0.0096,
      "step": 10450
    },
    {
      "epoch": 7.3426573426573425,
      "grad_norm": 1.6481350660324097,
      "learning_rate": 1.329020979020979e-05,
      "loss": 0.0108,
      "step": 10500
    },
    {
      "epoch": 7.3776223776223775,
      "grad_norm": 0.8598477840423584,
      "learning_rate": 1.3115384615384616e-05,
      "loss": 0.0087,
      "step": 10550
    },
    {
      "epoch": 7.4125874125874125,
      "grad_norm": 2.954636335372925,
      "learning_rate": 1.2940559440559441e-05,
      "loss": 0.0099,
      "step": 10600
    },
    {
      "epoch": 7.4475524475524475,
      "grad_norm": 0.8048421740531921,
      "learning_rate": 1.2765734265734266e-05,
      "loss": 0.0086,
      "step": 10650
    },
    {
      "epoch": 7.4825174825174825,
      "grad_norm": 1.6150635480880737,
      "learning_rate": 1.2590909090909091e-05,
      "loss": 0.0109,
      "step": 10700
    },
    {
      "epoch": 7.5174825174825175,
      "grad_norm": 0.3794255256652832,
      "learning_rate": 1.2416083916083917e-05,
      "loss": 0.0087,
      "step": 10750
    },
    {
      "epoch": 7.5524475524475525,
      "grad_norm": 1.3250499963760376,
      "learning_rate": 1.2241258741258742e-05,
      "loss": 0.0104,
      "step": 10800
    },
    {
      "epoch": 7.5874125874125875,
      "grad_norm": 1.4667859077453613,
      "learning_rate": 1.2066433566433567e-05,
      "loss": 0.0077,
      "step": 10850
    },
    {
      "epoch": 7.6223776223776225,
      "grad_norm": 1.450753092765808,
      "learning_rate": 1.1891608391608394e-05,
      "loss": 0.0087,
      "step": 10900
    },
    {
      "epoch": 7.6573426573426575,
      "grad_norm": 1.640714406967163,
      "learning_rate": 1.1716783216783217e-05,
      "loss": 0.0098,
      "step": 10950
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 0.6778318285942078,
      "learning_rate": 1.1541958041958042e-05,
      "loss": 0.009,
      "step": 11000
    },
    {
      "epoch": 7.7272727272727275,
      "grad_norm": 0.7808396220207214,
      "learning_rate": 1.1367132867132869e-05,
      "loss": 0.0092,
      "step": 11050
    },
    {
      "epoch": 7.7622377622377625,
      "grad_norm": 0.9850504398345947,
      "learning_rate": 1.1192307692307692e-05,
      "loss": 0.009,
      "step": 11100
    },
    {
      "epoch": 7.7972027972027975,
      "grad_norm": 3.057839870452881,
      "learning_rate": 1.1017482517482517e-05,
      "loss": 0.0094,
      "step": 11150
    },
    {
      "epoch": 7.8321678321678325,
      "grad_norm": 1.4855209589004517,
      "learning_rate": 1.0842657342657342e-05,
      "loss": 0.0091,
      "step": 11200
    },
    {
      "epoch": 7.867132867132867,
      "grad_norm": 2.2467260360717773,
      "learning_rate": 1.066783216783217e-05,
      "loss": 0.0085,
      "step": 11250
    },
    {
      "epoch": 7.902097902097902,
      "grad_norm": 2.3254029750823975,
      "learning_rate": 1.0493006993006993e-05,
      "loss": 0.0091,
      "step": 11300
    },
    {
      "epoch": 7.937062937062937,
      "grad_norm": 3.1004741191864014,
      "learning_rate": 1.0318181818181818e-05,
      "loss": 0.0087,
      "step": 11350
    },
    {
      "epoch": 7.972027972027972,
      "grad_norm": 1.900883436203003,
      "learning_rate": 1.0143356643356645e-05,
      "loss": 0.0098,
      "step": 11400
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.005268641281872988,
      "eval_runtime": 1.2036,
      "eval_samples_per_second": 569.934,
      "eval_steps_per_second": 71.45,
      "step": 11440
    },
    {
      "epoch": 8.006993006993007,
      "grad_norm": 1.191483974456787,
      "learning_rate": 9.96853146853147e-06,
      "loss": 0.0102,
      "step": 11450
    },
    {
      "epoch": 8.041958041958042,
      "grad_norm": 3.653595209121704,
      "learning_rate": 9.793706293706293e-06,
      "loss": 0.011,
      "step": 11500
    },
    {
      "epoch": 8.076923076923077,
      "grad_norm": 0.866232693195343,
      "learning_rate": 9.61888111888112e-06,
      "loss": 0.0082,
      "step": 11550
    },
    {
      "epoch": 8.111888111888112,
      "grad_norm": 1.0501993894577026,
      "learning_rate": 9.444055944055945e-06,
      "loss": 0.0091,
      "step": 11600
    },
    {
      "epoch": 8.146853146853147,
      "grad_norm": 0.9513629078865051,
      "learning_rate": 9.26923076923077e-06,
      "loss": 0.0079,
      "step": 11650
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 3.58304762840271,
      "learning_rate": 9.094405594405595e-06,
      "loss": 0.0081,
      "step": 11700
    },
    {
      "epoch": 8.216783216783217,
      "grad_norm": 0.822368323802948,
      "learning_rate": 8.91958041958042e-06,
      "loss": 0.0102,
      "step": 11750
    },
    {
      "epoch": 8.251748251748252,
      "grad_norm": 1.1516519784927368,
      "learning_rate": 8.744755244755245e-06,
      "loss": 0.0087,
      "step": 11800
    },
    {
      "epoch": 8.286713286713287,
      "grad_norm": 0.41635259985923767,
      "learning_rate": 8.569930069930069e-06,
      "loss": 0.0081,
      "step": 11850
    },
    {
      "epoch": 8.321678321678322,
      "grad_norm": 2.387134552001953,
      "learning_rate": 8.395104895104896e-06,
      "loss": 0.0077,
      "step": 11900
    },
    {
      "epoch": 8.356643356643357,
      "grad_norm": 1.9082181453704834,
      "learning_rate": 8.22027972027972e-06,
      "loss": 0.008,
      "step": 11950
    },
    {
      "epoch": 8.391608391608392,
      "grad_norm": 1.485305666923523,
      "learning_rate": 8.045454545454546e-06,
      "loss": 0.01,
      "step": 12000
    },
    {
      "epoch": 8.426573426573427,
      "grad_norm": 1.3403685092926025,
      "learning_rate": 7.870629370629371e-06,
      "loss": 0.0091,
      "step": 12050
    },
    {
      "epoch": 8.461538461538462,
      "grad_norm": 0.9165741205215454,
      "learning_rate": 7.695804195804196e-06,
      "loss": 0.0077,
      "step": 12100
    },
    {
      "epoch": 8.496503496503497,
      "grad_norm": 1.3177298307418823,
      "learning_rate": 7.520979020979021e-06,
      "loss": 0.009,
      "step": 12150
    },
    {
      "epoch": 8.531468531468532,
      "grad_norm": 1.1187794208526611,
      "learning_rate": 7.346153846153847e-06,
      "loss": 0.0083,
      "step": 12200
    },
    {
      "epoch": 8.566433566433567,
      "grad_norm": 1.9406895637512207,
      "learning_rate": 7.1713286713286714e-06,
      "loss": 0.0091,
      "step": 12250
    },
    {
      "epoch": 8.601398601398602,
      "grad_norm": 0.8251610398292542,
      "learning_rate": 6.9965034965034965e-06,
      "loss": 0.0069,
      "step": 12300
    },
    {
      "epoch": 8.636363636363637,
      "grad_norm": 2.1271708011627197,
      "learning_rate": 6.8216783216783225e-06,
      "loss": 0.0111,
      "step": 12350
    },
    {
      "epoch": 8.671328671328672,
      "grad_norm": 0.9863345623016357,
      "learning_rate": 6.646853146853148e-06,
      "loss": 0.009,
      "step": 12400
    },
    {
      "epoch": 8.706293706293707,
      "grad_norm": 0.9901391863822937,
      "learning_rate": 6.472027972027972e-06,
      "loss": 0.0075,
      "step": 12450
    },
    {
      "epoch": 8.741258741258742,
      "grad_norm": 0.3511747121810913,
      "learning_rate": 6.297202797202798e-06,
      "loss": 0.0068,
      "step": 12500
    },
    {
      "epoch": 8.776223776223777,
      "grad_norm": 1.9802547693252563,
      "learning_rate": 6.122377622377622e-06,
      "loss": 0.0099,
      "step": 12550
    },
    {
      "epoch": 8.811188811188812,
      "grad_norm": 0.8490275740623474,
      "learning_rate": 5.947552447552448e-06,
      "loss": 0.0083,
      "step": 12600
    },
    {
      "epoch": 8.846153846153847,
      "grad_norm": 1.2943763732910156,
      "learning_rate": 5.772727272727272e-06,
      "loss": 0.0089,
      "step": 12650
    },
    {
      "epoch": 8.881118881118882,
      "grad_norm": 2.0366783142089844,
      "learning_rate": 5.597902097902098e-06,
      "loss": 0.0081,
      "step": 12700
    },
    {
      "epoch": 8.916083916083917,
      "grad_norm": 1.876067876815796,
      "learning_rate": 5.423076923076923e-06,
      "loss": 0.0091,
      "step": 12750
    },
    {
      "epoch": 8.951048951048952,
      "grad_norm": 0.7789478898048401,
      "learning_rate": 5.2482517482517485e-06,
      "loss": 0.0083,
      "step": 12800
    },
    {
      "epoch": 8.986013986013987,
      "grad_norm": 0.7106555104255676,
      "learning_rate": 5.0734265734265736e-06,
      "loss": 0.007,
      "step": 12850
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.005201386287808418,
      "eval_runtime": 1.2059,
      "eval_samples_per_second": 568.848,
      "eval_steps_per_second": 71.313,
      "step": 12870
    },
    {
      "epoch": 9.020979020979022,
      "grad_norm": 0.11908203363418579,
      "learning_rate": 4.898601398601399e-06,
      "loss": 0.0086,
      "step": 12900
    },
    {
      "epoch": 9.055944055944057,
      "grad_norm": 4.112720012664795,
      "learning_rate": 4.723776223776224e-06,
      "loss": 0.0099,
      "step": 12950
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.6690908074378967,
      "learning_rate": 4.54895104895105e-06,
      "loss": 0.0074,
      "step": 13000
    },
    {
      "epoch": 9.125874125874127,
      "grad_norm": 1.300812005996704,
      "learning_rate": 4.374125874125874e-06,
      "loss": 0.0088,
      "step": 13050
    },
    {
      "epoch": 9.16083916083916,
      "grad_norm": 0.4101615846157074,
      "learning_rate": 4.1993006993007e-06,
      "loss": 0.0083,
      "step": 13100
    },
    {
      "epoch": 9.195804195804195,
      "grad_norm": 1.8279435634613037,
      "learning_rate": 4.024475524475524e-06,
      "loss": 0.0082,
      "step": 13150
    },
    {
      "epoch": 9.23076923076923,
      "grad_norm": 1.1671578884124756,
      "learning_rate": 3.84965034965035e-06,
      "loss": 0.0081,
      "step": 13200
    },
    {
      "epoch": 9.265734265734265,
      "grad_norm": 1.8591338396072388,
      "learning_rate": 3.674825174825175e-06,
      "loss": 0.0078,
      "step": 13250
    },
    {
      "epoch": 9.3006993006993,
      "grad_norm": 1.911037802696228,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0069,
      "step": 13300
    },
    {
      "epoch": 9.335664335664335,
      "grad_norm": 1.6729743480682373,
      "learning_rate": 3.3251748251748255e-06,
      "loss": 0.008,
      "step": 13350
    },
    {
      "epoch": 9.37062937062937,
      "grad_norm": 1.1313077211380005,
      "learning_rate": 3.15034965034965e-06,
      "loss": 0.0074,
      "step": 13400
    },
    {
      "epoch": 9.405594405594405,
      "grad_norm": 1.4324160814285278,
      "learning_rate": 2.9755244755244757e-06,
      "loss": 0.0088,
      "step": 13450
    },
    {
      "epoch": 9.44055944055944,
      "grad_norm": 1.1222423315048218,
      "learning_rate": 2.800699300699301e-06,
      "loss": 0.0076,
      "step": 13500
    },
    {
      "epoch": 9.475524475524475,
      "grad_norm": 1.4647001028060913,
      "learning_rate": 2.625874125874126e-06,
      "loss": 0.0072,
      "step": 13550
    },
    {
      "epoch": 9.51048951048951,
      "grad_norm": 3.043658971786499,
      "learning_rate": 2.4510489510489514e-06,
      "loss": 0.0075,
      "step": 13600
    },
    {
      "epoch": 9.545454545454545,
      "grad_norm": 1.0530234575271606,
      "learning_rate": 2.2762237762237765e-06,
      "loss": 0.0088,
      "step": 13650
    },
    {
      "epoch": 9.58041958041958,
      "grad_norm": 0.5610027313232422,
      "learning_rate": 2.1013986013986017e-06,
      "loss": 0.0083,
      "step": 13700
    },
    {
      "epoch": 9.615384615384615,
      "grad_norm": 0.9219720959663391,
      "learning_rate": 1.9265734265734263e-06,
      "loss": 0.0096,
      "step": 13750
    },
    {
      "epoch": 9.65034965034965,
      "grad_norm": 1.5615593194961548,
      "learning_rate": 1.7517482517482517e-06,
      "loss": 0.0085,
      "step": 13800
    },
    {
      "epoch": 9.685314685314685,
      "grad_norm": 1.4606356620788574,
      "learning_rate": 1.576923076923077e-06,
      "loss": 0.0065,
      "step": 13850
    },
    {
      "epoch": 9.72027972027972,
      "grad_norm": 2.107776165008545,
      "learning_rate": 1.4020979020979023e-06,
      "loss": 0.008,
      "step": 13900
    },
    {
      "epoch": 9.755244755244755,
      "grad_norm": 2.2102367877960205,
      "learning_rate": 1.2272727272727272e-06,
      "loss": 0.0081,
      "step": 13950
    },
    {
      "epoch": 9.79020979020979,
      "grad_norm": 1.2008041143417358,
      "learning_rate": 1.0524475524475525e-06,
      "loss": 0.0063,
      "step": 14000
    },
    {
      "epoch": 9.825174825174825,
      "grad_norm": 0.684811532497406,
      "learning_rate": 8.776223776223776e-07,
      "loss": 0.008,
      "step": 14050
    },
    {
      "epoch": 9.86013986013986,
      "grad_norm": 2.255596160888672,
      "learning_rate": 7.027972027972028e-07,
      "loss": 0.0087,
      "step": 14100
    },
    {
      "epoch": 9.895104895104895,
      "grad_norm": 1.6909701824188232,
      "learning_rate": 5.27972027972028e-07,
      "loss": 0.008,
      "step": 14150
    },
    {
      "epoch": 9.93006993006993,
      "grad_norm": 0.6092426180839539,
      "learning_rate": 3.5314685314685315e-07,
      "loss": 0.0073,
      "step": 14200
    },
    {
      "epoch": 9.965034965034965,
      "grad_norm": 1.3540116548538208,
      "learning_rate": 1.7832167832167833e-07,
      "loss": 0.0099,
      "step": 14250
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.8298065662384033,
      "learning_rate": 3.4965034965034967e-09,
      "loss": 0.0074,
      "step": 14300
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.005395329091697931,
      "eval_runtime": 1.1986,
      "eval_samples_per_second": 572.358,
      "eval_steps_per_second": 71.753,
      "step": 14300
    }
  ],
  "logging_steps": 50,
  "max_steps": 14300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6328807402428360.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
