{
  "best_global_step": 4290,
  "best_metric": 0.007323035504668951,
  "best_model_checkpoint": "ckpt/neurips.pt/Tg/Tg3/checkpoint-4290",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 7150,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03496503496503497,
      "grad_norm": 4.0460124015808105,
      "learning_rate": 4.9828671328671335e-05,
      "loss": 0.0626,
      "step": 50
    },
    {
      "epoch": 0.06993006993006994,
      "grad_norm": 5.247748851776123,
      "learning_rate": 4.9653846153846155e-05,
      "loss": 0.043,
      "step": 100
    },
    {
      "epoch": 0.1048951048951049,
      "grad_norm": 2.920362710952759,
      "learning_rate": 4.947902097902098e-05,
      "loss": 0.0449,
      "step": 150
    },
    {
      "epoch": 0.13986013986013987,
      "grad_norm": 2.4365577697753906,
      "learning_rate": 4.930419580419581e-05,
      "loss": 0.0397,
      "step": 200
    },
    {
      "epoch": 0.17482517482517482,
      "grad_norm": 4.891193389892578,
      "learning_rate": 4.912937062937063e-05,
      "loss": 0.0385,
      "step": 250
    },
    {
      "epoch": 0.2097902097902098,
      "grad_norm": 9.300712585449219,
      "learning_rate": 4.8954545454545456e-05,
      "loss": 0.0376,
      "step": 300
    },
    {
      "epoch": 0.24475524475524477,
      "grad_norm": 0.919330894947052,
      "learning_rate": 4.877972027972028e-05,
      "loss": 0.0386,
      "step": 350
    },
    {
      "epoch": 0.27972027972027974,
      "grad_norm": 4.37784481048584,
      "learning_rate": 4.860489510489511e-05,
      "loss": 0.0462,
      "step": 400
    },
    {
      "epoch": 0.3146853146853147,
      "grad_norm": 1.0429356098175049,
      "learning_rate": 4.843006993006993e-05,
      "loss": 0.0321,
      "step": 450
    },
    {
      "epoch": 0.34965034965034963,
      "grad_norm": 3.154421806335449,
      "learning_rate": 4.8255244755244756e-05,
      "loss": 0.0296,
      "step": 500
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 1.6218092441558838,
      "learning_rate": 4.808041958041958e-05,
      "loss": 0.0279,
      "step": 550
    },
    {
      "epoch": 0.4195804195804196,
      "grad_norm": 1.4075489044189453,
      "learning_rate": 4.79055944055944e-05,
      "loss": 0.0355,
      "step": 600
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 3.885253667831421,
      "learning_rate": 4.7730769230769236e-05,
      "loss": 0.0399,
      "step": 650
    },
    {
      "epoch": 0.48951048951048953,
      "grad_norm": 2.6196184158325195,
      "learning_rate": 4.7555944055944056e-05,
      "loss": 0.0287,
      "step": 700
    },
    {
      "epoch": 0.5244755244755245,
      "grad_norm": 1.9398581981658936,
      "learning_rate": 4.738111888111888e-05,
      "loss": 0.0331,
      "step": 750
    },
    {
      "epoch": 0.5594405594405595,
      "grad_norm": 9.205826759338379,
      "learning_rate": 4.720629370629371e-05,
      "loss": 0.0346,
      "step": 800
    },
    {
      "epoch": 0.5944055944055944,
      "grad_norm": 8.020177841186523,
      "learning_rate": 4.703146853146853e-05,
      "loss": 0.0349,
      "step": 850
    },
    {
      "epoch": 0.6293706293706294,
      "grad_norm": 3.0041942596435547,
      "learning_rate": 4.685664335664336e-05,
      "loss": 0.0272,
      "step": 900
    },
    {
      "epoch": 0.6643356643356644,
      "grad_norm": 4.522710800170898,
      "learning_rate": 4.6681818181818184e-05,
      "loss": 0.0252,
      "step": 950
    },
    {
      "epoch": 0.6993006993006993,
      "grad_norm": 4.079707145690918,
      "learning_rate": 4.650699300699301e-05,
      "loss": 0.028,
      "step": 1000
    },
    {
      "epoch": 0.7342657342657343,
      "grad_norm": 3.331531286239624,
      "learning_rate": 4.633216783216783e-05,
      "loss": 0.0406,
      "step": 1050
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 2.0518362522125244,
      "learning_rate": 4.6157342657342664e-05,
      "loss": 0.0305,
      "step": 1100
    },
    {
      "epoch": 0.8041958041958042,
      "grad_norm": 3.7431859970092773,
      "learning_rate": 4.5982517482517484e-05,
      "loss": 0.0281,
      "step": 1150
    },
    {
      "epoch": 0.8391608391608392,
      "grad_norm": 3.6855645179748535,
      "learning_rate": 4.580769230769231e-05,
      "loss": 0.0276,
      "step": 1200
    },
    {
      "epoch": 0.8741258741258742,
      "grad_norm": 3.6754565238952637,
      "learning_rate": 4.563286713286714e-05,
      "loss": 0.0328,
      "step": 1250
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 2.336467742919922,
      "learning_rate": 4.545804195804196e-05,
      "loss": 0.0332,
      "step": 1300
    },
    {
      "epoch": 0.9440559440559441,
      "grad_norm": 0.6736522912979126,
      "learning_rate": 4.5283216783216785e-05,
      "loss": 0.0259,
      "step": 1350
    },
    {
      "epoch": 0.9790209790209791,
      "grad_norm": 5.134487628936768,
      "learning_rate": 4.510839160839161e-05,
      "loss": 0.0255,
      "step": 1400
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.018024427816271782,
      "eval_runtime": 1.2654,
      "eval_samples_per_second": 542.132,
      "eval_steps_per_second": 67.964,
      "step": 1430
    },
    {
      "epoch": 1.013986013986014,
      "grad_norm": 3.5689384937286377,
      "learning_rate": 4.493356643356644e-05,
      "loss": 0.0236,
      "step": 1450
    },
    {
      "epoch": 1.048951048951049,
      "grad_norm": 5.190891265869141,
      "learning_rate": 4.475874125874126e-05,
      "loss": 0.0285,
      "step": 1500
    },
    {
      "epoch": 1.083916083916084,
      "grad_norm": 5.990734100341797,
      "learning_rate": 4.458391608391609e-05,
      "loss": 0.0262,
      "step": 1550
    },
    {
      "epoch": 1.118881118881119,
      "grad_norm": 1.9340689182281494,
      "learning_rate": 4.440909090909091e-05,
      "loss": 0.0246,
      "step": 1600
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 4.810998439788818,
      "learning_rate": 4.423426573426573e-05,
      "loss": 0.0204,
      "step": 1650
    },
    {
      "epoch": 1.1888111888111887,
      "grad_norm": 4.133477210998535,
      "learning_rate": 4.4059440559440565e-05,
      "loss": 0.0229,
      "step": 1700
    },
    {
      "epoch": 1.2237762237762237,
      "grad_norm": 2.6859052181243896,
      "learning_rate": 4.3884615384615385e-05,
      "loss": 0.0248,
      "step": 1750
    },
    {
      "epoch": 1.2587412587412588,
      "grad_norm": 4.31719970703125,
      "learning_rate": 4.370979020979021e-05,
      "loss": 0.0312,
      "step": 1800
    },
    {
      "epoch": 1.2937062937062938,
      "grad_norm": 4.739706993103027,
      "learning_rate": 4.353496503496504e-05,
      "loss": 0.0241,
      "step": 1850
    },
    {
      "epoch": 1.3286713286713288,
      "grad_norm": 3.504575490951538,
      "learning_rate": 4.3360139860139866e-05,
      "loss": 0.0312,
      "step": 1900
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 2.048098564147949,
      "learning_rate": 4.3185314685314686e-05,
      "loss": 0.0264,
      "step": 1950
    },
    {
      "epoch": 1.3986013986013985,
      "grad_norm": 3.308321714401245,
      "learning_rate": 4.301048951048951e-05,
      "loss": 0.0215,
      "step": 2000
    },
    {
      "epoch": 1.4335664335664335,
      "grad_norm": 0.9561813473701477,
      "learning_rate": 4.283566433566434e-05,
      "loss": 0.0269,
      "step": 2050
    },
    {
      "epoch": 1.4685314685314685,
      "grad_norm": 5.10230016708374,
      "learning_rate": 4.266083916083916e-05,
      "loss": 0.0243,
      "step": 2100
    },
    {
      "epoch": 1.5034965034965035,
      "grad_norm": 1.3080036640167236,
      "learning_rate": 4.2486013986013986e-05,
      "loss": 0.0266,
      "step": 2150
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 1.4027392864227295,
      "learning_rate": 4.231118881118881e-05,
      "loss": 0.024,
      "step": 2200
    },
    {
      "epoch": 1.5734265734265733,
      "grad_norm": 3.6318349838256836,
      "learning_rate": 4.213636363636364e-05,
      "loss": 0.0213,
      "step": 2250
    },
    {
      "epoch": 1.6083916083916083,
      "grad_norm": 6.8114848136901855,
      "learning_rate": 4.196153846153847e-05,
      "loss": 0.0193,
      "step": 2300
    },
    {
      "epoch": 1.6433566433566433,
      "grad_norm": 3.9062211513519287,
      "learning_rate": 4.178671328671329e-05,
      "loss": 0.0282,
      "step": 2350
    },
    {
      "epoch": 1.6783216783216783,
      "grad_norm": 3.0352649688720703,
      "learning_rate": 4.1611888111888113e-05,
      "loss": 0.0227,
      "step": 2400
    },
    {
      "epoch": 1.7132867132867133,
      "grad_norm": 1.981090784072876,
      "learning_rate": 4.143706293706294e-05,
      "loss": 0.0202,
      "step": 2450
    },
    {
      "epoch": 1.7482517482517483,
      "grad_norm": 3.7714805603027344,
      "learning_rate": 4.126223776223777e-05,
      "loss": 0.0254,
      "step": 2500
    },
    {
      "epoch": 1.7832167832167833,
      "grad_norm": 2.0775294303894043,
      "learning_rate": 4.108741258741259e-05,
      "loss": 0.0199,
      "step": 2550
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 3.1659271717071533,
      "learning_rate": 4.0912587412587414e-05,
      "loss": 0.0237,
      "step": 2600
    },
    {
      "epoch": 1.8531468531468531,
      "grad_norm": 1.8954981565475464,
      "learning_rate": 4.073776223776224e-05,
      "loss": 0.0193,
      "step": 2650
    },
    {
      "epoch": 1.8881118881118881,
      "grad_norm": 2.7792015075683594,
      "learning_rate": 4.056293706293707e-05,
      "loss": 0.0229,
      "step": 2700
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 5.826480865478516,
      "learning_rate": 4.038811188811189e-05,
      "loss": 0.0188,
      "step": 2750
    },
    {
      "epoch": 1.958041958041958,
      "grad_norm": 3.5110554695129395,
      "learning_rate": 4.0213286713286714e-05,
      "loss": 0.0251,
      "step": 2800
    },
    {
      "epoch": 1.993006993006993,
      "grad_norm": 4.289358139038086,
      "learning_rate": 4.003846153846154e-05,
      "loss": 0.0194,
      "step": 2850
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.030122345313429832,
      "eval_runtime": 1.2356,
      "eval_samples_per_second": 555.189,
      "eval_steps_per_second": 69.601,
      "step": 2860
    },
    {
      "epoch": 2.027972027972028,
      "grad_norm": 2.757859945297241,
      "learning_rate": 3.986363636363636e-05,
      "loss": 0.0207,
      "step": 2900
    },
    {
      "epoch": 2.062937062937063,
      "grad_norm": 1.8687750101089478,
      "learning_rate": 3.9688811188811195e-05,
      "loss": 0.0206,
      "step": 2950
    },
    {
      "epoch": 2.097902097902098,
      "grad_norm": 3.3136839866638184,
      "learning_rate": 3.9513986013986015e-05,
      "loss": 0.0186,
      "step": 3000
    },
    {
      "epoch": 2.132867132867133,
      "grad_norm": 5.236958980560303,
      "learning_rate": 3.933916083916084e-05,
      "loss": 0.0191,
      "step": 3050
    },
    {
      "epoch": 2.167832167832168,
      "grad_norm": 1.1324948072433472,
      "learning_rate": 3.916433566433567e-05,
      "loss": 0.0195,
      "step": 3100
    },
    {
      "epoch": 2.202797202797203,
      "grad_norm": 5.60981559753418,
      "learning_rate": 3.898951048951049e-05,
      "loss": 0.0173,
      "step": 3150
    },
    {
      "epoch": 2.237762237762238,
      "grad_norm": 2.3239946365356445,
      "learning_rate": 3.8814685314685315e-05,
      "loss": 0.0191,
      "step": 3200
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 3.283874273300171,
      "learning_rate": 3.863986013986014e-05,
      "loss": 0.0209,
      "step": 3250
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.6467664241790771,
      "learning_rate": 3.846503496503497e-05,
      "loss": 0.0201,
      "step": 3300
    },
    {
      "epoch": 2.3426573426573425,
      "grad_norm": 1.998552680015564,
      "learning_rate": 3.829020979020979e-05,
      "loss": 0.0213,
      "step": 3350
    },
    {
      "epoch": 2.3776223776223775,
      "grad_norm": 1.6491259336471558,
      "learning_rate": 3.811538461538462e-05,
      "loss": 0.0191,
      "step": 3400
    },
    {
      "epoch": 2.4125874125874125,
      "grad_norm": 2.4563803672790527,
      "learning_rate": 3.794055944055944e-05,
      "loss": 0.0171,
      "step": 3450
    },
    {
      "epoch": 2.4475524475524475,
      "grad_norm": 2.1083219051361084,
      "learning_rate": 3.776573426573426e-05,
      "loss": 0.0188,
      "step": 3500
    },
    {
      "epoch": 2.4825174825174825,
      "grad_norm": 2.1164634227752686,
      "learning_rate": 3.7590909090909096e-05,
      "loss": 0.0167,
      "step": 3550
    },
    {
      "epoch": 2.5174825174825175,
      "grad_norm": 2.810203790664673,
      "learning_rate": 3.7416083916083916e-05,
      "loss": 0.0171,
      "step": 3600
    },
    {
      "epoch": 2.5524475524475525,
      "grad_norm": 2.746258497238159,
      "learning_rate": 3.724125874125874e-05,
      "loss": 0.0154,
      "step": 3650
    },
    {
      "epoch": 2.5874125874125875,
      "grad_norm": 6.077376842498779,
      "learning_rate": 3.706643356643357e-05,
      "loss": 0.0187,
      "step": 3700
    },
    {
      "epoch": 2.6223776223776225,
      "grad_norm": 4.215087890625,
      "learning_rate": 3.6891608391608396e-05,
      "loss": 0.0206,
      "step": 3750
    },
    {
      "epoch": 2.6573426573426575,
      "grad_norm": 0.6970813274383545,
      "learning_rate": 3.6716783216783216e-05,
      "loss": 0.018,
      "step": 3800
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 3.698075532913208,
      "learning_rate": 3.654195804195804e-05,
      "loss": 0.0191,
      "step": 3850
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 3.440303325653076,
      "learning_rate": 3.636713286713287e-05,
      "loss": 0.016,
      "step": 3900
    },
    {
      "epoch": 2.762237762237762,
      "grad_norm": 1.8602033853530884,
      "learning_rate": 3.619230769230769e-05,
      "loss": 0.0177,
      "step": 3950
    },
    {
      "epoch": 2.797202797202797,
      "grad_norm": 0.8668479919433594,
      "learning_rate": 3.6017482517482524e-05,
      "loss": 0.016,
      "step": 4000
    },
    {
      "epoch": 2.832167832167832,
      "grad_norm": 0.9113363027572632,
      "learning_rate": 3.5842657342657344e-05,
      "loss": 0.0199,
      "step": 4050
    },
    {
      "epoch": 2.867132867132867,
      "grad_norm": 0.9230194687843323,
      "learning_rate": 3.566783216783217e-05,
      "loss": 0.0202,
      "step": 4100
    },
    {
      "epoch": 2.902097902097902,
      "grad_norm": 1.741329312324524,
      "learning_rate": 3.5493006993007e-05,
      "loss": 0.0176,
      "step": 4150
    },
    {
      "epoch": 2.937062937062937,
      "grad_norm": 3.202277898788452,
      "learning_rate": 3.5318181818181824e-05,
      "loss": 0.0181,
      "step": 4200
    },
    {
      "epoch": 2.972027972027972,
      "grad_norm": 2.4718072414398193,
      "learning_rate": 3.5143356643356644e-05,
      "loss": 0.0179,
      "step": 4250
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.007323035504668951,
      "eval_runtime": 1.2212,
      "eval_samples_per_second": 561.731,
      "eval_steps_per_second": 70.421,
      "step": 4290
    },
    {
      "epoch": 3.006993006993007,
      "grad_norm": 3.442272901535034,
      "learning_rate": 3.496853146853147e-05,
      "loss": 0.0169,
      "step": 4300
    },
    {
      "epoch": 3.041958041958042,
      "grad_norm": 1.6529269218444824,
      "learning_rate": 3.47937062937063e-05,
      "loss": 0.0162,
      "step": 4350
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 2.4449408054351807,
      "learning_rate": 3.461888111888112e-05,
      "loss": 0.0144,
      "step": 4400
    },
    {
      "epoch": 3.111888111888112,
      "grad_norm": 1.357448935508728,
      "learning_rate": 3.4444055944055945e-05,
      "loss": 0.0153,
      "step": 4450
    },
    {
      "epoch": 3.1468531468531467,
      "grad_norm": 0.8985098600387573,
      "learning_rate": 3.426923076923077e-05,
      "loss": 0.0128,
      "step": 4500
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 2.687858819961548,
      "learning_rate": 3.40944055944056e-05,
      "loss": 0.0152,
      "step": 4550
    },
    {
      "epoch": 3.2167832167832167,
      "grad_norm": 1.9819952249526978,
      "learning_rate": 3.391958041958042e-05,
      "loss": 0.0186,
      "step": 4600
    },
    {
      "epoch": 3.2517482517482517,
      "grad_norm": 1.8411800861358643,
      "learning_rate": 3.3744755244755245e-05,
      "loss": 0.014,
      "step": 4650
    },
    {
      "epoch": 3.2867132867132867,
      "grad_norm": 1.3710209131240845,
      "learning_rate": 3.356993006993007e-05,
      "loss": 0.0189,
      "step": 4700
    },
    {
      "epoch": 3.3216783216783217,
      "grad_norm": 1.4193499088287354,
      "learning_rate": 3.339510489510489e-05,
      "loss": 0.0141,
      "step": 4750
    },
    {
      "epoch": 3.3566433566433567,
      "grad_norm": 1.7819782495498657,
      "learning_rate": 3.3220279720279725e-05,
      "loss": 0.0163,
      "step": 4800
    },
    {
      "epoch": 3.3916083916083917,
      "grad_norm": 1.0626827478408813,
      "learning_rate": 3.3045454545454545e-05,
      "loss": 0.0134,
      "step": 4850
    },
    {
      "epoch": 3.4265734265734267,
      "grad_norm": 3.8357467651367188,
      "learning_rate": 3.287062937062937e-05,
      "loss": 0.0136,
      "step": 4900
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 3.4918622970581055,
      "learning_rate": 3.26958041958042e-05,
      "loss": 0.0175,
      "step": 4950
    },
    {
      "epoch": 3.4965034965034967,
      "grad_norm": 1.3521064519882202,
      "learning_rate": 3.252097902097902e-05,
      "loss": 0.016,
      "step": 5000
    },
    {
      "epoch": 3.5314685314685317,
      "grad_norm": 1.3103936910629272,
      "learning_rate": 3.2346153846153846e-05,
      "loss": 0.0157,
      "step": 5050
    },
    {
      "epoch": 3.5664335664335667,
      "grad_norm": 2.7274649143218994,
      "learning_rate": 3.217132867132867e-05,
      "loss": 0.0136,
      "step": 5100
    },
    {
      "epoch": 3.6013986013986012,
      "grad_norm": 0.8652522563934326,
      "learning_rate": 3.19965034965035e-05,
      "loss": 0.0132,
      "step": 5150
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 1.3450685739517212,
      "learning_rate": 3.182167832167832e-05,
      "loss": 0.0141,
      "step": 5200
    },
    {
      "epoch": 3.6713286713286712,
      "grad_norm": 1.658837080001831,
      "learning_rate": 3.164685314685315e-05,
      "loss": 0.013,
      "step": 5250
    },
    {
      "epoch": 3.7062937062937062,
      "grad_norm": 1.549672245979309,
      "learning_rate": 3.147202797202797e-05,
      "loss": 0.0107,
      "step": 5300
    },
    {
      "epoch": 3.7412587412587412,
      "grad_norm": 1.5802072286605835,
      "learning_rate": 3.12972027972028e-05,
      "loss": 0.0173,
      "step": 5350
    },
    {
      "epoch": 3.7762237762237763,
      "grad_norm": 1.030411720275879,
      "learning_rate": 3.112237762237763e-05,
      "loss": 0.011,
      "step": 5400
    },
    {
      "epoch": 3.8111888111888113,
      "grad_norm": 1.3119268417358398,
      "learning_rate": 3.094755244755245e-05,
      "loss": 0.0146,
      "step": 5450
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 3.5443341732025146,
      "learning_rate": 3.0772727272727273e-05,
      "loss": 0.0103,
      "step": 5500
    },
    {
      "epoch": 3.8811188811188813,
      "grad_norm": 1.7622323036193848,
      "learning_rate": 3.05979020979021e-05,
      "loss": 0.0154,
      "step": 5550
    },
    {
      "epoch": 3.916083916083916,
      "grad_norm": 4.825716972351074,
      "learning_rate": 3.0423076923076927e-05,
      "loss": 0.0145,
      "step": 5600
    },
    {
      "epoch": 3.951048951048951,
      "grad_norm": 1.0734108686447144,
      "learning_rate": 3.024825174825175e-05,
      "loss": 0.0147,
      "step": 5650
    },
    {
      "epoch": 3.986013986013986,
      "grad_norm": 3.0331599712371826,
      "learning_rate": 3.0073426573426577e-05,
      "loss": 0.014,
      "step": 5700
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.009357336908578873,
      "eval_runtime": 1.2265,
      "eval_samples_per_second": 559.322,
      "eval_steps_per_second": 70.119,
      "step": 5720
    },
    {
      "epoch": 4.020979020979021,
      "grad_norm": 1.3086472749710083,
      "learning_rate": 2.98986013986014e-05,
      "loss": 0.0183,
      "step": 5750
    },
    {
      "epoch": 4.055944055944056,
      "grad_norm": 2.9838521480560303,
      "learning_rate": 2.9723776223776224e-05,
      "loss": 0.0145,
      "step": 5800
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 1.009426474571228,
      "learning_rate": 2.954895104895105e-05,
      "loss": 0.0136,
      "step": 5850
    },
    {
      "epoch": 4.125874125874126,
      "grad_norm": 1.1615469455718994,
      "learning_rate": 2.9374125874125874e-05,
      "loss": 0.012,
      "step": 5900
    },
    {
      "epoch": 4.160839160839161,
      "grad_norm": 6.727407932281494,
      "learning_rate": 2.91993006993007e-05,
      "loss": 0.0111,
      "step": 5950
    },
    {
      "epoch": 4.195804195804196,
      "grad_norm": 4.083500862121582,
      "learning_rate": 2.9024475524475525e-05,
      "loss": 0.0132,
      "step": 6000
    },
    {
      "epoch": 4.230769230769231,
      "grad_norm": 1.4086931943893433,
      "learning_rate": 2.8849650349650355e-05,
      "loss": 0.0183,
      "step": 6050
    },
    {
      "epoch": 4.265734265734266,
      "grad_norm": 2.097416639328003,
      "learning_rate": 2.8674825174825175e-05,
      "loss": 0.0119,
      "step": 6100
    },
    {
      "epoch": 4.300699300699301,
      "grad_norm": 1.3249423503875732,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0147,
      "step": 6150
    },
    {
      "epoch": 4.335664335664336,
      "grad_norm": 1.064623236656189,
      "learning_rate": 2.832517482517483e-05,
      "loss": 0.0126,
      "step": 6200
    },
    {
      "epoch": 4.370629370629371,
      "grad_norm": 2.184468984603882,
      "learning_rate": 2.815034965034965e-05,
      "loss": 0.0136,
      "step": 6250
    },
    {
      "epoch": 4.405594405594406,
      "grad_norm": 1.061729907989502,
      "learning_rate": 2.797552447552448e-05,
      "loss": 0.0092,
      "step": 6300
    },
    {
      "epoch": 4.440559440559441,
      "grad_norm": 1.124277949333191,
      "learning_rate": 2.7800699300699302e-05,
      "loss": 0.0148,
      "step": 6350
    },
    {
      "epoch": 4.475524475524476,
      "grad_norm": 1.6680095195770264,
      "learning_rate": 2.762587412587413e-05,
      "loss": 0.0128,
      "step": 6400
    },
    {
      "epoch": 4.510489510489511,
      "grad_norm": 1.1022192239761353,
      "learning_rate": 2.7451048951048952e-05,
      "loss": 0.0134,
      "step": 6450
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.8124281764030457,
      "learning_rate": 2.7276223776223776e-05,
      "loss": 0.0111,
      "step": 6500
    },
    {
      "epoch": 4.58041958041958,
      "grad_norm": 1.4187066555023193,
      "learning_rate": 2.7101398601398602e-05,
      "loss": 0.0097,
      "step": 6550
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 2.064164161682129,
      "learning_rate": 2.6926573426573426e-05,
      "loss": 0.0139,
      "step": 6600
    },
    {
      "epoch": 4.65034965034965,
      "grad_norm": 1.1308422088623047,
      "learning_rate": 2.6751748251748253e-05,
      "loss": 0.0136,
      "step": 6650
    },
    {
      "epoch": 4.685314685314685,
      "grad_norm": 3.866032123565674,
      "learning_rate": 2.6576923076923076e-05,
      "loss": 0.012,
      "step": 6700
    },
    {
      "epoch": 4.72027972027972,
      "grad_norm": 1.6258597373962402,
      "learning_rate": 2.6402097902097906e-05,
      "loss": 0.0113,
      "step": 6750
    },
    {
      "epoch": 4.755244755244755,
      "grad_norm": 1.082198143005371,
      "learning_rate": 2.622727272727273e-05,
      "loss": 0.0117,
      "step": 6800
    },
    {
      "epoch": 4.79020979020979,
      "grad_norm": 4.256885051727295,
      "learning_rate": 2.6052447552447556e-05,
      "loss": 0.0127,
      "step": 6850
    },
    {
      "epoch": 4.825174825174825,
      "grad_norm": 1.8099477291107178,
      "learning_rate": 2.587762237762238e-05,
      "loss": 0.0151,
      "step": 6900
    },
    {
      "epoch": 4.86013986013986,
      "grad_norm": 2.127312183380127,
      "learning_rate": 2.5702797202797203e-05,
      "loss": 0.0112,
      "step": 6950
    },
    {
      "epoch": 4.895104895104895,
      "grad_norm": 2.1341705322265625,
      "learning_rate": 2.552797202797203e-05,
      "loss": 0.0121,
      "step": 7000
    },
    {
      "epoch": 4.93006993006993,
      "grad_norm": 1.5028691291809082,
      "learning_rate": 2.5353146853146853e-05,
      "loss": 0.0129,
      "step": 7050
    },
    {
      "epoch": 4.965034965034965,
      "grad_norm": 1.5115845203399658,
      "learning_rate": 2.517832167832168e-05,
      "loss": 0.0131,
      "step": 7100
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.92621111869812,
      "learning_rate": 2.5003496503496504e-05,
      "loss": 0.0115,
      "step": 7150
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.010017193853855133,
      "eval_runtime": 1.2443,
      "eval_samples_per_second": 551.326,
      "eval_steps_per_second": 69.117,
      "step": 7150
    }
  ],
  "logging_steps": 50,
  "max_steps": 14300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3091643857497060.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
