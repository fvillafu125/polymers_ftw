{
  "best_global_step": 8580,
  "best_metric": 0.004830549005419016,
  "best_model_checkpoint": "ckpt/neurips.pt/Tg/checkpoint-8580",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 11440,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03496503496503497,
      "grad_norm": 5.827893257141113,
      "learning_rate": 4.9828671328671335e-05,
      "loss": 0.0941,
      "step": 50
    },
    {
      "epoch": 0.06993006993006994,
      "grad_norm": 4.803689956665039,
      "learning_rate": 4.9653846153846155e-05,
      "loss": 0.0443,
      "step": 100
    },
    {
      "epoch": 0.1048951048951049,
      "grad_norm": 4.374913215637207,
      "learning_rate": 4.947902097902098e-05,
      "loss": 0.042,
      "step": 150
    },
    {
      "epoch": 0.13986013986013987,
      "grad_norm": 5.075766563415527,
      "learning_rate": 4.930419580419581e-05,
      "loss": 0.0369,
      "step": 200
    },
    {
      "epoch": 0.17482517482517482,
      "grad_norm": 2.5878748893737793,
      "learning_rate": 4.912937062937063e-05,
      "loss": 0.0411,
      "step": 250
    },
    {
      "epoch": 0.2097902097902098,
      "grad_norm": 4.01615047454834,
      "learning_rate": 4.8954545454545456e-05,
      "loss": 0.0394,
      "step": 300
    },
    {
      "epoch": 0.24475524475524477,
      "grad_norm": 4.776307106018066,
      "learning_rate": 4.877972027972028e-05,
      "loss": 0.028,
      "step": 350
    },
    {
      "epoch": 0.27972027972027974,
      "grad_norm": 1.2111189365386963,
      "learning_rate": 4.860489510489511e-05,
      "loss": 0.0354,
      "step": 400
    },
    {
      "epoch": 0.3146853146853147,
      "grad_norm": 2.267179489135742,
      "learning_rate": 4.843006993006993e-05,
      "loss": 0.0338,
      "step": 450
    },
    {
      "epoch": 0.34965034965034963,
      "grad_norm": 5.507717132568359,
      "learning_rate": 4.8255244755244756e-05,
      "loss": 0.0328,
      "step": 500
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 2.638183116912842,
      "learning_rate": 4.808041958041958e-05,
      "loss": 0.0252,
      "step": 550
    },
    {
      "epoch": 0.4195804195804196,
      "grad_norm": 5.04449987411499,
      "learning_rate": 4.79055944055944e-05,
      "loss": 0.0326,
      "step": 600
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 1.1807876825332642,
      "learning_rate": 4.7730769230769236e-05,
      "loss": 0.0335,
      "step": 650
    },
    {
      "epoch": 0.48951048951048953,
      "grad_norm": 0.9684118032455444,
      "learning_rate": 4.7555944055944056e-05,
      "loss": 0.0304,
      "step": 700
    },
    {
      "epoch": 0.5244755244755245,
      "grad_norm": 2.0045783519744873,
      "learning_rate": 4.738111888111888e-05,
      "loss": 0.0302,
      "step": 750
    },
    {
      "epoch": 0.5594405594405595,
      "grad_norm": 3.07348370552063,
      "learning_rate": 4.720629370629371e-05,
      "loss": 0.0244,
      "step": 800
    },
    {
      "epoch": 0.5944055944055944,
      "grad_norm": 1.3041417598724365,
      "learning_rate": 4.703146853146853e-05,
      "loss": 0.026,
      "step": 850
    },
    {
      "epoch": 0.6293706293706294,
      "grad_norm": 2.5184640884399414,
      "learning_rate": 4.685664335664336e-05,
      "loss": 0.0326,
      "step": 900
    },
    {
      "epoch": 0.6643356643356644,
      "grad_norm": 3.5873823165893555,
      "learning_rate": 4.6681818181818184e-05,
      "loss": 0.0247,
      "step": 950
    },
    {
      "epoch": 0.6993006993006993,
      "grad_norm": 4.8383989334106445,
      "learning_rate": 4.650699300699301e-05,
      "loss": 0.0343,
      "step": 1000
    },
    {
      "epoch": 0.7342657342657343,
      "grad_norm": 3.8589799404144287,
      "learning_rate": 4.633216783216783e-05,
      "loss": 0.03,
      "step": 1050
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 3.8364689350128174,
      "learning_rate": 4.6157342657342664e-05,
      "loss": 0.0308,
      "step": 1100
    },
    {
      "epoch": 0.8041958041958042,
      "grad_norm": 8.118742942810059,
      "learning_rate": 4.5982517482517484e-05,
      "loss": 0.027,
      "step": 1150
    },
    {
      "epoch": 0.8391608391608392,
      "grad_norm": 1.3547890186309814,
      "learning_rate": 4.580769230769231e-05,
      "loss": 0.0245,
      "step": 1200
    },
    {
      "epoch": 0.8741258741258742,
      "grad_norm": 4.784916877746582,
      "learning_rate": 4.563286713286714e-05,
      "loss": 0.0292,
      "step": 1250
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 2.2664198875427246,
      "learning_rate": 4.545804195804196e-05,
      "loss": 0.0289,
      "step": 1300
    },
    {
      "epoch": 0.9440559440559441,
      "grad_norm": 2.999605417251587,
      "learning_rate": 4.5283216783216785e-05,
      "loss": 0.0255,
      "step": 1350
    },
    {
      "epoch": 0.9790209790209791,
      "grad_norm": 5.455573558807373,
      "learning_rate": 4.510839160839161e-05,
      "loss": 0.0323,
      "step": 1400
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.010401396080851555,
      "eval_runtime": 1.2402,
      "eval_samples_per_second": 553.155,
      "eval_steps_per_second": 69.346,
      "step": 1430
    },
    {
      "epoch": 1.013986013986014,
      "grad_norm": 3.6828761100769043,
      "learning_rate": 4.493356643356644e-05,
      "loss": 0.0222,
      "step": 1450
    },
    {
      "epoch": 1.048951048951049,
      "grad_norm": 2.2806220054626465,
      "learning_rate": 4.475874125874126e-05,
      "loss": 0.0253,
      "step": 1500
    },
    {
      "epoch": 1.083916083916084,
      "grad_norm": 3.9519636631011963,
      "learning_rate": 4.458391608391609e-05,
      "loss": 0.0238,
      "step": 1550
    },
    {
      "epoch": 1.118881118881119,
      "grad_norm": 3.2071032524108887,
      "learning_rate": 4.440909090909091e-05,
      "loss": 0.0262,
      "step": 1600
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 3.013568162918091,
      "learning_rate": 4.423426573426573e-05,
      "loss": 0.0237,
      "step": 1650
    },
    {
      "epoch": 1.1888111888111887,
      "grad_norm": 2.7892210483551025,
      "learning_rate": 4.4059440559440565e-05,
      "loss": 0.0213,
      "step": 1700
    },
    {
      "epoch": 1.2237762237762237,
      "grad_norm": 3.9789273738861084,
      "learning_rate": 4.3884615384615385e-05,
      "loss": 0.0245,
      "step": 1750
    },
    {
      "epoch": 1.2587412587412588,
      "grad_norm": 5.48696756362915,
      "learning_rate": 4.370979020979021e-05,
      "loss": 0.0216,
      "step": 1800
    },
    {
      "epoch": 1.2937062937062938,
      "grad_norm": 7.337183952331543,
      "learning_rate": 4.353496503496504e-05,
      "loss": 0.0252,
      "step": 1850
    },
    {
      "epoch": 1.3286713286713288,
      "grad_norm": 3.1126914024353027,
      "learning_rate": 4.3360139860139866e-05,
      "loss": 0.0245,
      "step": 1900
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 2.2431247234344482,
      "learning_rate": 4.3185314685314686e-05,
      "loss": 0.0231,
      "step": 1950
    },
    {
      "epoch": 1.3986013986013985,
      "grad_norm": 5.21701192855835,
      "learning_rate": 4.301048951048951e-05,
      "loss": 0.0189,
      "step": 2000
    },
    {
      "epoch": 1.4335664335664335,
      "grad_norm": 1.9624130725860596,
      "learning_rate": 4.283566433566434e-05,
      "loss": 0.0223,
      "step": 2050
    },
    {
      "epoch": 1.4685314685314685,
      "grad_norm": 2.09610915184021,
      "learning_rate": 4.266083916083916e-05,
      "loss": 0.0244,
      "step": 2100
    },
    {
      "epoch": 1.5034965034965035,
      "grad_norm": 2.208373785018921,
      "learning_rate": 4.2486013986013986e-05,
      "loss": 0.0227,
      "step": 2150
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 2.7751190662384033,
      "learning_rate": 4.231118881118881e-05,
      "loss": 0.0195,
      "step": 2200
    },
    {
      "epoch": 1.5734265734265733,
      "grad_norm": 4.149500370025635,
      "learning_rate": 4.213636363636364e-05,
      "loss": 0.0178,
      "step": 2250
    },
    {
      "epoch": 1.6083916083916083,
      "grad_norm": 1.3234201669692993,
      "learning_rate": 4.196153846153847e-05,
      "loss": 0.0194,
      "step": 2300
    },
    {
      "epoch": 1.6433566433566433,
      "grad_norm": 2.1088414192199707,
      "learning_rate": 4.178671328671329e-05,
      "loss": 0.0194,
      "step": 2350
    },
    {
      "epoch": 1.6783216783216783,
      "grad_norm": 0.6376057863235474,
      "learning_rate": 4.1611888111888113e-05,
      "loss": 0.0203,
      "step": 2400
    },
    {
      "epoch": 1.7132867132867133,
      "grad_norm": 3.0765464305877686,
      "learning_rate": 4.143706293706294e-05,
      "loss": 0.0222,
      "step": 2450
    },
    {
      "epoch": 1.7482517482517483,
      "grad_norm": 2.6312344074249268,
      "learning_rate": 4.126223776223777e-05,
      "loss": 0.0192,
      "step": 2500
    },
    {
      "epoch": 1.7832167832167833,
      "grad_norm": 3.1310665607452393,
      "learning_rate": 4.108741258741259e-05,
      "loss": 0.0159,
      "step": 2550
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 1.612595796585083,
      "learning_rate": 4.0912587412587414e-05,
      "loss": 0.0202,
      "step": 2600
    },
    {
      "epoch": 1.8531468531468531,
      "grad_norm": 1.7591118812561035,
      "learning_rate": 4.073776223776224e-05,
      "loss": 0.0187,
      "step": 2650
    },
    {
      "epoch": 1.8881118881118881,
      "grad_norm": 0.7683690190315247,
      "learning_rate": 4.056293706293707e-05,
      "loss": 0.0201,
      "step": 2700
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 7.7582573890686035,
      "learning_rate": 4.038811188811189e-05,
      "loss": 0.0185,
      "step": 2750
    },
    {
      "epoch": 1.958041958041958,
      "grad_norm": 3.2477211952209473,
      "learning_rate": 4.0213286713286714e-05,
      "loss": 0.0226,
      "step": 2800
    },
    {
      "epoch": 1.993006993006993,
      "grad_norm": 2.5306389331817627,
      "learning_rate": 4.003846153846154e-05,
      "loss": 0.0157,
      "step": 2850
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.007507560774683952,
      "eval_runtime": 1.2276,
      "eval_samples_per_second": 558.83,
      "eval_steps_per_second": 70.057,
      "step": 2860
    },
    {
      "epoch": 2.027972027972028,
      "grad_norm": 3.681864023208618,
      "learning_rate": 3.986363636363636e-05,
      "loss": 0.0201,
      "step": 2900
    },
    {
      "epoch": 2.062937062937063,
      "grad_norm": 2.5896201133728027,
      "learning_rate": 3.9688811188811195e-05,
      "loss": 0.022,
      "step": 2950
    },
    {
      "epoch": 2.097902097902098,
      "grad_norm": 1.2683358192443848,
      "learning_rate": 3.9513986013986015e-05,
      "loss": 0.02,
      "step": 3000
    },
    {
      "epoch": 2.132867132867133,
      "grad_norm": 2.70465350151062,
      "learning_rate": 3.933916083916084e-05,
      "loss": 0.02,
      "step": 3050
    },
    {
      "epoch": 2.167832167832168,
      "grad_norm": 1.5703529119491577,
      "learning_rate": 3.916433566433567e-05,
      "loss": 0.0199,
      "step": 3100
    },
    {
      "epoch": 2.202797202797203,
      "grad_norm": 2.5489251613616943,
      "learning_rate": 3.898951048951049e-05,
      "loss": 0.019,
      "step": 3150
    },
    {
      "epoch": 2.237762237762238,
      "grad_norm": 1.4974037408828735,
      "learning_rate": 3.8814685314685315e-05,
      "loss": 0.0193,
      "step": 3200
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 2.140310764312744,
      "learning_rate": 3.863986013986014e-05,
      "loss": 0.0184,
      "step": 3250
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.5683202743530273,
      "learning_rate": 3.846503496503497e-05,
      "loss": 0.0151,
      "step": 3300
    },
    {
      "epoch": 2.3426573426573425,
      "grad_norm": 2.2838902473449707,
      "learning_rate": 3.829020979020979e-05,
      "loss": 0.0182,
      "step": 3350
    },
    {
      "epoch": 2.3776223776223775,
      "grad_norm": 1.4438728094100952,
      "learning_rate": 3.811538461538462e-05,
      "loss": 0.0185,
      "step": 3400
    },
    {
      "epoch": 2.4125874125874125,
      "grad_norm": 1.4256080389022827,
      "learning_rate": 3.794055944055944e-05,
      "loss": 0.0167,
      "step": 3450
    },
    {
      "epoch": 2.4475524475524475,
      "grad_norm": 0.497727632522583,
      "learning_rate": 3.776573426573426e-05,
      "loss": 0.0157,
      "step": 3500
    },
    {
      "epoch": 2.4825174825174825,
      "grad_norm": 1.4627187252044678,
      "learning_rate": 3.7590909090909096e-05,
      "loss": 0.0151,
      "step": 3550
    },
    {
      "epoch": 2.5174825174825175,
      "grad_norm": 3.4877443313598633,
      "learning_rate": 3.7416083916083916e-05,
      "loss": 0.0157,
      "step": 3600
    },
    {
      "epoch": 2.5524475524475525,
      "grad_norm": 2.21282696723938,
      "learning_rate": 3.724125874125874e-05,
      "loss": 0.0176,
      "step": 3650
    },
    {
      "epoch": 2.5874125874125875,
      "grad_norm": 4.268651008605957,
      "learning_rate": 3.706643356643357e-05,
      "loss": 0.0176,
      "step": 3700
    },
    {
      "epoch": 2.6223776223776225,
      "grad_norm": 6.4475860595703125,
      "learning_rate": 3.6891608391608396e-05,
      "loss": 0.0181,
      "step": 3750
    },
    {
      "epoch": 2.6573426573426575,
      "grad_norm": 1.1014610528945923,
      "learning_rate": 3.6716783216783216e-05,
      "loss": 0.0189,
      "step": 3800
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 0.7348929047584534,
      "learning_rate": 3.654195804195804e-05,
      "loss": 0.0142,
      "step": 3850
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 1.6243910789489746,
      "learning_rate": 3.636713286713287e-05,
      "loss": 0.0132,
      "step": 3900
    },
    {
      "epoch": 2.762237762237762,
      "grad_norm": 2.2931132316589355,
      "learning_rate": 3.619230769230769e-05,
      "loss": 0.0148,
      "step": 3950
    },
    {
      "epoch": 2.797202797202797,
      "grad_norm": 5.6515302658081055,
      "learning_rate": 3.6017482517482524e-05,
      "loss": 0.0168,
      "step": 4000
    },
    {
      "epoch": 2.832167832167832,
      "grad_norm": 1.856640100479126,
      "learning_rate": 3.5842657342657344e-05,
      "loss": 0.0198,
      "step": 4050
    },
    {
      "epoch": 2.867132867132867,
      "grad_norm": 0.8130698204040527,
      "learning_rate": 3.566783216783217e-05,
      "loss": 0.0171,
      "step": 4100
    },
    {
      "epoch": 2.902097902097902,
      "grad_norm": 3.506819486618042,
      "learning_rate": 3.5493006993007e-05,
      "loss": 0.0163,
      "step": 4150
    },
    {
      "epoch": 2.937062937062937,
      "grad_norm": 2.0990984439849854,
      "learning_rate": 3.5318181818181824e-05,
      "loss": 0.0148,
      "step": 4200
    },
    {
      "epoch": 2.972027972027972,
      "grad_norm": 3.627293586730957,
      "learning_rate": 3.5143356643356644e-05,
      "loss": 0.0166,
      "step": 4250
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.00952828861773014,
      "eval_runtime": 1.225,
      "eval_samples_per_second": 559.987,
      "eval_steps_per_second": 70.202,
      "step": 4290
    },
    {
      "epoch": 3.006993006993007,
      "grad_norm": 2.265127420425415,
      "learning_rate": 3.496853146853147e-05,
      "loss": 0.0133,
      "step": 4300
    },
    {
      "epoch": 3.041958041958042,
      "grad_norm": 0.9044035077095032,
      "learning_rate": 3.47937062937063e-05,
      "loss": 0.0173,
      "step": 4350
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 1.8444372415542603,
      "learning_rate": 3.461888111888112e-05,
      "loss": 0.0148,
      "step": 4400
    },
    {
      "epoch": 3.111888111888112,
      "grad_norm": 3.9101462364196777,
      "learning_rate": 3.4444055944055945e-05,
      "loss": 0.0169,
      "step": 4450
    },
    {
      "epoch": 3.1468531468531467,
      "grad_norm": 1.3206727504730225,
      "learning_rate": 3.426923076923077e-05,
      "loss": 0.0117,
      "step": 4500
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 2.5426955223083496,
      "learning_rate": 3.40944055944056e-05,
      "loss": 0.016,
      "step": 4550
    },
    {
      "epoch": 3.2167832167832167,
      "grad_norm": 1.9093073606491089,
      "learning_rate": 3.391958041958042e-05,
      "loss": 0.0144,
      "step": 4600
    },
    {
      "epoch": 3.2517482517482517,
      "grad_norm": 0.8580020070075989,
      "learning_rate": 3.3744755244755245e-05,
      "loss": 0.0138,
      "step": 4650
    },
    {
      "epoch": 3.2867132867132867,
      "grad_norm": 1.122733473777771,
      "learning_rate": 3.356993006993007e-05,
      "loss": 0.0151,
      "step": 4700
    },
    {
      "epoch": 3.3216783216783217,
      "grad_norm": 1.1311593055725098,
      "learning_rate": 3.339510489510489e-05,
      "loss": 0.0125,
      "step": 4750
    },
    {
      "epoch": 3.3566433566433567,
      "grad_norm": 1.450813889503479,
      "learning_rate": 3.3220279720279725e-05,
      "loss": 0.0151,
      "step": 4800
    },
    {
      "epoch": 3.3916083916083917,
      "grad_norm": 1.7575632333755493,
      "learning_rate": 3.3045454545454545e-05,
      "loss": 0.0156,
      "step": 4850
    },
    {
      "epoch": 3.4265734265734267,
      "grad_norm": 0.8044407963752747,
      "learning_rate": 3.287062937062937e-05,
      "loss": 0.0114,
      "step": 4900
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 2.1270666122436523,
      "learning_rate": 3.26958041958042e-05,
      "loss": 0.0168,
      "step": 4950
    },
    {
      "epoch": 3.4965034965034967,
      "grad_norm": 1.6239287853240967,
      "learning_rate": 3.252097902097902e-05,
      "loss": 0.0133,
      "step": 5000
    },
    {
      "epoch": 3.5314685314685317,
      "grad_norm": 2.670360803604126,
      "learning_rate": 3.2346153846153846e-05,
      "loss": 0.0139,
      "step": 5050
    },
    {
      "epoch": 3.5664335664335667,
      "grad_norm": 0.9970749020576477,
      "learning_rate": 3.217132867132867e-05,
      "loss": 0.0122,
      "step": 5100
    },
    {
      "epoch": 3.6013986013986012,
      "grad_norm": 1.0569990873336792,
      "learning_rate": 3.19965034965035e-05,
      "loss": 0.0121,
      "step": 5150
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 1.0572463274002075,
      "learning_rate": 3.182167832167832e-05,
      "loss": 0.0134,
      "step": 5200
    },
    {
      "epoch": 3.6713286713286712,
      "grad_norm": 1.129922866821289,
      "learning_rate": 3.164685314685315e-05,
      "loss": 0.0146,
      "step": 5250
    },
    {
      "epoch": 3.7062937062937062,
      "grad_norm": 0.577083170413971,
      "learning_rate": 3.147202797202797e-05,
      "loss": 0.0127,
      "step": 5300
    },
    {
      "epoch": 3.7412587412587412,
      "grad_norm": 4.965869426727295,
      "learning_rate": 3.12972027972028e-05,
      "loss": 0.0195,
      "step": 5350
    },
    {
      "epoch": 3.7762237762237763,
      "grad_norm": 0.9542391896247864,
      "learning_rate": 3.112237762237763e-05,
      "loss": 0.0127,
      "step": 5400
    },
    {
      "epoch": 3.8111888111888113,
      "grad_norm": 2.0562150478363037,
      "learning_rate": 3.094755244755245e-05,
      "loss": 0.0156,
      "step": 5450
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 2.7257614135742188,
      "learning_rate": 3.0772727272727273e-05,
      "loss": 0.0124,
      "step": 5500
    },
    {
      "epoch": 3.8811188811188813,
      "grad_norm": 1.0547324419021606,
      "learning_rate": 3.05979020979021e-05,
      "loss": 0.0138,
      "step": 5550
    },
    {
      "epoch": 3.916083916083916,
      "grad_norm": 3.9994609355926514,
      "learning_rate": 3.0423076923076927e-05,
      "loss": 0.0121,
      "step": 5600
    },
    {
      "epoch": 3.951048951048951,
      "grad_norm": 1.3751873970031738,
      "learning_rate": 3.024825174825175e-05,
      "loss": 0.0114,
      "step": 5650
    },
    {
      "epoch": 3.986013986013986,
      "grad_norm": 2.664155960083008,
      "learning_rate": 3.0073426573426577e-05,
      "loss": 0.0152,
      "step": 5700
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.005734528414905071,
      "eval_runtime": 1.2294,
      "eval_samples_per_second": 558.011,
      "eval_steps_per_second": 69.955,
      "step": 5720
    },
    {
      "epoch": 4.020979020979021,
      "grad_norm": 1.1100037097930908,
      "learning_rate": 2.98986013986014e-05,
      "loss": 0.0151,
      "step": 5750
    },
    {
      "epoch": 4.055944055944056,
      "grad_norm": 2.827944278717041,
      "learning_rate": 2.9723776223776224e-05,
      "loss": 0.0137,
      "step": 5800
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 0.7586674094200134,
      "learning_rate": 2.954895104895105e-05,
      "loss": 0.0131,
      "step": 5850
    },
    {
      "epoch": 4.125874125874126,
      "grad_norm": 0.8360681533813477,
      "learning_rate": 2.9374125874125874e-05,
      "loss": 0.0145,
      "step": 5900
    },
    {
      "epoch": 4.160839160839161,
      "grad_norm": 2.0909414291381836,
      "learning_rate": 2.91993006993007e-05,
      "loss": 0.0081,
      "step": 5950
    },
    {
      "epoch": 4.195804195804196,
      "grad_norm": 2.6179769039154053,
      "learning_rate": 2.9024475524475525e-05,
      "loss": 0.0111,
      "step": 6000
    },
    {
      "epoch": 4.230769230769231,
      "grad_norm": 1.4931129217147827,
      "learning_rate": 2.8849650349650355e-05,
      "loss": 0.0134,
      "step": 6050
    },
    {
      "epoch": 4.265734265734266,
      "grad_norm": 1.4317433834075928,
      "learning_rate": 2.8674825174825175e-05,
      "loss": 0.0094,
      "step": 6100
    },
    {
      "epoch": 4.300699300699301,
      "grad_norm": 1.383352518081665,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.013,
      "step": 6150
    },
    {
      "epoch": 4.335664335664336,
      "grad_norm": 2.0087757110595703,
      "learning_rate": 2.832517482517483e-05,
      "loss": 0.0123,
      "step": 6200
    },
    {
      "epoch": 4.370629370629371,
      "grad_norm": 2.1436848640441895,
      "learning_rate": 2.815034965034965e-05,
      "loss": 0.0113,
      "step": 6250
    },
    {
      "epoch": 4.405594405594406,
      "grad_norm": 2.2914607524871826,
      "learning_rate": 2.797552447552448e-05,
      "loss": 0.0099,
      "step": 6300
    },
    {
      "epoch": 4.440559440559441,
      "grad_norm": 1.3032591342926025,
      "learning_rate": 2.7800699300699302e-05,
      "loss": 0.0129,
      "step": 6350
    },
    {
      "epoch": 4.475524475524476,
      "grad_norm": 1.9710530042648315,
      "learning_rate": 2.762587412587413e-05,
      "loss": 0.0106,
      "step": 6400
    },
    {
      "epoch": 4.510489510489511,
      "grad_norm": 1.8099247217178345,
      "learning_rate": 2.7451048951048952e-05,
      "loss": 0.0114,
      "step": 6450
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 1.0706576108932495,
      "learning_rate": 2.7276223776223776e-05,
      "loss": 0.0092,
      "step": 6500
    },
    {
      "epoch": 4.58041958041958,
      "grad_norm": 1.9494740962982178,
      "learning_rate": 2.7101398601398602e-05,
      "loss": 0.0092,
      "step": 6550
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 1.3440604209899902,
      "learning_rate": 2.6926573426573426e-05,
      "loss": 0.0102,
      "step": 6600
    },
    {
      "epoch": 4.65034965034965,
      "grad_norm": 1.3519649505615234,
      "learning_rate": 2.6751748251748253e-05,
      "loss": 0.0113,
      "step": 6650
    },
    {
      "epoch": 4.685314685314685,
      "grad_norm": 3.2783708572387695,
      "learning_rate": 2.6576923076923076e-05,
      "loss": 0.0118,
      "step": 6700
    },
    {
      "epoch": 4.72027972027972,
      "grad_norm": 1.4799308776855469,
      "learning_rate": 2.6402097902097906e-05,
      "loss": 0.0102,
      "step": 6750
    },
    {
      "epoch": 4.755244755244755,
      "grad_norm": 2.912400722503662,
      "learning_rate": 2.622727272727273e-05,
      "loss": 0.0115,
      "step": 6800
    },
    {
      "epoch": 4.79020979020979,
      "grad_norm": 0.6089240908622742,
      "learning_rate": 2.6052447552447556e-05,
      "loss": 0.0123,
      "step": 6850
    },
    {
      "epoch": 4.825174825174825,
      "grad_norm": 2.0007216930389404,
      "learning_rate": 2.587762237762238e-05,
      "loss": 0.0129,
      "step": 6900
    },
    {
      "epoch": 4.86013986013986,
      "grad_norm": 2.440957546234131,
      "learning_rate": 2.5702797202797203e-05,
      "loss": 0.0122,
      "step": 6950
    },
    {
      "epoch": 4.895104895104895,
      "grad_norm": 1.0794219970703125,
      "learning_rate": 2.552797202797203e-05,
      "loss": 0.012,
      "step": 7000
    },
    {
      "epoch": 4.93006993006993,
      "grad_norm": 0.7564066648483276,
      "learning_rate": 2.5353146853146853e-05,
      "loss": 0.0117,
      "step": 7050
    },
    {
      "epoch": 4.965034965034965,
      "grad_norm": 0.8090391755104065,
      "learning_rate": 2.517832167832168e-05,
      "loss": 0.0097,
      "step": 7100
    },
    {
      "epoch": 5.0,
      "grad_norm": Infinity,
      "learning_rate": 2.5003496503496504e-05,
      "loss": 0.0127,
      "step": 7150
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.005794099066406488,
      "eval_runtime": 1.2256,
      "eval_samples_per_second": 559.715,
      "eval_steps_per_second": 70.168,
      "step": 7150
    },
    {
      "epoch": 5.034965034965035,
      "grad_norm": 0.9673511385917664,
      "learning_rate": 2.482867132867133e-05,
      "loss": 0.0094,
      "step": 7200
    },
    {
      "epoch": 5.06993006993007,
      "grad_norm": 1.9961713552474976,
      "learning_rate": 2.4653846153846154e-05,
      "loss": 0.0111,
      "step": 7250
    },
    {
      "epoch": 5.104895104895105,
      "grad_norm": 1.3592272996902466,
      "learning_rate": 2.447902097902098e-05,
      "loss": 0.0095,
      "step": 7300
    },
    {
      "epoch": 5.13986013986014,
      "grad_norm": 2.4824888706207275,
      "learning_rate": 2.4304195804195808e-05,
      "loss": 0.013,
      "step": 7350
    },
    {
      "epoch": 5.174825174825175,
      "grad_norm": 1.7060632705688477,
      "learning_rate": 2.412937062937063e-05,
      "loss": 0.0083,
      "step": 7400
    },
    {
      "epoch": 5.20979020979021,
      "grad_norm": 2.164593458175659,
      "learning_rate": 2.3954545454545454e-05,
      "loss": 0.0094,
      "step": 7450
    },
    {
      "epoch": 5.244755244755245,
      "grad_norm": 2.213263750076294,
      "learning_rate": 2.377972027972028e-05,
      "loss": 0.0127,
      "step": 7500
    },
    {
      "epoch": 5.27972027972028,
      "grad_norm": 1.8938781023025513,
      "learning_rate": 2.3604895104895105e-05,
      "loss": 0.0108,
      "step": 7550
    },
    {
      "epoch": 5.314685314685315,
      "grad_norm": 1.0352139472961426,
      "learning_rate": 2.343006993006993e-05,
      "loss": 0.0087,
      "step": 7600
    },
    {
      "epoch": 5.34965034965035,
      "grad_norm": 1.1083953380584717,
      "learning_rate": 2.3255244755244758e-05,
      "loss": 0.0116,
      "step": 7650
    },
    {
      "epoch": 5.384615384615385,
      "grad_norm": 0.6284055113792419,
      "learning_rate": 2.308041958041958e-05,
      "loss": 0.0114,
      "step": 7700
    },
    {
      "epoch": 5.41958041958042,
      "grad_norm": 2.9989845752716064,
      "learning_rate": 2.290559440559441e-05,
      "loss": 0.0108,
      "step": 7750
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 2.57619047164917,
      "learning_rate": 2.2730769230769232e-05,
      "loss": 0.0091,
      "step": 7800
    },
    {
      "epoch": 5.489510489510489,
      "grad_norm": 0.977891206741333,
      "learning_rate": 2.2555944055944055e-05,
      "loss": 0.0092,
      "step": 7850
    },
    {
      "epoch": 5.524475524475524,
      "grad_norm": 2.6030631065368652,
      "learning_rate": 2.2381118881118882e-05,
      "loss": 0.0111,
      "step": 7900
    },
    {
      "epoch": 5.559440559440559,
      "grad_norm": 1.1361687183380127,
      "learning_rate": 2.2206293706293705e-05,
      "loss": 0.0103,
      "step": 7950
    },
    {
      "epoch": 5.594405594405594,
      "grad_norm": 1.4373297691345215,
      "learning_rate": 2.2031468531468532e-05,
      "loss": 0.0091,
      "step": 8000
    },
    {
      "epoch": 5.629370629370629,
      "grad_norm": 1.3879339694976807,
      "learning_rate": 2.185664335664336e-05,
      "loss": 0.0083,
      "step": 8050
    },
    {
      "epoch": 5.664335664335664,
      "grad_norm": 1.6508842706680298,
      "learning_rate": 2.1681818181818182e-05,
      "loss": 0.0097,
      "step": 8100
    },
    {
      "epoch": 5.699300699300699,
      "grad_norm": 2.8579494953155518,
      "learning_rate": 2.150699300699301e-05,
      "loss": 0.0101,
      "step": 8150
    },
    {
      "epoch": 5.734265734265734,
      "grad_norm": 1.2432421445846558,
      "learning_rate": 2.1332167832167833e-05,
      "loss": 0.0107,
      "step": 8200
    },
    {
      "epoch": 5.769230769230769,
      "grad_norm": 0.4174785315990448,
      "learning_rate": 2.1157342657342656e-05,
      "loss": 0.0107,
      "step": 8250
    },
    {
      "epoch": 5.804195804195804,
      "grad_norm": 2.0816659927368164,
      "learning_rate": 2.0982517482517483e-05,
      "loss": 0.0143,
      "step": 8300
    },
    {
      "epoch": 5.839160839160839,
      "grad_norm": 1.834961175918579,
      "learning_rate": 2.080769230769231e-05,
      "loss": 0.0082,
      "step": 8350
    },
    {
      "epoch": 5.874125874125874,
      "grad_norm": 0.6219109296798706,
      "learning_rate": 2.0632867132867133e-05,
      "loss": 0.0118,
      "step": 8400
    },
    {
      "epoch": 5.909090909090909,
      "grad_norm": 2.361424446105957,
      "learning_rate": 2.045804195804196e-05,
      "loss": 0.0103,
      "step": 8450
    },
    {
      "epoch": 5.944055944055944,
      "grad_norm": 2.1754679679870605,
      "learning_rate": 2.0283216783216787e-05,
      "loss": 0.0128,
      "step": 8500
    },
    {
      "epoch": 5.979020979020979,
      "grad_norm": 1.6875979900360107,
      "learning_rate": 2.010839160839161e-05,
      "loss": 0.011,
      "step": 8550
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.004830549005419016,
      "eval_runtime": 1.2247,
      "eval_samples_per_second": 560.152,
      "eval_steps_per_second": 70.223,
      "step": 8580
    },
    {
      "epoch": 6.013986013986014,
      "grad_norm": 3.586094617843628,
      "learning_rate": 1.9933566433566434e-05,
      "loss": 0.0117,
      "step": 8600
    },
    {
      "epoch": 6.048951048951049,
      "grad_norm": 1.6701598167419434,
      "learning_rate": 1.975874125874126e-05,
      "loss": 0.011,
      "step": 8650
    },
    {
      "epoch": 6.083916083916084,
      "grad_norm": 2.164691925048828,
      "learning_rate": 1.9583916083916084e-05,
      "loss": 0.0098,
      "step": 8700
    },
    {
      "epoch": 6.118881118881119,
      "grad_norm": 1.453486442565918,
      "learning_rate": 1.940909090909091e-05,
      "loss": 0.0107,
      "step": 8750
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 1.025376558303833,
      "learning_rate": 1.9234265734265734e-05,
      "loss": 0.0085,
      "step": 8800
    },
    {
      "epoch": 6.188811188811189,
      "grad_norm": 1.8643455505371094,
      "learning_rate": 1.905944055944056e-05,
      "loss": 0.0087,
      "step": 8850
    },
    {
      "epoch": 6.223776223776224,
      "grad_norm": 2.8923850059509277,
      "learning_rate": 1.8884615384615388e-05,
      "loss": 0.01,
      "step": 8900
    },
    {
      "epoch": 6.258741258741258,
      "grad_norm": 1.3126401901245117,
      "learning_rate": 1.870979020979021e-05,
      "loss": 0.0101,
      "step": 8950
    },
    {
      "epoch": 6.293706293706293,
      "grad_norm": 2.0680148601531982,
      "learning_rate": 1.8534965034965034e-05,
      "loss": 0.0101,
      "step": 9000
    },
    {
      "epoch": 6.328671328671328,
      "grad_norm": 0.6126468181610107,
      "learning_rate": 1.836013986013986e-05,
      "loss": 0.0111,
      "step": 9050
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 0.8535735607147217,
      "learning_rate": 1.8185314685314685e-05,
      "loss": 0.0094,
      "step": 9100
    },
    {
      "epoch": 6.398601398601398,
      "grad_norm": 2.654794454574585,
      "learning_rate": 1.801048951048951e-05,
      "loss": 0.0087,
      "step": 9150
    },
    {
      "epoch": 6.433566433566433,
      "grad_norm": 2.4701619148254395,
      "learning_rate": 1.7835664335664338e-05,
      "loss": 0.0083,
      "step": 9200
    },
    {
      "epoch": 6.468531468531468,
      "grad_norm": 0.6761932373046875,
      "learning_rate": 1.766083916083916e-05,
      "loss": 0.0101,
      "step": 9250
    },
    {
      "epoch": 6.503496503496503,
      "grad_norm": 0.2995677590370178,
      "learning_rate": 1.748601398601399e-05,
      "loss": 0.0085,
      "step": 9300
    },
    {
      "epoch": 6.538461538461538,
      "grad_norm": 0.5627045631408691,
      "learning_rate": 1.7311188811188812e-05,
      "loss": 0.0088,
      "step": 9350
    },
    {
      "epoch": 6.573426573426573,
      "grad_norm": 0.9288763403892517,
      "learning_rate": 1.7136363636363635e-05,
      "loss": 0.0088,
      "step": 9400
    },
    {
      "epoch": 6.608391608391608,
      "grad_norm": 1.130626916885376,
      "learning_rate": 1.6961538461538462e-05,
      "loss": 0.0103,
      "step": 9450
    },
    {
      "epoch": 6.643356643356643,
      "grad_norm": 1.6208479404449463,
      "learning_rate": 1.678671328671329e-05,
      "loss": 0.0099,
      "step": 9500
    },
    {
      "epoch": 6.678321678321678,
      "grad_norm": 4.236320495605469,
      "learning_rate": 1.6611888111888112e-05,
      "loss": 0.0077,
      "step": 9550
    },
    {
      "epoch": 6.713286713286713,
      "grad_norm": 1.5209325551986694,
      "learning_rate": 1.643706293706294e-05,
      "loss": 0.0088,
      "step": 9600
    },
    {
      "epoch": 6.748251748251748,
      "grad_norm": 1.33158278465271,
      "learning_rate": 1.6262237762237766e-05,
      "loss": 0.0111,
      "step": 9650
    },
    {
      "epoch": 6.783216783216783,
      "grad_norm": 0.8294786810874939,
      "learning_rate": 1.6087412587412586e-05,
      "loss": 0.0099,
      "step": 9700
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 1.5192288160324097,
      "learning_rate": 1.5912587412587413e-05,
      "loss": 0.0097,
      "step": 9750
    },
    {
      "epoch": 6.853146853146853,
      "grad_norm": 0.8121991753578186,
      "learning_rate": 1.573776223776224e-05,
      "loss": 0.0098,
      "step": 9800
    },
    {
      "epoch": 6.888111888111888,
      "grad_norm": 1.0411925315856934,
      "learning_rate": 1.5562937062937063e-05,
      "loss": 0.0064,
      "step": 9850
    },
    {
      "epoch": 6.923076923076923,
      "grad_norm": 0.9290215969085693,
      "learning_rate": 1.538811188811189e-05,
      "loss": 0.0088,
      "step": 9900
    },
    {
      "epoch": 6.958041958041958,
      "grad_norm": 2.4434802532196045,
      "learning_rate": 1.5213286713286715e-05,
      "loss": 0.0077,
      "step": 9950
    },
    {
      "epoch": 6.993006993006993,
      "grad_norm": 1.7714720964431763,
      "learning_rate": 1.503846153846154e-05,
      "loss": 0.0091,
      "step": 10000
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.00581778958439827,
      "eval_runtime": 1.2314,
      "eval_samples_per_second": 557.095,
      "eval_steps_per_second": 69.84,
      "step": 10010
    },
    {
      "epoch": 7.027972027972028,
      "grad_norm": 2.1090495586395264,
      "learning_rate": 1.4863636363636365e-05,
      "loss": 0.0099,
      "step": 10050
    },
    {
      "epoch": 7.062937062937063,
      "grad_norm": 1.457740306854248,
      "learning_rate": 1.4688811188811188e-05,
      "loss": 0.0103,
      "step": 10100
    },
    {
      "epoch": 7.0979020979020975,
      "grad_norm": 1.6271063089370728,
      "learning_rate": 1.4513986013986014e-05,
      "loss": 0.0116,
      "step": 10150
    },
    {
      "epoch": 7.1328671328671325,
      "grad_norm": 0.8322763442993164,
      "learning_rate": 1.433916083916084e-05,
      "loss": 0.0099,
      "step": 10200
    },
    {
      "epoch": 7.1678321678321675,
      "grad_norm": 0.7296620607376099,
      "learning_rate": 1.4164335664335665e-05,
      "loss": 0.0092,
      "step": 10250
    },
    {
      "epoch": 7.2027972027972025,
      "grad_norm": 1.4780147075653076,
      "learning_rate": 1.398951048951049e-05,
      "loss": 0.0081,
      "step": 10300
    },
    {
      "epoch": 7.2377622377622375,
      "grad_norm": 1.7271323204040527,
      "learning_rate": 1.3814685314685316e-05,
      "loss": 0.0078,
      "step": 10350
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 1.8516491651535034,
      "learning_rate": 1.3639860139860142e-05,
      "loss": 0.009,
      "step": 10400
    },
    {
      "epoch": 7.3076923076923075,
      "grad_norm": 1.755075216293335,
      "learning_rate": 1.3465034965034964e-05,
      "loss": 0.009,
      "step": 10450
    },
    {
      "epoch": 7.3426573426573425,
      "grad_norm": 0.9958688616752625,
      "learning_rate": 1.329020979020979e-05,
      "loss": 0.0094,
      "step": 10500
    },
    {
      "epoch": 7.3776223776223775,
      "grad_norm": 0.6459609866142273,
      "learning_rate": 1.3115384615384616e-05,
      "loss": 0.0083,
      "step": 10550
    },
    {
      "epoch": 7.4125874125874125,
      "grad_norm": 1.1502399444580078,
      "learning_rate": 1.2940559440559441e-05,
      "loss": 0.0085,
      "step": 10600
    },
    {
      "epoch": 7.4475524475524475,
      "grad_norm": 1.9400901794433594,
      "learning_rate": 1.2765734265734266e-05,
      "loss": 0.0091,
      "step": 10650
    },
    {
      "epoch": 7.4825174825174825,
      "grad_norm": 0.18814882636070251,
      "learning_rate": 1.2590909090909091e-05,
      "loss": 0.0093,
      "step": 10700
    },
    {
      "epoch": 7.5174825174825175,
      "grad_norm": 0.2111869752407074,
      "learning_rate": 1.2416083916083917e-05,
      "loss": 0.007,
      "step": 10750
    },
    {
      "epoch": 7.5524475524475525,
      "grad_norm": 0.7740596532821655,
      "learning_rate": 1.2241258741258742e-05,
      "loss": 0.0085,
      "step": 10800
    },
    {
      "epoch": 7.5874125874125875,
      "grad_norm": 1.5865081548690796,
      "learning_rate": 1.2066433566433567e-05,
      "loss": 0.0071,
      "step": 10850
    },
    {
      "epoch": 7.6223776223776225,
      "grad_norm": 1.500407099723816,
      "learning_rate": 1.1891608391608394e-05,
      "loss": 0.0078,
      "step": 10900
    },
    {
      "epoch": 7.6573426573426575,
      "grad_norm": 1.5341545343399048,
      "learning_rate": 1.1716783216783217e-05,
      "loss": 0.0093,
      "step": 10950
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 0.5262644290924072,
      "learning_rate": 1.1541958041958042e-05,
      "loss": 0.0088,
      "step": 11000
    },
    {
      "epoch": 7.7272727272727275,
      "grad_norm": 1.4339827299118042,
      "learning_rate": 1.1367132867132869e-05,
      "loss": 0.0073,
      "step": 11050
    },
    {
      "epoch": 7.7622377622377625,
      "grad_norm": 1.2114386558532715,
      "learning_rate": 1.1192307692307692e-05,
      "loss": 0.0086,
      "step": 11100
    },
    {
      "epoch": 7.7972027972027975,
      "grad_norm": 2.0651097297668457,
      "learning_rate": 1.1017482517482517e-05,
      "loss": 0.0088,
      "step": 11150
    },
    {
      "epoch": 7.8321678321678325,
      "grad_norm": 1.3017147779464722,
      "learning_rate": 1.0842657342657342e-05,
      "loss": 0.0078,
      "step": 11200
    },
    {
      "epoch": 7.867132867132867,
      "grad_norm": 1.8232331275939941,
      "learning_rate": 1.066783216783217e-05,
      "loss": 0.0065,
      "step": 11250
    },
    {
      "epoch": 7.902097902097902,
      "grad_norm": 1.3008157014846802,
      "learning_rate": 1.0493006993006993e-05,
      "loss": 0.0087,
      "step": 11300
    },
    {
      "epoch": 7.937062937062937,
      "grad_norm": 1.0695843696594238,
      "learning_rate": 1.0318181818181818e-05,
      "loss": 0.0084,
      "step": 11350
    },
    {
      "epoch": 7.972027972027972,
      "grad_norm": 1.156715750694275,
      "learning_rate": 1.0143356643356645e-05,
      "loss": 0.0092,
      "step": 11400
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.005710331257432699,
      "eval_runtime": 1.2244,
      "eval_samples_per_second": 560.277,
      "eval_steps_per_second": 70.239,
      "step": 11440
    }
  ],
  "logging_steps": 50,
  "max_steps": 14300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4946630171995296.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
