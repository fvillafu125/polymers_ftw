{
  "best_global_step": 6108,
  "best_metric": 0.01135026291012764,
  "best_model_checkpoint": "ckpt/neurips.pt/density/checkpoint-6108",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 9162,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03274394237066143,
      "grad_norm": 5.697667598724365,
      "learning_rate": 4.983955468238376e-05,
      "loss": 0.1136,
      "step": 50
    },
    {
      "epoch": 0.06548788474132286,
      "grad_norm": 4.070349216461182,
      "learning_rate": 4.9675834970530455e-05,
      "loss": 0.0527,
      "step": 100
    },
    {
      "epoch": 0.09823182711198428,
      "grad_norm": 3.003369092941284,
      "learning_rate": 4.951211525867715e-05,
      "loss": 0.043,
      "step": 150
    },
    {
      "epoch": 0.13097576948264572,
      "grad_norm": 4.152775287628174,
      "learning_rate": 4.934839554682384e-05,
      "loss": 0.0524,
      "step": 200
    },
    {
      "epoch": 0.16371971185330714,
      "grad_norm": 6.77022647857666,
      "learning_rate": 4.9184675834970536e-05,
      "loss": 0.0341,
      "step": 250
    },
    {
      "epoch": 0.19646365422396855,
      "grad_norm": 1.4674232006072998,
      "learning_rate": 4.9020956123117225e-05,
      "loss": 0.0284,
      "step": 300
    },
    {
      "epoch": 0.22920759659463,
      "grad_norm": 3.8906657695770264,
      "learning_rate": 4.885723641126392e-05,
      "loss": 0.0326,
      "step": 350
    },
    {
      "epoch": 0.26195153896529144,
      "grad_norm": 4.728728294372559,
      "learning_rate": 4.869351669941061e-05,
      "loss": 0.0358,
      "step": 400
    },
    {
      "epoch": 0.29469548133595286,
      "grad_norm": 2.2672722339630127,
      "learning_rate": 4.8529796987557305e-05,
      "loss": 0.0248,
      "step": 450
    },
    {
      "epoch": 0.3274394237066143,
      "grad_norm": 4.103261470794678,
      "learning_rate": 4.8366077275703994e-05,
      "loss": 0.0281,
      "step": 500
    },
    {
      "epoch": 0.3601833660772757,
      "grad_norm": 5.957397937774658,
      "learning_rate": 4.820235756385069e-05,
      "loss": 0.0288,
      "step": 550
    },
    {
      "epoch": 0.3929273084479371,
      "grad_norm": 5.626086711883545,
      "learning_rate": 4.803863785199738e-05,
      "loss": 0.0324,
      "step": 600
    },
    {
      "epoch": 0.4256712508185986,
      "grad_norm": 5.579730033874512,
      "learning_rate": 4.7874918140144075e-05,
      "loss": 0.029,
      "step": 650
    },
    {
      "epoch": 0.45841519318926,
      "grad_norm": 0.88924640417099,
      "learning_rate": 4.771119842829077e-05,
      "loss": 0.0271,
      "step": 700
    },
    {
      "epoch": 0.4911591355599214,
      "grad_norm": 1.8356502056121826,
      "learning_rate": 4.754747871643746e-05,
      "loss": 0.0294,
      "step": 750
    },
    {
      "epoch": 0.5239030779305829,
      "grad_norm": 1.9218376874923706,
      "learning_rate": 4.7383759004584156e-05,
      "loss": 0.021,
      "step": 800
    },
    {
      "epoch": 0.5566470203012442,
      "grad_norm": 2.1181280612945557,
      "learning_rate": 4.7220039292730845e-05,
      "loss": 0.026,
      "step": 850
    },
    {
      "epoch": 0.5893909626719057,
      "grad_norm": 1.7535018920898438,
      "learning_rate": 4.705631958087754e-05,
      "loss": 0.0231,
      "step": 900
    },
    {
      "epoch": 0.6221349050425671,
      "grad_norm": 2.4535539150238037,
      "learning_rate": 4.6892599869024236e-05,
      "loss": 0.024,
      "step": 950
    },
    {
      "epoch": 0.6548788474132285,
      "grad_norm": 2.268825054168701,
      "learning_rate": 4.6728880157170925e-05,
      "loss": 0.024,
      "step": 1000
    },
    {
      "epoch": 0.68762278978389,
      "grad_norm": 0.9420124888420105,
      "learning_rate": 4.656516044531762e-05,
      "loss": 0.0321,
      "step": 1050
    },
    {
      "epoch": 0.7203667321545514,
      "grad_norm": 6.390240669250488,
      "learning_rate": 4.640144073346431e-05,
      "loss": 0.0255,
      "step": 1100
    },
    {
      "epoch": 0.7531106745252129,
      "grad_norm": 2.259183883666992,
      "learning_rate": 4.6237721021611006e-05,
      "loss": 0.0255,
      "step": 1150
    },
    {
      "epoch": 0.7858546168958742,
      "grad_norm": 2.438373327255249,
      "learning_rate": 4.6074001309757695e-05,
      "loss": 0.0218,
      "step": 1200
    },
    {
      "epoch": 0.8185985592665357,
      "grad_norm": 3.8547441959381104,
      "learning_rate": 4.591028159790439e-05,
      "loss": 0.024,
      "step": 1250
    },
    {
      "epoch": 0.8513425016371972,
      "grad_norm": 2.1896021366119385,
      "learning_rate": 4.574656188605108e-05,
      "loss": 0.0214,
      "step": 1300
    },
    {
      "epoch": 0.8840864440078585,
      "grad_norm": 2.991584062576294,
      "learning_rate": 4.5582842174197775e-05,
      "loss": 0.0222,
      "step": 1350
    },
    {
      "epoch": 0.91683038637852,
      "grad_norm": 1.7233768701553345,
      "learning_rate": 4.541912246234447e-05,
      "loss": 0.0224,
      "step": 1400
    },
    {
      "epoch": 0.9495743287491814,
      "grad_norm": 3.185915946960449,
      "learning_rate": 4.525540275049116e-05,
      "loss": 0.0175,
      "step": 1450
    },
    {
      "epoch": 0.9823182711198428,
      "grad_norm": 1.6477018594741821,
      "learning_rate": 4.5091683038637856e-05,
      "loss": 0.0268,
      "step": 1500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.01746586710214615,
      "eval_runtime": 1.0513,
      "eval_samples_per_second": 585.967,
      "eval_steps_per_second": 73.246,
      "step": 1527
    },
    {
      "epoch": 1.0150622134905043,
      "grad_norm": 3.9420788288116455,
      "learning_rate": 4.4927963326784545e-05,
      "loss": 0.0189,
      "step": 1550
    },
    {
      "epoch": 1.0478061558611658,
      "grad_norm": 3.459937572479248,
      "learning_rate": 4.476424361493124e-05,
      "loss": 0.0225,
      "step": 1600
    },
    {
      "epoch": 1.080550098231827,
      "grad_norm": 1.3782103061676025,
      "learning_rate": 4.4600523903077936e-05,
      "loss": 0.0171,
      "step": 1650
    },
    {
      "epoch": 1.1132940406024885,
      "grad_norm": 2.452453851699829,
      "learning_rate": 4.4436804191224625e-05,
      "loss": 0.0231,
      "step": 1700
    },
    {
      "epoch": 1.14603798297315,
      "grad_norm": 1.6980856657028198,
      "learning_rate": 4.427308447937132e-05,
      "loss": 0.0185,
      "step": 1750
    },
    {
      "epoch": 1.1787819253438114,
      "grad_norm": 0.8548741936683655,
      "learning_rate": 4.410936476751801e-05,
      "loss": 0.0158,
      "step": 1800
    },
    {
      "epoch": 1.211525867714473,
      "grad_norm": 3.010770559310913,
      "learning_rate": 4.39456450556647e-05,
      "loss": 0.0166,
      "step": 1850
    },
    {
      "epoch": 1.2442698100851342,
      "grad_norm": 2.2000069618225098,
      "learning_rate": 4.3781925343811395e-05,
      "loss": 0.0167,
      "step": 1900
    },
    {
      "epoch": 1.2770137524557956,
      "grad_norm": 1.5987780094146729,
      "learning_rate": 4.361820563195809e-05,
      "loss": 0.0174,
      "step": 1950
    },
    {
      "epoch": 1.309757694826457,
      "grad_norm": 1.255493402481079,
      "learning_rate": 4.345448592010478e-05,
      "loss": 0.0216,
      "step": 2000
    },
    {
      "epoch": 1.3425016371971186,
      "grad_norm": 3.5669100284576416,
      "learning_rate": 4.3290766208251476e-05,
      "loss": 0.0178,
      "step": 2050
    },
    {
      "epoch": 1.37524557956778,
      "grad_norm": 2.338906764984131,
      "learning_rate": 4.3127046496398165e-05,
      "loss": 0.0175,
      "step": 2100
    },
    {
      "epoch": 1.4079895219384415,
      "grad_norm": 3.779803991317749,
      "learning_rate": 4.296332678454486e-05,
      "loss": 0.0172,
      "step": 2150
    },
    {
      "epoch": 1.4407334643091028,
      "grad_norm": 5.224480152130127,
      "learning_rate": 4.2799607072691556e-05,
      "loss": 0.0178,
      "step": 2200
    },
    {
      "epoch": 1.4734774066797642,
      "grad_norm": 1.2148959636688232,
      "learning_rate": 4.2635887360838245e-05,
      "loss": 0.0144,
      "step": 2250
    },
    {
      "epoch": 1.5062213490504257,
      "grad_norm": 2.2346951961517334,
      "learning_rate": 4.247216764898494e-05,
      "loss": 0.0141,
      "step": 2300
    },
    {
      "epoch": 1.538965291421087,
      "grad_norm": 1.720654845237732,
      "learning_rate": 4.230844793713164e-05,
      "loss": 0.0159,
      "step": 2350
    },
    {
      "epoch": 1.5717092337917484,
      "grad_norm": 1.6525909900665283,
      "learning_rate": 4.2144728225278326e-05,
      "loss": 0.0181,
      "step": 2400
    },
    {
      "epoch": 1.60445317616241,
      "grad_norm": 1.5277482271194458,
      "learning_rate": 4.198100851342502e-05,
      "loss": 0.0158,
      "step": 2450
    },
    {
      "epoch": 1.6371971185330714,
      "grad_norm": 0.7783527970314026,
      "learning_rate": 4.181728880157171e-05,
      "loss": 0.0152,
      "step": 2500
    },
    {
      "epoch": 1.6699410609037328,
      "grad_norm": 1.868420958518982,
      "learning_rate": 4.16535690897184e-05,
      "loss": 0.0156,
      "step": 2550
    },
    {
      "epoch": 1.7026850032743943,
      "grad_norm": 4.016542434692383,
      "learning_rate": 4.1489849377865095e-05,
      "loss": 0.0162,
      "step": 2600
    },
    {
      "epoch": 1.7354289456450558,
      "grad_norm": 5.0990777015686035,
      "learning_rate": 4.132612966601179e-05,
      "loss": 0.0187,
      "step": 2650
    },
    {
      "epoch": 1.768172888015717,
      "grad_norm": 3.3967552185058594,
      "learning_rate": 4.116240995415848e-05,
      "loss": 0.018,
      "step": 2700
    },
    {
      "epoch": 1.8009168303863785,
      "grad_norm": 2.805243492126465,
      "learning_rate": 4.0998690242305176e-05,
      "loss": 0.0158,
      "step": 2750
    },
    {
      "epoch": 1.83366077275704,
      "grad_norm": 5.316118240356445,
      "learning_rate": 4.0834970530451865e-05,
      "loss": 0.0154,
      "step": 2800
    },
    {
      "epoch": 1.8664047151277012,
      "grad_norm": 2.289421319961548,
      "learning_rate": 4.067125081859856e-05,
      "loss": 0.0181,
      "step": 2850
    },
    {
      "epoch": 1.8991486574983627,
      "grad_norm": 0.9714036583900452,
      "learning_rate": 4.0507531106745257e-05,
      "loss": 0.0147,
      "step": 2900
    },
    {
      "epoch": 1.9318925998690242,
      "grad_norm": 2.4726147651672363,
      "learning_rate": 4.0343811394891946e-05,
      "loss": 0.0139,
      "step": 2950
    },
    {
      "epoch": 1.9646365422396856,
      "grad_norm": 0.30642348527908325,
      "learning_rate": 4.018009168303864e-05,
      "loss": 0.0153,
      "step": 3000
    },
    {
      "epoch": 1.9973804846103471,
      "grad_norm": 4.586114406585693,
      "learning_rate": 4.001637197118534e-05,
      "loss": 0.0105,
      "step": 3050
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.02685140073299408,
      "eval_runtime": 1.0564,
      "eval_samples_per_second": 583.104,
      "eval_steps_per_second": 72.888,
      "step": 3054
    },
    {
      "epoch": 2.0301244269810086,
      "grad_norm": 8.534652709960938,
      "learning_rate": 3.9852652259332026e-05,
      "loss": 0.0205,
      "step": 3100
    },
    {
      "epoch": 2.06286836935167,
      "grad_norm": 1.9979668855667114,
      "learning_rate": 3.968893254747872e-05,
      "loss": 0.0148,
      "step": 3150
    },
    {
      "epoch": 2.0956123117223315,
      "grad_norm": 2.5798864364624023,
      "learning_rate": 3.952521283562541e-05,
      "loss": 0.0149,
      "step": 3200
    },
    {
      "epoch": 2.128356254092993,
      "grad_norm": 2.5578837394714355,
      "learning_rate": 3.93614931237721e-05,
      "loss": 0.014,
      "step": 3250
    },
    {
      "epoch": 2.161100196463654,
      "grad_norm": 1.0920956134796143,
      "learning_rate": 3.9197773411918796e-05,
      "loss": 0.0121,
      "step": 3300
    },
    {
      "epoch": 2.1938441388343155,
      "grad_norm": 0.9291795492172241,
      "learning_rate": 3.9034053700065485e-05,
      "loss": 0.0138,
      "step": 3350
    },
    {
      "epoch": 2.226588081204977,
      "grad_norm": 1.9838987588882446,
      "learning_rate": 3.887033398821218e-05,
      "loss": 0.0116,
      "step": 3400
    },
    {
      "epoch": 2.2593320235756384,
      "grad_norm": 3.1661431789398193,
      "learning_rate": 3.8706614276358876e-05,
      "loss": 0.0152,
      "step": 3450
    },
    {
      "epoch": 2.2920759659463,
      "grad_norm": 1.358157992362976,
      "learning_rate": 3.8542894564505565e-05,
      "loss": 0.0116,
      "step": 3500
    },
    {
      "epoch": 2.3248199083169614,
      "grad_norm": 0.8097653388977051,
      "learning_rate": 3.837917485265226e-05,
      "loss": 0.0112,
      "step": 3550
    },
    {
      "epoch": 2.357563850687623,
      "grad_norm": 4.206581115722656,
      "learning_rate": 3.821545514079896e-05,
      "loss": 0.0123,
      "step": 3600
    },
    {
      "epoch": 2.3903077930582843,
      "grad_norm": 0.6029289960861206,
      "learning_rate": 3.8051735428945646e-05,
      "loss": 0.0115,
      "step": 3650
    },
    {
      "epoch": 2.423051735428946,
      "grad_norm": 1.3397436141967773,
      "learning_rate": 3.788801571709234e-05,
      "loss": 0.0111,
      "step": 3700
    },
    {
      "epoch": 2.455795677799607,
      "grad_norm": 1.8219237327575684,
      "learning_rate": 3.772429600523904e-05,
      "loss": 0.0094,
      "step": 3750
    },
    {
      "epoch": 2.4885396201702683,
      "grad_norm": 1.9007610082626343,
      "learning_rate": 3.7560576293385726e-05,
      "loss": 0.0159,
      "step": 3800
    },
    {
      "epoch": 2.52128356254093,
      "grad_norm": 1.934905767440796,
      "learning_rate": 3.739685658153242e-05,
      "loss": 0.0105,
      "step": 3850
    },
    {
      "epoch": 2.5540275049115913,
      "grad_norm": 1.7136106491088867,
      "learning_rate": 3.723313686967911e-05,
      "loss": 0.0114,
      "step": 3900
    },
    {
      "epoch": 2.5867714472822527,
      "grad_norm": 1.7063031196594238,
      "learning_rate": 3.70694171578258e-05,
      "loss": 0.01,
      "step": 3950
    },
    {
      "epoch": 2.619515389652914,
      "grad_norm": 2.723198175430298,
      "learning_rate": 3.6905697445972496e-05,
      "loss": 0.0106,
      "step": 4000
    },
    {
      "epoch": 2.6522593320235757,
      "grad_norm": 2.733003616333008,
      "learning_rate": 3.6741977734119185e-05,
      "loss": 0.0114,
      "step": 4050
    },
    {
      "epoch": 2.685003274394237,
      "grad_norm": 1.519292950630188,
      "learning_rate": 3.657825802226588e-05,
      "loss": 0.0077,
      "step": 4100
    },
    {
      "epoch": 2.7177472167648986,
      "grad_norm": 3.8650975227355957,
      "learning_rate": 3.6414538310412577e-05,
      "loss": 0.0108,
      "step": 4150
    },
    {
      "epoch": 2.75049115913556,
      "grad_norm": 1.274109959602356,
      "learning_rate": 3.6250818598559266e-05,
      "loss": 0.011,
      "step": 4200
    },
    {
      "epoch": 2.7832351015062216,
      "grad_norm": 1.6698858737945557,
      "learning_rate": 3.608709888670596e-05,
      "loss": 0.011,
      "step": 4250
    },
    {
      "epoch": 2.815979043876883,
      "grad_norm": 1.131338119506836,
      "learning_rate": 3.592337917485266e-05,
      "loss": 0.0111,
      "step": 4300
    },
    {
      "epoch": 2.848722986247544,
      "grad_norm": 0.4349902868270874,
      "learning_rate": 3.5759659462999346e-05,
      "loss": 0.0101,
      "step": 4350
    },
    {
      "epoch": 2.8814669286182055,
      "grad_norm": 1.4776275157928467,
      "learning_rate": 3.559593975114604e-05,
      "loss": 0.0122,
      "step": 4400
    },
    {
      "epoch": 2.914210870988867,
      "grad_norm": 1.1232973337173462,
      "learning_rate": 3.543222003929274e-05,
      "loss": 0.0083,
      "step": 4450
    },
    {
      "epoch": 2.9469548133595285,
      "grad_norm": 1.398186445236206,
      "learning_rate": 3.526850032743943e-05,
      "loss": 0.0085,
      "step": 4500
    },
    {
      "epoch": 2.97969875573019,
      "grad_norm": 1.7195732593536377,
      "learning_rate": 3.510478061558612e-05,
      "loss": 0.0098,
      "step": 4550
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.015222395770251751,
      "eval_runtime": 1.0548,
      "eval_samples_per_second": 583.99,
      "eval_steps_per_second": 72.999,
      "step": 4581
    },
    {
      "epoch": 3.0124426981008514,
      "grad_norm": 1.278278112411499,
      "learning_rate": 3.494106090373281e-05,
      "loss": 0.0091,
      "step": 4600
    },
    {
      "epoch": 3.045186640471513,
      "grad_norm": 1.1808838844299316,
      "learning_rate": 3.47773411918795e-05,
      "loss": 0.0094,
      "step": 4650
    },
    {
      "epoch": 3.0779305828421744,
      "grad_norm": 2.3256423473358154,
      "learning_rate": 3.4613621480026196e-05,
      "loss": 0.0087,
      "step": 4700
    },
    {
      "epoch": 3.110674525212836,
      "grad_norm": 0.9987910985946655,
      "learning_rate": 3.4449901768172885e-05,
      "loss": 0.0108,
      "step": 4750
    },
    {
      "epoch": 3.143418467583497,
      "grad_norm": 0.13976533710956573,
      "learning_rate": 3.428618205631958e-05,
      "loss": 0.0095,
      "step": 4800
    },
    {
      "epoch": 3.1761624099541583,
      "grad_norm": 1.2458332777023315,
      "learning_rate": 3.412246234446628e-05,
      "loss": 0.0098,
      "step": 4850
    },
    {
      "epoch": 3.20890635232482,
      "grad_norm": 2.481863260269165,
      "learning_rate": 3.3958742632612966e-05,
      "loss": 0.0099,
      "step": 4900
    },
    {
      "epoch": 3.2416502946954813,
      "grad_norm": 0.7032220959663391,
      "learning_rate": 3.379502292075966e-05,
      "loss": 0.011,
      "step": 4950
    },
    {
      "epoch": 3.2743942370661427,
      "grad_norm": 1.354057788848877,
      "learning_rate": 3.363130320890636e-05,
      "loss": 0.0099,
      "step": 5000
    },
    {
      "epoch": 3.307138179436804,
      "grad_norm": 1.708951711654663,
      "learning_rate": 3.3467583497053046e-05,
      "loss": 0.0098,
      "step": 5050
    },
    {
      "epoch": 3.3398821218074657,
      "grad_norm": 2.0952258110046387,
      "learning_rate": 3.330386378519974e-05,
      "loss": 0.0097,
      "step": 5100
    },
    {
      "epoch": 3.372626064178127,
      "grad_norm": 1.3976871967315674,
      "learning_rate": 3.314014407334644e-05,
      "loss": 0.0077,
      "step": 5150
    },
    {
      "epoch": 3.4053700065487886,
      "grad_norm": 1.8393834829330444,
      "learning_rate": 3.297642436149313e-05,
      "loss": 0.0085,
      "step": 5200
    },
    {
      "epoch": 3.43811394891945,
      "grad_norm": 1.387181282043457,
      "learning_rate": 3.2812704649639816e-05,
      "loss": 0.0088,
      "step": 5250
    },
    {
      "epoch": 3.4708578912901116,
      "grad_norm": 1.607256531715393,
      "learning_rate": 3.264898493778651e-05,
      "loss": 0.009,
      "step": 5300
    },
    {
      "epoch": 3.5036018336607726,
      "grad_norm": 1.9736266136169434,
      "learning_rate": 3.24852652259332e-05,
      "loss": 0.0098,
      "step": 5350
    },
    {
      "epoch": 3.536345776031434,
      "grad_norm": 1.3132153749465942,
      "learning_rate": 3.2321545514079897e-05,
      "loss": 0.0081,
      "step": 5400
    },
    {
      "epoch": 3.5690897184020955,
      "grad_norm": 1.9195581674575806,
      "learning_rate": 3.2157825802226586e-05,
      "loss": 0.0079,
      "step": 5450
    },
    {
      "epoch": 3.601833660772757,
      "grad_norm": 1.376725673675537,
      "learning_rate": 3.199410609037328e-05,
      "loss": 0.0091,
      "step": 5500
    },
    {
      "epoch": 3.6345776031434185,
      "grad_norm": 1.580392599105835,
      "learning_rate": 3.183038637851998e-05,
      "loss": 0.008,
      "step": 5550
    },
    {
      "epoch": 3.66732154551408,
      "grad_norm": 2.4178504943847656,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.0055,
      "step": 5600
    },
    {
      "epoch": 3.7000654878847414,
      "grad_norm": 1.3362863063812256,
      "learning_rate": 3.150294695481336e-05,
      "loss": 0.006,
      "step": 5650
    },
    {
      "epoch": 3.732809430255403,
      "grad_norm": 1.951325535774231,
      "learning_rate": 3.133922724296006e-05,
      "loss": 0.0084,
      "step": 5700
    },
    {
      "epoch": 3.765553372626064,
      "grad_norm": 0.31248027086257935,
      "learning_rate": 3.117550753110675e-05,
      "loss": 0.0075,
      "step": 5750
    },
    {
      "epoch": 3.7982973149967254,
      "grad_norm": 1.920452356338501,
      "learning_rate": 3.101178781925344e-05,
      "loss": 0.0077,
      "step": 5800
    },
    {
      "epoch": 3.831041257367387,
      "grad_norm": 2.3028054237365723,
      "learning_rate": 3.084806810740013e-05,
      "loss": 0.0062,
      "step": 5850
    },
    {
      "epoch": 3.8637851997380483,
      "grad_norm": 1.0227493047714233,
      "learning_rate": 3.068434839554683e-05,
      "loss": 0.0085,
      "step": 5900
    },
    {
      "epoch": 3.89652914210871,
      "grad_norm": 1.9125585556030273,
      "learning_rate": 3.0520628683693516e-05,
      "loss": 0.0079,
      "step": 5950
    },
    {
      "epoch": 3.9292730844793713,
      "grad_norm": 1.069050669670105,
      "learning_rate": 3.035690897184021e-05,
      "loss": 0.0069,
      "step": 6000
    },
    {
      "epoch": 3.9620170268500328,
      "grad_norm": 2.815260887145996,
      "learning_rate": 3.0193189259986904e-05,
      "loss": 0.0097,
      "step": 6050
    },
    {
      "epoch": 3.9947609692206942,
      "grad_norm": 1.2199156284332275,
      "learning_rate": 3.00294695481336e-05,
      "loss": 0.0075,
      "step": 6100
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.01135026291012764,
      "eval_runtime": 1.0511,
      "eval_samples_per_second": 586.073,
      "eval_steps_per_second": 73.259,
      "step": 6108
    },
    {
      "epoch": 4.027504911591356,
      "grad_norm": 2.0659358501434326,
      "learning_rate": 2.986574983628029e-05,
      "loss": 0.0073,
      "step": 6150
    },
    {
      "epoch": 4.060248853962017,
      "grad_norm": 1.2146368026733398,
      "learning_rate": 2.970203012442698e-05,
      "loss": 0.0065,
      "step": 6200
    },
    {
      "epoch": 4.092992796332679,
      "grad_norm": 1.1451025009155273,
      "learning_rate": 2.9538310412573677e-05,
      "loss": 0.0087,
      "step": 6250
    },
    {
      "epoch": 4.12573673870334,
      "grad_norm": 0.4520278573036194,
      "learning_rate": 2.9374590700720366e-05,
      "loss": 0.0068,
      "step": 6300
    },
    {
      "epoch": 4.158480681074002,
      "grad_norm": 3.057300329208374,
      "learning_rate": 2.9210870988867062e-05,
      "loss": 0.0088,
      "step": 6350
    },
    {
      "epoch": 4.191224623444663,
      "grad_norm": 0.7898725271224976,
      "learning_rate": 2.9047151277013758e-05,
      "loss": 0.0058,
      "step": 6400
    },
    {
      "epoch": 4.2239685658153245,
      "grad_norm": 1.0084257125854492,
      "learning_rate": 2.8883431565160447e-05,
      "loss": 0.0053,
      "step": 6450
    },
    {
      "epoch": 4.256712508185986,
      "grad_norm": 0.8279995918273926,
      "learning_rate": 2.871971185330714e-05,
      "loss": 0.0091,
      "step": 6500
    },
    {
      "epoch": 4.2894564505566475,
      "grad_norm": 1.9282413721084595,
      "learning_rate": 2.855599214145383e-05,
      "loss": 0.0089,
      "step": 6550
    },
    {
      "epoch": 4.322200392927308,
      "grad_norm": 2.244967222213745,
      "learning_rate": 2.8392272429600524e-05,
      "loss": 0.0064,
      "step": 6600
    },
    {
      "epoch": 4.3549443352979695,
      "grad_norm": 0.5172426104545593,
      "learning_rate": 2.822855271774722e-05,
      "loss": 0.0057,
      "step": 6650
    },
    {
      "epoch": 4.387688277668631,
      "grad_norm": 0.8770626783370972,
      "learning_rate": 2.806483300589391e-05,
      "loss": 0.0053,
      "step": 6700
    },
    {
      "epoch": 4.4204322200392925,
      "grad_norm": 1.1318690776824951,
      "learning_rate": 2.7901113294040605e-05,
      "loss": 0.0071,
      "step": 6750
    },
    {
      "epoch": 4.453176162409954,
      "grad_norm": 0.7660800814628601,
      "learning_rate": 2.7737393582187297e-05,
      "loss": 0.0063,
      "step": 6800
    },
    {
      "epoch": 4.485920104780615,
      "grad_norm": 0.6067900657653809,
      "learning_rate": 2.757367387033399e-05,
      "loss": 0.0067,
      "step": 6850
    },
    {
      "epoch": 4.518664047151277,
      "grad_norm": 0.9447116255760193,
      "learning_rate": 2.7409954158480682e-05,
      "loss": 0.0067,
      "step": 6900
    },
    {
      "epoch": 4.551407989521938,
      "grad_norm": 2.531890392303467,
      "learning_rate": 2.7246234446627378e-05,
      "loss": 0.0064,
      "step": 6950
    },
    {
      "epoch": 4.5841519318926,
      "grad_norm": 0.9927736520767212,
      "learning_rate": 2.7082514734774067e-05,
      "loss": 0.0068,
      "step": 7000
    },
    {
      "epoch": 4.616895874263261,
      "grad_norm": 0.4067840576171875,
      "learning_rate": 2.6918795022920763e-05,
      "loss": 0.0047,
      "step": 7050
    },
    {
      "epoch": 4.649639816633923,
      "grad_norm": 0.8139780759811401,
      "learning_rate": 2.675507531106745e-05,
      "loss": 0.0049,
      "step": 7100
    },
    {
      "epoch": 4.682383759004584,
      "grad_norm": 3.6973378658294678,
      "learning_rate": 2.6591355599214147e-05,
      "loss": 0.0067,
      "step": 7150
    },
    {
      "epoch": 4.715127701375246,
      "grad_norm": 0.9609267115592957,
      "learning_rate": 2.642763588736084e-05,
      "loss": 0.0072,
      "step": 7200
    },
    {
      "epoch": 4.747871643745907,
      "grad_norm": 3.039332151412964,
      "learning_rate": 2.626391617550753e-05,
      "loss": 0.0066,
      "step": 7250
    },
    {
      "epoch": 4.780615586116569,
      "grad_norm": 1.4031208753585815,
      "learning_rate": 2.6100196463654225e-05,
      "loss": 0.0054,
      "step": 7300
    },
    {
      "epoch": 4.81335952848723,
      "grad_norm": 0.3508574366569519,
      "learning_rate": 2.593647675180092e-05,
      "loss": 0.0054,
      "step": 7350
    },
    {
      "epoch": 4.846103470857892,
      "grad_norm": 0.2215586155653,
      "learning_rate": 2.577275703994761e-05,
      "loss": 0.0045,
      "step": 7400
    },
    {
      "epoch": 4.878847413228553,
      "grad_norm": 1.5761849880218506,
      "learning_rate": 2.5609037328094305e-05,
      "loss": 0.0054,
      "step": 7450
    },
    {
      "epoch": 4.911591355599214,
      "grad_norm": 2.6713666915893555,
      "learning_rate": 2.5445317616240997e-05,
      "loss": 0.0057,
      "step": 7500
    },
    {
      "epoch": 4.944335297969875,
      "grad_norm": 0.46234506368637085,
      "learning_rate": 2.528159790438769e-05,
      "loss": 0.0048,
      "step": 7550
    },
    {
      "epoch": 4.977079240340537,
      "grad_norm": 1.5086930990219116,
      "learning_rate": 2.5117878192534382e-05,
      "loss": 0.0064,
      "step": 7600
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.014102816581726074,
      "eval_runtime": 1.0455,
      "eval_samples_per_second": 589.182,
      "eval_steps_per_second": 73.648,
      "step": 7635
    },
    {
      "epoch": 5.009823182711198,
      "grad_norm": 1.8219070434570312,
      "learning_rate": 2.4954158480681075e-05,
      "loss": 0.0051,
      "step": 7650
    },
    {
      "epoch": 5.04256712508186,
      "grad_norm": 0.8338509798049927,
      "learning_rate": 2.4790438768827767e-05,
      "loss": 0.0059,
      "step": 7700
    },
    {
      "epoch": 5.075311067452521,
      "grad_norm": 0.8333353400230408,
      "learning_rate": 2.4626719056974463e-05,
      "loss": 0.0059,
      "step": 7750
    },
    {
      "epoch": 5.1080550098231825,
      "grad_norm": 0.5006150603294373,
      "learning_rate": 2.4462999345121155e-05,
      "loss": 0.0055,
      "step": 7800
    },
    {
      "epoch": 5.140798952193844,
      "grad_norm": 1.8443124294281006,
      "learning_rate": 2.4299279633267848e-05,
      "loss": 0.0055,
      "step": 7850
    },
    {
      "epoch": 5.1735428945645054,
      "grad_norm": 1.3480236530303955,
      "learning_rate": 2.413555992141454e-05,
      "loss": 0.0061,
      "step": 7900
    },
    {
      "epoch": 5.206286836935167,
      "grad_norm": 1.0315308570861816,
      "learning_rate": 2.3971840209561232e-05,
      "loss": 0.0049,
      "step": 7950
    },
    {
      "epoch": 5.239030779305828,
      "grad_norm": 0.46268969774246216,
      "learning_rate": 2.3808120497707925e-05,
      "loss": 0.0059,
      "step": 8000
    },
    {
      "epoch": 5.27177472167649,
      "grad_norm": 0.8902148604393005,
      "learning_rate": 2.3644400785854617e-05,
      "loss": 0.0062,
      "step": 8050
    },
    {
      "epoch": 5.304518664047151,
      "grad_norm": 0.28809037804603577,
      "learning_rate": 2.3480681074001313e-05,
      "loss": 0.0063,
      "step": 8100
    },
    {
      "epoch": 5.337262606417813,
      "grad_norm": 1.037267804145813,
      "learning_rate": 2.3316961362148005e-05,
      "loss": 0.0051,
      "step": 8150
    },
    {
      "epoch": 5.370006548788474,
      "grad_norm": 0.7670493125915527,
      "learning_rate": 2.3153241650294698e-05,
      "loss": 0.0057,
      "step": 8200
    },
    {
      "epoch": 5.402750491159136,
      "grad_norm": 0.5716409683227539,
      "learning_rate": 2.2989521938441387e-05,
      "loss": 0.0047,
      "step": 8250
    },
    {
      "epoch": 5.435494433529797,
      "grad_norm": 1.7842556238174438,
      "learning_rate": 2.2825802226588083e-05,
      "loss": 0.0064,
      "step": 8300
    },
    {
      "epoch": 5.468238375900459,
      "grad_norm": 1.2895145416259766,
      "learning_rate": 2.2662082514734775e-05,
      "loss": 0.0037,
      "step": 8350
    },
    {
      "epoch": 5.50098231827112,
      "grad_norm": 0.4892295002937317,
      "learning_rate": 2.2498362802881467e-05,
      "loss": 0.0042,
      "step": 8400
    },
    {
      "epoch": 5.533726260641782,
      "grad_norm": 0.651628851890564,
      "learning_rate": 2.233464309102816e-05,
      "loss": 0.0039,
      "step": 8450
    },
    {
      "epoch": 5.566470203012443,
      "grad_norm": 0.8841373920440674,
      "learning_rate": 2.2170923379174856e-05,
      "loss": 0.0052,
      "step": 8500
    },
    {
      "epoch": 5.599214145383105,
      "grad_norm": 1.0907129049301147,
      "learning_rate": 2.2007203667321548e-05,
      "loss": 0.0055,
      "step": 8550
    },
    {
      "epoch": 5.631958087753766,
      "grad_norm": 1.4040004014968872,
      "learning_rate": 2.1843483955468237e-05,
      "loss": 0.0048,
      "step": 8600
    },
    {
      "epoch": 5.664702030124427,
      "grad_norm": 1.5996239185333252,
      "learning_rate": 2.1679764243614933e-05,
      "loss": 0.005,
      "step": 8650
    },
    {
      "epoch": 5.697445972495088,
      "grad_norm": 0.5949797630310059,
      "learning_rate": 2.1516044531761625e-05,
      "loss": 0.005,
      "step": 8700
    },
    {
      "epoch": 5.73018991486575,
      "grad_norm": 1.3538281917572021,
      "learning_rate": 2.1352324819908318e-05,
      "loss": 0.0068,
      "step": 8750
    },
    {
      "epoch": 5.762933857236411,
      "grad_norm": 0.31014928221702576,
      "learning_rate": 2.118860510805501e-05,
      "loss": 0.0044,
      "step": 8800
    },
    {
      "epoch": 5.7956777996070725,
      "grad_norm": 0.9961514472961426,
      "learning_rate": 2.1024885396201706e-05,
      "loss": 0.0045,
      "step": 8850
    },
    {
      "epoch": 5.828421741977734,
      "grad_norm": 0.43076491355895996,
      "learning_rate": 2.0861165684348398e-05,
      "loss": 0.0056,
      "step": 8900
    },
    {
      "epoch": 5.8611656843483955,
      "grad_norm": 0.5010103583335876,
      "learning_rate": 2.0697445972495087e-05,
      "loss": 0.005,
      "step": 8950
    },
    {
      "epoch": 5.893909626719057,
      "grad_norm": 0.7131481766700745,
      "learning_rate": 2.0533726260641783e-05,
      "loss": 0.0048,
      "step": 9000
    },
    {
      "epoch": 5.926653569089718,
      "grad_norm": 0.7099803686141968,
      "learning_rate": 2.0370006548788475e-05,
      "loss": 0.0037,
      "step": 9050
    },
    {
      "epoch": 5.95939751146038,
      "grad_norm": 0.23360015451908112,
      "learning_rate": 2.0206286836935168e-05,
      "loss": 0.0054,
      "step": 9100
    },
    {
      "epoch": 5.992141453831041,
      "grad_norm": 1.695686936378479,
      "learning_rate": 2.004256712508186e-05,
      "loss": 0.0042,
      "step": 9150
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.013358760625123978,
      "eval_runtime": 1.0448,
      "eval_samples_per_second": 589.561,
      "eval_steps_per_second": 73.695,
      "step": 9162
    }
  ],
  "logging_steps": 50,
  "max_steps": 15270,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3961760171422680.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
