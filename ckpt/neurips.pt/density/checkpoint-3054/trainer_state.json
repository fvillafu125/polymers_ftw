{
  "best_global_step": 3054,
  "best_metric": 0.011831247247755527,
  "best_model_checkpoint": "ckpt/neurips.pt/density/checkpoint-3054",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3054,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03274394237066143,
      "grad_norm": 2.422405481338501,
      "learning_rate": 4.983955468238376e-05,
      "loss": 0.2487,
      "step": 50
    },
    {
      "epoch": 0.06548788474132286,
      "grad_norm": 3.9796531200408936,
      "learning_rate": 4.9675834970530455e-05,
      "loss": 0.053,
      "step": 100
    },
    {
      "epoch": 0.09823182711198428,
      "grad_norm": 1.5206763744354248,
      "learning_rate": 4.951211525867715e-05,
      "loss": 0.0386,
      "step": 150
    },
    {
      "epoch": 0.13097576948264572,
      "grad_norm": 7.348196029663086,
      "learning_rate": 4.934839554682384e-05,
      "loss": 0.0421,
      "step": 200
    },
    {
      "epoch": 0.16371971185330714,
      "grad_norm": 2.5446834564208984,
      "learning_rate": 4.9184675834970536e-05,
      "loss": 0.0392,
      "step": 250
    },
    {
      "epoch": 0.19646365422396855,
      "grad_norm": 2.2413947582244873,
      "learning_rate": 4.9020956123117225e-05,
      "loss": 0.0324,
      "step": 300
    },
    {
      "epoch": 0.22920759659463,
      "grad_norm": 1.8477280139923096,
      "learning_rate": 4.885723641126392e-05,
      "loss": 0.0308,
      "step": 350
    },
    {
      "epoch": 0.26195153896529144,
      "grad_norm": 1.797134518623352,
      "learning_rate": 4.869351669941061e-05,
      "loss": 0.0326,
      "step": 400
    },
    {
      "epoch": 0.29469548133595286,
      "grad_norm": 3.2537410259246826,
      "learning_rate": 4.8529796987557305e-05,
      "loss": 0.0336,
      "step": 450
    },
    {
      "epoch": 0.3274394237066143,
      "grad_norm": 1.3920249938964844,
      "learning_rate": 4.8366077275703994e-05,
      "loss": 0.0321,
      "step": 500
    },
    {
      "epoch": 0.3601833660772757,
      "grad_norm": 3.355429172515869,
      "learning_rate": 4.820235756385069e-05,
      "loss": 0.0317,
      "step": 550
    },
    {
      "epoch": 0.3929273084479371,
      "grad_norm": 5.2383880615234375,
      "learning_rate": 4.803863785199738e-05,
      "loss": 0.0339,
      "step": 600
    },
    {
      "epoch": 0.4256712508185986,
      "grad_norm": 5.204562187194824,
      "learning_rate": 4.7874918140144075e-05,
      "loss": 0.0318,
      "step": 650
    },
    {
      "epoch": 0.45841519318926,
      "grad_norm": 4.723176002502441,
      "learning_rate": 4.771119842829077e-05,
      "loss": 0.0286,
      "step": 700
    },
    {
      "epoch": 0.4911591355599214,
      "grad_norm": 4.123966693878174,
      "learning_rate": 4.754747871643746e-05,
      "loss": 0.0322,
      "step": 750
    },
    {
      "epoch": 0.5239030779305829,
      "grad_norm": 1.3999706506729126,
      "learning_rate": 4.7383759004584156e-05,
      "loss": 0.0282,
      "step": 800
    },
    {
      "epoch": 0.5566470203012442,
      "grad_norm": 1.9938522577285767,
      "learning_rate": 4.7220039292730845e-05,
      "loss": 0.0263,
      "step": 850
    },
    {
      "epoch": 0.5893909626719057,
      "grad_norm": 3.306260585784912,
      "learning_rate": 4.705631958087754e-05,
      "loss": 0.0205,
      "step": 900
    },
    {
      "epoch": 0.6221349050425671,
      "grad_norm": 2.1056127548217773,
      "learning_rate": 4.6892599869024236e-05,
      "loss": 0.0279,
      "step": 950
    },
    {
      "epoch": 0.6548788474132285,
      "grad_norm": 2.9797472953796387,
      "learning_rate": 4.6728880157170925e-05,
      "loss": 0.0228,
      "step": 1000
    },
    {
      "epoch": 0.68762278978389,
      "grad_norm": 3.4961376190185547,
      "learning_rate": 4.656516044531762e-05,
      "loss": 0.0248,
      "step": 1050
    },
    {
      "epoch": 0.7203667321545514,
      "grad_norm": 4.391420841217041,
      "learning_rate": 4.640144073346431e-05,
      "loss": 0.0244,
      "step": 1100
    },
    {
      "epoch": 0.7531106745252129,
      "grad_norm": 2.839322566986084,
      "learning_rate": 4.6237721021611006e-05,
      "loss": 0.0254,
      "step": 1150
    },
    {
      "epoch": 0.7858546168958742,
      "grad_norm": 3.357933282852173,
      "learning_rate": 4.6074001309757695e-05,
      "loss": 0.0232,
      "step": 1200
    },
    {
      "epoch": 0.8185985592665357,
      "grad_norm": 3.857168197631836,
      "learning_rate": 4.591028159790439e-05,
      "loss": 0.0257,
      "step": 1250
    },
    {
      "epoch": 0.8513425016371972,
      "grad_norm": 2.128424644470215,
      "learning_rate": 4.574656188605108e-05,
      "loss": 0.0268,
      "step": 1300
    },
    {
      "epoch": 0.8840864440078585,
      "grad_norm": 1.940350890159607,
      "learning_rate": 4.5582842174197775e-05,
      "loss": 0.0231,
      "step": 1350
    },
    {
      "epoch": 0.91683038637852,
      "grad_norm": 4.247508525848389,
      "learning_rate": 4.541912246234447e-05,
      "loss": 0.0256,
      "step": 1400
    },
    {
      "epoch": 0.9495743287491814,
      "grad_norm": 1.7199496030807495,
      "learning_rate": 4.525540275049116e-05,
      "loss": 0.0199,
      "step": 1450
    },
    {
      "epoch": 0.9823182711198428,
      "grad_norm": 3.4620773792266846,
      "learning_rate": 4.5091683038637856e-05,
      "loss": 0.0287,
      "step": 1500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0223134383559227,
      "eval_runtime": 1.0685,
      "eval_samples_per_second": 576.503,
      "eval_steps_per_second": 72.063,
      "step": 1527
    },
    {
      "epoch": 1.0150622134905043,
      "grad_norm": 2.584414482116699,
      "learning_rate": 4.4927963326784545e-05,
      "loss": 0.0243,
      "step": 1550
    },
    {
      "epoch": 1.0478061558611658,
      "grad_norm": 2.5988755226135254,
      "learning_rate": 4.476424361493124e-05,
      "loss": 0.0196,
      "step": 1600
    },
    {
      "epoch": 1.080550098231827,
      "grad_norm": 5.41241455078125,
      "learning_rate": 4.4600523903077936e-05,
      "loss": 0.0189,
      "step": 1650
    },
    {
      "epoch": 1.1132940406024885,
      "grad_norm": 2.660098075866699,
      "learning_rate": 4.4436804191224625e-05,
      "loss": 0.0178,
      "step": 1700
    },
    {
      "epoch": 1.14603798297315,
      "grad_norm": 3.4277801513671875,
      "learning_rate": 4.427308447937132e-05,
      "loss": 0.0225,
      "step": 1750
    },
    {
      "epoch": 1.1787819253438114,
      "grad_norm": 4.29623556137085,
      "learning_rate": 4.410936476751801e-05,
      "loss": 0.0186,
      "step": 1800
    },
    {
      "epoch": 1.211525867714473,
      "grad_norm": 2.621361017227173,
      "learning_rate": 4.39456450556647e-05,
      "loss": 0.0188,
      "step": 1850
    },
    {
      "epoch": 1.2442698100851342,
      "grad_norm": 2.111732006072998,
      "learning_rate": 4.3781925343811395e-05,
      "loss": 0.0167,
      "step": 1900
    },
    {
      "epoch": 1.2770137524557956,
      "grad_norm": 2.6073944568634033,
      "learning_rate": 4.361820563195809e-05,
      "loss": 0.0212,
      "step": 1950
    },
    {
      "epoch": 1.309757694826457,
      "grad_norm": 2.0432944297790527,
      "learning_rate": 4.345448592010478e-05,
      "loss": 0.0171,
      "step": 2000
    },
    {
      "epoch": 1.3425016371971186,
      "grad_norm": 1.782891035079956,
      "learning_rate": 4.3290766208251476e-05,
      "loss": 0.02,
      "step": 2050
    },
    {
      "epoch": 1.37524557956778,
      "grad_norm": 0.6446648836135864,
      "learning_rate": 4.3127046496398165e-05,
      "loss": 0.0162,
      "step": 2100
    },
    {
      "epoch": 1.4079895219384415,
      "grad_norm": 3.5440213680267334,
      "learning_rate": 4.296332678454486e-05,
      "loss": 0.0194,
      "step": 2150
    },
    {
      "epoch": 1.4407334643091028,
      "grad_norm": 5.565827369689941,
      "learning_rate": 4.2799607072691556e-05,
      "loss": 0.0193,
      "step": 2200
    },
    {
      "epoch": 1.4734774066797642,
      "grad_norm": 1.090164303779602,
      "learning_rate": 4.2635887360838245e-05,
      "loss": 0.0202,
      "step": 2250
    },
    {
      "epoch": 1.5062213490504257,
      "grad_norm": 4.278792858123779,
      "learning_rate": 4.247216764898494e-05,
      "loss": 0.0148,
      "step": 2300
    },
    {
      "epoch": 1.538965291421087,
      "grad_norm": 1.9027740955352783,
      "learning_rate": 4.230844793713164e-05,
      "loss": 0.0196,
      "step": 2350
    },
    {
      "epoch": 1.5717092337917484,
      "grad_norm": 1.067586064338684,
      "learning_rate": 4.2144728225278326e-05,
      "loss": 0.0167,
      "step": 2400
    },
    {
      "epoch": 1.60445317616241,
      "grad_norm": 2.871483087539673,
      "learning_rate": 4.198100851342502e-05,
      "loss": 0.0173,
      "step": 2450
    },
    {
      "epoch": 1.6371971185330714,
      "grad_norm": 5.255079746246338,
      "learning_rate": 4.181728880157171e-05,
      "loss": 0.016,
      "step": 2500
    },
    {
      "epoch": 1.6699410609037328,
      "grad_norm": 1.3147292137145996,
      "learning_rate": 4.16535690897184e-05,
      "loss": 0.018,
      "step": 2550
    },
    {
      "epoch": 1.7026850032743943,
      "grad_norm": 6.372485160827637,
      "learning_rate": 4.1489849377865095e-05,
      "loss": 0.0196,
      "step": 2600
    },
    {
      "epoch": 1.7354289456450558,
      "grad_norm": 1.6707299947738647,
      "learning_rate": 4.132612966601179e-05,
      "loss": 0.0144,
      "step": 2650
    },
    {
      "epoch": 1.768172888015717,
      "grad_norm": 2.627504348754883,
      "learning_rate": 4.116240995415848e-05,
      "loss": 0.0184,
      "step": 2700
    },
    {
      "epoch": 1.8009168303863785,
      "grad_norm": 3.6045069694519043,
      "learning_rate": 4.0998690242305176e-05,
      "loss": 0.0173,
      "step": 2750
    },
    {
      "epoch": 1.83366077275704,
      "grad_norm": 4.0520453453063965,
      "learning_rate": 4.0834970530451865e-05,
      "loss": 0.0172,
      "step": 2800
    },
    {
      "epoch": 1.8664047151277012,
      "grad_norm": 1.9398167133331299,
      "learning_rate": 4.067125081859856e-05,
      "loss": 0.0166,
      "step": 2850
    },
    {
      "epoch": 1.8991486574983627,
      "grad_norm": 1.1761409044265747,
      "learning_rate": 4.0507531106745257e-05,
      "loss": 0.0142,
      "step": 2900
    },
    {
      "epoch": 1.9318925998690242,
      "grad_norm": 1.5480221509933472,
      "learning_rate": 4.0343811394891946e-05,
      "loss": 0.0158,
      "step": 2950
    },
    {
      "epoch": 1.9646365422396856,
      "grad_norm": 0.7853421568870544,
      "learning_rate": 4.018009168303864e-05,
      "loss": 0.0134,
      "step": 3000
    },
    {
      "epoch": 1.9973804846103471,
      "grad_norm": 1.8182448148727417,
      "learning_rate": 4.001637197118534e-05,
      "loss": 0.0146,
      "step": 3050
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.011831247247755527,
      "eval_runtime": 1.0572,
      "eval_samples_per_second": 582.681,
      "eval_steps_per_second": 72.835,
      "step": 3054
    }
  ],
  "logging_steps": 50,
  "max_steps": 15270,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1351665880420680.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
