{
  "best_global_step": 145677,
  "best_metric": 0.00011828333663288504,
  "best_model_checkpoint": "ckpt/neurips.pt/FFV/checkpoint-145677",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 187299,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0024025755610013935,
      "grad_norm": 2.855074405670166,
      "learning_rate": 4.99882273797511e-05,
      "loss": 0.0347,
      "step": 50
    },
    {
      "epoch": 0.004805151122002787,
      "grad_norm": 2.639685869216919,
      "learning_rate": 4.997621450194609e-05,
      "loss": 0.0303,
      "step": 100
    },
    {
      "epoch": 0.00720772668300418,
      "grad_norm": 5.205687999725342,
      "learning_rate": 4.996420162414108e-05,
      "loss": 0.0262,
      "step": 150
    },
    {
      "epoch": 0.009610302244005574,
      "grad_norm": 3.4584152698516846,
      "learning_rate": 4.995218874633608e-05,
      "loss": 0.0272,
      "step": 200
    },
    {
      "epoch": 0.012012877805006967,
      "grad_norm": 5.212934970855713,
      "learning_rate": 4.994017586853107e-05,
      "loss": 0.0377,
      "step": 250
    },
    {
      "epoch": 0.01441545336600836,
      "grad_norm": 2.743358850479126,
      "learning_rate": 4.9928162990726066e-05,
      "loss": 0.0307,
      "step": 300
    },
    {
      "epoch": 0.016818028927009756,
      "grad_norm": 1.9200159311294556,
      "learning_rate": 4.991615011292106e-05,
      "loss": 0.0241,
      "step": 350
    },
    {
      "epoch": 0.019220604488011148,
      "grad_norm": 2.634976387023926,
      "learning_rate": 4.990413723511604e-05,
      "loss": 0.0209,
      "step": 400
    },
    {
      "epoch": 0.021623180049012543,
      "grad_norm": 3.4932680130004883,
      "learning_rate": 4.989212435731104e-05,
      "loss": 0.0186,
      "step": 450
    },
    {
      "epoch": 0.024025755610013935,
      "grad_norm": 3.449796676635742,
      "learning_rate": 4.988011147950603e-05,
      "loss": 0.0235,
      "step": 500
    },
    {
      "epoch": 0.02642833117101533,
      "grad_norm": 4.707396507263184,
      "learning_rate": 4.986809860170103e-05,
      "loss": 0.0234,
      "step": 550
    },
    {
      "epoch": 0.02883090673201672,
      "grad_norm": 3.8685600757598877,
      "learning_rate": 4.985608572389602e-05,
      "loss": 0.0205,
      "step": 600
    },
    {
      "epoch": 0.031233482293018117,
      "grad_norm": 2.336749792098999,
      "learning_rate": 4.984407284609101e-05,
      "loss": 0.0212,
      "step": 650
    },
    {
      "epoch": 0.03363605785401951,
      "grad_norm": 2.721029758453369,
      "learning_rate": 4.9832059968286006e-05,
      "loss": 0.0196,
      "step": 700
    },
    {
      "epoch": 0.0360386334150209,
      "grad_norm": 1.8945461511611938,
      "learning_rate": 4.9820047090481e-05,
      "loss": 0.0193,
      "step": 750
    },
    {
      "epoch": 0.038441208976022295,
      "grad_norm": 2.531226634979248,
      "learning_rate": 4.980803421267599e-05,
      "loss": 0.0194,
      "step": 800
    },
    {
      "epoch": 0.04084378453702369,
      "grad_norm": 1.4480412006378174,
      "learning_rate": 4.9796021334870986e-05,
      "loss": 0.0193,
      "step": 850
    },
    {
      "epoch": 0.043246360098025086,
      "grad_norm": 3.2245445251464844,
      "learning_rate": 4.9784008457065976e-05,
      "loss": 0.0143,
      "step": 900
    },
    {
      "epoch": 0.045648935659026474,
      "grad_norm": 1.8062041997909546,
      "learning_rate": 4.9771995579260974e-05,
      "loss": 0.019,
      "step": 950
    },
    {
      "epoch": 0.04805151122002787,
      "grad_norm": 4.044005870819092,
      "learning_rate": 4.9759982701455965e-05,
      "loss": 0.0193,
      "step": 1000
    },
    {
      "epoch": 0.050454086781029264,
      "grad_norm": 3.9040868282318115,
      "learning_rate": 4.9747969823650956e-05,
      "loss": 0.0198,
      "step": 1050
    },
    {
      "epoch": 0.05285666234203066,
      "grad_norm": 2.933267116546631,
      "learning_rate": 4.973595694584595e-05,
      "loss": 0.0183,
      "step": 1100
    },
    {
      "epoch": 0.05525923790303205,
      "grad_norm": 2.323146343231201,
      "learning_rate": 4.972394406804094e-05,
      "loss": 0.0131,
      "step": 1150
    },
    {
      "epoch": 0.05766181346403344,
      "grad_norm": 3.399937868118286,
      "learning_rate": 4.9711931190235935e-05,
      "loss": 0.016,
      "step": 1200
    },
    {
      "epoch": 0.06006438902503484,
      "grad_norm": 3.4841089248657227,
      "learning_rate": 4.9699918312430926e-05,
      "loss": 0.0194,
      "step": 1250
    },
    {
      "epoch": 0.06246696458603623,
      "grad_norm": 2.5179357528686523,
      "learning_rate": 4.968790543462592e-05,
      "loss": 0.0135,
      "step": 1300
    },
    {
      "epoch": 0.06486954014703762,
      "grad_norm": 1.3771666288375854,
      "learning_rate": 4.9675892556820914e-05,
      "loss": 0.0152,
      "step": 1350
    },
    {
      "epoch": 0.06727211570803902,
      "grad_norm": 5.149067401885986,
      "learning_rate": 4.9663879679015905e-05,
      "loss": 0.0135,
      "step": 1400
    },
    {
      "epoch": 0.06967469126904041,
      "grad_norm": 0.37823569774627686,
      "learning_rate": 4.96518668012109e-05,
      "loss": 0.0134,
      "step": 1450
    },
    {
      "epoch": 0.0720772668300418,
      "grad_norm": 2.895939588546753,
      "learning_rate": 4.9639853923405893e-05,
      "loss": 0.0144,
      "step": 1500
    },
    {
      "epoch": 0.0744798423910432,
      "grad_norm": 0.3481068015098572,
      "learning_rate": 4.9627841045600884e-05,
      "loss": 0.0114,
      "step": 1550
    },
    {
      "epoch": 0.07688241795204459,
      "grad_norm": 1.6198161840438843,
      "learning_rate": 4.961582816779588e-05,
      "loss": 0.0149,
      "step": 1600
    },
    {
      "epoch": 0.07928499351304598,
      "grad_norm": 0.9730125665664673,
      "learning_rate": 4.960381528999087e-05,
      "loss": 0.0146,
      "step": 1650
    },
    {
      "epoch": 0.08168756907404738,
      "grad_norm": 1.0430914163589478,
      "learning_rate": 4.959180241218587e-05,
      "loss": 0.0134,
      "step": 1700
    },
    {
      "epoch": 0.08409014463504877,
      "grad_norm": 2.156064987182617,
      "learning_rate": 4.957978953438086e-05,
      "loss": 0.0098,
      "step": 1750
    },
    {
      "epoch": 0.08649272019605017,
      "grad_norm": 2.5098302364349365,
      "learning_rate": 4.956777665657585e-05,
      "loss": 0.0158,
      "step": 1800
    },
    {
      "epoch": 0.08889529575705156,
      "grad_norm": 3.7031712532043457,
      "learning_rate": 4.955576377877085e-05,
      "loss": 0.0135,
      "step": 1850
    },
    {
      "epoch": 0.09129787131805295,
      "grad_norm": 0.637346088886261,
      "learning_rate": 4.9543750900965834e-05,
      "loss": 0.0122,
      "step": 1900
    },
    {
      "epoch": 0.09370044687905435,
      "grad_norm": 7.567546367645264,
      "learning_rate": 4.953173802316083e-05,
      "loss": 0.0159,
      "step": 1950
    },
    {
      "epoch": 0.09610302244005574,
      "grad_norm": 1.253493070602417,
      "learning_rate": 4.951972514535582e-05,
      "loss": 0.0165,
      "step": 2000
    },
    {
      "epoch": 0.09850559800105713,
      "grad_norm": 1.5063796043395996,
      "learning_rate": 4.950771226755081e-05,
      "loss": 0.013,
      "step": 2050
    },
    {
      "epoch": 0.10090817356205853,
      "grad_norm": 2.158581256866455,
      "learning_rate": 4.949569938974581e-05,
      "loss": 0.0102,
      "step": 2100
    },
    {
      "epoch": 0.10331074912305992,
      "grad_norm": 0.7609875798225403,
      "learning_rate": 4.94836865119408e-05,
      "loss": 0.0104,
      "step": 2150
    },
    {
      "epoch": 0.10571332468406132,
      "grad_norm": 2.1931138038635254,
      "learning_rate": 4.94716736341358e-05,
      "loss": 0.0102,
      "step": 2200
    },
    {
      "epoch": 0.10811590024506271,
      "grad_norm": 0.8873978853225708,
      "learning_rate": 4.945966075633079e-05,
      "loss": 0.0103,
      "step": 2250
    },
    {
      "epoch": 0.1105184758060641,
      "grad_norm": 4.764172554016113,
      "learning_rate": 4.944764787852578e-05,
      "loss": 0.0134,
      "step": 2300
    },
    {
      "epoch": 0.1129210513670655,
      "grad_norm": 1.3519344329833984,
      "learning_rate": 4.943563500072078e-05,
      "loss": 0.0122,
      "step": 2350
    },
    {
      "epoch": 0.11532362692806689,
      "grad_norm": 1.2938191890716553,
      "learning_rate": 4.942362212291577e-05,
      "loss": 0.0115,
      "step": 2400
    },
    {
      "epoch": 0.11772620248906829,
      "grad_norm": 0.7159448862075806,
      "learning_rate": 4.941160924511076e-05,
      "loss": 0.0089,
      "step": 2450
    },
    {
      "epoch": 0.12012877805006968,
      "grad_norm": 0.96760493516922,
      "learning_rate": 4.939959636730576e-05,
      "loss": 0.0099,
      "step": 2500
    },
    {
      "epoch": 0.12253135361107106,
      "grad_norm": 1.445373296737671,
      "learning_rate": 4.938758348950075e-05,
      "loss": 0.0093,
      "step": 2550
    },
    {
      "epoch": 0.12493392917207247,
      "grad_norm": 1.450989007949829,
      "learning_rate": 4.9375570611695746e-05,
      "loss": 0.009,
      "step": 2600
    },
    {
      "epoch": 0.12733650473307387,
      "grad_norm": 2.87245774269104,
      "learning_rate": 4.936355773389073e-05,
      "loss": 0.0077,
      "step": 2650
    },
    {
      "epoch": 0.12973908029407524,
      "grad_norm": 2.096208333969116,
      "learning_rate": 4.935154485608572e-05,
      "loss": 0.0109,
      "step": 2700
    },
    {
      "epoch": 0.13214165585507665,
      "grad_norm": 1.5831499099731445,
      "learning_rate": 4.933953197828072e-05,
      "loss": 0.0076,
      "step": 2750
    },
    {
      "epoch": 0.13454423141607805,
      "grad_norm": 2.803596019744873,
      "learning_rate": 4.932751910047571e-05,
      "loss": 0.0104,
      "step": 2800
    },
    {
      "epoch": 0.13694680697707942,
      "grad_norm": 0.7394824028015137,
      "learning_rate": 4.931550622267071e-05,
      "loss": 0.0127,
      "step": 2850
    },
    {
      "epoch": 0.13934938253808082,
      "grad_norm": 0.9581887722015381,
      "learning_rate": 4.93034933448657e-05,
      "loss": 0.0084,
      "step": 2900
    },
    {
      "epoch": 0.14175195809908223,
      "grad_norm": 0.9261215329170227,
      "learning_rate": 4.929148046706069e-05,
      "loss": 0.0074,
      "step": 2950
    },
    {
      "epoch": 0.1441545336600836,
      "grad_norm": 2.659689426422119,
      "learning_rate": 4.9279467589255686e-05,
      "loss": 0.0082,
      "step": 3000
    },
    {
      "epoch": 0.146557109221085,
      "grad_norm": 1.5095456838607788,
      "learning_rate": 4.926745471145068e-05,
      "loss": 0.0088,
      "step": 3050
    },
    {
      "epoch": 0.1489596847820864,
      "grad_norm": 0.6860654950141907,
      "learning_rate": 4.9255441833645674e-05,
      "loss": 0.0093,
      "step": 3100
    },
    {
      "epoch": 0.15136226034308778,
      "grad_norm": 0.862184464931488,
      "learning_rate": 4.9243428955840665e-05,
      "loss": 0.0074,
      "step": 3150
    },
    {
      "epoch": 0.15376483590408918,
      "grad_norm": 0.5099988579750061,
      "learning_rate": 4.9231416078035656e-05,
      "loss": 0.0087,
      "step": 3200
    },
    {
      "epoch": 0.15616741146509058,
      "grad_norm": 1.4015438556671143,
      "learning_rate": 4.9219403200230654e-05,
      "loss": 0.006,
      "step": 3250
    },
    {
      "epoch": 0.15856998702609196,
      "grad_norm": 2.962959051132202,
      "learning_rate": 4.9207390322425645e-05,
      "loss": 0.0091,
      "step": 3300
    },
    {
      "epoch": 0.16097256258709336,
      "grad_norm": 1.6102049350738525,
      "learning_rate": 4.9195377444620635e-05,
      "loss": 0.01,
      "step": 3350
    },
    {
      "epoch": 0.16337513814809476,
      "grad_norm": 0.42275357246398926,
      "learning_rate": 4.9183364566815626e-05,
      "loss": 0.0065,
      "step": 3400
    },
    {
      "epoch": 0.16577771370909616,
      "grad_norm": 2.399735450744629,
      "learning_rate": 4.917135168901062e-05,
      "loss": 0.0064,
      "step": 3450
    },
    {
      "epoch": 0.16818028927009754,
      "grad_norm": 0.8063199520111084,
      "learning_rate": 4.9159338811205615e-05,
      "loss": 0.0073,
      "step": 3500
    },
    {
      "epoch": 0.17058286483109894,
      "grad_norm": 1.6180987358093262,
      "learning_rate": 4.9147325933400605e-05,
      "loss": 0.0076,
      "step": 3550
    },
    {
      "epoch": 0.17298544039210034,
      "grad_norm": 2.6137208938598633,
      "learning_rate": 4.91353130555956e-05,
      "loss": 0.0057,
      "step": 3600
    },
    {
      "epoch": 0.17538801595310172,
      "grad_norm": 1.5802152156829834,
      "learning_rate": 4.9123300177790594e-05,
      "loss": 0.0065,
      "step": 3650
    },
    {
      "epoch": 0.17779059151410312,
      "grad_norm": 0.40969011187553406,
      "learning_rate": 4.9111287299985585e-05,
      "loss": 0.006,
      "step": 3700
    },
    {
      "epoch": 0.18019316707510452,
      "grad_norm": 2.8526294231414795,
      "learning_rate": 4.909927442218058e-05,
      "loss": 0.011,
      "step": 3750
    },
    {
      "epoch": 0.1825957426361059,
      "grad_norm": 1.4968115091323853,
      "learning_rate": 4.908726154437557e-05,
      "loss": 0.0057,
      "step": 3800
    },
    {
      "epoch": 0.1849983181971073,
      "grad_norm": 0.5753910541534424,
      "learning_rate": 4.9075248666570564e-05,
      "loss": 0.01,
      "step": 3850
    },
    {
      "epoch": 0.1874008937581087,
      "grad_norm": 2.0928211212158203,
      "learning_rate": 4.906323578876556e-05,
      "loss": 0.0047,
      "step": 3900
    },
    {
      "epoch": 0.18980346931911007,
      "grad_norm": 3.281006097793579,
      "learning_rate": 4.905122291096055e-05,
      "loss": 0.0056,
      "step": 3950
    },
    {
      "epoch": 0.19220604488011148,
      "grad_norm": 1.5894031524658203,
      "learning_rate": 4.903921003315555e-05,
      "loss": 0.0051,
      "step": 4000
    },
    {
      "epoch": 0.19460862044111288,
      "grad_norm": 1.5904240608215332,
      "learning_rate": 4.902719715535054e-05,
      "loss": 0.0059,
      "step": 4050
    },
    {
      "epoch": 0.19701119600211425,
      "grad_norm": 1.9213956594467163,
      "learning_rate": 4.901518427754553e-05,
      "loss": 0.0055,
      "step": 4100
    },
    {
      "epoch": 0.19941377156311565,
      "grad_norm": 0.4942978024482727,
      "learning_rate": 4.900317139974052e-05,
      "loss": 0.0037,
      "step": 4150
    },
    {
      "epoch": 0.20181634712411706,
      "grad_norm": 0.34901583194732666,
      "learning_rate": 4.899115852193551e-05,
      "loss": 0.0056,
      "step": 4200
    },
    {
      "epoch": 0.20421892268511846,
      "grad_norm": 0.28053784370422363,
      "learning_rate": 4.897914564413051e-05,
      "loss": 0.0064,
      "step": 4250
    },
    {
      "epoch": 0.20662149824611983,
      "grad_norm": 2.1337811946868896,
      "learning_rate": 4.89671327663255e-05,
      "loss": 0.0067,
      "step": 4300
    },
    {
      "epoch": 0.20902407380712124,
      "grad_norm": 1.0024199485778809,
      "learning_rate": 4.895511988852049e-05,
      "loss": 0.004,
      "step": 4350
    },
    {
      "epoch": 0.21142664936812264,
      "grad_norm": 2.2833023071289062,
      "learning_rate": 4.894310701071549e-05,
      "loss": 0.005,
      "step": 4400
    },
    {
      "epoch": 0.213829224929124,
      "grad_norm": 0.7472466826438904,
      "learning_rate": 4.893109413291048e-05,
      "loss": 0.0046,
      "step": 4450
    },
    {
      "epoch": 0.21623180049012541,
      "grad_norm": 1.1328545808792114,
      "learning_rate": 4.891908125510548e-05,
      "loss": 0.0048,
      "step": 4500
    },
    {
      "epoch": 0.21863437605112682,
      "grad_norm": 2.1823370456695557,
      "learning_rate": 4.890706837730047e-05,
      "loss": 0.0039,
      "step": 4550
    },
    {
      "epoch": 0.2210369516121282,
      "grad_norm": 1.7865623235702515,
      "learning_rate": 4.889505549949546e-05,
      "loss": 0.0051,
      "step": 4600
    },
    {
      "epoch": 0.2234395271731296,
      "grad_norm": 0.8334906697273254,
      "learning_rate": 4.888304262169046e-05,
      "loss": 0.0047,
      "step": 4650
    },
    {
      "epoch": 0.225842102734131,
      "grad_norm": 0.8110542893409729,
      "learning_rate": 4.887102974388545e-05,
      "loss": 0.0047,
      "step": 4700
    },
    {
      "epoch": 0.22824467829513237,
      "grad_norm": 1.3888715505599976,
      "learning_rate": 4.885901686608044e-05,
      "loss": 0.0066,
      "step": 4750
    },
    {
      "epoch": 0.23064725385613377,
      "grad_norm": 1.5709378719329834,
      "learning_rate": 4.884700398827544e-05,
      "loss": 0.0049,
      "step": 4800
    },
    {
      "epoch": 0.23304982941713517,
      "grad_norm": 1.5283292531967163,
      "learning_rate": 4.883499111047043e-05,
      "loss": 0.0052,
      "step": 4850
    },
    {
      "epoch": 0.23545240497813658,
      "grad_norm": 2.0936429500579834,
      "learning_rate": 4.882297823266542e-05,
      "loss": 0.0044,
      "step": 4900
    },
    {
      "epoch": 0.23785498053913795,
      "grad_norm": 0.771620512008667,
      "learning_rate": 4.881096535486041e-05,
      "loss": 0.0057,
      "step": 4950
    },
    {
      "epoch": 0.24025755610013935,
      "grad_norm": 2.5177175998687744,
      "learning_rate": 4.879895247705541e-05,
      "loss": 0.0052,
      "step": 5000
    },
    {
      "epoch": 0.24266013166114075,
      "grad_norm": 1.3984240293502808,
      "learning_rate": 4.87869395992504e-05,
      "loss": 0.0047,
      "step": 5050
    },
    {
      "epoch": 0.24506270722214213,
      "grad_norm": 2.4532008171081543,
      "learning_rate": 4.877492672144539e-05,
      "loss": 0.0049,
      "step": 5100
    },
    {
      "epoch": 0.24746528278314353,
      "grad_norm": 0.9584483504295349,
      "learning_rate": 4.8762913843640386e-05,
      "loss": 0.0056,
      "step": 5150
    },
    {
      "epoch": 0.24986785834414493,
      "grad_norm": 0.4151340425014496,
      "learning_rate": 4.875090096583538e-05,
      "loss": 0.0037,
      "step": 5200
    },
    {
      "epoch": 0.2522704339051463,
      "grad_norm": 0.6460613012313843,
      "learning_rate": 4.873888808803037e-05,
      "loss": 0.0037,
      "step": 5250
    },
    {
      "epoch": 0.25467300946614774,
      "grad_norm": 1.0556416511535645,
      "learning_rate": 4.8726875210225366e-05,
      "loss": 0.004,
      "step": 5300
    },
    {
      "epoch": 0.2570755850271491,
      "grad_norm": 1.8167074918746948,
      "learning_rate": 4.8714862332420356e-05,
      "loss": 0.0044,
      "step": 5350
    },
    {
      "epoch": 0.2594781605881505,
      "grad_norm": 0.4752849340438843,
      "learning_rate": 4.8702849454615354e-05,
      "loss": 0.0037,
      "step": 5400
    },
    {
      "epoch": 0.2618807361491519,
      "grad_norm": 0.7112948298454285,
      "learning_rate": 4.8690836576810345e-05,
      "loss": 0.0026,
      "step": 5450
    },
    {
      "epoch": 0.2642833117101533,
      "grad_norm": 0.8000620007514954,
      "learning_rate": 4.8678823699005336e-05,
      "loss": 0.0036,
      "step": 5500
    },
    {
      "epoch": 0.26668588727115466,
      "grad_norm": 0.4132373332977295,
      "learning_rate": 4.866681082120033e-05,
      "loss": 0.0028,
      "step": 5550
    },
    {
      "epoch": 0.2690884628321561,
      "grad_norm": 2.176790952682495,
      "learning_rate": 4.865479794339532e-05,
      "loss": 0.0033,
      "step": 5600
    },
    {
      "epoch": 0.27149103839315747,
      "grad_norm": 0.5252588391304016,
      "learning_rate": 4.8642785065590315e-05,
      "loss": 0.0032,
      "step": 5650
    },
    {
      "epoch": 0.27389361395415884,
      "grad_norm": 0.3610243797302246,
      "learning_rate": 4.8630772187785306e-05,
      "loss": 0.0027,
      "step": 5700
    },
    {
      "epoch": 0.2762961895151603,
      "grad_norm": 0.3485068678855896,
      "learning_rate": 4.8618759309980297e-05,
      "loss": 0.0037,
      "step": 5750
    },
    {
      "epoch": 0.27869876507616165,
      "grad_norm": 1.8369581699371338,
      "learning_rate": 4.8606746432175294e-05,
      "loss": 0.0029,
      "step": 5800
    },
    {
      "epoch": 0.281101340637163,
      "grad_norm": 0.7570080161094666,
      "learning_rate": 4.8594733554370285e-05,
      "loss": 0.0052,
      "step": 5850
    },
    {
      "epoch": 0.28350391619816445,
      "grad_norm": 0.5753280520439148,
      "learning_rate": 4.858272067656528e-05,
      "loss": 0.0029,
      "step": 5900
    },
    {
      "epoch": 0.2859064917591658,
      "grad_norm": 0.21374638378620148,
      "learning_rate": 4.8570707798760273e-05,
      "loss": 0.0026,
      "step": 5950
    },
    {
      "epoch": 0.2883090673201672,
      "grad_norm": 0.6558489203453064,
      "learning_rate": 4.8558694920955264e-05,
      "loss": 0.0042,
      "step": 6000
    },
    {
      "epoch": 0.29071164288116863,
      "grad_norm": 0.7233584523200989,
      "learning_rate": 4.854668204315026e-05,
      "loss": 0.0045,
      "step": 6050
    },
    {
      "epoch": 0.29311421844217,
      "grad_norm": 0.7425406575202942,
      "learning_rate": 4.853466916534525e-05,
      "loss": 0.0026,
      "step": 6100
    },
    {
      "epoch": 0.2955167940031714,
      "grad_norm": 0.4937346279621124,
      "learning_rate": 4.8522656287540244e-05,
      "loss": 0.0031,
      "step": 6150
    },
    {
      "epoch": 0.2979193695641728,
      "grad_norm": 0.9314649701118469,
      "learning_rate": 4.851064340973524e-05,
      "loss": 0.0029,
      "step": 6200
    },
    {
      "epoch": 0.3003219451251742,
      "grad_norm": 0.6067662239074707,
      "learning_rate": 4.849863053193023e-05,
      "loss": 0.0026,
      "step": 6250
    },
    {
      "epoch": 0.30272452068617556,
      "grad_norm": 0.4987545311450958,
      "learning_rate": 4.848661765412523e-05,
      "loss": 0.004,
      "step": 6300
    },
    {
      "epoch": 0.305127096247177,
      "grad_norm": 1.0057427883148193,
      "learning_rate": 4.8474604776320214e-05,
      "loss": 0.0031,
      "step": 6350
    },
    {
      "epoch": 0.30752967180817836,
      "grad_norm": 0.6347069144248962,
      "learning_rate": 4.846259189851521e-05,
      "loss": 0.0025,
      "step": 6400
    },
    {
      "epoch": 0.30993224736917974,
      "grad_norm": 1.2231426239013672,
      "learning_rate": 4.84505790207102e-05,
      "loss": 0.0029,
      "step": 6450
    },
    {
      "epoch": 0.31233482293018117,
      "grad_norm": 0.8451859354972839,
      "learning_rate": 4.843856614290519e-05,
      "loss": 0.0033,
      "step": 6500
    },
    {
      "epoch": 0.31473739849118254,
      "grad_norm": 2.1087870597839355,
      "learning_rate": 4.842655326510019e-05,
      "loss": 0.0025,
      "step": 6550
    },
    {
      "epoch": 0.3171399740521839,
      "grad_norm": 1.526558518409729,
      "learning_rate": 4.841454038729518e-05,
      "loss": 0.0024,
      "step": 6600
    },
    {
      "epoch": 0.31954254961318534,
      "grad_norm": 0.3222004771232605,
      "learning_rate": 4.840252750949017e-05,
      "loss": 0.0024,
      "step": 6650
    },
    {
      "epoch": 0.3219451251741867,
      "grad_norm": 0.6456441283226013,
      "learning_rate": 4.839051463168517e-05,
      "loss": 0.0029,
      "step": 6700
    },
    {
      "epoch": 0.32434770073518815,
      "grad_norm": 0.37155765295028687,
      "learning_rate": 4.837850175388016e-05,
      "loss": 0.0048,
      "step": 6750
    },
    {
      "epoch": 0.3267502762961895,
      "grad_norm": 1.3868972063064575,
      "learning_rate": 4.836648887607516e-05,
      "loss": 0.0027,
      "step": 6800
    },
    {
      "epoch": 0.3291528518571909,
      "grad_norm": 0.24058780074119568,
      "learning_rate": 4.835447599827015e-05,
      "loss": 0.0028,
      "step": 6850
    },
    {
      "epoch": 0.33155542741819233,
      "grad_norm": 0.811981201171875,
      "learning_rate": 4.834246312046514e-05,
      "loss": 0.0032,
      "step": 6900
    },
    {
      "epoch": 0.3339580029791937,
      "grad_norm": 0.21522051095962524,
      "learning_rate": 4.833045024266014e-05,
      "loss": 0.0023,
      "step": 6950
    },
    {
      "epoch": 0.3363605785401951,
      "grad_norm": 0.45441094040870667,
      "learning_rate": 4.831843736485513e-05,
      "loss": 0.0025,
      "step": 7000
    },
    {
      "epoch": 0.3387631541011965,
      "grad_norm": 1.6417003870010376,
      "learning_rate": 4.8306424487050126e-05,
      "loss": 0.0026,
      "step": 7050
    },
    {
      "epoch": 0.3411657296621979,
      "grad_norm": 1.4304070472717285,
      "learning_rate": 4.829441160924511e-05,
      "loss": 0.0019,
      "step": 7100
    },
    {
      "epoch": 0.34356830522319926,
      "grad_norm": 0.6305409669876099,
      "learning_rate": 4.82823987314401e-05,
      "loss": 0.0025,
      "step": 7150
    },
    {
      "epoch": 0.3459708807842007,
      "grad_norm": 0.5326513051986694,
      "learning_rate": 4.82703858536351e-05,
      "loss": 0.0027,
      "step": 7200
    },
    {
      "epoch": 0.34837345634520206,
      "grad_norm": 0.27553245425224304,
      "learning_rate": 4.825837297583009e-05,
      "loss": 0.0021,
      "step": 7250
    },
    {
      "epoch": 0.35077603190620343,
      "grad_norm": 2.139711618423462,
      "learning_rate": 4.824636009802509e-05,
      "loss": 0.003,
      "step": 7300
    },
    {
      "epoch": 0.35317860746720486,
      "grad_norm": 1.5768239498138428,
      "learning_rate": 4.823434722022008e-05,
      "loss": 0.0038,
      "step": 7350
    },
    {
      "epoch": 0.35558118302820624,
      "grad_norm": 1.6278427839279175,
      "learning_rate": 4.822233434241507e-05,
      "loss": 0.0022,
      "step": 7400
    },
    {
      "epoch": 0.3579837585892076,
      "grad_norm": 1.106412410736084,
      "learning_rate": 4.8210321464610066e-05,
      "loss": 0.0028,
      "step": 7450
    },
    {
      "epoch": 0.36038633415020904,
      "grad_norm": 0.1896696388721466,
      "learning_rate": 4.819830858680506e-05,
      "loss": 0.0023,
      "step": 7500
    },
    {
      "epoch": 0.3627889097112104,
      "grad_norm": 0.4526345431804657,
      "learning_rate": 4.8186295709000054e-05,
      "loss": 0.0021,
      "step": 7550
    },
    {
      "epoch": 0.3651914852722118,
      "grad_norm": 0.3502681851387024,
      "learning_rate": 4.8174282831195045e-05,
      "loss": 0.0017,
      "step": 7600
    },
    {
      "epoch": 0.3675940608332132,
      "grad_norm": 0.7386513948440552,
      "learning_rate": 4.8162269953390036e-05,
      "loss": 0.0018,
      "step": 7650
    },
    {
      "epoch": 0.3699966363942146,
      "grad_norm": 0.3770776391029358,
      "learning_rate": 4.8150257075585034e-05,
      "loss": 0.0022,
      "step": 7700
    },
    {
      "epoch": 0.37239921195521597,
      "grad_norm": 0.4438103437423706,
      "learning_rate": 4.8138244197780024e-05,
      "loss": 0.0017,
      "step": 7750
    },
    {
      "epoch": 0.3748017875162174,
      "grad_norm": 0.147531196475029,
      "learning_rate": 4.8126231319975015e-05,
      "loss": 0.0017,
      "step": 7800
    },
    {
      "epoch": 0.3772043630772188,
      "grad_norm": 1.0662126541137695,
      "learning_rate": 4.8114218442170006e-05,
      "loss": 0.0021,
      "step": 7850
    },
    {
      "epoch": 0.37960693863822015,
      "grad_norm": 1.390408992767334,
      "learning_rate": 4.8102205564365e-05,
      "loss": 0.0028,
      "step": 7900
    },
    {
      "epoch": 0.3820095141992216,
      "grad_norm": 1.016981840133667,
      "learning_rate": 4.8090192686559995e-05,
      "loss": 0.0018,
      "step": 7950
    },
    {
      "epoch": 0.38441208976022295,
      "grad_norm": 0.1773741990327835,
      "learning_rate": 4.8078179808754985e-05,
      "loss": 0.0024,
      "step": 8000
    },
    {
      "epoch": 0.3868146653212243,
      "grad_norm": 0.39177650213241577,
      "learning_rate": 4.8066166930949976e-05,
      "loss": 0.0019,
      "step": 8050
    },
    {
      "epoch": 0.38921724088222576,
      "grad_norm": 1.4168206453323364,
      "learning_rate": 4.8054154053144974e-05,
      "loss": 0.0025,
      "step": 8100
    },
    {
      "epoch": 0.39161981644322713,
      "grad_norm": 1.0218371152877808,
      "learning_rate": 4.8042141175339965e-05,
      "loss": 0.0016,
      "step": 8150
    },
    {
      "epoch": 0.3940223920042285,
      "grad_norm": 0.4960063695907593,
      "learning_rate": 4.803012829753496e-05,
      "loss": 0.0013,
      "step": 8200
    },
    {
      "epoch": 0.39642496756522994,
      "grad_norm": 0.42857375741004944,
      "learning_rate": 4.801811541972995e-05,
      "loss": 0.0025,
      "step": 8250
    },
    {
      "epoch": 0.3988275431262313,
      "grad_norm": 0.29174432158470154,
      "learning_rate": 4.8006102541924944e-05,
      "loss": 0.0031,
      "step": 8300
    },
    {
      "epoch": 0.40123011868723274,
      "grad_norm": 1.0242136716842651,
      "learning_rate": 4.799408966411994e-05,
      "loss": 0.0016,
      "step": 8350
    },
    {
      "epoch": 0.4036326942482341,
      "grad_norm": 0.6900956034660339,
      "learning_rate": 4.798207678631493e-05,
      "loss": 0.0016,
      "step": 8400
    },
    {
      "epoch": 0.4060352698092355,
      "grad_norm": 0.16494126617908478,
      "learning_rate": 4.797006390850993e-05,
      "loss": 0.0014,
      "step": 8450
    },
    {
      "epoch": 0.4084378453702369,
      "grad_norm": 0.27514350414276123,
      "learning_rate": 4.795805103070492e-05,
      "loss": 0.0019,
      "step": 8500
    },
    {
      "epoch": 0.4108404209312383,
      "grad_norm": 0.38906118273735046,
      "learning_rate": 4.794603815289991e-05,
      "loss": 0.0016,
      "step": 8550
    },
    {
      "epoch": 0.41324299649223967,
      "grad_norm": 1.202871322631836,
      "learning_rate": 4.79340252750949e-05,
      "loss": 0.0017,
      "step": 8600
    },
    {
      "epoch": 0.4156455720532411,
      "grad_norm": 0.618334949016571,
      "learning_rate": 4.792201239728989e-05,
      "loss": 0.0017,
      "step": 8650
    },
    {
      "epoch": 0.41804814761424247,
      "grad_norm": 0.45148158073425293,
      "learning_rate": 4.790999951948489e-05,
      "loss": 0.0017,
      "step": 8700
    },
    {
      "epoch": 0.42045072317524385,
      "grad_norm": 0.45100918412208557,
      "learning_rate": 4.789798664167988e-05,
      "loss": 0.0016,
      "step": 8750
    },
    {
      "epoch": 0.4228532987362453,
      "grad_norm": 0.22719576954841614,
      "learning_rate": 4.788597376387487e-05,
      "loss": 0.0016,
      "step": 8800
    },
    {
      "epoch": 0.42525587429724665,
      "grad_norm": 0.21816249191761017,
      "learning_rate": 4.787396088606987e-05,
      "loss": 0.0015,
      "step": 8850
    },
    {
      "epoch": 0.427658449858248,
      "grad_norm": 0.5738443732261658,
      "learning_rate": 4.786194800826486e-05,
      "loss": 0.0014,
      "step": 8900
    },
    {
      "epoch": 0.43006102541924945,
      "grad_norm": 0.42381036281585693,
      "learning_rate": 4.784993513045986e-05,
      "loss": 0.0015,
      "step": 8950
    },
    {
      "epoch": 0.43246360098025083,
      "grad_norm": 0.4967932105064392,
      "learning_rate": 4.783792225265485e-05,
      "loss": 0.0012,
      "step": 9000
    },
    {
      "epoch": 0.4348661765412522,
      "grad_norm": 0.07739371806383133,
      "learning_rate": 4.782590937484984e-05,
      "loss": 0.0012,
      "step": 9050
    },
    {
      "epoch": 0.43726875210225363,
      "grad_norm": 0.4330582916736603,
      "learning_rate": 4.781389649704484e-05,
      "loss": 0.0014,
      "step": 9100
    },
    {
      "epoch": 0.439671327663255,
      "grad_norm": 0.16531363129615784,
      "learning_rate": 4.780188361923983e-05,
      "loss": 0.001,
      "step": 9150
    },
    {
      "epoch": 0.4420739032242564,
      "grad_norm": 0.3392813205718994,
      "learning_rate": 4.778987074143482e-05,
      "loss": 0.0013,
      "step": 9200
    },
    {
      "epoch": 0.4444764787852578,
      "grad_norm": 0.678136944770813,
      "learning_rate": 4.777785786362982e-05,
      "loss": 0.0013,
      "step": 9250
    },
    {
      "epoch": 0.4468790543462592,
      "grad_norm": 0.7079349756240845,
      "learning_rate": 4.776584498582481e-05,
      "loss": 0.0017,
      "step": 9300
    },
    {
      "epoch": 0.44928162990726056,
      "grad_norm": 0.4895235300064087,
      "learning_rate": 4.77538321080198e-05,
      "loss": 0.0013,
      "step": 9350
    },
    {
      "epoch": 0.451684205468262,
      "grad_norm": 0.281464159488678,
      "learning_rate": 4.774181923021479e-05,
      "loss": 0.0025,
      "step": 9400
    },
    {
      "epoch": 0.45408678102926336,
      "grad_norm": 1.1597802639007568,
      "learning_rate": 4.772980635240979e-05,
      "loss": 0.0015,
      "step": 9450
    },
    {
      "epoch": 0.45648935659026474,
      "grad_norm": 0.4603518545627594,
      "learning_rate": 4.771779347460478e-05,
      "loss": 0.0023,
      "step": 9500
    },
    {
      "epoch": 0.45889193215126617,
      "grad_norm": 0.21402840316295624,
      "learning_rate": 4.770578059679977e-05,
      "loss": 0.0011,
      "step": 9550
    },
    {
      "epoch": 0.46129450771226754,
      "grad_norm": 0.3259953558444977,
      "learning_rate": 4.7693767718994766e-05,
      "loss": 0.002,
      "step": 9600
    },
    {
      "epoch": 0.4636970832732689,
      "grad_norm": 0.42909014225006104,
      "learning_rate": 4.768175484118976e-05,
      "loss": 0.0011,
      "step": 9650
    },
    {
      "epoch": 0.46609965883427035,
      "grad_norm": 0.7243877053260803,
      "learning_rate": 4.766974196338475e-05,
      "loss": 0.0012,
      "step": 9700
    },
    {
      "epoch": 0.4685022343952717,
      "grad_norm": 0.344512939453125,
      "learning_rate": 4.7657729085579746e-05,
      "loss": 0.0011,
      "step": 9750
    },
    {
      "epoch": 0.47090480995627315,
      "grad_norm": 0.473008394241333,
      "learning_rate": 4.7645716207774736e-05,
      "loss": 0.0013,
      "step": 9800
    },
    {
      "epoch": 0.4733073855172745,
      "grad_norm": 0.2414960265159607,
      "learning_rate": 4.7633703329969734e-05,
      "loss": 0.0013,
      "step": 9850
    },
    {
      "epoch": 0.4757099610782759,
      "grad_norm": 0.2492026388645172,
      "learning_rate": 4.7621690452164725e-05,
      "loss": 0.001,
      "step": 9900
    },
    {
      "epoch": 0.47811253663927733,
      "grad_norm": 0.4360458552837372,
      "learning_rate": 4.7609677574359716e-05,
      "loss": 0.0015,
      "step": 9950
    },
    {
      "epoch": 0.4805151122002787,
      "grad_norm": 0.18786387145519257,
      "learning_rate": 4.759766469655471e-05,
      "loss": 0.001,
      "step": 10000
    },
    {
      "epoch": 0.4829176877612801,
      "grad_norm": 0.7892693877220154,
      "learning_rate": 4.7585651818749704e-05,
      "loss": 0.0012,
      "step": 10050
    },
    {
      "epoch": 0.4853202633222815,
      "grad_norm": 0.2488766759634018,
      "learning_rate": 4.7573638940944695e-05,
      "loss": 0.0016,
      "step": 10100
    },
    {
      "epoch": 0.4877228388832829,
      "grad_norm": 0.5023505687713623,
      "learning_rate": 4.7561626063139686e-05,
      "loss": 0.0009,
      "step": 10150
    },
    {
      "epoch": 0.49012541444428426,
      "grad_norm": 0.29928240180015564,
      "learning_rate": 4.7549613185334677e-05,
      "loss": 0.001,
      "step": 10200
    },
    {
      "epoch": 0.4925279900052857,
      "grad_norm": 0.18543873727321625,
      "learning_rate": 4.7537600307529674e-05,
      "loss": 0.0013,
      "step": 10250
    },
    {
      "epoch": 0.49493056556628706,
      "grad_norm": 0.5265039205551147,
      "learning_rate": 4.7525587429724665e-05,
      "loss": 0.0011,
      "step": 10300
    },
    {
      "epoch": 0.49733314112728844,
      "grad_norm": 0.5920664668083191,
      "learning_rate": 4.751357455191966e-05,
      "loss": 0.0009,
      "step": 10350
    },
    {
      "epoch": 0.49973571668828987,
      "grad_norm": 0.8853898644447327,
      "learning_rate": 4.7501561674114653e-05,
      "loss": 0.0011,
      "step": 10400
    },
    {
      "epoch": 0.5021382922492912,
      "grad_norm": 0.18062996864318848,
      "learning_rate": 4.7489548796309644e-05,
      "loss": 0.0011,
      "step": 10450
    },
    {
      "epoch": 0.5045408678102926,
      "grad_norm": 0.405576229095459,
      "learning_rate": 4.747753591850464e-05,
      "loss": 0.001,
      "step": 10500
    },
    {
      "epoch": 0.506943443371294,
      "grad_norm": 0.6660116910934448,
      "learning_rate": 4.746552304069963e-05,
      "loss": 0.0012,
      "step": 10550
    },
    {
      "epoch": 0.5093460189322955,
      "grad_norm": 0.36080336570739746,
      "learning_rate": 4.7453510162894623e-05,
      "loss": 0.0009,
      "step": 10600
    },
    {
      "epoch": 0.5117485944932968,
      "grad_norm": 0.315073162317276,
      "learning_rate": 4.744149728508962e-05,
      "loss": 0.0009,
      "step": 10650
    },
    {
      "epoch": 0.5141511700542982,
      "grad_norm": 0.21552017331123352,
      "learning_rate": 4.742948440728461e-05,
      "loss": 0.001,
      "step": 10700
    },
    {
      "epoch": 0.5165537456152997,
      "grad_norm": 0.8097035884857178,
      "learning_rate": 4.741747152947961e-05,
      "loss": 0.0008,
      "step": 10750
    },
    {
      "epoch": 0.518956321176301,
      "grad_norm": 0.6803234219551086,
      "learning_rate": 4.74054586516746e-05,
      "loss": 0.0006,
      "step": 10800
    },
    {
      "epoch": 0.5213588967373024,
      "grad_norm": 0.2582549750804901,
      "learning_rate": 4.739344577386959e-05,
      "loss": 0.0006,
      "step": 10850
    },
    {
      "epoch": 0.5237614722983038,
      "grad_norm": 0.11792430281639099,
      "learning_rate": 4.738143289606458e-05,
      "loss": 0.0008,
      "step": 10900
    },
    {
      "epoch": 0.5261640478593052,
      "grad_norm": 0.4464760422706604,
      "learning_rate": 4.736942001825957e-05,
      "loss": 0.0009,
      "step": 10950
    },
    {
      "epoch": 0.5285666234203066,
      "grad_norm": 1.3060452938079834,
      "learning_rate": 4.735740714045457e-05,
      "loss": 0.0015,
      "step": 11000
    },
    {
      "epoch": 0.530969198981308,
      "grad_norm": 0.23525315523147583,
      "learning_rate": 4.734539426264956e-05,
      "loss": 0.0017,
      "step": 11050
    },
    {
      "epoch": 0.5333717745423093,
      "grad_norm": 0.26891469955444336,
      "learning_rate": 4.733338138484455e-05,
      "loss": 0.0009,
      "step": 11100
    },
    {
      "epoch": 0.5357743501033108,
      "grad_norm": 0.7590559124946594,
      "learning_rate": 4.732136850703955e-05,
      "loss": 0.0008,
      "step": 11150
    },
    {
      "epoch": 0.5381769256643122,
      "grad_norm": 0.3766399919986725,
      "learning_rate": 4.730935562923454e-05,
      "loss": 0.0008,
      "step": 11200
    },
    {
      "epoch": 0.5405795012253135,
      "grad_norm": 0.24707773327827454,
      "learning_rate": 4.729734275142954e-05,
      "loss": 0.0014,
      "step": 11250
    },
    {
      "epoch": 0.5429820767863149,
      "grad_norm": 0.42296716570854187,
      "learning_rate": 4.728532987362453e-05,
      "loss": 0.0007,
      "step": 11300
    },
    {
      "epoch": 0.5453846523473164,
      "grad_norm": 0.46715208888053894,
      "learning_rate": 4.727331699581952e-05,
      "loss": 0.0011,
      "step": 11350
    },
    {
      "epoch": 0.5477872279083177,
      "grad_norm": 0.26571908593177795,
      "learning_rate": 4.726130411801452e-05,
      "loss": 0.0012,
      "step": 11400
    },
    {
      "epoch": 0.5501898034693191,
      "grad_norm": 0.22861836850643158,
      "learning_rate": 4.724929124020951e-05,
      "loss": 0.001,
      "step": 11450
    },
    {
      "epoch": 0.5525923790303205,
      "grad_norm": 0.5314511656761169,
      "learning_rate": 4.72372783624045e-05,
      "loss": 0.0009,
      "step": 11500
    },
    {
      "epoch": 0.5549949545913219,
      "grad_norm": 0.21105512976646423,
      "learning_rate": 4.722526548459949e-05,
      "loss": 0.0008,
      "step": 11550
    },
    {
      "epoch": 0.5573975301523233,
      "grad_norm": 0.5149452686309814,
      "learning_rate": 4.721325260679448e-05,
      "loss": 0.0008,
      "step": 11600
    },
    {
      "epoch": 0.5598001057133247,
      "grad_norm": 0.1806778609752655,
      "learning_rate": 4.720123972898948e-05,
      "loss": 0.0008,
      "step": 11650
    },
    {
      "epoch": 0.562202681274326,
      "grad_norm": 0.49645936489105225,
      "learning_rate": 4.718922685118447e-05,
      "loss": 0.0017,
      "step": 11700
    },
    {
      "epoch": 0.5646052568353275,
      "grad_norm": 0.33778658509254456,
      "learning_rate": 4.717721397337947e-05,
      "loss": 0.0008,
      "step": 11750
    },
    {
      "epoch": 0.5670078323963289,
      "grad_norm": 0.7080723643302917,
      "learning_rate": 4.716520109557446e-05,
      "loss": 0.0006,
      "step": 11800
    },
    {
      "epoch": 0.5694104079573302,
      "grad_norm": 0.15494802594184875,
      "learning_rate": 4.715318821776945e-05,
      "loss": 0.0008,
      "step": 11850
    },
    {
      "epoch": 0.5718129835183317,
      "grad_norm": 0.1549999862909317,
      "learning_rate": 4.7141175339964446e-05,
      "loss": 0.0009,
      "step": 11900
    },
    {
      "epoch": 0.5742155590793331,
      "grad_norm": 0.18029102683067322,
      "learning_rate": 4.712916246215944e-05,
      "loss": 0.0008,
      "step": 11950
    },
    {
      "epoch": 0.5766181346403344,
      "grad_norm": 0.4563058912754059,
      "learning_rate": 4.711714958435443e-05,
      "loss": 0.0006,
      "step": 12000
    },
    {
      "epoch": 0.5790207102013358,
      "grad_norm": 0.3730584979057312,
      "learning_rate": 4.7105136706549425e-05,
      "loss": 0.0009,
      "step": 12050
    },
    {
      "epoch": 0.5814232857623373,
      "grad_norm": 0.37291210889816284,
      "learning_rate": 4.7093123828744416e-05,
      "loss": 0.0007,
      "step": 12100
    },
    {
      "epoch": 0.5838258613233386,
      "grad_norm": 0.7107646465301514,
      "learning_rate": 4.7081110950939414e-05,
      "loss": 0.0006,
      "step": 12150
    },
    {
      "epoch": 0.58622843688434,
      "grad_norm": 0.405076801776886,
      "learning_rate": 4.7069098073134404e-05,
      "loss": 0.0006,
      "step": 12200
    },
    {
      "epoch": 0.5886310124453414,
      "grad_norm": 0.29385441541671753,
      "learning_rate": 4.7057085195329395e-05,
      "loss": 0.0012,
      "step": 12250
    },
    {
      "epoch": 0.5910335880063428,
      "grad_norm": 0.3255021572113037,
      "learning_rate": 4.7045072317524386e-05,
      "loss": 0.0015,
      "step": 12300
    },
    {
      "epoch": 0.5934361635673442,
      "grad_norm": 0.6020157933235168,
      "learning_rate": 4.703305943971938e-05,
      "loss": 0.0009,
      "step": 12350
    },
    {
      "epoch": 0.5958387391283456,
      "grad_norm": 0.16084226965904236,
      "learning_rate": 4.7021046561914375e-05,
      "loss": 0.0006,
      "step": 12400
    },
    {
      "epoch": 0.5982413146893469,
      "grad_norm": 0.3288974463939667,
      "learning_rate": 4.7009033684109365e-05,
      "loss": 0.0007,
      "step": 12450
    },
    {
      "epoch": 0.6006438902503484,
      "grad_norm": 0.29523196816444397,
      "learning_rate": 4.6997020806304356e-05,
      "loss": 0.0006,
      "step": 12500
    },
    {
      "epoch": 0.6030464658113498,
      "grad_norm": 0.48559483885765076,
      "learning_rate": 4.6985007928499354e-05,
      "loss": 0.0006,
      "step": 12550
    },
    {
      "epoch": 0.6054490413723511,
      "grad_norm": 0.35820886492729187,
      "learning_rate": 4.6972995050694345e-05,
      "loss": 0.0008,
      "step": 12600
    },
    {
      "epoch": 0.6078516169333525,
      "grad_norm": 0.31307724118232727,
      "learning_rate": 4.696098217288934e-05,
      "loss": 0.0007,
      "step": 12650
    },
    {
      "epoch": 0.610254192494354,
      "grad_norm": 0.2471470981836319,
      "learning_rate": 4.694896929508433e-05,
      "loss": 0.0006,
      "step": 12700
    },
    {
      "epoch": 0.6126567680553553,
      "grad_norm": 0.5291588306427002,
      "learning_rate": 4.6936956417279324e-05,
      "loss": 0.0006,
      "step": 12750
    },
    {
      "epoch": 0.6150593436163567,
      "grad_norm": 0.3205917477607727,
      "learning_rate": 4.692494353947432e-05,
      "loss": 0.0007,
      "step": 12800
    },
    {
      "epoch": 0.6174619191773582,
      "grad_norm": 0.15991155803203583,
      "learning_rate": 4.691293066166931e-05,
      "loss": 0.0006,
      "step": 12850
    },
    {
      "epoch": 0.6198644947383595,
      "grad_norm": 0.44846558570861816,
      "learning_rate": 4.690091778386431e-05,
      "loss": 0.0009,
      "step": 12900
    },
    {
      "epoch": 0.6222670702993609,
      "grad_norm": 0.2811257243156433,
      "learning_rate": 4.68889049060593e-05,
      "loss": 0.0006,
      "step": 12950
    },
    {
      "epoch": 0.6246696458603623,
      "grad_norm": 0.1796385496854782,
      "learning_rate": 4.687689202825429e-05,
      "loss": 0.0005,
      "step": 13000
    },
    {
      "epoch": 0.6270722214213637,
      "grad_norm": 0.06024529039859772,
      "learning_rate": 4.686487915044928e-05,
      "loss": 0.0005,
      "step": 13050
    },
    {
      "epoch": 0.6294747969823651,
      "grad_norm": 0.2210806906223297,
      "learning_rate": 4.685286627264427e-05,
      "loss": 0.0006,
      "step": 13100
    },
    {
      "epoch": 0.6318773725433665,
      "grad_norm": 0.2483021467924118,
      "learning_rate": 4.684085339483927e-05,
      "loss": 0.0005,
      "step": 13150
    },
    {
      "epoch": 0.6342799481043678,
      "grad_norm": 0.44292160868644714,
      "learning_rate": 4.682884051703426e-05,
      "loss": 0.0006,
      "step": 13200
    },
    {
      "epoch": 0.6366825236653693,
      "grad_norm": 0.45030534267425537,
      "learning_rate": 4.681682763922925e-05,
      "loss": 0.0006,
      "step": 13250
    },
    {
      "epoch": 0.6390850992263707,
      "grad_norm": 0.20659713447093964,
      "learning_rate": 4.680481476142425e-05,
      "loss": 0.0006,
      "step": 13300
    },
    {
      "epoch": 0.641487674787372,
      "grad_norm": 0.7419323325157166,
      "learning_rate": 4.679280188361924e-05,
      "loss": 0.0007,
      "step": 13350
    },
    {
      "epoch": 0.6438902503483734,
      "grad_norm": 0.4334513247013092,
      "learning_rate": 4.678078900581424e-05,
      "loss": 0.0006,
      "step": 13400
    },
    {
      "epoch": 0.6462928259093749,
      "grad_norm": 0.479362428188324,
      "learning_rate": 4.676877612800923e-05,
      "loss": 0.0008,
      "step": 13450
    },
    {
      "epoch": 0.6486954014703763,
      "grad_norm": 0.17617224156856537,
      "learning_rate": 4.675676325020422e-05,
      "loss": 0.0006,
      "step": 13500
    },
    {
      "epoch": 0.6510979770313776,
      "grad_norm": 0.19105267524719238,
      "learning_rate": 4.674475037239922e-05,
      "loss": 0.0006,
      "step": 13550
    },
    {
      "epoch": 0.653500552592379,
      "grad_norm": 0.2580304741859436,
      "learning_rate": 4.673273749459421e-05,
      "loss": 0.0005,
      "step": 13600
    },
    {
      "epoch": 0.6559031281533805,
      "grad_norm": 0.057192232459783554,
      "learning_rate": 4.67207246167892e-05,
      "loss": 0.0005,
      "step": 13650
    },
    {
      "epoch": 0.6583057037143818,
      "grad_norm": 0.1908128410577774,
      "learning_rate": 4.67087117389842e-05,
      "loss": 0.001,
      "step": 13700
    },
    {
      "epoch": 0.6607082792753832,
      "grad_norm": 0.19951626658439636,
      "learning_rate": 4.669669886117919e-05,
      "loss": 0.0007,
      "step": 13750
    },
    {
      "epoch": 0.6631108548363847,
      "grad_norm": 0.24864786863327026,
      "learning_rate": 4.668468598337418e-05,
      "loss": 0.0006,
      "step": 13800
    },
    {
      "epoch": 0.665513430397386,
      "grad_norm": 0.18368496000766754,
      "learning_rate": 4.667267310556917e-05,
      "loss": 0.0006,
      "step": 13850
    },
    {
      "epoch": 0.6679160059583874,
      "grad_norm": 0.47824224829673767,
      "learning_rate": 4.666066022776416e-05,
      "loss": 0.0007,
      "step": 13900
    },
    {
      "epoch": 0.6703185815193888,
      "grad_norm": 0.5020542740821838,
      "learning_rate": 4.664864734995916e-05,
      "loss": 0.0008,
      "step": 13950
    },
    {
      "epoch": 0.6727211570803902,
      "grad_norm": 0.347461998462677,
      "learning_rate": 4.663663447215415e-05,
      "loss": 0.0012,
      "step": 14000
    },
    {
      "epoch": 0.6751237326413916,
      "grad_norm": 0.35125234723091125,
      "learning_rate": 4.6624621594349146e-05,
      "loss": 0.0005,
      "step": 14050
    },
    {
      "epoch": 0.677526308202393,
      "grad_norm": 0.5235538482666016,
      "learning_rate": 4.661260871654414e-05,
      "loss": 0.0006,
      "step": 14100
    },
    {
      "epoch": 0.6799288837633943,
      "grad_norm": 0.20669257640838623,
      "learning_rate": 4.660059583873913e-05,
      "loss": 0.0004,
      "step": 14150
    },
    {
      "epoch": 0.6823314593243958,
      "grad_norm": 0.16009646654129028,
      "learning_rate": 4.6588582960934126e-05,
      "loss": 0.0006,
      "step": 14200
    },
    {
      "epoch": 0.6847340348853972,
      "grad_norm": 0.11407052725553513,
      "learning_rate": 4.6576570083129116e-05,
      "loss": 0.0004,
      "step": 14250
    },
    {
      "epoch": 0.6871366104463985,
      "grad_norm": 0.13027803599834442,
      "learning_rate": 4.6564557205324114e-05,
      "loss": 0.0004,
      "step": 14300
    },
    {
      "epoch": 0.6895391860073999,
      "grad_norm": 0.5561893582344055,
      "learning_rate": 4.6552544327519105e-05,
      "loss": 0.0005,
      "step": 14350
    },
    {
      "epoch": 0.6919417615684014,
      "grad_norm": 0.48622801899909973,
      "learning_rate": 4.6540531449714096e-05,
      "loss": 0.0006,
      "step": 14400
    },
    {
      "epoch": 0.6943443371294027,
      "grad_norm": 0.11524581909179688,
      "learning_rate": 4.652851857190909e-05,
      "loss": 0.0006,
      "step": 14450
    },
    {
      "epoch": 0.6967469126904041,
      "grad_norm": 0.4872836470603943,
      "learning_rate": 4.6516505694104084e-05,
      "loss": 0.0006,
      "step": 14500
    },
    {
      "epoch": 0.6991494882514055,
      "grad_norm": 0.044106680899858475,
      "learning_rate": 4.6504492816299075e-05,
      "loss": 0.0012,
      "step": 14550
    },
    {
      "epoch": 0.7015520638124069,
      "grad_norm": 0.132712721824646,
      "learning_rate": 4.6492479938494066e-05,
      "loss": 0.0011,
      "step": 14600
    },
    {
      "epoch": 0.7039546393734083,
      "grad_norm": 0.2791624069213867,
      "learning_rate": 4.6480467060689057e-05,
      "loss": 0.0004,
      "step": 14650
    },
    {
      "epoch": 0.7063572149344097,
      "grad_norm": 0.1338568478822708,
      "learning_rate": 4.6468454182884054e-05,
      "loss": 0.0005,
      "step": 14700
    },
    {
      "epoch": 0.708759790495411,
      "grad_norm": 0.006235484965145588,
      "learning_rate": 4.6456441305079045e-05,
      "loss": 0.0005,
      "step": 14750
    },
    {
      "epoch": 0.7111623660564125,
      "grad_norm": 0.291797399520874,
      "learning_rate": 4.644442842727404e-05,
      "loss": 0.0005,
      "step": 14800
    },
    {
      "epoch": 0.7135649416174139,
      "grad_norm": 0.31796297430992126,
      "learning_rate": 4.643241554946903e-05,
      "loss": 0.0005,
      "step": 14850
    },
    {
      "epoch": 0.7159675171784152,
      "grad_norm": 0.5951027274131775,
      "learning_rate": 4.6420402671664024e-05,
      "loss": 0.0005,
      "step": 14900
    },
    {
      "epoch": 0.7183700927394167,
      "grad_norm": 0.5069403648376465,
      "learning_rate": 4.640838979385902e-05,
      "loss": 0.0019,
      "step": 14950
    },
    {
      "epoch": 0.7207726683004181,
      "grad_norm": 0.35902073979377747,
      "learning_rate": 4.639637691605401e-05,
      "loss": 0.0005,
      "step": 15000
    },
    {
      "epoch": 0.7231752438614194,
      "grad_norm": 0.13194774091243744,
      "learning_rate": 4.6384364038249003e-05,
      "loss": 0.0005,
      "step": 15050
    },
    {
      "epoch": 0.7255778194224208,
      "grad_norm": 0.21186858415603638,
      "learning_rate": 4.6372351160444e-05,
      "loss": 0.0004,
      "step": 15100
    },
    {
      "epoch": 0.7279803949834223,
      "grad_norm": 0.09237228333950043,
      "learning_rate": 4.636033828263899e-05,
      "loss": 0.0007,
      "step": 15150
    },
    {
      "epoch": 0.7303829705444236,
      "grad_norm": 0.17555812001228333,
      "learning_rate": 4.634832540483399e-05,
      "loss": 0.0006,
      "step": 15200
    },
    {
      "epoch": 0.732785546105425,
      "grad_norm": 0.11348073929548264,
      "learning_rate": 4.633631252702898e-05,
      "loss": 0.0006,
      "step": 15250
    },
    {
      "epoch": 0.7351881216664264,
      "grad_norm": 0.12045582383871078,
      "learning_rate": 4.632429964922397e-05,
      "loss": 0.0003,
      "step": 15300
    },
    {
      "epoch": 0.7375906972274278,
      "grad_norm": 0.2896325886249542,
      "learning_rate": 4.631228677141896e-05,
      "loss": 0.0004,
      "step": 15350
    },
    {
      "epoch": 0.7399932727884292,
      "grad_norm": 0.19790582358837128,
      "learning_rate": 4.630027389361395e-05,
      "loss": 0.0004,
      "step": 15400
    },
    {
      "epoch": 0.7423958483494306,
      "grad_norm": 0.20079602301120758,
      "learning_rate": 4.628826101580895e-05,
      "loss": 0.0005,
      "step": 15450
    },
    {
      "epoch": 0.7447984239104319,
      "grad_norm": 0.3078109622001648,
      "learning_rate": 4.627624813800394e-05,
      "loss": 0.0006,
      "step": 15500
    },
    {
      "epoch": 0.7472009994714334,
      "grad_norm": 0.24048614501953125,
      "learning_rate": 4.626423526019893e-05,
      "loss": 0.0005,
      "step": 15550
    },
    {
      "epoch": 0.7496035750324348,
      "grad_norm": 0.28681784868240356,
      "learning_rate": 4.625222238239393e-05,
      "loss": 0.0005,
      "step": 15600
    },
    {
      "epoch": 0.7520061505934361,
      "grad_norm": 0.2027241289615631,
      "learning_rate": 4.624020950458892e-05,
      "loss": 0.0004,
      "step": 15650
    },
    {
      "epoch": 0.7544087261544375,
      "grad_norm": 0.5148528814315796,
      "learning_rate": 4.622819662678392e-05,
      "loss": 0.0005,
      "step": 15700
    },
    {
      "epoch": 0.756811301715439,
      "grad_norm": 0.3106798529624939,
      "learning_rate": 4.621618374897891e-05,
      "loss": 0.0003,
      "step": 15750
    },
    {
      "epoch": 0.7592138772764403,
      "grad_norm": 0.2230282872915268,
      "learning_rate": 4.62041708711739e-05,
      "loss": 0.0005,
      "step": 15800
    },
    {
      "epoch": 0.7616164528374417,
      "grad_norm": 0.18024879693984985,
      "learning_rate": 4.61921579933689e-05,
      "loss": 0.0005,
      "step": 15850
    },
    {
      "epoch": 0.7640190283984432,
      "grad_norm": 0.41634660959243774,
      "learning_rate": 4.618014511556389e-05,
      "loss": 0.0004,
      "step": 15900
    },
    {
      "epoch": 0.7664216039594445,
      "grad_norm": 0.3646915853023529,
      "learning_rate": 4.616813223775888e-05,
      "loss": 0.0005,
      "step": 15950
    },
    {
      "epoch": 0.7688241795204459,
      "grad_norm": 0.45304974913597107,
      "learning_rate": 4.6156119359953877e-05,
      "loss": 0.0012,
      "step": 16000
    },
    {
      "epoch": 0.7712267550814473,
      "grad_norm": 0.239519402384758,
      "learning_rate": 4.614410648214886e-05,
      "loss": 0.0004,
      "step": 16050
    },
    {
      "epoch": 0.7736293306424487,
      "grad_norm": 0.1284036487340927,
      "learning_rate": 4.613209360434386e-05,
      "loss": 0.0004,
      "step": 16100
    },
    {
      "epoch": 0.7760319062034501,
      "grad_norm": 0.17256514728069305,
      "learning_rate": 4.612008072653885e-05,
      "loss": 0.0004,
      "step": 16150
    },
    {
      "epoch": 0.7784344817644515,
      "grad_norm": 0.3822995722293854,
      "learning_rate": 4.610806784873385e-05,
      "loss": 0.0004,
      "step": 16200
    },
    {
      "epoch": 0.7808370573254528,
      "grad_norm": 0.29100462794303894,
      "learning_rate": 4.609605497092884e-05,
      "loss": 0.0003,
      "step": 16250
    },
    {
      "epoch": 0.7832396328864543,
      "grad_norm": 0.3352905809879303,
      "learning_rate": 4.608404209312383e-05,
      "loss": 0.0005,
      "step": 16300
    },
    {
      "epoch": 0.7856422084474557,
      "grad_norm": 0.4822274446487427,
      "learning_rate": 4.6072029215318826e-05,
      "loss": 0.0004,
      "step": 16350
    },
    {
      "epoch": 0.788044784008457,
      "grad_norm": 0.2009902000427246,
      "learning_rate": 4.606001633751382e-05,
      "loss": 0.0005,
      "step": 16400
    },
    {
      "epoch": 0.7904473595694584,
      "grad_norm": 0.6537049412727356,
      "learning_rate": 4.604800345970881e-05,
      "loss": 0.0004,
      "step": 16450
    },
    {
      "epoch": 0.7928499351304599,
      "grad_norm": 0.29081133008003235,
      "learning_rate": 4.6035990581903805e-05,
      "loss": 0.0003,
      "step": 16500
    },
    {
      "epoch": 0.7952525106914613,
      "grad_norm": 0.06786534935235977,
      "learning_rate": 4.6023977704098796e-05,
      "loss": 0.0003,
      "step": 16550
    },
    {
      "epoch": 0.7976550862524626,
      "grad_norm": 0.2497783899307251,
      "learning_rate": 4.6011964826293794e-05,
      "loss": 0.0004,
      "step": 16600
    },
    {
      "epoch": 0.800057661813464,
      "grad_norm": 0.33183857798576355,
      "learning_rate": 4.5999951948488784e-05,
      "loss": 0.0004,
      "step": 16650
    },
    {
      "epoch": 0.8024602373744655,
      "grad_norm": 0.28383931517601013,
      "learning_rate": 4.5987939070683775e-05,
      "loss": 0.0006,
      "step": 16700
    },
    {
      "epoch": 0.8048628129354668,
      "grad_norm": 0.2841387093067169,
      "learning_rate": 4.597592619287877e-05,
      "loss": 0.0004,
      "step": 16750
    },
    {
      "epoch": 0.8072653884964682,
      "grad_norm": 0.12186664342880249,
      "learning_rate": 4.596391331507376e-05,
      "loss": 0.0006,
      "step": 16800
    },
    {
      "epoch": 0.8096679640574697,
      "grad_norm": 0.308255136013031,
      "learning_rate": 4.5951900437268754e-05,
      "loss": 0.0004,
      "step": 16850
    },
    {
      "epoch": 0.812070539618471,
      "grad_norm": 0.19127264618873596,
      "learning_rate": 4.5939887559463745e-05,
      "loss": 0.0003,
      "step": 16900
    },
    {
      "epoch": 0.8144731151794724,
      "grad_norm": 0.10896549373865128,
      "learning_rate": 4.5927874681658736e-05,
      "loss": 0.0003,
      "step": 16950
    },
    {
      "epoch": 0.8168756907404738,
      "grad_norm": 0.12297916412353516,
      "learning_rate": 4.5915861803853734e-05,
      "loss": 0.0005,
      "step": 17000
    },
    {
      "epoch": 0.8192782663014752,
      "grad_norm": 0.12324438244104385,
      "learning_rate": 4.5903848926048725e-05,
      "loss": 0.0004,
      "step": 17050
    },
    {
      "epoch": 0.8216808418624766,
      "grad_norm": 0.1879609078168869,
      "learning_rate": 4.589183604824372e-05,
      "loss": 0.0004,
      "step": 17100
    },
    {
      "epoch": 0.824083417423478,
      "grad_norm": 0.21061260998249054,
      "learning_rate": 4.587982317043871e-05,
      "loss": 0.0003,
      "step": 17150
    },
    {
      "epoch": 0.8264859929844793,
      "grad_norm": 0.5788460373878479,
      "learning_rate": 4.5867810292633704e-05,
      "loss": 0.0004,
      "step": 17200
    },
    {
      "epoch": 0.8288885685454808,
      "grad_norm": 0.7356735467910767,
      "learning_rate": 4.58557974148287e-05,
      "loss": 0.0004,
      "step": 17250
    },
    {
      "epoch": 0.8312911441064822,
      "grad_norm": 0.16135093569755554,
      "learning_rate": 4.584378453702369e-05,
      "loss": 0.0004,
      "step": 17300
    },
    {
      "epoch": 0.8336937196674835,
      "grad_norm": 0.232765793800354,
      "learning_rate": 4.583177165921868e-05,
      "loss": 0.0019,
      "step": 17350
    },
    {
      "epoch": 0.8360962952284849,
      "grad_norm": 0.3111654222011566,
      "learning_rate": 4.581975878141368e-05,
      "loss": 0.0011,
      "step": 17400
    },
    {
      "epoch": 0.8384988707894864,
      "grad_norm": 0.08823210000991821,
      "learning_rate": 4.580774590360867e-05,
      "loss": 0.0004,
      "step": 17450
    },
    {
      "epoch": 0.8409014463504877,
      "grad_norm": 0.6173869967460632,
      "learning_rate": 4.579573302580366e-05,
      "loss": 0.0004,
      "step": 17500
    },
    {
      "epoch": 0.8433040219114891,
      "grad_norm": 0.13648352026939392,
      "learning_rate": 4.578372014799865e-05,
      "loss": 0.0004,
      "step": 17550
    },
    {
      "epoch": 0.8457065974724906,
      "grad_norm": 0.3549957573413849,
      "learning_rate": 4.577170727019365e-05,
      "loss": 0.0003,
      "step": 17600
    },
    {
      "epoch": 0.8481091730334919,
      "grad_norm": 0.14587044715881348,
      "learning_rate": 4.575969439238864e-05,
      "loss": 0.0004,
      "step": 17650
    },
    {
      "epoch": 0.8505117485944933,
      "grad_norm": 0.4429173767566681,
      "learning_rate": 4.574768151458363e-05,
      "loss": 0.0004,
      "step": 17700
    },
    {
      "epoch": 0.8529143241554947,
      "grad_norm": 0.059514183551073074,
      "learning_rate": 4.573566863677863e-05,
      "loss": 0.0003,
      "step": 17750
    },
    {
      "epoch": 0.855316899716496,
      "grad_norm": 0.2522858679294586,
      "learning_rate": 4.572365575897362e-05,
      "loss": 0.0003,
      "step": 17800
    },
    {
      "epoch": 0.8577194752774975,
      "grad_norm": 0.40156057476997375,
      "learning_rate": 4.571164288116861e-05,
      "loss": 0.0003,
      "step": 17850
    },
    {
      "epoch": 0.8601220508384989,
      "grad_norm": 0.34386488795280457,
      "learning_rate": 4.569963000336361e-05,
      "loss": 0.0004,
      "step": 17900
    },
    {
      "epoch": 0.8625246263995002,
      "grad_norm": 0.17729447782039642,
      "learning_rate": 4.56876171255586e-05,
      "loss": 0.0003,
      "step": 17950
    },
    {
      "epoch": 0.8649272019605017,
      "grad_norm": 0.1382342129945755,
      "learning_rate": 4.56756042477536e-05,
      "loss": 0.0003,
      "step": 18000
    },
    {
      "epoch": 0.8673297775215031,
      "grad_norm": 0.30963319540023804,
      "learning_rate": 4.566359136994859e-05,
      "loss": 0.0004,
      "step": 18050
    },
    {
      "epoch": 0.8697323530825044,
      "grad_norm": 0.12881293892860413,
      "learning_rate": 4.565157849214358e-05,
      "loss": 0.0004,
      "step": 18100
    },
    {
      "epoch": 0.8721349286435058,
      "grad_norm": 0.24800540506839752,
      "learning_rate": 4.563956561433858e-05,
      "loss": 0.0004,
      "step": 18150
    },
    {
      "epoch": 0.8745375042045073,
      "grad_norm": 0.13534410297870636,
      "learning_rate": 4.562755273653357e-05,
      "loss": 0.0003,
      "step": 18200
    },
    {
      "epoch": 0.8769400797655086,
      "grad_norm": 0.18325188755989075,
      "learning_rate": 4.561553985872856e-05,
      "loss": 0.0003,
      "step": 18250
    },
    {
      "epoch": 0.87934265532651,
      "grad_norm": 0.41386333107948303,
      "learning_rate": 4.560352698092355e-05,
      "loss": 0.0003,
      "step": 18300
    },
    {
      "epoch": 0.8817452308875114,
      "grad_norm": 0.35381925106048584,
      "learning_rate": 4.559151410311854e-05,
      "loss": 0.0003,
      "step": 18350
    },
    {
      "epoch": 0.8841478064485128,
      "grad_norm": 0.3708048164844513,
      "learning_rate": 4.557950122531354e-05,
      "loss": 0.0004,
      "step": 18400
    },
    {
      "epoch": 0.8865503820095142,
      "grad_norm": 0.2895982563495636,
      "learning_rate": 4.556748834750853e-05,
      "loss": 0.0004,
      "step": 18450
    },
    {
      "epoch": 0.8889529575705156,
      "grad_norm": 0.38220536708831787,
      "learning_rate": 4.5555475469703526e-05,
      "loss": 0.0004,
      "step": 18500
    },
    {
      "epoch": 0.8913555331315169,
      "grad_norm": 0.3828330636024475,
      "learning_rate": 4.554346259189852e-05,
      "loss": 0.0003,
      "step": 18550
    },
    {
      "epoch": 0.8937581086925184,
      "grad_norm": 0.18191121518611908,
      "learning_rate": 4.553144971409351e-05,
      "loss": 0.0003,
      "step": 18600
    },
    {
      "epoch": 0.8961606842535198,
      "grad_norm": 0.11843583732843399,
      "learning_rate": 4.5519436836288505e-05,
      "loss": 0.0003,
      "step": 18650
    },
    {
      "epoch": 0.8985632598145211,
      "grad_norm": 0.5659192204475403,
      "learning_rate": 4.5507423958483496e-05,
      "loss": 0.0003,
      "step": 18700
    },
    {
      "epoch": 0.9009658353755226,
      "grad_norm": 0.1916276067495346,
      "learning_rate": 4.5495411080678494e-05,
      "loss": 0.0003,
      "step": 18750
    },
    {
      "epoch": 0.903368410936524,
      "grad_norm": 0.20407399535179138,
      "learning_rate": 4.5483398202873485e-05,
      "loss": 0.0004,
      "step": 18800
    },
    {
      "epoch": 0.9057709864975253,
      "grad_norm": 0.19015559554100037,
      "learning_rate": 4.5471385325068476e-05,
      "loss": 0.0004,
      "step": 18850
    },
    {
      "epoch": 0.9081735620585267,
      "grad_norm": 0.7096550464630127,
      "learning_rate": 4.545937244726347e-05,
      "loss": 0.0003,
      "step": 18900
    },
    {
      "epoch": 0.9105761376195282,
      "grad_norm": 0.4541942775249481,
      "learning_rate": 4.5447359569458464e-05,
      "loss": 0.0003,
      "step": 18950
    },
    {
      "epoch": 0.9129787131805295,
      "grad_norm": 0.06263459473848343,
      "learning_rate": 4.5435346691653455e-05,
      "loss": 0.0003,
      "step": 19000
    },
    {
      "epoch": 0.9153812887415309,
      "grad_norm": 0.2495947629213333,
      "learning_rate": 4.5423333813848446e-05,
      "loss": 0.0003,
      "step": 19050
    },
    {
      "epoch": 0.9177838643025323,
      "grad_norm": 0.12499867379665375,
      "learning_rate": 4.5411320936043436e-05,
      "loss": 0.0003,
      "step": 19100
    },
    {
      "epoch": 0.9201864398635337,
      "grad_norm": 0.10081028938293457,
      "learning_rate": 4.5399308058238434e-05,
      "loss": 0.0004,
      "step": 19150
    },
    {
      "epoch": 0.9225890154245351,
      "grad_norm": 0.26548975706100464,
      "learning_rate": 4.5387295180433425e-05,
      "loss": 0.0003,
      "step": 19200
    },
    {
      "epoch": 0.9249915909855365,
      "grad_norm": 0.4328870177268982,
      "learning_rate": 4.5375282302628416e-05,
      "loss": 0.0003,
      "step": 19250
    },
    {
      "epoch": 0.9273941665465378,
      "grad_norm": 0.1897134929895401,
      "learning_rate": 4.536326942482341e-05,
      "loss": 0.0003,
      "step": 19300
    },
    {
      "epoch": 0.9297967421075393,
      "grad_norm": 0.3149201273918152,
      "learning_rate": 4.5351256547018404e-05,
      "loss": 0.0002,
      "step": 19350
    },
    {
      "epoch": 0.9321993176685407,
      "grad_norm": 0.17295347154140472,
      "learning_rate": 4.53392436692134e-05,
      "loss": 0.0003,
      "step": 19400
    },
    {
      "epoch": 0.9346018932295421,
      "grad_norm": 0.16053813695907593,
      "learning_rate": 4.532723079140839e-05,
      "loss": 0.0004,
      "step": 19450
    },
    {
      "epoch": 0.9370044687905434,
      "grad_norm": 0.3346681296825409,
      "learning_rate": 4.5315217913603383e-05,
      "loss": 0.0003,
      "step": 19500
    },
    {
      "epoch": 0.9394070443515449,
      "grad_norm": 0.2689376175403595,
      "learning_rate": 4.530320503579838e-05,
      "loss": 0.0003,
      "step": 19550
    },
    {
      "epoch": 0.9418096199125463,
      "grad_norm": 0.12769551575183868,
      "learning_rate": 4.529119215799337e-05,
      "loss": 0.0003,
      "step": 19600
    },
    {
      "epoch": 0.9442121954735476,
      "grad_norm": 0.14148201048374176,
      "learning_rate": 4.527917928018837e-05,
      "loss": 0.0005,
      "step": 19650
    },
    {
      "epoch": 0.946614771034549,
      "grad_norm": 0.5525450110435486,
      "learning_rate": 4.526716640238336e-05,
      "loss": 0.0004,
      "step": 19700
    },
    {
      "epoch": 0.9490173465955505,
      "grad_norm": 0.3551063537597656,
      "learning_rate": 4.5255153524578344e-05,
      "loss": 0.0004,
      "step": 19750
    },
    {
      "epoch": 0.9514199221565518,
      "grad_norm": 0.05376994237303734,
      "learning_rate": 4.524314064677334e-05,
      "loss": 0.0003,
      "step": 19800
    },
    {
      "epoch": 0.9538224977175532,
      "grad_norm": 0.35119491815567017,
      "learning_rate": 4.523112776896833e-05,
      "loss": 0.0003,
      "step": 19850
    },
    {
      "epoch": 0.9562250732785547,
      "grad_norm": 0.1343444436788559,
      "learning_rate": 4.521911489116333e-05,
      "loss": 0.0004,
      "step": 19900
    },
    {
      "epoch": 0.958627648839556,
      "grad_norm": 0.16195446252822876,
      "learning_rate": 4.520710201335832e-05,
      "loss": 0.0009,
      "step": 19950
    },
    {
      "epoch": 0.9610302244005574,
      "grad_norm": 0.21652139723300934,
      "learning_rate": 4.519508913555331e-05,
      "loss": 0.0004,
      "step": 20000
    },
    {
      "epoch": 0.9634327999615588,
      "grad_norm": 0.46089300513267517,
      "learning_rate": 4.518307625774831e-05,
      "loss": 0.0013,
      "step": 20050
    },
    {
      "epoch": 0.9658353755225602,
      "grad_norm": 0.18202561140060425,
      "learning_rate": 4.51710633799433e-05,
      "loss": 0.0005,
      "step": 20100
    },
    {
      "epoch": 0.9682379510835616,
      "grad_norm": 0.19541607797145844,
      "learning_rate": 4.51590505021383e-05,
      "loss": 0.0011,
      "step": 20150
    },
    {
      "epoch": 0.970640526644563,
      "grad_norm": 0.12705935537815094,
      "learning_rate": 4.514703762433329e-05,
      "loss": 0.0004,
      "step": 20200
    },
    {
      "epoch": 0.9730431022055643,
      "grad_norm": 0.12171241641044617,
      "learning_rate": 4.513502474652828e-05,
      "loss": 0.0003,
      "step": 20250
    },
    {
      "epoch": 0.9754456777665658,
      "grad_norm": 0.13683979213237762,
      "learning_rate": 4.512301186872328e-05,
      "loss": 0.0002,
      "step": 20300
    },
    {
      "epoch": 0.9778482533275672,
      "grad_norm": 0.09811008721590042,
      "learning_rate": 4.511099899091827e-05,
      "loss": 0.001,
      "step": 20350
    },
    {
      "epoch": 0.9802508288885685,
      "grad_norm": 0.3162173926830292,
      "learning_rate": 4.509898611311326e-05,
      "loss": 0.0002,
      "step": 20400
    },
    {
      "epoch": 0.98265340444957,
      "grad_norm": 0.15758995711803436,
      "learning_rate": 4.5086973235308257e-05,
      "loss": 0.0004,
      "step": 20450
    },
    {
      "epoch": 0.9850559800105714,
      "grad_norm": 0.42061087489128113,
      "learning_rate": 4.507496035750324e-05,
      "loss": 0.0003,
      "step": 20500
    },
    {
      "epoch": 0.9874585555715727,
      "grad_norm": 0.12353028357028961,
      "learning_rate": 4.506294747969824e-05,
      "loss": 0.0004,
      "step": 20550
    },
    {
      "epoch": 0.9898611311325741,
      "grad_norm": 0.675588846206665,
      "learning_rate": 4.505093460189323e-05,
      "loss": 0.0003,
      "step": 20600
    },
    {
      "epoch": 0.9922637066935756,
      "grad_norm": 0.11372146755456924,
      "learning_rate": 4.5038921724088227e-05,
      "loss": 0.0003,
      "step": 20650
    },
    {
      "epoch": 0.9946662822545769,
      "grad_norm": 0.0813709944486618,
      "learning_rate": 4.502690884628322e-05,
      "loss": 0.0002,
      "step": 20700
    },
    {
      "epoch": 0.9970688578155783,
      "grad_norm": 0.11499778181314468,
      "learning_rate": 4.501489596847821e-05,
      "loss": 0.0003,
      "step": 20750
    },
    {
      "epoch": 0.9994714333765797,
      "grad_norm": 0.33942148089408875,
      "learning_rate": 4.5002883090673206e-05,
      "loss": 0.0008,
      "step": 20800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.00034524090006016195,
      "eval_runtime": 17.3726,
      "eval_samples_per_second": 546.608,
      "eval_steps_per_second": 68.326,
      "step": 20811
    },
    {
      "epoch": 1.001874008937581,
      "grad_norm": 0.48221883177757263,
      "learning_rate": 4.49908702128682e-05,
      "loss": 0.0003,
      "step": 20850
    },
    {
      "epoch": 1.0042765844985824,
      "grad_norm": 0.45837825536727905,
      "learning_rate": 4.497885733506319e-05,
      "loss": 0.0002,
      "step": 20900
    },
    {
      "epoch": 1.006679160059584,
      "grad_norm": 0.6192991137504578,
      "learning_rate": 4.4966844457258185e-05,
      "loss": 0.0003,
      "step": 20950
    },
    {
      "epoch": 1.0090817356205852,
      "grad_norm": 0.17462512850761414,
      "learning_rate": 4.4954831579453176e-05,
      "loss": 0.0003,
      "step": 21000
    },
    {
      "epoch": 1.0114843111815868,
      "grad_norm": 0.1386604905128479,
      "learning_rate": 4.4942818701648174e-05,
      "loss": 0.0003,
      "step": 21050
    },
    {
      "epoch": 1.013886886742588,
      "grad_norm": 0.2307000309228897,
      "learning_rate": 4.4930805823843164e-05,
      "loss": 0.0003,
      "step": 21100
    },
    {
      "epoch": 1.0162894623035894,
      "grad_norm": 0.26700901985168457,
      "learning_rate": 4.4918792946038155e-05,
      "loss": 0.0004,
      "step": 21150
    },
    {
      "epoch": 1.018692037864591,
      "grad_norm": 0.35909995436668396,
      "learning_rate": 4.490678006823315e-05,
      "loss": 0.0003,
      "step": 21200
    },
    {
      "epoch": 1.0210946134255923,
      "grad_norm": 0.17944617569446564,
      "learning_rate": 4.489476719042814e-05,
      "loss": 0.0003,
      "step": 21250
    },
    {
      "epoch": 1.0234971889865936,
      "grad_norm": 0.12093477696180344,
      "learning_rate": 4.4882754312623134e-05,
      "loss": 0.0003,
      "step": 21300
    },
    {
      "epoch": 1.0258997645475951,
      "grad_norm": 0.079491525888443,
      "learning_rate": 4.4870741434818125e-05,
      "loss": 0.0012,
      "step": 21350
    },
    {
      "epoch": 1.0283023401085964,
      "grad_norm": 0.12363824993371964,
      "learning_rate": 4.4858728557013116e-05,
      "loss": 0.0003,
      "step": 21400
    },
    {
      "epoch": 1.0307049156695978,
      "grad_norm": 0.31926068663597107,
      "learning_rate": 4.4846715679208114e-05,
      "loss": 0.0003,
      "step": 21450
    },
    {
      "epoch": 1.0331074912305993,
      "grad_norm": 0.3591650128364563,
      "learning_rate": 4.4834702801403105e-05,
      "loss": 0.0003,
      "step": 21500
    },
    {
      "epoch": 1.0355100667916006,
      "grad_norm": 0.0957217663526535,
      "learning_rate": 4.48226899235981e-05,
      "loss": 0.0003,
      "step": 21550
    },
    {
      "epoch": 1.037912642352602,
      "grad_norm": 0.0872880145907402,
      "learning_rate": 4.481067704579309e-05,
      "loss": 0.0002,
      "step": 21600
    },
    {
      "epoch": 1.0403152179136035,
      "grad_norm": 0.1203431710600853,
      "learning_rate": 4.4798664167988084e-05,
      "loss": 0.0002,
      "step": 21650
    },
    {
      "epoch": 1.0427177934746048,
      "grad_norm": 0.22692811489105225,
      "learning_rate": 4.478665129018308e-05,
      "loss": 0.0009,
      "step": 21700
    },
    {
      "epoch": 1.0451203690356061,
      "grad_norm": 0.1329628825187683,
      "learning_rate": 4.477463841237807e-05,
      "loss": 0.0003,
      "step": 21750
    },
    {
      "epoch": 1.0475229445966077,
      "grad_norm": 0.15191657841205597,
      "learning_rate": 4.476262553457306e-05,
      "loss": 0.0003,
      "step": 21800
    },
    {
      "epoch": 1.049925520157609,
      "grad_norm": 0.48838281631469727,
      "learning_rate": 4.475061265676806e-05,
      "loss": 0.0003,
      "step": 21850
    },
    {
      "epoch": 1.0523280957186103,
      "grad_norm": 0.08528462797403336,
      "learning_rate": 4.473859977896305e-05,
      "loss": 0.0003,
      "step": 21900
    },
    {
      "epoch": 1.0547306712796118,
      "grad_norm": 0.2374875694513321,
      "learning_rate": 4.472658690115805e-05,
      "loss": 0.0004,
      "step": 21950
    },
    {
      "epoch": 1.0571332468406132,
      "grad_norm": 0.202311173081398,
      "learning_rate": 4.471457402335303e-05,
      "loss": 0.0003,
      "step": 22000
    },
    {
      "epoch": 1.0595358224016145,
      "grad_norm": 0.3355664610862732,
      "learning_rate": 4.470256114554803e-05,
      "loss": 0.0003,
      "step": 22050
    },
    {
      "epoch": 1.061938397962616,
      "grad_norm": 0.15233872830867767,
      "learning_rate": 4.469054826774302e-05,
      "loss": 0.0004,
      "step": 22100
    },
    {
      "epoch": 1.0643409735236173,
      "grad_norm": 0.11062321811914444,
      "learning_rate": 4.467853538993801e-05,
      "loss": 0.0004,
      "step": 22150
    },
    {
      "epoch": 1.0667435490846187,
      "grad_norm": 0.2863272428512573,
      "learning_rate": 4.466652251213301e-05,
      "loss": 0.0011,
      "step": 22200
    },
    {
      "epoch": 1.0691461246456202,
      "grad_norm": 0.2571388781070709,
      "learning_rate": 4.4654509634328e-05,
      "loss": 0.0004,
      "step": 22250
    },
    {
      "epoch": 1.0715487002066215,
      "grad_norm": 0.45789670944213867,
      "learning_rate": 4.464249675652299e-05,
      "loss": 0.0003,
      "step": 22300
    },
    {
      "epoch": 1.0739512757676228,
      "grad_norm": 0.12971360981464386,
      "learning_rate": 4.463048387871799e-05,
      "loss": 0.0003,
      "step": 22350
    },
    {
      "epoch": 1.0763538513286244,
      "grad_norm": 0.3247299790382385,
      "learning_rate": 4.461847100091298e-05,
      "loss": 0.0003,
      "step": 22400
    },
    {
      "epoch": 1.0787564268896257,
      "grad_norm": 0.16840961575508118,
      "learning_rate": 4.460645812310798e-05,
      "loss": 0.0003,
      "step": 22450
    },
    {
      "epoch": 1.081159002450627,
      "grad_norm": 0.5311122536659241,
      "learning_rate": 4.459444524530297e-05,
      "loss": 0.0003,
      "step": 22500
    },
    {
      "epoch": 1.0835615780116286,
      "grad_norm": 0.5571647882461548,
      "learning_rate": 4.458243236749796e-05,
      "loss": 0.0003,
      "step": 22550
    },
    {
      "epoch": 1.0859641535726299,
      "grad_norm": 0.0769767314195633,
      "learning_rate": 4.457041948969296e-05,
      "loss": 0.0002,
      "step": 22600
    },
    {
      "epoch": 1.0883667291336312,
      "grad_norm": 0.14870405197143555,
      "learning_rate": 4.455840661188795e-05,
      "loss": 0.0003,
      "step": 22650
    },
    {
      "epoch": 1.0907693046946327,
      "grad_norm": 0.3221113085746765,
      "learning_rate": 4.454639373408294e-05,
      "loss": 0.0003,
      "step": 22700
    },
    {
      "epoch": 1.093171880255634,
      "grad_norm": 0.36296015977859497,
      "learning_rate": 4.453438085627793e-05,
      "loss": 0.0003,
      "step": 22750
    },
    {
      "epoch": 1.0955744558166354,
      "grad_norm": 0.12143855541944504,
      "learning_rate": 4.452236797847292e-05,
      "loss": 0.0003,
      "step": 22800
    },
    {
      "epoch": 1.097977031377637,
      "grad_norm": 0.07128897309303284,
      "learning_rate": 4.451035510066792e-05,
      "loss": 0.0009,
      "step": 22850
    },
    {
      "epoch": 1.1003796069386382,
      "grad_norm": 0.31282347440719604,
      "learning_rate": 4.449834222286291e-05,
      "loss": 0.0008,
      "step": 22900
    },
    {
      "epoch": 1.1027821824996396,
      "grad_norm": 0.17998380959033966,
      "learning_rate": 4.4486329345057906e-05,
      "loss": 0.0003,
      "step": 22950
    },
    {
      "epoch": 1.105184758060641,
      "grad_norm": 0.07765867561101913,
      "learning_rate": 4.44743164672529e-05,
      "loss": 0.0003,
      "step": 23000
    },
    {
      "epoch": 1.1075873336216424,
      "grad_norm": 0.22407381236553192,
      "learning_rate": 4.446230358944789e-05,
      "loss": 0.0003,
      "step": 23050
    },
    {
      "epoch": 1.1099899091826437,
      "grad_norm": 0.17516519129276276,
      "learning_rate": 4.4450290711642885e-05,
      "loss": 0.0005,
      "step": 23100
    },
    {
      "epoch": 1.1123924847436453,
      "grad_norm": 0.3645484745502472,
      "learning_rate": 4.4438277833837876e-05,
      "loss": 0.0003,
      "step": 23150
    },
    {
      "epoch": 1.1147950603046466,
      "grad_norm": 0.1095147654414177,
      "learning_rate": 4.442626495603287e-05,
      "loss": 0.0003,
      "step": 23200
    },
    {
      "epoch": 1.117197635865648,
      "grad_norm": 0.2715730369091034,
      "learning_rate": 4.4414252078227865e-05,
      "loss": 0.0003,
      "step": 23250
    },
    {
      "epoch": 1.1196002114266494,
      "grad_norm": 0.3865211606025696,
      "learning_rate": 4.4402239200422856e-05,
      "loss": 0.0003,
      "step": 23300
    },
    {
      "epoch": 1.1220027869876508,
      "grad_norm": 0.3780287504196167,
      "learning_rate": 4.439022632261785e-05,
      "loss": 0.0003,
      "step": 23350
    },
    {
      "epoch": 1.124405362548652,
      "grad_norm": 0.6599106192588806,
      "learning_rate": 4.4378213444812844e-05,
      "loss": 0.0002,
      "step": 23400
    },
    {
      "epoch": 1.1268079381096536,
      "grad_norm": 0.4608757495880127,
      "learning_rate": 4.4366200567007835e-05,
      "loss": 0.0004,
      "step": 23450
    },
    {
      "epoch": 1.129210513670655,
      "grad_norm": 0.6796547770500183,
      "learning_rate": 4.4354187689202826e-05,
      "loss": 0.0003,
      "step": 23500
    },
    {
      "epoch": 1.1316130892316563,
      "grad_norm": 0.15828557312488556,
      "learning_rate": 4.4342174811397816e-05,
      "loss": 0.0003,
      "step": 23550
    },
    {
      "epoch": 1.1340156647926578,
      "grad_norm": 0.17193712294101715,
      "learning_rate": 4.4330161933592814e-05,
      "loss": 0.0003,
      "step": 23600
    },
    {
      "epoch": 1.1364182403536591,
      "grad_norm": 0.6673498749732971,
      "learning_rate": 4.4318149055787805e-05,
      "loss": 0.0003,
      "step": 23650
    },
    {
      "epoch": 1.1388208159146604,
      "grad_norm": 0.23551031947135925,
      "learning_rate": 4.4306136177982796e-05,
      "loss": 0.0003,
      "step": 23700
    },
    {
      "epoch": 1.141223391475662,
      "grad_norm": 0.24611663818359375,
      "learning_rate": 4.429412330017779e-05,
      "loss": 0.0003,
      "step": 23750
    },
    {
      "epoch": 1.1436259670366633,
      "grad_norm": 0.352804958820343,
      "learning_rate": 4.4282110422372784e-05,
      "loss": 0.0002,
      "step": 23800
    },
    {
      "epoch": 1.1460285425976646,
      "grad_norm": 0.28601786494255066,
      "learning_rate": 4.427009754456778e-05,
      "loss": 0.0003,
      "step": 23850
    },
    {
      "epoch": 1.1484311181586662,
      "grad_norm": 0.10640526562929153,
      "learning_rate": 4.425808466676277e-05,
      "loss": 0.0003,
      "step": 23900
    },
    {
      "epoch": 1.1508336937196675,
      "grad_norm": 0.3688700497150421,
      "learning_rate": 4.424607178895776e-05,
      "loss": 0.0003,
      "step": 23950
    },
    {
      "epoch": 1.1532362692806688,
      "grad_norm": 0.4131123721599579,
      "learning_rate": 4.423405891115276e-05,
      "loss": 0.0003,
      "step": 24000
    },
    {
      "epoch": 1.1556388448416703,
      "grad_norm": 0.1396731287240982,
      "learning_rate": 4.422204603334775e-05,
      "loss": 0.0004,
      "step": 24050
    },
    {
      "epoch": 1.1580414204026717,
      "grad_norm": 0.4073904752731323,
      "learning_rate": 4.421003315554275e-05,
      "loss": 0.0004,
      "step": 24100
    },
    {
      "epoch": 1.160443995963673,
      "grad_norm": 0.3621229827404022,
      "learning_rate": 4.419802027773774e-05,
      "loss": 0.0003,
      "step": 24150
    },
    {
      "epoch": 1.1628465715246745,
      "grad_norm": 0.6947054862976074,
      "learning_rate": 4.4186007399932724e-05,
      "loss": 0.0004,
      "step": 24200
    },
    {
      "epoch": 1.1652491470856758,
      "grad_norm": 0.09939543902873993,
      "learning_rate": 4.417399452212772e-05,
      "loss": 0.0004,
      "step": 24250
    },
    {
      "epoch": 1.1676517226466772,
      "grad_norm": 0.09223843365907669,
      "learning_rate": 4.416198164432271e-05,
      "loss": 0.0004,
      "step": 24300
    },
    {
      "epoch": 1.1700542982076787,
      "grad_norm": 0.12157754600048065,
      "learning_rate": 4.414996876651771e-05,
      "loss": 0.0003,
      "step": 24350
    },
    {
      "epoch": 1.17245687376868,
      "grad_norm": 0.3942124545574188,
      "learning_rate": 4.41379558887127e-05,
      "loss": 0.0003,
      "step": 24400
    },
    {
      "epoch": 1.1748594493296813,
      "grad_norm": 0.7143355011940002,
      "learning_rate": 4.412594301090769e-05,
      "loss": 0.0003,
      "step": 24450
    },
    {
      "epoch": 1.1772620248906829,
      "grad_norm": 0.18803715705871582,
      "learning_rate": 4.411393013310269e-05,
      "loss": 0.0004,
      "step": 24500
    },
    {
      "epoch": 1.1796646004516842,
      "grad_norm": 0.10409154742956161,
      "learning_rate": 4.410191725529768e-05,
      "loss": 0.0002,
      "step": 24550
    },
    {
      "epoch": 1.1820671760126855,
      "grad_norm": 0.1990359127521515,
      "learning_rate": 4.408990437749267e-05,
      "loss": 0.0003,
      "step": 24600
    },
    {
      "epoch": 1.184469751573687,
      "grad_norm": 0.23324742913246155,
      "learning_rate": 4.407789149968767e-05,
      "loss": 0.0002,
      "step": 24650
    },
    {
      "epoch": 1.1868723271346884,
      "grad_norm": 0.15401402115821838,
      "learning_rate": 4.406587862188266e-05,
      "loss": 0.0003,
      "step": 24700
    },
    {
      "epoch": 1.1892749026956897,
      "grad_norm": 0.05560014769434929,
      "learning_rate": 4.405386574407766e-05,
      "loss": 0.0002,
      "step": 24750
    },
    {
      "epoch": 1.1916774782566912,
      "grad_norm": 0.13294441998004913,
      "learning_rate": 4.404185286627265e-05,
      "loss": 0.0011,
      "step": 24800
    },
    {
      "epoch": 1.1940800538176926,
      "grad_norm": 0.258311003446579,
      "learning_rate": 4.402983998846764e-05,
      "loss": 0.0003,
      "step": 24850
    },
    {
      "epoch": 1.1964826293786939,
      "grad_norm": 0.020678305998444557,
      "learning_rate": 4.4017827110662636e-05,
      "loss": 0.0002,
      "step": 24900
    },
    {
      "epoch": 1.1988852049396954,
      "grad_norm": 0.2109004706144333,
      "learning_rate": 4.400581423285762e-05,
      "loss": 0.0003,
      "step": 24950
    },
    {
      "epoch": 1.2012877805006967,
      "grad_norm": 0.06731533259153366,
      "learning_rate": 4.399380135505262e-05,
      "loss": 0.0002,
      "step": 25000
    },
    {
      "epoch": 1.203690356061698,
      "grad_norm": 0.35365182161331177,
      "learning_rate": 4.398178847724761e-05,
      "loss": 0.0003,
      "step": 25050
    },
    {
      "epoch": 1.2060929316226996,
      "grad_norm": 0.28061920404434204,
      "learning_rate": 4.39697755994426e-05,
      "loss": 0.0003,
      "step": 25100
    },
    {
      "epoch": 1.208495507183701,
      "grad_norm": 0.15934857726097107,
      "learning_rate": 4.39577627216376e-05,
      "loss": 0.0003,
      "step": 25150
    },
    {
      "epoch": 1.2108980827447022,
      "grad_norm": 0.5153653025627136,
      "learning_rate": 4.394574984383259e-05,
      "loss": 0.0003,
      "step": 25200
    },
    {
      "epoch": 1.2133006583057038,
      "grad_norm": 0.4997602105140686,
      "learning_rate": 4.3933736966027586e-05,
      "loss": 0.0004,
      "step": 25250
    },
    {
      "epoch": 1.215703233866705,
      "grad_norm": 0.4485347867012024,
      "learning_rate": 4.392172408822258e-05,
      "loss": 0.0002,
      "step": 25300
    },
    {
      "epoch": 1.2181058094277064,
      "grad_norm": 0.042900241911411285,
      "learning_rate": 4.390971121041757e-05,
      "loss": 0.0003,
      "step": 25350
    },
    {
      "epoch": 1.220508384988708,
      "grad_norm": 0.1291651874780655,
      "learning_rate": 4.3897698332612565e-05,
      "loss": 0.0003,
      "step": 25400
    },
    {
      "epoch": 1.2229109605497093,
      "grad_norm": 0.05098560452461243,
      "learning_rate": 4.3885685454807556e-05,
      "loss": 0.0003,
      "step": 25450
    },
    {
      "epoch": 1.2253135361107106,
      "grad_norm": 0.12895916402339935,
      "learning_rate": 4.3873672577002553e-05,
      "loss": 0.0003,
      "step": 25500
    },
    {
      "epoch": 1.2277161116717121,
      "grad_norm": 0.2929970920085907,
      "learning_rate": 4.3861659699197544e-05,
      "loss": 0.0003,
      "step": 25550
    },
    {
      "epoch": 1.2301186872327134,
      "grad_norm": 0.2863927483558655,
      "learning_rate": 4.3849646821392535e-05,
      "loss": 0.0002,
      "step": 25600
    },
    {
      "epoch": 1.2325212627937148,
      "grad_norm": 0.2197290062904358,
      "learning_rate": 4.383763394358753e-05,
      "loss": 0.0003,
      "step": 25650
    },
    {
      "epoch": 1.2349238383547163,
      "grad_norm": 0.28091171383857727,
      "learning_rate": 4.382562106578252e-05,
      "loss": 0.0002,
      "step": 25700
    },
    {
      "epoch": 1.2373264139157176,
      "grad_norm": 0.4872288703918457,
      "learning_rate": 4.3813608187977514e-05,
      "loss": 0.0003,
      "step": 25750
    },
    {
      "epoch": 1.2397289894767192,
      "grad_norm": 0.27439084649086,
      "learning_rate": 4.3801595310172505e-05,
      "loss": 0.0011,
      "step": 25800
    },
    {
      "epoch": 1.2421315650377205,
      "grad_norm": 0.6422477960586548,
      "learning_rate": 4.3789582432367496e-05,
      "loss": 0.0003,
      "step": 25850
    },
    {
      "epoch": 1.2445341405987218,
      "grad_norm": 0.22489289939403534,
      "learning_rate": 4.3777569554562494e-05,
      "loss": 0.0003,
      "step": 25900
    },
    {
      "epoch": 1.2469367161597233,
      "grad_norm": 0.1251702904701233,
      "learning_rate": 4.3765556676757484e-05,
      "loss": 0.0003,
      "step": 25950
    },
    {
      "epoch": 1.2493392917207247,
      "grad_norm": 0.4072878658771515,
      "learning_rate": 4.375354379895248e-05,
      "loss": 0.0004,
      "step": 26000
    },
    {
      "epoch": 1.251741867281726,
      "grad_norm": 0.027956075966358185,
      "learning_rate": 4.374153092114747e-05,
      "loss": 0.0003,
      "step": 26050
    },
    {
      "epoch": 1.2541444428427275,
      "grad_norm": 0.1008305549621582,
      "learning_rate": 4.3729518043342464e-05,
      "loss": 0.0003,
      "step": 26100
    },
    {
      "epoch": 1.2565470184037288,
      "grad_norm": 0.1109297052025795,
      "learning_rate": 4.371750516553746e-05,
      "loss": 0.0002,
      "step": 26150
    },
    {
      "epoch": 1.2589495939647302,
      "grad_norm": 0.14237098395824432,
      "learning_rate": 4.370549228773245e-05,
      "loss": 0.0002,
      "step": 26200
    },
    {
      "epoch": 1.2613521695257317,
      "grad_norm": 0.25022009015083313,
      "learning_rate": 4.369347940992744e-05,
      "loss": 0.0004,
      "step": 26250
    },
    {
      "epoch": 1.263754745086733,
      "grad_norm": 0.136672243475914,
      "learning_rate": 4.368146653212244e-05,
      "loss": 0.0002,
      "step": 26300
    },
    {
      "epoch": 1.2661573206477343,
      "grad_norm": 0.312778115272522,
      "learning_rate": 4.366945365431743e-05,
      "loss": 0.0002,
      "step": 26350
    },
    {
      "epoch": 1.2685598962087359,
      "grad_norm": 0.193180114030838,
      "learning_rate": 4.365744077651243e-05,
      "loss": 0.0002,
      "step": 26400
    },
    {
      "epoch": 1.2709624717697372,
      "grad_norm": 0.32164138555526733,
      "learning_rate": 4.364542789870741e-05,
      "loss": 0.0009,
      "step": 26450
    },
    {
      "epoch": 1.2733650473307385,
      "grad_norm": 0.17367814481258392,
      "learning_rate": 4.363341502090241e-05,
      "loss": 0.0003,
      "step": 26500
    },
    {
      "epoch": 1.27576762289174,
      "grad_norm": 0.4912625849246979,
      "learning_rate": 4.36214021430974e-05,
      "loss": 0.0004,
      "step": 26550
    },
    {
      "epoch": 1.2781701984527414,
      "grad_norm": 0.2932721674442291,
      "learning_rate": 4.360938926529239e-05,
      "loss": 0.0011,
      "step": 26600
    },
    {
      "epoch": 1.2805727740137427,
      "grad_norm": 0.4112415015697479,
      "learning_rate": 4.359737638748739e-05,
      "loss": 0.0003,
      "step": 26650
    },
    {
      "epoch": 1.2829753495747442,
      "grad_norm": 0.14050064980983734,
      "learning_rate": 4.358536350968238e-05,
      "loss": 0.0003,
      "step": 26700
    },
    {
      "epoch": 1.2853779251357456,
      "grad_norm": 0.13076865673065186,
      "learning_rate": 4.357335063187737e-05,
      "loss": 0.0002,
      "step": 26750
    },
    {
      "epoch": 1.2877805006967469,
      "grad_norm": 0.3863157033920288,
      "learning_rate": 4.356133775407237e-05,
      "loss": 0.0003,
      "step": 26800
    },
    {
      "epoch": 1.2901830762577484,
      "grad_norm": 0.10283765196800232,
      "learning_rate": 4.354932487626736e-05,
      "loss": 0.0003,
      "step": 26850
    },
    {
      "epoch": 1.2925856518187497,
      "grad_norm": 0.5531706213951111,
      "learning_rate": 4.353731199846236e-05,
      "loss": 0.0002,
      "step": 26900
    },
    {
      "epoch": 1.294988227379751,
      "grad_norm": 0.42569270730018616,
      "learning_rate": 4.352529912065735e-05,
      "loss": 0.0003,
      "step": 26950
    },
    {
      "epoch": 1.2973908029407526,
      "grad_norm": 0.09438596665859222,
      "learning_rate": 4.351328624285234e-05,
      "loss": 0.0003,
      "step": 27000
    },
    {
      "epoch": 1.299793378501754,
      "grad_norm": 0.18713833391666412,
      "learning_rate": 4.350127336504734e-05,
      "loss": 0.0002,
      "step": 27050
    },
    {
      "epoch": 1.3021959540627552,
      "grad_norm": 0.3687051236629486,
      "learning_rate": 4.348926048724233e-05,
      "loss": 0.0002,
      "step": 27100
    },
    {
      "epoch": 1.3045985296237568,
      "grad_norm": 0.10703268647193909,
      "learning_rate": 4.347724760943732e-05,
      "loss": 0.0004,
      "step": 27150
    },
    {
      "epoch": 1.307001105184758,
      "grad_norm": 0.42423561215400696,
      "learning_rate": 4.346523473163231e-05,
      "loss": 0.0003,
      "step": 27200
    },
    {
      "epoch": 1.3094036807457594,
      "grad_norm": 0.22656740248203278,
      "learning_rate": 4.34532218538273e-05,
      "loss": 0.0008,
      "step": 27250
    },
    {
      "epoch": 1.311806256306761,
      "grad_norm": 0.020967671647667885,
      "learning_rate": 4.34412089760223e-05,
      "loss": 0.0003,
      "step": 27300
    },
    {
      "epoch": 1.3142088318677623,
      "grad_norm": 0.39437320828437805,
      "learning_rate": 4.342919609821729e-05,
      "loss": 0.0003,
      "step": 27350
    },
    {
      "epoch": 1.3166114074287636,
      "grad_norm": 0.1322442889213562,
      "learning_rate": 4.3417183220412286e-05,
      "loss": 0.0003,
      "step": 27400
    },
    {
      "epoch": 1.3190139829897651,
      "grad_norm": 0.4006117284297943,
      "learning_rate": 4.340517034260728e-05,
      "loss": 0.0002,
      "step": 27450
    },
    {
      "epoch": 1.3214165585507665,
      "grad_norm": 0.30510345101356506,
      "learning_rate": 4.339315746480227e-05,
      "loss": 0.0002,
      "step": 27500
    },
    {
      "epoch": 1.3238191341117678,
      "grad_norm": 0.13772886991500854,
      "learning_rate": 4.3381144586997265e-05,
      "loss": 0.0012,
      "step": 27550
    },
    {
      "epoch": 1.3262217096727693,
      "grad_norm": 0.2053641676902771,
      "learning_rate": 4.3369131709192256e-05,
      "loss": 0.0002,
      "step": 27600
    },
    {
      "epoch": 1.3286242852337706,
      "grad_norm": 0.12360665947198868,
      "learning_rate": 4.335711883138725e-05,
      "loss": 0.0003,
      "step": 27650
    },
    {
      "epoch": 1.331026860794772,
      "grad_norm": 0.671349287033081,
      "learning_rate": 4.3345105953582245e-05,
      "loss": 0.0004,
      "step": 27700
    },
    {
      "epoch": 1.3334294363557735,
      "grad_norm": 0.1665024608373642,
      "learning_rate": 4.3333093075777235e-05,
      "loss": 0.0002,
      "step": 27750
    },
    {
      "epoch": 1.3358320119167748,
      "grad_norm": 0.14817515015602112,
      "learning_rate": 4.332108019797223e-05,
      "loss": 0.0003,
      "step": 27800
    },
    {
      "epoch": 1.3382345874777761,
      "grad_norm": 0.2649812400341034,
      "learning_rate": 4.3309067320167224e-05,
      "loss": 0.0002,
      "step": 27850
    },
    {
      "epoch": 1.3406371630387777,
      "grad_norm": 0.6536568999290466,
      "learning_rate": 4.3297054442362215e-05,
      "loss": 0.0003,
      "step": 27900
    },
    {
      "epoch": 1.343039738599779,
      "grad_norm": 0.259566992521286,
      "learning_rate": 4.3285041564557206e-05,
      "loss": 0.0002,
      "step": 27950
    },
    {
      "epoch": 1.3454423141607803,
      "grad_norm": 0.36451101303100586,
      "learning_rate": 4.3273028686752196e-05,
      "loss": 0.0002,
      "step": 28000
    },
    {
      "epoch": 1.3478448897217818,
      "grad_norm": 0.44514942169189453,
      "learning_rate": 4.3261015808947194e-05,
      "loss": 0.0004,
      "step": 28050
    },
    {
      "epoch": 1.3502474652827832,
      "grad_norm": 0.3766389489173889,
      "learning_rate": 4.3249002931142185e-05,
      "loss": 0.0004,
      "step": 28100
    },
    {
      "epoch": 1.3526500408437845,
      "grad_norm": 0.6705604791641235,
      "learning_rate": 4.3236990053337176e-05,
      "loss": 0.0004,
      "step": 28150
    },
    {
      "epoch": 1.355052616404786,
      "grad_norm": 0.26290997862815857,
      "learning_rate": 4.322497717553217e-05,
      "loss": 0.0011,
      "step": 28200
    },
    {
      "epoch": 1.3574551919657873,
      "grad_norm": 0.05913998931646347,
      "learning_rate": 4.3212964297727164e-05,
      "loss": 0.0003,
      "step": 28250
    },
    {
      "epoch": 1.3598577675267887,
      "grad_norm": 0.12936779856681824,
      "learning_rate": 4.320095141992216e-05,
      "loss": 0.0002,
      "step": 28300
    },
    {
      "epoch": 1.3622603430877902,
      "grad_norm": 0.147806316614151,
      "learning_rate": 4.318893854211715e-05,
      "loss": 0.0003,
      "step": 28350
    },
    {
      "epoch": 1.3646629186487915,
      "grad_norm": 0.09659397602081299,
      "learning_rate": 4.317692566431214e-05,
      "loss": 0.0003,
      "step": 28400
    },
    {
      "epoch": 1.3670654942097928,
      "grad_norm": 0.5055715441703796,
      "learning_rate": 4.316491278650714e-05,
      "loss": 0.0003,
      "step": 28450
    },
    {
      "epoch": 1.3694680697707944,
      "grad_norm": 0.11249908804893494,
      "learning_rate": 4.315289990870213e-05,
      "loss": 0.0011,
      "step": 28500
    },
    {
      "epoch": 1.3718706453317957,
      "grad_norm": 0.3577115833759308,
      "learning_rate": 4.314088703089712e-05,
      "loss": 0.0003,
      "step": 28550
    },
    {
      "epoch": 1.374273220892797,
      "grad_norm": 0.3944738805294037,
      "learning_rate": 4.312887415309212e-05,
      "loss": 0.0002,
      "step": 28600
    },
    {
      "epoch": 1.3766757964537986,
      "grad_norm": 0.32820621132850647,
      "learning_rate": 4.311686127528711e-05,
      "loss": 0.0009,
      "step": 28650
    },
    {
      "epoch": 1.3790783720147999,
      "grad_norm": 0.15769371390342712,
      "learning_rate": 4.31048483974821e-05,
      "loss": 0.0002,
      "step": 28700
    },
    {
      "epoch": 1.3814809475758012,
      "grad_norm": 0.14553388953208923,
      "learning_rate": 4.309283551967709e-05,
      "loss": 0.0002,
      "step": 28750
    },
    {
      "epoch": 1.3838835231368027,
      "grad_norm": 0.24018177390098572,
      "learning_rate": 4.308082264187209e-05,
      "loss": 0.0003,
      "step": 28800
    },
    {
      "epoch": 1.386286098697804,
      "grad_norm": 0.6289222836494446,
      "learning_rate": 4.306880976406708e-05,
      "loss": 0.0002,
      "step": 28850
    },
    {
      "epoch": 1.3886886742588054,
      "grad_norm": 0.0757250115275383,
      "learning_rate": 4.305679688626207e-05,
      "loss": 0.0003,
      "step": 28900
    },
    {
      "epoch": 1.391091249819807,
      "grad_norm": 0.19267046451568604,
      "learning_rate": 4.304478400845707e-05,
      "loss": 0.0004,
      "step": 28950
    },
    {
      "epoch": 1.3934938253808082,
      "grad_norm": 0.2675946354866028,
      "learning_rate": 4.303277113065206e-05,
      "loss": 0.0003,
      "step": 29000
    },
    {
      "epoch": 1.3958964009418096,
      "grad_norm": 0.3821225166320801,
      "learning_rate": 4.302075825284705e-05,
      "loss": 0.0003,
      "step": 29050
    },
    {
      "epoch": 1.398298976502811,
      "grad_norm": 0.24901506304740906,
      "learning_rate": 4.300874537504205e-05,
      "loss": 0.0002,
      "step": 29100
    },
    {
      "epoch": 1.4007015520638124,
      "grad_norm": 0.14829489588737488,
      "learning_rate": 4.299673249723704e-05,
      "loss": 0.0004,
      "step": 29150
    },
    {
      "epoch": 1.4031041276248137,
      "grad_norm": 0.5581374764442444,
      "learning_rate": 4.298471961943204e-05,
      "loss": 0.0003,
      "step": 29200
    },
    {
      "epoch": 1.4055067031858153,
      "grad_norm": 0.09935115277767181,
      "learning_rate": 4.297270674162703e-05,
      "loss": 0.001,
      "step": 29250
    },
    {
      "epoch": 1.4079092787468166,
      "grad_norm": 0.09791012853384018,
      "learning_rate": 4.296069386382202e-05,
      "loss": 0.0003,
      "step": 29300
    },
    {
      "epoch": 1.410311854307818,
      "grad_norm": 0.20853610336780548,
      "learning_rate": 4.2948680986017016e-05,
      "loss": 0.0002,
      "step": 29350
    },
    {
      "epoch": 1.4127144298688195,
      "grad_norm": 0.47356903553009033,
      "learning_rate": 4.2936668108212e-05,
      "loss": 0.0003,
      "step": 29400
    },
    {
      "epoch": 1.4151170054298208,
      "grad_norm": 0.2710569202899933,
      "learning_rate": 4.2924655230407e-05,
      "loss": 0.0011,
      "step": 29450
    },
    {
      "epoch": 1.417519580990822,
      "grad_norm": 0.5395613312721252,
      "learning_rate": 4.291264235260199e-05,
      "loss": 0.0003,
      "step": 29500
    },
    {
      "epoch": 1.4199221565518236,
      "grad_norm": 0.10278619080781937,
      "learning_rate": 4.290062947479698e-05,
      "loss": 0.001,
      "step": 29550
    },
    {
      "epoch": 1.422324732112825,
      "grad_norm": 0.23190857470035553,
      "learning_rate": 4.288861659699198e-05,
      "loss": 0.0002,
      "step": 29600
    },
    {
      "epoch": 1.4247273076738263,
      "grad_norm": 0.12419898808002472,
      "learning_rate": 4.287660371918697e-05,
      "loss": 0.0002,
      "step": 29650
    },
    {
      "epoch": 1.4271298832348278,
      "grad_norm": 0.30911585688591003,
      "learning_rate": 4.2864590841381966e-05,
      "loss": 0.0003,
      "step": 29700
    },
    {
      "epoch": 1.4295324587958291,
      "grad_norm": 0.07115300744771957,
      "learning_rate": 4.2852577963576957e-05,
      "loss": 0.0002,
      "step": 29750
    },
    {
      "epoch": 1.4319350343568304,
      "grad_norm": 0.5491831302642822,
      "learning_rate": 4.284056508577195e-05,
      "loss": 0.0002,
      "step": 29800
    },
    {
      "epoch": 1.434337609917832,
      "grad_norm": 0.18900063633918762,
      "learning_rate": 4.2828552207966945e-05,
      "loss": 0.0003,
      "step": 29850
    },
    {
      "epoch": 1.4367401854788333,
      "grad_norm": 0.15734277665615082,
      "learning_rate": 4.2816539330161936e-05,
      "loss": 0.0011,
      "step": 29900
    },
    {
      "epoch": 1.4391427610398346,
      "grad_norm": 0.3917519450187683,
      "learning_rate": 4.280452645235693e-05,
      "loss": 0.0004,
      "step": 29950
    },
    {
      "epoch": 1.4415453366008362,
      "grad_norm": 0.23969443142414093,
      "learning_rate": 4.2792513574551924e-05,
      "loss": 0.0004,
      "step": 30000
    },
    {
      "epoch": 1.4439479121618375,
      "grad_norm": 0.4724505841732025,
      "learning_rate": 4.2780500696746915e-05,
      "loss": 0.0008,
      "step": 30050
    },
    {
      "epoch": 1.4463504877228388,
      "grad_norm": 0.24086540937423706,
      "learning_rate": 4.276848781894191e-05,
      "loss": 0.0002,
      "step": 30100
    },
    {
      "epoch": 1.4487530632838403,
      "grad_norm": 0.20236583054065704,
      "learning_rate": 4.27564749411369e-05,
      "loss": 0.0003,
      "step": 30150
    },
    {
      "epoch": 1.4511556388448417,
      "grad_norm": 0.15934626758098602,
      "learning_rate": 4.2744462063331894e-05,
      "loss": 0.0003,
      "step": 30200
    },
    {
      "epoch": 1.453558214405843,
      "grad_norm": 0.17820481956005096,
      "learning_rate": 4.2732449185526885e-05,
      "loss": 0.0002,
      "step": 30250
    },
    {
      "epoch": 1.4559607899668445,
      "grad_norm": 0.32865217328071594,
      "learning_rate": 4.2720436307721876e-05,
      "loss": 0.0003,
      "step": 30300
    },
    {
      "epoch": 1.4583633655278458,
      "grad_norm": 0.4133210778236389,
      "learning_rate": 4.2708423429916874e-05,
      "loss": 0.0002,
      "step": 30350
    },
    {
      "epoch": 1.4607659410888472,
      "grad_norm": 0.19267451763153076,
      "learning_rate": 4.2696410552111864e-05,
      "loss": 0.0003,
      "step": 30400
    },
    {
      "epoch": 1.4631685166498487,
      "grad_norm": 0.45269522070884705,
      "learning_rate": 4.2684397674306855e-05,
      "loss": 0.0004,
      "step": 30450
    },
    {
      "epoch": 1.46557109221085,
      "grad_norm": 0.10568511486053467,
      "learning_rate": 4.267238479650185e-05,
      "loss": 0.0003,
      "step": 30500
    },
    {
      "epoch": 1.4679736677718513,
      "grad_norm": 0.19197295606136322,
      "learning_rate": 4.2660371918696844e-05,
      "loss": 0.0007,
      "step": 30550
    },
    {
      "epoch": 1.4703762433328529,
      "grad_norm": 0.14172814786434174,
      "learning_rate": 4.264835904089184e-05,
      "loss": 0.0002,
      "step": 30600
    },
    {
      "epoch": 1.4727788188938542,
      "grad_norm": 0.5767807960510254,
      "learning_rate": 4.263634616308683e-05,
      "loss": 0.0003,
      "step": 30650
    },
    {
      "epoch": 1.4751813944548555,
      "grad_norm": 0.5851039290428162,
      "learning_rate": 4.262433328528182e-05,
      "loss": 0.0002,
      "step": 30700
    },
    {
      "epoch": 1.477583970015857,
      "grad_norm": 0.12246149033308029,
      "learning_rate": 4.261232040747682e-05,
      "loss": 0.0003,
      "step": 30750
    },
    {
      "epoch": 1.4799865455768584,
      "grad_norm": 0.4345550239086151,
      "learning_rate": 4.260030752967181e-05,
      "loss": 0.0003,
      "step": 30800
    },
    {
      "epoch": 1.4823891211378597,
      "grad_norm": 0.3031659424304962,
      "learning_rate": 4.258829465186681e-05,
      "loss": 0.0003,
      "step": 30850
    },
    {
      "epoch": 1.4847916966988612,
      "grad_norm": 0.12642189860343933,
      "learning_rate": 4.257628177406179e-05,
      "loss": 0.0003,
      "step": 30900
    },
    {
      "epoch": 1.4871942722598626,
      "grad_norm": 0.15752844512462616,
      "learning_rate": 4.2564268896256784e-05,
      "loss": 0.0003,
      "step": 30950
    },
    {
      "epoch": 1.4895968478208639,
      "grad_norm": 0.8610702753067017,
      "learning_rate": 4.255225601845178e-05,
      "loss": 0.0003,
      "step": 31000
    },
    {
      "epoch": 1.4919994233818654,
      "grad_norm": 0.44568827748298645,
      "learning_rate": 4.254024314064677e-05,
      "loss": 0.0002,
      "step": 31050
    },
    {
      "epoch": 1.4944019989428667,
      "grad_norm": 0.504980742931366,
      "learning_rate": 4.252823026284177e-05,
      "loss": 0.0003,
      "step": 31100
    },
    {
      "epoch": 1.496804574503868,
      "grad_norm": 0.2573852241039276,
      "learning_rate": 4.251621738503676e-05,
      "loss": 0.0011,
      "step": 31150
    },
    {
      "epoch": 1.4992071500648696,
      "grad_norm": 0.27794596552848816,
      "learning_rate": 4.250420450723175e-05,
      "loss": 0.0002,
      "step": 31200
    },
    {
      "epoch": 1.501609725625871,
      "grad_norm": 0.037832267582416534,
      "learning_rate": 4.249219162942675e-05,
      "loss": 0.0003,
      "step": 31250
    },
    {
      "epoch": 1.5040123011868722,
      "grad_norm": 0.33286088705062866,
      "learning_rate": 4.248017875162174e-05,
      "loss": 0.0003,
      "step": 31300
    },
    {
      "epoch": 1.5064148767478738,
      "grad_norm": 0.09734633564949036,
      "learning_rate": 4.246816587381674e-05,
      "loss": 0.0002,
      "step": 31350
    },
    {
      "epoch": 1.508817452308875,
      "grad_norm": 0.08121754974126816,
      "learning_rate": 4.245615299601173e-05,
      "loss": 0.0002,
      "step": 31400
    },
    {
      "epoch": 1.5112200278698764,
      "grad_norm": 0.21642154455184937,
      "learning_rate": 4.244414011820672e-05,
      "loss": 0.0004,
      "step": 31450
    },
    {
      "epoch": 1.513622603430878,
      "grad_norm": 0.6522790789604187,
      "learning_rate": 4.243212724040172e-05,
      "loss": 0.001,
      "step": 31500
    },
    {
      "epoch": 1.5160251789918793,
      "grad_norm": 0.05113121494650841,
      "learning_rate": 4.242011436259671e-05,
      "loss": 0.0002,
      "step": 31550
    },
    {
      "epoch": 1.5184277545528806,
      "grad_norm": 0.2454591691493988,
      "learning_rate": 4.24081014847917e-05,
      "loss": 0.0002,
      "step": 31600
    },
    {
      "epoch": 1.5208303301138821,
      "grad_norm": 0.08910764753818512,
      "learning_rate": 4.239608860698669e-05,
      "loss": 0.0002,
      "step": 31650
    },
    {
      "epoch": 1.5232329056748835,
      "grad_norm": 0.4590721130371094,
      "learning_rate": 4.238407572918168e-05,
      "loss": 0.0003,
      "step": 31700
    },
    {
      "epoch": 1.5256354812358848,
      "grad_norm": 0.1568186730146408,
      "learning_rate": 4.237206285137668e-05,
      "loss": 0.0002,
      "step": 31750
    },
    {
      "epoch": 1.5280380567968863,
      "grad_norm": 0.13060863316059113,
      "learning_rate": 4.236004997357167e-05,
      "loss": 0.0003,
      "step": 31800
    },
    {
      "epoch": 1.5304406323578876,
      "grad_norm": 0.47091224789619446,
      "learning_rate": 4.2348037095766666e-05,
      "loss": 0.0002,
      "step": 31850
    },
    {
      "epoch": 1.532843207918889,
      "grad_norm": 0.13816192746162415,
      "learning_rate": 4.233602421796166e-05,
      "loss": 0.0003,
      "step": 31900
    },
    {
      "epoch": 1.5352457834798905,
      "grad_norm": 0.2621389329433441,
      "learning_rate": 4.232401134015665e-05,
      "loss": 0.0002,
      "step": 31950
    },
    {
      "epoch": 1.5376483590408918,
      "grad_norm": 0.19130779802799225,
      "learning_rate": 4.2311998462351645e-05,
      "loss": 0.0003,
      "step": 32000
    },
    {
      "epoch": 1.5400509346018931,
      "grad_norm": 0.9606940746307373,
      "learning_rate": 4.2299985584546636e-05,
      "loss": 0.0003,
      "step": 32050
    },
    {
      "epoch": 1.5424535101628947,
      "grad_norm": 0.06357505172491074,
      "learning_rate": 4.228797270674163e-05,
      "loss": 0.0002,
      "step": 32100
    },
    {
      "epoch": 1.544856085723896,
      "grad_norm": 0.10369432717561722,
      "learning_rate": 4.2275959828936625e-05,
      "loss": 0.0004,
      "step": 32150
    },
    {
      "epoch": 1.5472586612848973,
      "grad_norm": 0.2914813458919525,
      "learning_rate": 4.2263946951131615e-05,
      "loss": 0.0003,
      "step": 32200
    },
    {
      "epoch": 1.5496612368458988,
      "grad_norm": 0.15755809843540192,
      "learning_rate": 4.225193407332661e-05,
      "loss": 0.0002,
      "step": 32250
    },
    {
      "epoch": 1.5520638124069002,
      "grad_norm": 0.5451733469963074,
      "learning_rate": 4.2239921195521604e-05,
      "loss": 0.0003,
      "step": 32300
    },
    {
      "epoch": 1.5544663879679015,
      "grad_norm": 0.3793925940990448,
      "learning_rate": 4.2227908317716595e-05,
      "loss": 0.0003,
      "step": 32350
    },
    {
      "epoch": 1.556868963528903,
      "grad_norm": 0.30639103055000305,
      "learning_rate": 4.2215895439911586e-05,
      "loss": 0.0003,
      "step": 32400
    },
    {
      "epoch": 1.5592715390899043,
      "grad_norm": 0.3217355012893677,
      "learning_rate": 4.2203882562106576e-05,
      "loss": 0.0002,
      "step": 32450
    },
    {
      "epoch": 1.5616741146509057,
      "grad_norm": 0.15792211890220642,
      "learning_rate": 4.2191869684301574e-05,
      "loss": 0.0003,
      "step": 32500
    },
    {
      "epoch": 1.5640766902119072,
      "grad_norm": 0.11481926590204239,
      "learning_rate": 4.2179856806496565e-05,
      "loss": 0.0002,
      "step": 32550
    },
    {
      "epoch": 1.5664792657729085,
      "grad_norm": 0.11462369561195374,
      "learning_rate": 4.2167843928691556e-05,
      "loss": 0.0002,
      "step": 32600
    },
    {
      "epoch": 1.5688818413339098,
      "grad_norm": 0.4107135236263275,
      "learning_rate": 4.215583105088655e-05,
      "loss": 0.0003,
      "step": 32650
    },
    {
      "epoch": 1.5712844168949114,
      "grad_norm": 0.08250708132982254,
      "learning_rate": 4.2143818173081544e-05,
      "loss": 0.0002,
      "step": 32700
    },
    {
      "epoch": 1.5736869924559127,
      "grad_norm": 0.3693755269050598,
      "learning_rate": 4.213180529527654e-05,
      "loss": 0.0003,
      "step": 32750
    },
    {
      "epoch": 1.576089568016914,
      "grad_norm": 0.4356466233730316,
      "learning_rate": 4.211979241747153e-05,
      "loss": 0.0003,
      "step": 32800
    },
    {
      "epoch": 1.5784921435779156,
      "grad_norm": 0.1178211122751236,
      "learning_rate": 4.210777953966652e-05,
      "loss": 0.001,
      "step": 32850
    },
    {
      "epoch": 1.5808947191389169,
      "grad_norm": 0.12467298656702042,
      "learning_rate": 4.209576666186152e-05,
      "loss": 0.0002,
      "step": 32900
    },
    {
      "epoch": 1.5832972946999182,
      "grad_norm": 0.22230572998523712,
      "learning_rate": 4.208375378405651e-05,
      "loss": 0.0002,
      "step": 32950
    },
    {
      "epoch": 1.5856998702609197,
      "grad_norm": 0.31836703419685364,
      "learning_rate": 4.20717409062515e-05,
      "loss": 0.0002,
      "step": 33000
    },
    {
      "epoch": 1.588102445821921,
      "grad_norm": 0.27422893047332764,
      "learning_rate": 4.20597280284465e-05,
      "loss": 0.0003,
      "step": 33050
    },
    {
      "epoch": 1.5905050213829224,
      "grad_norm": 0.390323281288147,
      "learning_rate": 4.204771515064149e-05,
      "loss": 0.0003,
      "step": 33100
    },
    {
      "epoch": 1.592907596943924,
      "grad_norm": 0.4968453049659729,
      "learning_rate": 4.203570227283648e-05,
      "loss": 0.0003,
      "step": 33150
    },
    {
      "epoch": 1.5953101725049252,
      "grad_norm": 0.3111221492290497,
      "learning_rate": 4.202368939503147e-05,
      "loss": 0.0003,
      "step": 33200
    },
    {
      "epoch": 1.5977127480659266,
      "grad_norm": 0.152686208486557,
      "learning_rate": 4.201167651722647e-05,
      "loss": 0.0003,
      "step": 33250
    },
    {
      "epoch": 1.600115323626928,
      "grad_norm": 0.4430134892463684,
      "learning_rate": 4.199966363942146e-05,
      "loss": 0.0003,
      "step": 33300
    },
    {
      "epoch": 1.6025178991879294,
      "grad_norm": 0.3803720474243164,
      "learning_rate": 4.198765076161645e-05,
      "loss": 0.0002,
      "step": 33350
    },
    {
      "epoch": 1.6049204747489307,
      "grad_norm": 0.1453576236963272,
      "learning_rate": 4.197563788381145e-05,
      "loss": 0.0003,
      "step": 33400
    },
    {
      "epoch": 1.6073230503099323,
      "grad_norm": 0.1858004331588745,
      "learning_rate": 4.196362500600644e-05,
      "loss": 0.0003,
      "step": 33450
    },
    {
      "epoch": 1.6097256258709336,
      "grad_norm": 0.5270317792892456,
      "learning_rate": 4.195161212820143e-05,
      "loss": 0.0002,
      "step": 33500
    },
    {
      "epoch": 1.612128201431935,
      "grad_norm": 0.11945851892232895,
      "learning_rate": 4.193959925039643e-05,
      "loss": 0.0003,
      "step": 33550
    },
    {
      "epoch": 1.6145307769929365,
      "grad_norm": 0.2308734655380249,
      "learning_rate": 4.192758637259142e-05,
      "loss": 0.0003,
      "step": 33600
    },
    {
      "epoch": 1.6169333525539378,
      "grad_norm": 0.1625916063785553,
      "learning_rate": 4.191557349478642e-05,
      "loss": 0.0003,
      "step": 33650
    },
    {
      "epoch": 1.619335928114939,
      "grad_norm": 0.3900647461414337,
      "learning_rate": 4.190356061698141e-05,
      "loss": 0.0002,
      "step": 33700
    },
    {
      "epoch": 1.6217385036759406,
      "grad_norm": 0.45855849981307983,
      "learning_rate": 4.18915477391764e-05,
      "loss": 0.0002,
      "step": 33750
    },
    {
      "epoch": 1.624141079236942,
      "grad_norm": 0.03274661675095558,
      "learning_rate": 4.1879534861371396e-05,
      "loss": 0.0002,
      "step": 33800
    },
    {
      "epoch": 1.6265436547979433,
      "grad_norm": 0.033395420759916306,
      "learning_rate": 4.186752198356639e-05,
      "loss": 0.0002,
      "step": 33850
    },
    {
      "epoch": 1.6289462303589448,
      "grad_norm": 0.08158895373344421,
      "learning_rate": 4.185550910576138e-05,
      "loss": 0.0003,
      "step": 33900
    },
    {
      "epoch": 1.6313488059199461,
      "grad_norm": 0.16890868544578552,
      "learning_rate": 4.184349622795637e-05,
      "loss": 0.0002,
      "step": 33950
    },
    {
      "epoch": 1.6337513814809475,
      "grad_norm": 0.19341294467449188,
      "learning_rate": 4.183148335015136e-05,
      "loss": 0.0003,
      "step": 34000
    },
    {
      "epoch": 1.636153957041949,
      "grad_norm": 0.19728219509124756,
      "learning_rate": 4.181947047234636e-05,
      "loss": 0.0002,
      "step": 34050
    },
    {
      "epoch": 1.6385565326029503,
      "grad_norm": 0.11070950329303741,
      "learning_rate": 4.180745759454135e-05,
      "loss": 0.0002,
      "step": 34100
    },
    {
      "epoch": 1.6409591081639516,
      "grad_norm": 0.11785028129816055,
      "learning_rate": 4.1795444716736346e-05,
      "loss": 0.0002,
      "step": 34150
    },
    {
      "epoch": 1.6433616837249532,
      "grad_norm": 0.6852128505706787,
      "learning_rate": 4.1783431838931337e-05,
      "loss": 0.0003,
      "step": 34200
    },
    {
      "epoch": 1.6457642592859545,
      "grad_norm": 0.3379129469394684,
      "learning_rate": 4.177141896112633e-05,
      "loss": 0.0007,
      "step": 34250
    },
    {
      "epoch": 1.6481668348469558,
      "grad_norm": 0.06471764296293259,
      "learning_rate": 4.1759406083321325e-05,
      "loss": 0.0002,
      "step": 34300
    },
    {
      "epoch": 1.6505694104079573,
      "grad_norm": 0.5647966265678406,
      "learning_rate": 4.1747393205516316e-05,
      "loss": 0.0003,
      "step": 34350
    },
    {
      "epoch": 1.652971985968959,
      "grad_norm": 0.1440313458442688,
      "learning_rate": 4.173538032771131e-05,
      "loss": 0.0002,
      "step": 34400
    },
    {
      "epoch": 1.65537456152996,
      "grad_norm": 0.17076250910758972,
      "learning_rate": 4.1723367449906304e-05,
      "loss": 0.0002,
      "step": 34450
    },
    {
      "epoch": 1.6577771370909615,
      "grad_norm": 0.2810627520084381,
      "learning_rate": 4.1711354572101295e-05,
      "loss": 0.0004,
      "step": 34500
    },
    {
      "epoch": 1.660179712651963,
      "grad_norm": 0.4963262975215912,
      "learning_rate": 4.169934169429629e-05,
      "loss": 0.0002,
      "step": 34550
    },
    {
      "epoch": 1.6625822882129642,
      "grad_norm": 0.5100994110107422,
      "learning_rate": 4.1687328816491283e-05,
      "loss": 0.0003,
      "step": 34600
    },
    {
      "epoch": 1.6649848637739657,
      "grad_norm": 0.16967304050922394,
      "learning_rate": 4.1675315938686274e-05,
      "loss": 0.0009,
      "step": 34650
    },
    {
      "epoch": 1.6673874393349672,
      "grad_norm": 0.41890233755111694,
      "learning_rate": 4.1663303060881265e-05,
      "loss": 0.0003,
      "step": 34700
    },
    {
      "epoch": 1.6697900148959683,
      "grad_norm": 0.2722201645374298,
      "learning_rate": 4.1651290183076256e-05,
      "loss": 0.0002,
      "step": 34750
    },
    {
      "epoch": 1.6721925904569699,
      "grad_norm": 0.5116235613822937,
      "learning_rate": 4.1639277305271254e-05,
      "loss": 0.0004,
      "step": 34800
    },
    {
      "epoch": 1.6745951660179714,
      "grad_norm": 0.21882972121238708,
      "learning_rate": 4.1627264427466244e-05,
      "loss": 0.0002,
      "step": 34850
    },
    {
      "epoch": 1.6769977415789725,
      "grad_norm": 0.14306388795375824,
      "learning_rate": 4.1615251549661235e-05,
      "loss": 0.0002,
      "step": 34900
    },
    {
      "epoch": 1.679400317139974,
      "grad_norm": 0.22684133052825928,
      "learning_rate": 4.160323867185623e-05,
      "loss": 0.0003,
      "step": 34950
    },
    {
      "epoch": 1.6818028927009756,
      "grad_norm": 0.20797331631183624,
      "learning_rate": 4.1591225794051224e-05,
      "loss": 0.0002,
      "step": 35000
    },
    {
      "epoch": 1.6842054682619767,
      "grad_norm": 0.20454949140548706,
      "learning_rate": 4.157921291624622e-05,
      "loss": 0.0002,
      "step": 35050
    },
    {
      "epoch": 1.6866080438229782,
      "grad_norm": 0.13827095925807953,
      "learning_rate": 4.156720003844121e-05,
      "loss": 0.0002,
      "step": 35100
    },
    {
      "epoch": 1.6890106193839798,
      "grad_norm": 0.19108198583126068,
      "learning_rate": 4.15551871606362e-05,
      "loss": 0.0003,
      "step": 35150
    },
    {
      "epoch": 1.6914131949449809,
      "grad_norm": 0.6555622220039368,
      "learning_rate": 4.15431742828312e-05,
      "loss": 0.0002,
      "step": 35200
    },
    {
      "epoch": 1.6938157705059824,
      "grad_norm": 0.3032873570919037,
      "learning_rate": 4.153116140502619e-05,
      "loss": 0.0002,
      "step": 35250
    },
    {
      "epoch": 1.696218346066984,
      "grad_norm": 0.29255905747413635,
      "learning_rate": 4.151914852722118e-05,
      "loss": 0.0002,
      "step": 35300
    },
    {
      "epoch": 1.698620921627985,
      "grad_norm": 0.27045825123786926,
      "learning_rate": 4.150713564941617e-05,
      "loss": 0.0002,
      "step": 35350
    },
    {
      "epoch": 1.7010234971889866,
      "grad_norm": 0.05911386013031006,
      "learning_rate": 4.1495122771611164e-05,
      "loss": 0.0003,
      "step": 35400
    },
    {
      "epoch": 1.7034260727499881,
      "grad_norm": 0.262384295463562,
      "learning_rate": 4.148310989380616e-05,
      "loss": 0.0002,
      "step": 35450
    },
    {
      "epoch": 1.7058286483109892,
      "grad_norm": 0.10912946611642838,
      "learning_rate": 4.147109701600115e-05,
      "loss": 0.001,
      "step": 35500
    },
    {
      "epoch": 1.7082312238719908,
      "grad_norm": 0.5871476531028748,
      "learning_rate": 4.145908413819615e-05,
      "loss": 0.0002,
      "step": 35550
    },
    {
      "epoch": 1.7106337994329923,
      "grad_norm": 0.2495037466287613,
      "learning_rate": 4.144707126039114e-05,
      "loss": 0.0003,
      "step": 35600
    },
    {
      "epoch": 1.7130363749939934,
      "grad_norm": 0.31886816024780273,
      "learning_rate": 4.143505838258613e-05,
      "loss": 0.0008,
      "step": 35650
    },
    {
      "epoch": 1.715438950554995,
      "grad_norm": 0.14592300355434418,
      "learning_rate": 4.142304550478113e-05,
      "loss": 0.0003,
      "step": 35700
    },
    {
      "epoch": 1.7178415261159965,
      "grad_norm": 0.14673824608325958,
      "learning_rate": 4.141103262697612e-05,
      "loss": 0.0002,
      "step": 35750
    },
    {
      "epoch": 1.7202441016769976,
      "grad_norm": 0.19679830968379974,
      "learning_rate": 4.139901974917111e-05,
      "loss": 0.0002,
      "step": 35800
    },
    {
      "epoch": 1.7226466772379991,
      "grad_norm": 0.08040810376405716,
      "learning_rate": 4.138700687136611e-05,
      "loss": 0.0002,
      "step": 35850
    },
    {
      "epoch": 1.7250492527990007,
      "grad_norm": 0.23029187321662903,
      "learning_rate": 4.13749939935611e-05,
      "loss": 0.0003,
      "step": 35900
    },
    {
      "epoch": 1.7274518283600018,
      "grad_norm": 0.21109311282634735,
      "learning_rate": 4.13629811157561e-05,
      "loss": 0.0002,
      "step": 35950
    },
    {
      "epoch": 1.7298544039210033,
      "grad_norm": 0.14454880356788635,
      "learning_rate": 4.135096823795109e-05,
      "loss": 0.0003,
      "step": 36000
    },
    {
      "epoch": 1.7322569794820049,
      "grad_norm": 0.11944708228111267,
      "learning_rate": 4.133895536014608e-05,
      "loss": 0.0002,
      "step": 36050
    },
    {
      "epoch": 1.734659555043006,
      "grad_norm": 0.6354398131370544,
      "learning_rate": 4.132694248234107e-05,
      "loss": 0.0003,
      "step": 36100
    },
    {
      "epoch": 1.7370621306040075,
      "grad_norm": 0.4012227952480316,
      "learning_rate": 4.131492960453606e-05,
      "loss": 0.0003,
      "step": 36150
    },
    {
      "epoch": 1.739464706165009,
      "grad_norm": 0.5767280459403992,
      "learning_rate": 4.130291672673106e-05,
      "loss": 0.0002,
      "step": 36200
    },
    {
      "epoch": 1.7418672817260101,
      "grad_norm": 0.13659925758838654,
      "learning_rate": 4.129090384892605e-05,
      "loss": 0.0003,
      "step": 36250
    },
    {
      "epoch": 1.7442698572870117,
      "grad_norm": 0.10192728787660599,
      "learning_rate": 4.127889097112104e-05,
      "loss": 0.0002,
      "step": 36300
    },
    {
      "epoch": 1.7466724328480132,
      "grad_norm": 0.13291287422180176,
      "learning_rate": 4.126687809331604e-05,
      "loss": 0.0002,
      "step": 36350
    },
    {
      "epoch": 1.7490750084090143,
      "grad_norm": 0.34367793798446655,
      "learning_rate": 4.125486521551103e-05,
      "loss": 0.0002,
      "step": 36400
    },
    {
      "epoch": 1.7514775839700158,
      "grad_norm": 0.042495451867580414,
      "learning_rate": 4.1242852337706025e-05,
      "loss": 0.0003,
      "step": 36450
    },
    {
      "epoch": 1.7538801595310174,
      "grad_norm": 0.4699309468269348,
      "learning_rate": 4.1230839459901016e-05,
      "loss": 0.0002,
      "step": 36500
    },
    {
      "epoch": 1.7562827350920185,
      "grad_norm": 0.137606680393219,
      "learning_rate": 4.121882658209601e-05,
      "loss": 0.0003,
      "step": 36550
    },
    {
      "epoch": 1.75868531065302,
      "grad_norm": 0.1176922544836998,
      "learning_rate": 4.1206813704291005e-05,
      "loss": 0.0003,
      "step": 36600
    },
    {
      "epoch": 1.7610878862140216,
      "grad_norm": 0.39008069038391113,
      "learning_rate": 4.1194800826485995e-05,
      "loss": 0.0002,
      "step": 36650
    },
    {
      "epoch": 1.7634904617750227,
      "grad_norm": 0.08479086309671402,
      "learning_rate": 4.118278794868099e-05,
      "loss": 0.0002,
      "step": 36700
    },
    {
      "epoch": 1.7658930373360242,
      "grad_norm": 0.09371165186166763,
      "learning_rate": 4.1170775070875984e-05,
      "loss": 0.0007,
      "step": 36750
    },
    {
      "epoch": 1.7682956128970257,
      "grad_norm": 0.19759051501750946,
      "learning_rate": 4.1158762193070975e-05,
      "loss": 0.0002,
      "step": 36800
    },
    {
      "epoch": 1.7706981884580268,
      "grad_norm": 0.3097354471683502,
      "learning_rate": 4.1146749315265966e-05,
      "loss": 0.0003,
      "step": 36850
    },
    {
      "epoch": 1.7731007640190284,
      "grad_norm": 0.18050578236579895,
      "learning_rate": 4.1134736437460956e-05,
      "loss": 0.0002,
      "step": 36900
    },
    {
      "epoch": 1.77550333958003,
      "grad_norm": 0.3304624855518341,
      "learning_rate": 4.1122723559655954e-05,
      "loss": 0.0002,
      "step": 36950
    },
    {
      "epoch": 1.777905915141031,
      "grad_norm": 0.12055213749408722,
      "learning_rate": 4.1110710681850945e-05,
      "loss": 0.0003,
      "step": 37000
    },
    {
      "epoch": 1.7803084907020326,
      "grad_norm": 0.847044825553894,
      "learning_rate": 4.1098697804045936e-05,
      "loss": 0.0003,
      "step": 37050
    },
    {
      "epoch": 1.782711066263034,
      "grad_norm": 0.7736724019050598,
      "learning_rate": 4.108668492624093e-05,
      "loss": 0.0009,
      "step": 37100
    },
    {
      "epoch": 1.7851136418240352,
      "grad_norm": 0.5506842732429504,
      "learning_rate": 4.1074672048435924e-05,
      "loss": 0.0003,
      "step": 37150
    },
    {
      "epoch": 1.7875162173850367,
      "grad_norm": 0.1372326761484146,
      "learning_rate": 4.106265917063092e-05,
      "loss": 0.0003,
      "step": 37200
    },
    {
      "epoch": 1.7899187929460383,
      "grad_norm": 0.3775770664215088,
      "learning_rate": 4.105064629282591e-05,
      "loss": 0.0003,
      "step": 37250
    },
    {
      "epoch": 1.7923213685070394,
      "grad_norm": 0.3023049235343933,
      "learning_rate": 4.10386334150209e-05,
      "loss": 0.0007,
      "step": 37300
    },
    {
      "epoch": 1.794723944068041,
      "grad_norm": 0.04214485362172127,
      "learning_rate": 4.10266205372159e-05,
      "loss": 0.0011,
      "step": 37350
    },
    {
      "epoch": 1.7971265196290425,
      "grad_norm": 0.16066652536392212,
      "learning_rate": 4.101460765941089e-05,
      "loss": 0.0002,
      "step": 37400
    },
    {
      "epoch": 1.7995290951900438,
      "grad_norm": 0.07060271501541138,
      "learning_rate": 4.100259478160588e-05,
      "loss": 0.0002,
      "step": 37450
    },
    {
      "epoch": 1.801931670751045,
      "grad_norm": 0.17386461794376373,
      "learning_rate": 4.099058190380088e-05,
      "loss": 0.0003,
      "step": 37500
    },
    {
      "epoch": 1.8043342463120466,
      "grad_norm": 0.45072248578071594,
      "learning_rate": 4.097856902599587e-05,
      "loss": 0.0002,
      "step": 37550
    },
    {
      "epoch": 1.806736821873048,
      "grad_norm": 0.6054259538650513,
      "learning_rate": 4.096655614819086e-05,
      "loss": 0.0003,
      "step": 37600
    },
    {
      "epoch": 1.8091393974340493,
      "grad_norm": 0.25356364250183105,
      "learning_rate": 4.095454327038585e-05,
      "loss": 0.0003,
      "step": 37650
    },
    {
      "epoch": 1.8115419729950508,
      "grad_norm": 0.40668806433677673,
      "learning_rate": 4.0942530392580843e-05,
      "loss": 0.0004,
      "step": 37700
    },
    {
      "epoch": 1.8139445485560521,
      "grad_norm": 0.17888493835926056,
      "learning_rate": 4.093051751477584e-05,
      "loss": 0.0002,
      "step": 37750
    },
    {
      "epoch": 1.8163471241170535,
      "grad_norm": 0.3809927999973297,
      "learning_rate": 4.091850463697083e-05,
      "loss": 0.0002,
      "step": 37800
    },
    {
      "epoch": 1.818749699678055,
      "grad_norm": 0.29584020376205444,
      "learning_rate": 4.090649175916583e-05,
      "loss": 0.0002,
      "step": 37850
    },
    {
      "epoch": 1.8211522752390563,
      "grad_norm": 0.11884477734565735,
      "learning_rate": 4.089447888136082e-05,
      "loss": 0.0002,
      "step": 37900
    },
    {
      "epoch": 1.8235548508000576,
      "grad_norm": 0.2068791389465332,
      "learning_rate": 4.088246600355581e-05,
      "loss": 0.0002,
      "step": 37950
    },
    {
      "epoch": 1.8259574263610592,
      "grad_norm": 0.27642378211021423,
      "learning_rate": 4.087045312575081e-05,
      "loss": 0.0002,
      "step": 38000
    },
    {
      "epoch": 1.8283600019220605,
      "grad_norm": 0.4924783706665039,
      "learning_rate": 4.08584402479458e-05,
      "loss": 0.0002,
      "step": 38050
    },
    {
      "epoch": 1.8307625774830618,
      "grad_norm": 0.48848894238471985,
      "learning_rate": 4.08464273701408e-05,
      "loss": 0.0002,
      "step": 38100
    },
    {
      "epoch": 1.8331651530440634,
      "grad_norm": 0.26074090600013733,
      "learning_rate": 4.083441449233579e-05,
      "loss": 0.0003,
      "step": 38150
    },
    {
      "epoch": 1.8355677286050647,
      "grad_norm": 0.42432552576065063,
      "learning_rate": 4.082240161453078e-05,
      "loss": 0.0003,
      "step": 38200
    },
    {
      "epoch": 1.837970304166066,
      "grad_norm": 0.26474273204803467,
      "learning_rate": 4.0810388736725776e-05,
      "loss": 0.0003,
      "step": 38250
    },
    {
      "epoch": 1.8403728797270675,
      "grad_norm": 0.42805856466293335,
      "learning_rate": 4.079837585892077e-05,
      "loss": 0.0002,
      "step": 38300
    },
    {
      "epoch": 1.8427754552880689,
      "grad_norm": 0.21210886538028717,
      "learning_rate": 4.078636298111576e-05,
      "loss": 0.0008,
      "step": 38350
    },
    {
      "epoch": 1.8451780308490702,
      "grad_norm": 0.11841171234846115,
      "learning_rate": 4.077435010331075e-05,
      "loss": 0.0008,
      "step": 38400
    },
    {
      "epoch": 1.8475806064100717,
      "grad_norm": 0.27322691679000854,
      "learning_rate": 4.076233722550574e-05,
      "loss": 0.0008,
      "step": 38450
    },
    {
      "epoch": 1.849983181971073,
      "grad_norm": 0.23817472159862518,
      "learning_rate": 4.075032434770074e-05,
      "loss": 0.0002,
      "step": 38500
    },
    {
      "epoch": 1.8523857575320744,
      "grad_norm": 0.18291090428829193,
      "learning_rate": 4.073831146989573e-05,
      "loss": 0.0003,
      "step": 38550
    },
    {
      "epoch": 1.854788333093076,
      "grad_norm": 0.23092521727085114,
      "learning_rate": 4.0726298592090726e-05,
      "loss": 0.0002,
      "step": 38600
    },
    {
      "epoch": 1.8571909086540772,
      "grad_norm": 0.19583754241466522,
      "learning_rate": 4.0714285714285717e-05,
      "loss": 0.0002,
      "step": 38650
    },
    {
      "epoch": 1.8595934842150785,
      "grad_norm": 0.16047115623950958,
      "learning_rate": 4.070227283648071e-05,
      "loss": 0.0002,
      "step": 38700
    },
    {
      "epoch": 1.86199605977608,
      "grad_norm": 0.08019974082708359,
      "learning_rate": 4.0690259958675705e-05,
      "loss": 0.0007,
      "step": 38750
    },
    {
      "epoch": 1.8643986353370814,
      "grad_norm": 0.23967036604881287,
      "learning_rate": 4.0678247080870696e-05,
      "loss": 0.0002,
      "step": 38800
    },
    {
      "epoch": 1.8668012108980827,
      "grad_norm": 0.3579275906085968,
      "learning_rate": 4.0666234203065687e-05,
      "loss": 0.0002,
      "step": 38850
    },
    {
      "epoch": 1.8692037864590842,
      "grad_norm": 0.15823739767074585,
      "learning_rate": 4.0654221325260684e-05,
      "loss": 0.0003,
      "step": 38900
    },
    {
      "epoch": 1.8716063620200856,
      "grad_norm": 0.05771573632955551,
      "learning_rate": 4.0642208447455675e-05,
      "loss": 0.0003,
      "step": 38950
    },
    {
      "epoch": 1.8740089375810869,
      "grad_norm": 0.137210413813591,
      "learning_rate": 4.063019556965067e-05,
      "loss": 0.0002,
      "step": 39000
    },
    {
      "epoch": 1.8764115131420884,
      "grad_norm": 0.5417237877845764,
      "learning_rate": 4.0618182691845663e-05,
      "loss": 0.0002,
      "step": 39050
    },
    {
      "epoch": 1.8788140887030897,
      "grad_norm": 0.07978114485740662,
      "learning_rate": 4.0606169814040654e-05,
      "loss": 0.0003,
      "step": 39100
    },
    {
      "epoch": 1.881216664264091,
      "grad_norm": 0.12987108528614044,
      "learning_rate": 4.0594156936235645e-05,
      "loss": 0.0002,
      "step": 39150
    },
    {
      "epoch": 1.8836192398250926,
      "grad_norm": 0.4436926543712616,
      "learning_rate": 4.0582144058430636e-05,
      "loss": 0.0002,
      "step": 39200
    },
    {
      "epoch": 1.886021815386094,
      "grad_norm": 0.41544124484062195,
      "learning_rate": 4.0570131180625634e-05,
      "loss": 0.0003,
      "step": 39250
    },
    {
      "epoch": 1.8884243909470952,
      "grad_norm": 0.3395925462245941,
      "learning_rate": 4.0558118302820624e-05,
      "loss": 0.0002,
      "step": 39300
    },
    {
      "epoch": 1.8908269665080968,
      "grad_norm": 0.21765699982643127,
      "learning_rate": 4.0546105425015615e-05,
      "loss": 0.0003,
      "step": 39350
    },
    {
      "epoch": 1.893229542069098,
      "grad_norm": 0.08503136038780212,
      "learning_rate": 4.053409254721061e-05,
      "loss": 0.0003,
      "step": 39400
    },
    {
      "epoch": 1.8956321176300994,
      "grad_norm": 0.10764873772859573,
      "learning_rate": 4.0522079669405604e-05,
      "loss": 0.0002,
      "step": 39450
    },
    {
      "epoch": 1.898034693191101,
      "grad_norm": 0.2632705271244049,
      "learning_rate": 4.05100667916006e-05,
      "loss": 0.0002,
      "step": 39500
    },
    {
      "epoch": 1.9004372687521023,
      "grad_norm": 0.2093449980020523,
      "learning_rate": 4.049805391379559e-05,
      "loss": 0.0003,
      "step": 39550
    },
    {
      "epoch": 1.9028398443131036,
      "grad_norm": 0.11289598792791367,
      "learning_rate": 4.048604103599058e-05,
      "loss": 0.0002,
      "step": 39600
    },
    {
      "epoch": 1.9052424198741051,
      "grad_norm": 0.9395759105682373,
      "learning_rate": 4.047402815818558e-05,
      "loss": 0.0003,
      "step": 39650
    },
    {
      "epoch": 1.9076449954351065,
      "grad_norm": 0.23188011348247528,
      "learning_rate": 4.046201528038057e-05,
      "loss": 0.0003,
      "step": 39700
    },
    {
      "epoch": 1.9100475709961078,
      "grad_norm": 0.7873983383178711,
      "learning_rate": 4.045000240257556e-05,
      "loss": 0.0003,
      "step": 39750
    },
    {
      "epoch": 1.9124501465571093,
      "grad_norm": 0.14659303426742554,
      "learning_rate": 4.043798952477056e-05,
      "loss": 0.0009,
      "step": 39800
    },
    {
      "epoch": 1.9148527221181106,
      "grad_norm": 0.34164854884147644,
      "learning_rate": 4.0425976646965544e-05,
      "loss": 0.0003,
      "step": 39850
    },
    {
      "epoch": 1.917255297679112,
      "grad_norm": 0.33775514364242554,
      "learning_rate": 4.041396376916054e-05,
      "loss": 0.0003,
      "step": 39900
    },
    {
      "epoch": 1.9196578732401135,
      "grad_norm": 0.541831910610199,
      "learning_rate": 4.040195089135553e-05,
      "loss": 0.0003,
      "step": 39950
    },
    {
      "epoch": 1.9220604488011148,
      "grad_norm": 0.4892483353614807,
      "learning_rate": 4.038993801355053e-05,
      "loss": 0.0006,
      "step": 40000
    },
    {
      "epoch": 1.9244630243621161,
      "grad_norm": 0.17894788086414337,
      "learning_rate": 4.037792513574552e-05,
      "loss": 0.0006,
      "step": 40050
    },
    {
      "epoch": 1.9268655999231177,
      "grad_norm": 0.12384412437677383,
      "learning_rate": 4.036591225794051e-05,
      "loss": 0.0002,
      "step": 40100
    },
    {
      "epoch": 1.929268175484119,
      "grad_norm": 0.15206433832645416,
      "learning_rate": 4.035389938013551e-05,
      "loss": 0.0002,
      "step": 40150
    },
    {
      "epoch": 1.9316707510451203,
      "grad_norm": 0.18758971989154816,
      "learning_rate": 4.03418865023305e-05,
      "loss": 0.0002,
      "step": 40200
    },
    {
      "epoch": 1.9340733266061219,
      "grad_norm": 0.30751001834869385,
      "learning_rate": 4.032987362452549e-05,
      "loss": 0.0002,
      "step": 40250
    },
    {
      "epoch": 1.9364759021671232,
      "grad_norm": 0.13197536766529083,
      "learning_rate": 4.031786074672049e-05,
      "loss": 0.0003,
      "step": 40300
    },
    {
      "epoch": 1.9388784777281245,
      "grad_norm": 0.6317787170410156,
      "learning_rate": 4.030584786891548e-05,
      "loss": 0.0002,
      "step": 40350
    },
    {
      "epoch": 1.941281053289126,
      "grad_norm": 0.20778769254684448,
      "learning_rate": 4.029383499111048e-05,
      "loss": 0.0002,
      "step": 40400
    },
    {
      "epoch": 1.9436836288501274,
      "grad_norm": 0.2760555148124695,
      "learning_rate": 4.028182211330547e-05,
      "loss": 0.0009,
      "step": 40450
    },
    {
      "epoch": 1.9460862044111287,
      "grad_norm": 0.22902585566043854,
      "learning_rate": 4.026980923550046e-05,
      "loss": 0.0002,
      "step": 40500
    },
    {
      "epoch": 1.9484887799721302,
      "grad_norm": 0.5263626575469971,
      "learning_rate": 4.0257796357695456e-05,
      "loss": 0.0007,
      "step": 40550
    },
    {
      "epoch": 1.9508913555331315,
      "grad_norm": 0.27413174510002136,
      "learning_rate": 4.024578347989044e-05,
      "loss": 0.0003,
      "step": 40600
    },
    {
      "epoch": 1.9532939310941329,
      "grad_norm": 0.71458899974823,
      "learning_rate": 4.023377060208544e-05,
      "loss": 0.0003,
      "step": 40650
    },
    {
      "epoch": 1.9556965066551344,
      "grad_norm": 0.10358873754739761,
      "learning_rate": 4.022175772428043e-05,
      "loss": 0.0002,
      "step": 40700
    },
    {
      "epoch": 1.9580990822161357,
      "grad_norm": 0.6262933015823364,
      "learning_rate": 4.020974484647542e-05,
      "loss": 0.0003,
      "step": 40750
    },
    {
      "epoch": 1.960501657777137,
      "grad_norm": 0.23808132112026215,
      "learning_rate": 4.019773196867042e-05,
      "loss": 0.0002,
      "step": 40800
    },
    {
      "epoch": 1.9629042333381386,
      "grad_norm": 0.2969074845314026,
      "learning_rate": 4.018571909086541e-05,
      "loss": 0.0002,
      "step": 40850
    },
    {
      "epoch": 1.96530680889914,
      "grad_norm": 0.4671967625617981,
      "learning_rate": 4.0173706213060405e-05,
      "loss": 0.0003,
      "step": 40900
    },
    {
      "epoch": 1.9677093844601412,
      "grad_norm": 0.3284641206264496,
      "learning_rate": 4.0161693335255396e-05,
      "loss": 0.0002,
      "step": 40950
    },
    {
      "epoch": 1.9701119600211427,
      "grad_norm": 0.2863323986530304,
      "learning_rate": 4.014968045745039e-05,
      "loss": 0.0002,
      "step": 41000
    },
    {
      "epoch": 1.972514535582144,
      "grad_norm": 0.19911976158618927,
      "learning_rate": 4.0137667579645385e-05,
      "loss": 0.0002,
      "step": 41050
    },
    {
      "epoch": 1.9749171111431454,
      "grad_norm": 0.08168679475784302,
      "learning_rate": 4.0125654701840375e-05,
      "loss": 0.0003,
      "step": 41100
    },
    {
      "epoch": 1.977319686704147,
      "grad_norm": 0.13692544400691986,
      "learning_rate": 4.0113641824035366e-05,
      "loss": 0.0002,
      "step": 41150
    },
    {
      "epoch": 1.9797222622651482,
      "grad_norm": 0.2356395721435547,
      "learning_rate": 4.0101628946230364e-05,
      "loss": 0.0002,
      "step": 41200
    },
    {
      "epoch": 1.9821248378261496,
      "grad_norm": 0.12212463468313217,
      "learning_rate": 4.0089616068425355e-05,
      "loss": 0.0003,
      "step": 41250
    },
    {
      "epoch": 1.984527413387151,
      "grad_norm": 0.22638188302516937,
      "learning_rate": 4.0077603190620345e-05,
      "loss": 0.0003,
      "step": 41300
    },
    {
      "epoch": 1.9869299889481524,
      "grad_norm": 0.14832055568695068,
      "learning_rate": 4.0065590312815336e-05,
      "loss": 0.0003,
      "step": 41350
    },
    {
      "epoch": 1.9893325645091537,
      "grad_norm": 0.47758951783180237,
      "learning_rate": 4.0053577435010334e-05,
      "loss": 0.0002,
      "step": 41400
    },
    {
      "epoch": 1.9917351400701553,
      "grad_norm": 0.2947876453399658,
      "learning_rate": 4.0041564557205325e-05,
      "loss": 0.0003,
      "step": 41450
    },
    {
      "epoch": 1.9941377156311566,
      "grad_norm": 0.12103671580553055,
      "learning_rate": 4.0029551679400316e-05,
      "loss": 0.0002,
      "step": 41500
    },
    {
      "epoch": 1.996540291192158,
      "grad_norm": 0.21274054050445557,
      "learning_rate": 4.001753880159531e-05,
      "loss": 0.0002,
      "step": 41550
    },
    {
      "epoch": 1.9989428667531595,
      "grad_norm": 0.08813370019197464,
      "learning_rate": 4.0005525923790304e-05,
      "loss": 0.0002,
      "step": 41600
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0003063653421122581,
      "eval_runtime": 17.3653,
      "eval_samples_per_second": 546.839,
      "eval_steps_per_second": 68.355,
      "step": 41622
    },
    {
      "epoch": 2.0013454423141606,
      "grad_norm": 0.38524937629699707,
      "learning_rate": 3.9993513045985295e-05,
      "loss": 0.0002,
      "step": 41650
    },
    {
      "epoch": 2.003748017875162,
      "grad_norm": 0.0898514911532402,
      "learning_rate": 3.998150016818029e-05,
      "loss": 0.0006,
      "step": 41700
    },
    {
      "epoch": 2.0061505934361636,
      "grad_norm": 0.33804231882095337,
      "learning_rate": 3.996948729037528e-05,
      "loss": 0.0003,
      "step": 41750
    },
    {
      "epoch": 2.0085531689971647,
      "grad_norm": 0.4119917154312134,
      "learning_rate": 3.995747441257028e-05,
      "loss": 0.0003,
      "step": 41800
    },
    {
      "epoch": 2.0109557445581663,
      "grad_norm": 0.3812575936317444,
      "learning_rate": 3.994546153476527e-05,
      "loss": 0.0003,
      "step": 41850
    },
    {
      "epoch": 2.013358320119168,
      "grad_norm": 0.32175523042678833,
      "learning_rate": 3.993344865696026e-05,
      "loss": 0.0002,
      "step": 41900
    },
    {
      "epoch": 2.0157608956801694,
      "grad_norm": 0.15914218127727509,
      "learning_rate": 3.992143577915526e-05,
      "loss": 0.0002,
      "step": 41950
    },
    {
      "epoch": 2.0181634712411705,
      "grad_norm": 0.1776367872953415,
      "learning_rate": 3.990942290135025e-05,
      "loss": 0.0003,
      "step": 42000
    },
    {
      "epoch": 2.020566046802172,
      "grad_norm": 0.6085923910140991,
      "learning_rate": 3.989741002354524e-05,
      "loss": 0.0002,
      "step": 42050
    },
    {
      "epoch": 2.0229686223631735,
      "grad_norm": 0.20276114344596863,
      "learning_rate": 3.988539714574023e-05,
      "loss": 0.0003,
      "step": 42100
    },
    {
      "epoch": 2.0253711979241746,
      "grad_norm": 0.3093935549259186,
      "learning_rate": 3.987338426793522e-05,
      "loss": 0.0007,
      "step": 42150
    },
    {
      "epoch": 2.027773773485176,
      "grad_norm": 0.1735839694738388,
      "learning_rate": 3.986137139013022e-05,
      "loss": 0.0003,
      "step": 42200
    },
    {
      "epoch": 2.0301763490461777,
      "grad_norm": 0.2709968388080597,
      "learning_rate": 3.984935851232521e-05,
      "loss": 0.0002,
      "step": 42250
    },
    {
      "epoch": 2.032578924607179,
      "grad_norm": 0.1337984949350357,
      "learning_rate": 3.983734563452021e-05,
      "loss": 0.0002,
      "step": 42300
    },
    {
      "epoch": 2.0349815001681804,
      "grad_norm": 0.4532163739204407,
      "learning_rate": 3.98253327567152e-05,
      "loss": 0.0002,
      "step": 42350
    },
    {
      "epoch": 2.037384075729182,
      "grad_norm": 0.21853914856910706,
      "learning_rate": 3.981331987891019e-05,
      "loss": 0.0007,
      "step": 42400
    },
    {
      "epoch": 2.039786651290183,
      "grad_norm": 0.13346895575523376,
      "learning_rate": 3.980130700110519e-05,
      "loss": 0.0003,
      "step": 42450
    },
    {
      "epoch": 2.0421892268511845,
      "grad_norm": 0.025807032361626625,
      "learning_rate": 3.978929412330018e-05,
      "loss": 0.0002,
      "step": 42500
    },
    {
      "epoch": 2.044591802412186,
      "grad_norm": 0.07452744990587234,
      "learning_rate": 3.977728124549518e-05,
      "loss": 0.0002,
      "step": 42550
    },
    {
      "epoch": 2.046994377973187,
      "grad_norm": 0.2967053949832916,
      "learning_rate": 3.976526836769017e-05,
      "loss": 0.0002,
      "step": 42600
    },
    {
      "epoch": 2.0493969535341887,
      "grad_norm": 0.09039366245269775,
      "learning_rate": 3.975325548988516e-05,
      "loss": 0.0002,
      "step": 42650
    },
    {
      "epoch": 2.0517995290951903,
      "grad_norm": 0.0384397879242897,
      "learning_rate": 3.9741242612080156e-05,
      "loss": 0.0002,
      "step": 42700
    },
    {
      "epoch": 2.0542021046561914,
      "grad_norm": 0.37239763140678406,
      "learning_rate": 3.972922973427515e-05,
      "loss": 0.0002,
      "step": 42750
    },
    {
      "epoch": 2.056604680217193,
      "grad_norm": 0.12558022141456604,
      "learning_rate": 3.971721685647014e-05,
      "loss": 0.0002,
      "step": 42800
    },
    {
      "epoch": 2.0590072557781944,
      "grad_norm": 0.34162217378616333,
      "learning_rate": 3.970520397866513e-05,
      "loss": 0.0001,
      "step": 42850
    },
    {
      "epoch": 2.0614098313391955,
      "grad_norm": 0.1960538923740387,
      "learning_rate": 3.969319110086012e-05,
      "loss": 0.0003,
      "step": 42900
    },
    {
      "epoch": 2.063812406900197,
      "grad_norm": 0.41291847825050354,
      "learning_rate": 3.968117822305512e-05,
      "loss": 0.0002,
      "step": 42950
    },
    {
      "epoch": 2.0662149824611986,
      "grad_norm": 0.12590627372264862,
      "learning_rate": 3.966916534525011e-05,
      "loss": 0.0002,
      "step": 43000
    },
    {
      "epoch": 2.0686175580221997,
      "grad_norm": 0.3315293788909912,
      "learning_rate": 3.96571524674451e-05,
      "loss": 0.0002,
      "step": 43050
    },
    {
      "epoch": 2.0710201335832013,
      "grad_norm": 0.1501285284757614,
      "learning_rate": 3.9645139589640096e-05,
      "loss": 0.0002,
      "step": 43100
    },
    {
      "epoch": 2.073422709144203,
      "grad_norm": 0.10000620782375336,
      "learning_rate": 3.963312671183509e-05,
      "loss": 0.0002,
      "step": 43150
    },
    {
      "epoch": 2.075825284705204,
      "grad_norm": 0.3325801491737366,
      "learning_rate": 3.9621113834030085e-05,
      "loss": 0.0002,
      "step": 43200
    },
    {
      "epoch": 2.0782278602662054,
      "grad_norm": 0.14003141224384308,
      "learning_rate": 3.9609100956225076e-05,
      "loss": 0.0002,
      "step": 43250
    },
    {
      "epoch": 2.080630435827207,
      "grad_norm": 0.12950322031974792,
      "learning_rate": 3.9597088078420067e-05,
      "loss": 0.0002,
      "step": 43300
    },
    {
      "epoch": 2.083033011388208,
      "grad_norm": 0.1140657365322113,
      "learning_rate": 3.9585075200615064e-05,
      "loss": 0.0003,
      "step": 43350
    },
    {
      "epoch": 2.0854355869492096,
      "grad_norm": 0.26352718472480774,
      "learning_rate": 3.9573062322810055e-05,
      "loss": 0.0002,
      "step": 43400
    },
    {
      "epoch": 2.087838162510211,
      "grad_norm": 0.18859541416168213,
      "learning_rate": 3.956104944500505e-05,
      "loss": 0.0002,
      "step": 43450
    },
    {
      "epoch": 2.0902407380712122,
      "grad_norm": 0.15029484033584595,
      "learning_rate": 3.9549036567200043e-05,
      "loss": 0.0003,
      "step": 43500
    },
    {
      "epoch": 2.092643313632214,
      "grad_norm": 0.5811945199966431,
      "learning_rate": 3.953702368939503e-05,
      "loss": 0.0003,
      "step": 43550
    },
    {
      "epoch": 2.0950458891932153,
      "grad_norm": 0.15778213739395142,
      "learning_rate": 3.9525010811590025e-05,
      "loss": 0.0001,
      "step": 43600
    },
    {
      "epoch": 2.0974484647542164,
      "grad_norm": 0.2534387409687042,
      "learning_rate": 3.9512997933785016e-05,
      "loss": 0.0002,
      "step": 43650
    },
    {
      "epoch": 2.099851040315218,
      "grad_norm": 0.1965751349925995,
      "learning_rate": 3.9500985055980013e-05,
      "loss": 0.0002,
      "step": 43700
    },
    {
      "epoch": 2.1022536158762195,
      "grad_norm": 0.7179850935935974,
      "learning_rate": 3.9488972178175004e-05,
      "loss": 0.0002,
      "step": 43750
    },
    {
      "epoch": 2.1046561914372206,
      "grad_norm": 0.4146290719509125,
      "learning_rate": 3.9476959300369995e-05,
      "loss": 0.0002,
      "step": 43800
    },
    {
      "epoch": 2.107058766998222,
      "grad_norm": 0.18726973235607147,
      "learning_rate": 3.946494642256499e-05,
      "loss": 0.0002,
      "step": 43850
    },
    {
      "epoch": 2.1094613425592237,
      "grad_norm": 0.4824220538139343,
      "learning_rate": 3.9452933544759984e-05,
      "loss": 0.0002,
      "step": 43900
    },
    {
      "epoch": 2.111863918120225,
      "grad_norm": 0.11999401450157166,
      "learning_rate": 3.944092066695498e-05,
      "loss": 0.0002,
      "step": 43950
    },
    {
      "epoch": 2.1142664936812263,
      "grad_norm": 0.32918187975883484,
      "learning_rate": 3.942890778914997e-05,
      "loss": 0.0009,
      "step": 44000
    },
    {
      "epoch": 2.116669069242228,
      "grad_norm": 0.3474119305610657,
      "learning_rate": 3.941689491134496e-05,
      "loss": 0.0003,
      "step": 44050
    },
    {
      "epoch": 2.119071644803229,
      "grad_norm": 0.4124620854854584,
      "learning_rate": 3.940488203353996e-05,
      "loss": 0.0002,
      "step": 44100
    },
    {
      "epoch": 2.1214742203642305,
      "grad_norm": 0.2794119417667389,
      "learning_rate": 3.939286915573495e-05,
      "loss": 0.0002,
      "step": 44150
    },
    {
      "epoch": 2.123876795925232,
      "grad_norm": 0.11468055844306946,
      "learning_rate": 3.938085627792994e-05,
      "loss": 0.0003,
      "step": 44200
    },
    {
      "epoch": 2.126279371486233,
      "grad_norm": 0.4761878550052643,
      "learning_rate": 3.936884340012494e-05,
      "loss": 0.0004,
      "step": 44250
    },
    {
      "epoch": 2.1286819470472347,
      "grad_norm": 0.3860089182853699,
      "learning_rate": 3.9356830522319924e-05,
      "loss": 0.0002,
      "step": 44300
    },
    {
      "epoch": 2.131084522608236,
      "grad_norm": 0.14826983213424683,
      "learning_rate": 3.934481764451492e-05,
      "loss": 0.0002,
      "step": 44350
    },
    {
      "epoch": 2.1334870981692373,
      "grad_norm": 0.4868309199810028,
      "learning_rate": 3.933280476670991e-05,
      "loss": 0.0002,
      "step": 44400
    },
    {
      "epoch": 2.135889673730239,
      "grad_norm": 0.09596406668424606,
      "learning_rate": 3.932079188890491e-05,
      "loss": 0.0002,
      "step": 44450
    },
    {
      "epoch": 2.1382922492912404,
      "grad_norm": 0.27875491976737976,
      "learning_rate": 3.93087790110999e-05,
      "loss": 0.0002,
      "step": 44500
    },
    {
      "epoch": 2.1406948248522415,
      "grad_norm": 0.2913092076778412,
      "learning_rate": 3.929676613329489e-05,
      "loss": 0.0002,
      "step": 44550
    },
    {
      "epoch": 2.143097400413243,
      "grad_norm": 0.14076068997383118,
      "learning_rate": 3.928475325548989e-05,
      "loss": 0.0009,
      "step": 44600
    },
    {
      "epoch": 2.1454999759742446,
      "grad_norm": 0.4957664906978607,
      "learning_rate": 3.927274037768488e-05,
      "loss": 0.0003,
      "step": 44650
    },
    {
      "epoch": 2.1479025515352457,
      "grad_norm": 0.3024168610572815,
      "learning_rate": 3.926072749987987e-05,
      "loss": 0.0002,
      "step": 44700
    },
    {
      "epoch": 2.150305127096247,
      "grad_norm": 0.13192223012447357,
      "learning_rate": 3.924871462207487e-05,
      "loss": 0.0002,
      "step": 44750
    },
    {
      "epoch": 2.1527077026572488,
      "grad_norm": 0.07260045409202576,
      "learning_rate": 3.923670174426986e-05,
      "loss": 0.0002,
      "step": 44800
    },
    {
      "epoch": 2.15511027821825,
      "grad_norm": 0.19017286598682404,
      "learning_rate": 3.922468886646486e-05,
      "loss": 0.0002,
      "step": 44850
    },
    {
      "epoch": 2.1575128537792514,
      "grad_norm": 0.36822590231895447,
      "learning_rate": 3.921267598865985e-05,
      "loss": 0.0002,
      "step": 44900
    },
    {
      "epoch": 2.159915429340253,
      "grad_norm": 0.4991377592086792,
      "learning_rate": 3.920066311085484e-05,
      "loss": 0.0002,
      "step": 44950
    },
    {
      "epoch": 2.162318004901254,
      "grad_norm": 0.11468186229467392,
      "learning_rate": 3.9188650233049836e-05,
      "loss": 0.0003,
      "step": 45000
    },
    {
      "epoch": 2.1647205804622556,
      "grad_norm": 0.44088444113731384,
      "learning_rate": 3.917663735524482e-05,
      "loss": 0.0002,
      "step": 45050
    },
    {
      "epoch": 2.167123156023257,
      "grad_norm": 0.34834277629852295,
      "learning_rate": 3.916462447743982e-05,
      "loss": 0.0002,
      "step": 45100
    },
    {
      "epoch": 2.169525731584258,
      "grad_norm": 0.32602766156196594,
      "learning_rate": 3.915261159963481e-05,
      "loss": 0.0003,
      "step": 45150
    },
    {
      "epoch": 2.1719283071452598,
      "grad_norm": 0.2342442274093628,
      "learning_rate": 3.91405987218298e-05,
      "loss": 0.0002,
      "step": 45200
    },
    {
      "epoch": 2.1743308827062613,
      "grad_norm": 0.23244930803775787,
      "learning_rate": 3.91285858440248e-05,
      "loss": 0.0002,
      "step": 45250
    },
    {
      "epoch": 2.1767334582672624,
      "grad_norm": 0.6862323880195618,
      "learning_rate": 3.911657296621979e-05,
      "loss": 0.0002,
      "step": 45300
    },
    {
      "epoch": 2.179136033828264,
      "grad_norm": 0.27291640639305115,
      "learning_rate": 3.9104560088414785e-05,
      "loss": 0.001,
      "step": 45350
    },
    {
      "epoch": 2.1815386093892655,
      "grad_norm": 0.30406635999679565,
      "learning_rate": 3.9092547210609776e-05,
      "loss": 0.0002,
      "step": 45400
    },
    {
      "epoch": 2.1839411849502666,
      "grad_norm": 0.5573268532752991,
      "learning_rate": 3.908053433280477e-05,
      "loss": 0.0002,
      "step": 45450
    },
    {
      "epoch": 2.186343760511268,
      "grad_norm": 0.5311020016670227,
      "learning_rate": 3.9068521454999765e-05,
      "loss": 0.0004,
      "step": 45500
    },
    {
      "epoch": 2.1887463360722696,
      "grad_norm": 0.10427602380514145,
      "learning_rate": 3.9056508577194755e-05,
      "loss": 0.0003,
      "step": 45550
    },
    {
      "epoch": 2.1911489116332707,
      "grad_norm": 0.15815120935440063,
      "learning_rate": 3.9044495699389746e-05,
      "loss": 0.0009,
      "step": 45600
    },
    {
      "epoch": 2.1935514871942723,
      "grad_norm": 0.10921337455511093,
      "learning_rate": 3.9032482821584744e-05,
      "loss": 0.0002,
      "step": 45650
    },
    {
      "epoch": 2.195954062755274,
      "grad_norm": 0.026543952524662018,
      "learning_rate": 3.9020469943779735e-05,
      "loss": 0.0006,
      "step": 45700
    },
    {
      "epoch": 2.198356638316275,
      "grad_norm": 0.08750864118337631,
      "learning_rate": 3.900845706597473e-05,
      "loss": 0.0002,
      "step": 45750
    },
    {
      "epoch": 2.2007592138772765,
      "grad_norm": 0.09981412440538406,
      "learning_rate": 3.8996444188169716e-05,
      "loss": 0.0003,
      "step": 45800
    },
    {
      "epoch": 2.203161789438278,
      "grad_norm": 0.5961414575576782,
      "learning_rate": 3.8984431310364714e-05,
      "loss": 0.0002,
      "step": 45850
    },
    {
      "epoch": 2.205564364999279,
      "grad_norm": 0.16566337645053864,
      "learning_rate": 3.8972418432559705e-05,
      "loss": 0.0002,
      "step": 45900
    },
    {
      "epoch": 2.2079669405602806,
      "grad_norm": 0.2915385663509369,
      "learning_rate": 3.8960405554754696e-05,
      "loss": 0.0003,
      "step": 45950
    },
    {
      "epoch": 2.210369516121282,
      "grad_norm": 0.26650068163871765,
      "learning_rate": 3.894839267694969e-05,
      "loss": 0.0002,
      "step": 46000
    },
    {
      "epoch": 2.2127720916822833,
      "grad_norm": 0.1880682110786438,
      "learning_rate": 3.8936379799144684e-05,
      "loss": 0.0002,
      "step": 46050
    },
    {
      "epoch": 2.215174667243285,
      "grad_norm": 0.23392058908939362,
      "learning_rate": 3.8924366921339675e-05,
      "loss": 0.0002,
      "step": 46100
    },
    {
      "epoch": 2.2175772428042864,
      "grad_norm": 0.13683022558689117,
      "learning_rate": 3.891235404353467e-05,
      "loss": 0.0002,
      "step": 46150
    },
    {
      "epoch": 2.2199798183652875,
      "grad_norm": 0.5785334706306458,
      "learning_rate": 3.890034116572966e-05,
      "loss": 0.0002,
      "step": 46200
    },
    {
      "epoch": 2.222382393926289,
      "grad_norm": 0.7189435362815857,
      "learning_rate": 3.888832828792466e-05,
      "loss": 0.0002,
      "step": 46250
    },
    {
      "epoch": 2.2247849694872905,
      "grad_norm": 0.4476172924041748,
      "learning_rate": 3.887631541011965e-05,
      "loss": 0.0002,
      "step": 46300
    },
    {
      "epoch": 2.2271875450482916,
      "grad_norm": 0.3143037259578705,
      "learning_rate": 3.886430253231464e-05,
      "loss": 0.0002,
      "step": 46350
    },
    {
      "epoch": 2.229590120609293,
      "grad_norm": 0.14240920543670654,
      "learning_rate": 3.885228965450964e-05,
      "loss": 0.0002,
      "step": 46400
    },
    {
      "epoch": 2.2319926961702947,
      "grad_norm": 0.25518548488616943,
      "learning_rate": 3.884027677670463e-05,
      "loss": 0.0002,
      "step": 46450
    },
    {
      "epoch": 2.234395271731296,
      "grad_norm": 0.29122698307037354,
      "learning_rate": 3.882826389889962e-05,
      "loss": 0.0004,
      "step": 46500
    },
    {
      "epoch": 2.2367978472922974,
      "grad_norm": 0.22359032928943634,
      "learning_rate": 3.881625102109461e-05,
      "loss": 0.0002,
      "step": 46550
    },
    {
      "epoch": 2.239200422853299,
      "grad_norm": 0.07996029406785965,
      "learning_rate": 3.88042381432896e-05,
      "loss": 0.0002,
      "step": 46600
    },
    {
      "epoch": 2.2416029984143,
      "grad_norm": 0.06111347675323486,
      "learning_rate": 3.87922252654846e-05,
      "loss": 0.0002,
      "step": 46650
    },
    {
      "epoch": 2.2440055739753015,
      "grad_norm": 0.1859862357378006,
      "learning_rate": 3.878021238767959e-05,
      "loss": 0.0002,
      "step": 46700
    },
    {
      "epoch": 2.246408149536303,
      "grad_norm": 0.4853624999523163,
      "learning_rate": 3.876819950987459e-05,
      "loss": 0.0002,
      "step": 46750
    },
    {
      "epoch": 2.248810725097304,
      "grad_norm": 0.219403937458992,
      "learning_rate": 3.875618663206958e-05,
      "loss": 0.0002,
      "step": 46800
    },
    {
      "epoch": 2.2512133006583057,
      "grad_norm": 0.5107920169830322,
      "learning_rate": 3.874417375426457e-05,
      "loss": 0.0002,
      "step": 46850
    },
    {
      "epoch": 2.2536158762193073,
      "grad_norm": 0.3223479092121124,
      "learning_rate": 3.873216087645957e-05,
      "loss": 0.0001,
      "step": 46900
    },
    {
      "epoch": 2.2560184517803084,
      "grad_norm": 0.17748184502124786,
      "learning_rate": 3.872014799865456e-05,
      "loss": 0.0002,
      "step": 46950
    },
    {
      "epoch": 2.25842102734131,
      "grad_norm": 0.24607300758361816,
      "learning_rate": 3.870813512084955e-05,
      "loss": 0.0002,
      "step": 47000
    },
    {
      "epoch": 2.2608236029023114,
      "grad_norm": 0.15607105195522308,
      "learning_rate": 3.869612224304455e-05,
      "loss": 0.0002,
      "step": 47050
    },
    {
      "epoch": 2.2632261784633125,
      "grad_norm": 0.18539200723171234,
      "learning_rate": 3.868410936523954e-05,
      "loss": 0.0006,
      "step": 47100
    },
    {
      "epoch": 2.265628754024314,
      "grad_norm": 0.07958295196294785,
      "learning_rate": 3.8672096487434536e-05,
      "loss": 0.0002,
      "step": 47150
    },
    {
      "epoch": 2.2680313295853156,
      "grad_norm": 0.1205616444349289,
      "learning_rate": 3.866008360962953e-05,
      "loss": 0.0002,
      "step": 47200
    },
    {
      "epoch": 2.2704339051463167,
      "grad_norm": 0.09531211107969284,
      "learning_rate": 3.864807073182452e-05,
      "loss": 0.0002,
      "step": 47250
    },
    {
      "epoch": 2.2728364807073183,
      "grad_norm": 0.1425720602273941,
      "learning_rate": 3.863605785401951e-05,
      "loss": 0.0002,
      "step": 47300
    },
    {
      "epoch": 2.27523905626832,
      "grad_norm": 0.27886897325515747,
      "learning_rate": 3.86240449762145e-05,
      "loss": 0.0002,
      "step": 47350
    },
    {
      "epoch": 2.277641631829321,
      "grad_norm": 0.08373530954122543,
      "learning_rate": 3.86120320984095e-05,
      "loss": 0.0002,
      "step": 47400
    },
    {
      "epoch": 2.2800442073903224,
      "grad_norm": 0.3432517647743225,
      "learning_rate": 3.860001922060449e-05,
      "loss": 0.0008,
      "step": 47450
    },
    {
      "epoch": 2.282446782951324,
      "grad_norm": 0.5364928841590881,
      "learning_rate": 3.858800634279948e-05,
      "loss": 0.0002,
      "step": 47500
    },
    {
      "epoch": 2.284849358512325,
      "grad_norm": 0.4432714283466339,
      "learning_rate": 3.8575993464994476e-05,
      "loss": 0.0002,
      "step": 47550
    },
    {
      "epoch": 2.2872519340733266,
      "grad_norm": 0.23081105947494507,
      "learning_rate": 3.856398058718947e-05,
      "loss": 0.0002,
      "step": 47600
    },
    {
      "epoch": 2.289654509634328,
      "grad_norm": 0.2035466432571411,
      "learning_rate": 3.8551967709384465e-05,
      "loss": 0.0007,
      "step": 47650
    },
    {
      "epoch": 2.2920570851953292,
      "grad_norm": 0.5064334869384766,
      "learning_rate": 3.8539954831579456e-05,
      "loss": 0.0002,
      "step": 47700
    },
    {
      "epoch": 2.294459660756331,
      "grad_norm": 0.24495740234851837,
      "learning_rate": 3.8527941953774447e-05,
      "loss": 0.0002,
      "step": 47750
    },
    {
      "epoch": 2.2968622363173323,
      "grad_norm": 0.3566277325153351,
      "learning_rate": 3.8515929075969444e-05,
      "loss": 0.0003,
      "step": 47800
    },
    {
      "epoch": 2.2992648118783334,
      "grad_norm": 0.05187039077281952,
      "learning_rate": 3.8503916198164435e-05,
      "loss": 0.0002,
      "step": 47850
    },
    {
      "epoch": 2.301667387439335,
      "grad_norm": 0.26571962237358093,
      "learning_rate": 3.849190332035943e-05,
      "loss": 0.0002,
      "step": 47900
    },
    {
      "epoch": 2.3040699630003365,
      "grad_norm": 0.430929958820343,
      "learning_rate": 3.847989044255442e-05,
      "loss": 0.0003,
      "step": 47950
    },
    {
      "epoch": 2.3064725385613376,
      "grad_norm": 0.17873312532901764,
      "learning_rate": 3.846787756474941e-05,
      "loss": 0.0006,
      "step": 48000
    },
    {
      "epoch": 2.308875114122339,
      "grad_norm": 0.05599689856171608,
      "learning_rate": 3.8455864686944405e-05,
      "loss": 0.0001,
      "step": 48050
    },
    {
      "epoch": 2.3112776896833407,
      "grad_norm": 0.33917635679244995,
      "learning_rate": 3.8443851809139396e-05,
      "loss": 0.0002,
      "step": 48100
    },
    {
      "epoch": 2.313680265244342,
      "grad_norm": 0.14813312888145447,
      "learning_rate": 3.8431838931334393e-05,
      "loss": 0.0002,
      "step": 48150
    },
    {
      "epoch": 2.3160828408053433,
      "grad_norm": 0.10982035100460052,
      "learning_rate": 3.8419826053529384e-05,
      "loss": 0.0008,
      "step": 48200
    },
    {
      "epoch": 2.318485416366345,
      "grad_norm": 0.24600502848625183,
      "learning_rate": 3.8407813175724375e-05,
      "loss": 0.0002,
      "step": 48250
    },
    {
      "epoch": 2.320887991927346,
      "grad_norm": 0.29639747738838196,
      "learning_rate": 3.839580029791937e-05,
      "loss": 0.0002,
      "step": 48300
    },
    {
      "epoch": 2.3232905674883475,
      "grad_norm": 0.42210984230041504,
      "learning_rate": 3.8383787420114364e-05,
      "loss": 0.0002,
      "step": 48350
    },
    {
      "epoch": 2.325693143049349,
      "grad_norm": 0.40594974160194397,
      "learning_rate": 3.837177454230936e-05,
      "loss": 0.0002,
      "step": 48400
    },
    {
      "epoch": 2.32809571861035,
      "grad_norm": 0.09081798791885376,
      "learning_rate": 3.835976166450435e-05,
      "loss": 0.0002,
      "step": 48450
    },
    {
      "epoch": 2.3304982941713517,
      "grad_norm": 0.1842746138572693,
      "learning_rate": 3.834774878669934e-05,
      "loss": 0.0002,
      "step": 48500
    },
    {
      "epoch": 2.332900869732353,
      "grad_norm": 0.28261369466781616,
      "learning_rate": 3.833573590889434e-05,
      "loss": 0.0002,
      "step": 48550
    },
    {
      "epoch": 2.3353034452933543,
      "grad_norm": 0.6386477947235107,
      "learning_rate": 3.832372303108933e-05,
      "loss": 0.0002,
      "step": 48600
    },
    {
      "epoch": 2.337706020854356,
      "grad_norm": 0.21331153810024261,
      "learning_rate": 3.831171015328432e-05,
      "loss": 0.0002,
      "step": 48650
    },
    {
      "epoch": 2.3401085964153574,
      "grad_norm": 0.08838251978158951,
      "learning_rate": 3.829969727547932e-05,
      "loss": 0.0002,
      "step": 48700
    },
    {
      "epoch": 2.3425111719763585,
      "grad_norm": 0.08817286789417267,
      "learning_rate": 3.8287684397674304e-05,
      "loss": 0.0002,
      "step": 48750
    },
    {
      "epoch": 2.34491374753736,
      "grad_norm": 0.08719487488269806,
      "learning_rate": 3.82756715198693e-05,
      "loss": 0.0002,
      "step": 48800
    },
    {
      "epoch": 2.3473163230983616,
      "grad_norm": 0.22962523996829987,
      "learning_rate": 3.826365864206429e-05,
      "loss": 0.0006,
      "step": 48850
    },
    {
      "epoch": 2.3497188986593627,
      "grad_norm": 0.20017869770526886,
      "learning_rate": 3.825164576425928e-05,
      "loss": 0.0002,
      "step": 48900
    },
    {
      "epoch": 2.352121474220364,
      "grad_norm": 0.28335925936698914,
      "learning_rate": 3.823963288645428e-05,
      "loss": 0.0002,
      "step": 48950
    },
    {
      "epoch": 2.3545240497813658,
      "grad_norm": 0.32257020473480225,
      "learning_rate": 3.822762000864927e-05,
      "loss": 0.0007,
      "step": 49000
    },
    {
      "epoch": 2.356926625342367,
      "grad_norm": 0.14557114243507385,
      "learning_rate": 3.821560713084427e-05,
      "loss": 0.0002,
      "step": 49050
    },
    {
      "epoch": 2.3593292009033684,
      "grad_norm": 0.6019649505615234,
      "learning_rate": 3.820359425303926e-05,
      "loss": 0.0002,
      "step": 49100
    },
    {
      "epoch": 2.36173177646437,
      "grad_norm": 0.27241069078445435,
      "learning_rate": 3.819158137523425e-05,
      "loss": 0.0002,
      "step": 49150
    },
    {
      "epoch": 2.364134352025371,
      "grad_norm": 0.38180437684059143,
      "learning_rate": 3.817956849742925e-05,
      "loss": 0.0002,
      "step": 49200
    },
    {
      "epoch": 2.3665369275863726,
      "grad_norm": 0.3749006390571594,
      "learning_rate": 3.816755561962424e-05,
      "loss": 0.0002,
      "step": 49250
    },
    {
      "epoch": 2.368939503147374,
      "grad_norm": 0.25643396377563477,
      "learning_rate": 3.815554274181924e-05,
      "loss": 0.001,
      "step": 49300
    },
    {
      "epoch": 2.371342078708375,
      "grad_norm": 0.11560656130313873,
      "learning_rate": 3.814352986401423e-05,
      "loss": 0.0002,
      "step": 49350
    },
    {
      "epoch": 2.3737446542693768,
      "grad_norm": 0.2089674323797226,
      "learning_rate": 3.813151698620922e-05,
      "loss": 0.0002,
      "step": 49400
    },
    {
      "epoch": 2.3761472298303783,
      "grad_norm": 0.07389693707227707,
      "learning_rate": 3.8119504108404216e-05,
      "loss": 0.0003,
      "step": 49450
    },
    {
      "epoch": 2.3785498053913794,
      "grad_norm": 0.05217525362968445,
      "learning_rate": 3.81074912305992e-05,
      "loss": 0.0002,
      "step": 49500
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.10198366641998291,
      "learning_rate": 3.80954783527942e-05,
      "loss": 0.0002,
      "step": 49550
    },
    {
      "epoch": 2.3833549565133825,
      "grad_norm": 0.19105136394500732,
      "learning_rate": 3.808346547498919e-05,
      "loss": 0.0003,
      "step": 49600
    },
    {
      "epoch": 2.3857575320743836,
      "grad_norm": 0.4490693211555481,
      "learning_rate": 3.807145259718418e-05,
      "loss": 0.0002,
      "step": 49650
    },
    {
      "epoch": 2.388160107635385,
      "grad_norm": 0.09384104609489441,
      "learning_rate": 3.805943971937918e-05,
      "loss": 0.0002,
      "step": 49700
    },
    {
      "epoch": 2.3905626831963867,
      "grad_norm": 0.3071911931037903,
      "learning_rate": 3.804742684157417e-05,
      "loss": 0.0002,
      "step": 49750
    },
    {
      "epoch": 2.3929652587573877,
      "grad_norm": 0.32043397426605225,
      "learning_rate": 3.8035413963769165e-05,
      "loss": 0.0002,
      "step": 49800
    },
    {
      "epoch": 2.3953678343183893,
      "grad_norm": 0.4881574809551239,
      "learning_rate": 3.8023401085964156e-05,
      "loss": 0.0002,
      "step": 49850
    },
    {
      "epoch": 2.397770409879391,
      "grad_norm": 0.2008199840784073,
      "learning_rate": 3.801138820815915e-05,
      "loss": 0.0002,
      "step": 49900
    },
    {
      "epoch": 2.400172985440392,
      "grad_norm": 0.12875087559223175,
      "learning_rate": 3.7999375330354144e-05,
      "loss": 0.0002,
      "step": 49950
    },
    {
      "epoch": 2.4025755610013935,
      "grad_norm": 0.14735540747642517,
      "learning_rate": 3.7987362452549135e-05,
      "loss": 0.0002,
      "step": 50000
    },
    {
      "epoch": 2.404978136562395,
      "grad_norm": 0.19596697390079498,
      "learning_rate": 3.7975349574744126e-05,
      "loss": 0.0002,
      "step": 50050
    },
    {
      "epoch": 2.407380712123396,
      "grad_norm": 0.32098472118377686,
      "learning_rate": 3.7963336696939124e-05,
      "loss": 0.0007,
      "step": 50100
    },
    {
      "epoch": 2.4097832876843976,
      "grad_norm": 0.10349211096763611,
      "learning_rate": 3.7951323819134115e-05,
      "loss": 0.0008,
      "step": 50150
    },
    {
      "epoch": 2.412185863245399,
      "grad_norm": 0.16324423253536224,
      "learning_rate": 3.793931094132911e-05,
      "loss": 0.0003,
      "step": 50200
    },
    {
      "epoch": 2.4145884388064003,
      "grad_norm": 0.17664235830307007,
      "learning_rate": 3.7927298063524096e-05,
      "loss": 0.0003,
      "step": 50250
    },
    {
      "epoch": 2.416991014367402,
      "grad_norm": 0.19690953195095062,
      "learning_rate": 3.7915285185719094e-05,
      "loss": 0.0002,
      "step": 50300
    },
    {
      "epoch": 2.4193935899284034,
      "grad_norm": 0.1554660052061081,
      "learning_rate": 3.7903272307914085e-05,
      "loss": 0.0008,
      "step": 50350
    },
    {
      "epoch": 2.4217961654894045,
      "grad_norm": 0.49002084136009216,
      "learning_rate": 3.7891259430109075e-05,
      "loss": 0.0002,
      "step": 50400
    },
    {
      "epoch": 2.424198741050406,
      "grad_norm": 0.3025818169116974,
      "learning_rate": 3.787924655230407e-05,
      "loss": 0.0008,
      "step": 50450
    },
    {
      "epoch": 2.4266013166114075,
      "grad_norm": 0.27222463488578796,
      "learning_rate": 3.7867233674499064e-05,
      "loss": 0.0003,
      "step": 50500
    },
    {
      "epoch": 2.4290038921724086,
      "grad_norm": 0.14062543213367462,
      "learning_rate": 3.7855220796694055e-05,
      "loss": 0.0001,
      "step": 50550
    },
    {
      "epoch": 2.43140646773341,
      "grad_norm": 0.036847565323114395,
      "learning_rate": 3.784320791888905e-05,
      "loss": 0.0002,
      "step": 50600
    },
    {
      "epoch": 2.4338090432944117,
      "grad_norm": 0.3089803457260132,
      "learning_rate": 3.783119504108404e-05,
      "loss": 0.0002,
      "step": 50650
    },
    {
      "epoch": 2.436211618855413,
      "grad_norm": 0.34555330872535706,
      "learning_rate": 3.781918216327904e-05,
      "loss": 0.0002,
      "step": 50700
    },
    {
      "epoch": 2.4386141944164144,
      "grad_norm": 0.2504410147666931,
      "learning_rate": 3.780716928547403e-05,
      "loss": 0.0002,
      "step": 50750
    },
    {
      "epoch": 2.441016769977416,
      "grad_norm": 0.14386649429798126,
      "learning_rate": 3.779515640766902e-05,
      "loss": 0.0002,
      "step": 50800
    },
    {
      "epoch": 2.443419345538417,
      "grad_norm": 0.3493916392326355,
      "learning_rate": 3.778314352986402e-05,
      "loss": 0.0008,
      "step": 50850
    },
    {
      "epoch": 2.4458219210994185,
      "grad_norm": 0.7136110663414001,
      "learning_rate": 3.777113065205901e-05,
      "loss": 0.0002,
      "step": 50900
    },
    {
      "epoch": 2.44822449666042,
      "grad_norm": 0.3839907944202423,
      "learning_rate": 3.7759117774254e-05,
      "loss": 0.0007,
      "step": 50950
    },
    {
      "epoch": 2.450627072221421,
      "grad_norm": 0.5920220017433167,
      "learning_rate": 3.774710489644899e-05,
      "loss": 0.0002,
      "step": 51000
    },
    {
      "epoch": 2.4530296477824227,
      "grad_norm": 0.13505339622497559,
      "learning_rate": 3.773509201864398e-05,
      "loss": 0.0002,
      "step": 51050
    },
    {
      "epoch": 2.4554322233434243,
      "grad_norm": 0.22719036042690277,
      "learning_rate": 3.772307914083898e-05,
      "loss": 0.0002,
      "step": 51100
    },
    {
      "epoch": 2.4578347989044254,
      "grad_norm": 0.35509854555130005,
      "learning_rate": 3.771106626303397e-05,
      "loss": 0.0002,
      "step": 51150
    },
    {
      "epoch": 2.460237374465427,
      "grad_norm": 0.09054353088140488,
      "learning_rate": 3.769905338522897e-05,
      "loss": 0.0002,
      "step": 51200
    },
    {
      "epoch": 2.4626399500264284,
      "grad_norm": 0.10326522588729858,
      "learning_rate": 3.768704050742396e-05,
      "loss": 0.0007,
      "step": 51250
    },
    {
      "epoch": 2.4650425255874295,
      "grad_norm": 0.2109566628932953,
      "learning_rate": 3.767502762961895e-05,
      "loss": 0.0002,
      "step": 51300
    },
    {
      "epoch": 2.467445101148431,
      "grad_norm": 0.05849549546837807,
      "learning_rate": 3.766301475181395e-05,
      "loss": 0.0002,
      "step": 51350
    },
    {
      "epoch": 2.4698476767094326,
      "grad_norm": 0.16460618376731873,
      "learning_rate": 3.765100187400894e-05,
      "loss": 0.0002,
      "step": 51400
    },
    {
      "epoch": 2.4722502522704337,
      "grad_norm": 0.4063788056373596,
      "learning_rate": 3.763898899620393e-05,
      "loss": 0.0003,
      "step": 51450
    },
    {
      "epoch": 2.4746528278314353,
      "grad_norm": 0.34655970335006714,
      "learning_rate": 3.762697611839893e-05,
      "loss": 0.0002,
      "step": 51500
    },
    {
      "epoch": 2.477055403392437,
      "grad_norm": 0.18148593604564667,
      "learning_rate": 3.761496324059392e-05,
      "loss": 0.0002,
      "step": 51550
    },
    {
      "epoch": 2.4794579789534383,
      "grad_norm": 0.14968380331993103,
      "learning_rate": 3.7602950362788916e-05,
      "loss": 0.0002,
      "step": 51600
    },
    {
      "epoch": 2.4818605545144394,
      "grad_norm": 0.20912259817123413,
      "learning_rate": 3.759093748498391e-05,
      "loss": 0.0002,
      "step": 51650
    },
    {
      "epoch": 2.484263130075441,
      "grad_norm": 0.41967856884002686,
      "learning_rate": 3.75789246071789e-05,
      "loss": 0.0002,
      "step": 51700
    },
    {
      "epoch": 2.486665705636442,
      "grad_norm": 0.22091145813465118,
      "learning_rate": 3.756691172937389e-05,
      "loss": 0.0003,
      "step": 51750
    },
    {
      "epoch": 2.4890682811974436,
      "grad_norm": 0.31154927611351013,
      "learning_rate": 3.755489885156888e-05,
      "loss": 0.0002,
      "step": 51800
    },
    {
      "epoch": 2.491470856758445,
      "grad_norm": 0.10159236937761307,
      "learning_rate": 3.754288597376388e-05,
      "loss": 0.0002,
      "step": 51850
    },
    {
      "epoch": 2.4938734323194467,
      "grad_norm": 0.06439867615699768,
      "learning_rate": 3.753087309595887e-05,
      "loss": 0.0003,
      "step": 51900
    },
    {
      "epoch": 2.496276007880448,
      "grad_norm": 0.07878109067678452,
      "learning_rate": 3.751886021815386e-05,
      "loss": 0.0002,
      "step": 51950
    },
    {
      "epoch": 2.4986785834414493,
      "grad_norm": 0.49044182896614075,
      "learning_rate": 3.7506847340348856e-05,
      "loss": 0.0002,
      "step": 52000
    },
    {
      "epoch": 2.5010811590024504,
      "grad_norm": 0.11166366189718246,
      "learning_rate": 3.749483446254385e-05,
      "loss": 0.0002,
      "step": 52050
    },
    {
      "epoch": 2.503483734563452,
      "grad_norm": 0.2606707215309143,
      "learning_rate": 3.7482821584738845e-05,
      "loss": 0.0002,
      "step": 52100
    },
    {
      "epoch": 2.5058863101244535,
      "grad_norm": 0.203792542219162,
      "learning_rate": 3.7470808706933836e-05,
      "loss": 0.0003,
      "step": 52150
    },
    {
      "epoch": 2.508288885685455,
      "grad_norm": 0.33067938685417175,
      "learning_rate": 3.7458795829128826e-05,
      "loss": 0.0002,
      "step": 52200
    },
    {
      "epoch": 2.510691461246456,
      "grad_norm": 0.4558263421058655,
      "learning_rate": 3.7446782951323824e-05,
      "loss": 0.0003,
      "step": 52250
    },
    {
      "epoch": 2.5130940368074577,
      "grad_norm": 0.030555231496691704,
      "learning_rate": 3.7434770073518815e-05,
      "loss": 0.0003,
      "step": 52300
    },
    {
      "epoch": 2.515496612368459,
      "grad_norm": 0.23773618042469025,
      "learning_rate": 3.7422757195713806e-05,
      "loss": 0.0002,
      "step": 52350
    },
    {
      "epoch": 2.5178991879294603,
      "grad_norm": 0.17746661603450775,
      "learning_rate": 3.74107443179088e-05,
      "loss": 0.0002,
      "step": 52400
    },
    {
      "epoch": 2.520301763490462,
      "grad_norm": 0.41970378160476685,
      "learning_rate": 3.7398731440103794e-05,
      "loss": 0.0002,
      "step": 52450
    },
    {
      "epoch": 2.5227043390514634,
      "grad_norm": 0.13039414584636688,
      "learning_rate": 3.7386718562298785e-05,
      "loss": 0.0002,
      "step": 52500
    },
    {
      "epoch": 2.5251069146124645,
      "grad_norm": 0.2873457968235016,
      "learning_rate": 3.7374705684493776e-05,
      "loss": 0.0002,
      "step": 52550
    },
    {
      "epoch": 2.527509490173466,
      "grad_norm": 0.49351564049720764,
      "learning_rate": 3.7362692806688773e-05,
      "loss": 0.0002,
      "step": 52600
    },
    {
      "epoch": 2.529912065734467,
      "grad_norm": 0.34878674149513245,
      "learning_rate": 3.7350679928883764e-05,
      "loss": 0.0002,
      "step": 52650
    },
    {
      "epoch": 2.5323146412954687,
      "grad_norm": 0.277617484331131,
      "learning_rate": 3.7338667051078755e-05,
      "loss": 0.0002,
      "step": 52700
    },
    {
      "epoch": 2.5347172168564702,
      "grad_norm": 0.1591365784406662,
      "learning_rate": 3.732665417327375e-05,
      "loss": 0.0002,
      "step": 52750
    },
    {
      "epoch": 2.5371197924174718,
      "grad_norm": 0.12611614167690277,
      "learning_rate": 3.7314641295468744e-05,
      "loss": 0.0002,
      "step": 52800
    },
    {
      "epoch": 2.539522367978473,
      "grad_norm": 0.15142673254013062,
      "learning_rate": 3.7302628417663734e-05,
      "loss": 0.0002,
      "step": 52850
    },
    {
      "epoch": 2.5419249435394744,
      "grad_norm": 0.08408248424530029,
      "learning_rate": 3.729061553985873e-05,
      "loss": 0.0002,
      "step": 52900
    },
    {
      "epoch": 2.5443275191004755,
      "grad_norm": 0.363165020942688,
      "learning_rate": 3.727860266205372e-05,
      "loss": 0.0002,
      "step": 52950
    },
    {
      "epoch": 2.546730094661477,
      "grad_norm": 0.30199557542800903,
      "learning_rate": 3.726658978424872e-05,
      "loss": 0.0002,
      "step": 53000
    },
    {
      "epoch": 2.5491326702224786,
      "grad_norm": 0.40148210525512695,
      "learning_rate": 3.725457690644371e-05,
      "loss": 0.0002,
      "step": 53050
    },
    {
      "epoch": 2.55153524578348,
      "grad_norm": 0.18880371749401093,
      "learning_rate": 3.72425640286387e-05,
      "loss": 0.0002,
      "step": 53100
    },
    {
      "epoch": 2.553937821344481,
      "grad_norm": 0.8357138633728027,
      "learning_rate": 3.72305511508337e-05,
      "loss": 0.0002,
      "step": 53150
    },
    {
      "epoch": 2.5563403969054828,
      "grad_norm": 0.2890995442867279,
      "learning_rate": 3.7218538273028684e-05,
      "loss": 0.0002,
      "step": 53200
    },
    {
      "epoch": 2.558742972466484,
      "grad_norm": 0.26466628909111023,
      "learning_rate": 3.720652539522368e-05,
      "loss": 0.0007,
      "step": 53250
    },
    {
      "epoch": 2.5611455480274854,
      "grad_norm": 0.13673743605613708,
      "learning_rate": 3.719451251741867e-05,
      "loss": 0.0002,
      "step": 53300
    },
    {
      "epoch": 2.563548123588487,
      "grad_norm": 0.27792394161224365,
      "learning_rate": 3.718249963961366e-05,
      "loss": 0.0002,
      "step": 53350
    },
    {
      "epoch": 2.5659506991494885,
      "grad_norm": 0.5920325517654419,
      "learning_rate": 3.717048676180866e-05,
      "loss": 0.0003,
      "step": 53400
    },
    {
      "epoch": 2.5683532747104896,
      "grad_norm": 0.35453492403030396,
      "learning_rate": 3.715847388400365e-05,
      "loss": 0.0001,
      "step": 53450
    },
    {
      "epoch": 2.570755850271491,
      "grad_norm": 0.07775140553712845,
      "learning_rate": 3.714646100619865e-05,
      "loss": 0.0002,
      "step": 53500
    },
    {
      "epoch": 2.573158425832492,
      "grad_norm": 0.22362381219863892,
      "learning_rate": 3.713444812839364e-05,
      "loss": 0.0002,
      "step": 53550
    },
    {
      "epoch": 2.5755610013934938,
      "grad_norm": 0.14409303665161133,
      "learning_rate": 3.712243525058863e-05,
      "loss": 0.0002,
      "step": 53600
    },
    {
      "epoch": 2.5779635769544953,
      "grad_norm": 0.2725564241409302,
      "learning_rate": 3.711042237278363e-05,
      "loss": 0.0002,
      "step": 53650
    },
    {
      "epoch": 2.580366152515497,
      "grad_norm": 0.317215234041214,
      "learning_rate": 3.709840949497862e-05,
      "loss": 0.0003,
      "step": 53700
    },
    {
      "epoch": 2.582768728076498,
      "grad_norm": 0.03501782938838005,
      "learning_rate": 3.708639661717362e-05,
      "loss": 0.0003,
      "step": 53750
    },
    {
      "epoch": 2.5851713036374995,
      "grad_norm": 0.1525425910949707,
      "learning_rate": 3.707438373936861e-05,
      "loss": 0.0002,
      "step": 53800
    },
    {
      "epoch": 2.5875738791985006,
      "grad_norm": 0.11339621990919113,
      "learning_rate": 3.70623708615636e-05,
      "loss": 0.0002,
      "step": 53850
    },
    {
      "epoch": 2.589976454759502,
      "grad_norm": 0.1524539589881897,
      "learning_rate": 3.7050357983758596e-05,
      "loss": 0.0002,
      "step": 53900
    },
    {
      "epoch": 2.5923790303205037,
      "grad_norm": 0.17886769771575928,
      "learning_rate": 3.703834510595358e-05,
      "loss": 0.0002,
      "step": 53950
    },
    {
      "epoch": 2.594781605881505,
      "grad_norm": 0.1955372840166092,
      "learning_rate": 3.702633222814858e-05,
      "loss": 0.0002,
      "step": 54000
    },
    {
      "epoch": 2.5971841814425063,
      "grad_norm": 0.5436677932739258,
      "learning_rate": 3.701431935034357e-05,
      "loss": 0.0003,
      "step": 54050
    },
    {
      "epoch": 2.599586757003508,
      "grad_norm": 0.19271399080753326,
      "learning_rate": 3.700230647253856e-05,
      "loss": 0.0002,
      "step": 54100
    },
    {
      "epoch": 2.601989332564509,
      "grad_norm": 0.14898604154586792,
      "learning_rate": 3.699029359473356e-05,
      "loss": 0.0002,
      "step": 54150
    },
    {
      "epoch": 2.6043919081255105,
      "grad_norm": 0.40297433733940125,
      "learning_rate": 3.697828071692855e-05,
      "loss": 0.0002,
      "step": 54200
    },
    {
      "epoch": 2.606794483686512,
      "grad_norm": 0.2033635824918747,
      "learning_rate": 3.696626783912354e-05,
      "loss": 0.0002,
      "step": 54250
    },
    {
      "epoch": 2.6091970592475136,
      "grad_norm": 0.5466210246086121,
      "learning_rate": 3.6954254961318536e-05,
      "loss": 0.0003,
      "step": 54300
    },
    {
      "epoch": 2.6115996348085146,
      "grad_norm": 0.5983782410621643,
      "learning_rate": 3.694224208351353e-05,
      "loss": 0.0007,
      "step": 54350
    },
    {
      "epoch": 2.614002210369516,
      "grad_norm": 0.24613085389137268,
      "learning_rate": 3.6930229205708524e-05,
      "loss": 0.0002,
      "step": 54400
    },
    {
      "epoch": 2.6164047859305173,
      "grad_norm": 0.27397337555885315,
      "learning_rate": 3.6918216327903515e-05,
      "loss": 0.0002,
      "step": 54450
    },
    {
      "epoch": 2.618807361491519,
      "grad_norm": 0.4494089186191559,
      "learning_rate": 3.6906203450098506e-05,
      "loss": 0.0002,
      "step": 54500
    },
    {
      "epoch": 2.6212099370525204,
      "grad_norm": 0.30006879568099976,
      "learning_rate": 3.6894190572293504e-05,
      "loss": 0.0003,
      "step": 54550
    },
    {
      "epoch": 2.623612512613522,
      "grad_norm": 0.30434563755989075,
      "learning_rate": 3.6882177694488495e-05,
      "loss": 0.0006,
      "step": 54600
    },
    {
      "epoch": 2.626015088174523,
      "grad_norm": 0.14061596989631653,
      "learning_rate": 3.687016481668349e-05,
      "loss": 0.0002,
      "step": 54650
    },
    {
      "epoch": 2.6284176637355245,
      "grad_norm": 0.12288456410169601,
      "learning_rate": 3.6858151938878476e-05,
      "loss": 0.0002,
      "step": 54700
    },
    {
      "epoch": 2.6308202392965256,
      "grad_norm": 0.5924113392829895,
      "learning_rate": 3.684613906107347e-05,
      "loss": 0.0003,
      "step": 54750
    },
    {
      "epoch": 2.633222814857527,
      "grad_norm": 0.13971348106861115,
      "learning_rate": 3.6834126183268465e-05,
      "loss": 0.0002,
      "step": 54800
    },
    {
      "epoch": 2.6356253904185287,
      "grad_norm": 0.1881733536720276,
      "learning_rate": 3.6822113305463455e-05,
      "loss": 0.0002,
      "step": 54850
    },
    {
      "epoch": 2.6380279659795303,
      "grad_norm": 0.6087917685508728,
      "learning_rate": 3.681010042765845e-05,
      "loss": 0.0006,
      "step": 54900
    },
    {
      "epoch": 2.6404305415405314,
      "grad_norm": 0.1502494513988495,
      "learning_rate": 3.6798087549853444e-05,
      "loss": 0.0002,
      "step": 54950
    },
    {
      "epoch": 2.642833117101533,
      "grad_norm": 0.6742326021194458,
      "learning_rate": 3.6786074672048435e-05,
      "loss": 0.0003,
      "step": 55000
    },
    {
      "epoch": 2.645235692662534,
      "grad_norm": 0.49655404686927795,
      "learning_rate": 3.677406179424343e-05,
      "loss": 0.0002,
      "step": 55050
    },
    {
      "epoch": 2.6476382682235355,
      "grad_norm": 0.3712688386440277,
      "learning_rate": 3.676204891643842e-05,
      "loss": 0.0002,
      "step": 55100
    },
    {
      "epoch": 2.650040843784537,
      "grad_norm": 0.37914493680000305,
      "learning_rate": 3.675003603863342e-05,
      "loss": 0.0002,
      "step": 55150
    },
    {
      "epoch": 2.6524434193455386,
      "grad_norm": 0.14164134860038757,
      "learning_rate": 3.673802316082841e-05,
      "loss": 0.0002,
      "step": 55200
    },
    {
      "epoch": 2.6548459949065397,
      "grad_norm": 0.02028832957148552,
      "learning_rate": 3.67260102830234e-05,
      "loss": 0.0002,
      "step": 55250
    },
    {
      "epoch": 2.6572485704675413,
      "grad_norm": 0.07230215519666672,
      "learning_rate": 3.67139974052184e-05,
      "loss": 0.0002,
      "step": 55300
    },
    {
      "epoch": 2.6596511460285424,
      "grad_norm": 0.11415915936231613,
      "learning_rate": 3.670198452741339e-05,
      "loss": 0.0002,
      "step": 55350
    },
    {
      "epoch": 2.662053721589544,
      "grad_norm": 0.2712925970554352,
      "learning_rate": 3.668997164960838e-05,
      "loss": 0.0002,
      "step": 55400
    },
    {
      "epoch": 2.6644562971505454,
      "grad_norm": 0.27289777994155884,
      "learning_rate": 3.667795877180337e-05,
      "loss": 0.0002,
      "step": 55450
    },
    {
      "epoch": 2.666858872711547,
      "grad_norm": 0.0934680923819542,
      "learning_rate": 3.666594589399836e-05,
      "loss": 0.0002,
      "step": 55500
    },
    {
      "epoch": 2.669261448272548,
      "grad_norm": 0.5146604776382446,
      "learning_rate": 3.665393301619336e-05,
      "loss": 0.0002,
      "step": 55550
    },
    {
      "epoch": 2.6716640238335496,
      "grad_norm": 0.4529120624065399,
      "learning_rate": 3.664192013838835e-05,
      "loss": 0.0002,
      "step": 55600
    },
    {
      "epoch": 2.6740665993945507,
      "grad_norm": 0.1667935997247696,
      "learning_rate": 3.662990726058335e-05,
      "loss": 0.0002,
      "step": 55650
    },
    {
      "epoch": 2.6764691749555523,
      "grad_norm": 0.1604042798280716,
      "learning_rate": 3.661789438277834e-05,
      "loss": 0.0001,
      "step": 55700
    },
    {
      "epoch": 2.678871750516554,
      "grad_norm": 0.28134000301361084,
      "learning_rate": 3.660588150497333e-05,
      "loss": 0.0002,
      "step": 55750
    },
    {
      "epoch": 2.6812743260775553,
      "grad_norm": 0.38357317447662354,
      "learning_rate": 3.659386862716833e-05,
      "loss": 0.0002,
      "step": 55800
    },
    {
      "epoch": 2.6836769016385564,
      "grad_norm": 0.22598712146282196,
      "learning_rate": 3.658185574936332e-05,
      "loss": 0.0002,
      "step": 55850
    },
    {
      "epoch": 2.686079477199558,
      "grad_norm": 0.14803151786327362,
      "learning_rate": 3.656984287155831e-05,
      "loss": 0.0003,
      "step": 55900
    },
    {
      "epoch": 2.688482052760559,
      "grad_norm": 0.25123676657676697,
      "learning_rate": 3.655782999375331e-05,
      "loss": 0.0002,
      "step": 55950
    },
    {
      "epoch": 2.6908846283215606,
      "grad_norm": 0.2855950593948364,
      "learning_rate": 3.65458171159483e-05,
      "loss": 0.0002,
      "step": 56000
    },
    {
      "epoch": 2.693287203882562,
      "grad_norm": 0.11510172486305237,
      "learning_rate": 3.6533804238143296e-05,
      "loss": 0.0002,
      "step": 56050
    },
    {
      "epoch": 2.6956897794435637,
      "grad_norm": 0.5332032442092896,
      "learning_rate": 3.652179136033829e-05,
      "loss": 0.0002,
      "step": 56100
    },
    {
      "epoch": 2.698092355004565,
      "grad_norm": 0.09074476361274719,
      "learning_rate": 3.650977848253328e-05,
      "loss": 0.0002,
      "step": 56150
    },
    {
      "epoch": 2.7004949305655663,
      "grad_norm": 0.4861583411693573,
      "learning_rate": 3.649776560472827e-05,
      "loss": 0.0003,
      "step": 56200
    },
    {
      "epoch": 2.7028975061265674,
      "grad_norm": 0.17327150702476501,
      "learning_rate": 3.648575272692326e-05,
      "loss": 0.0006,
      "step": 56250
    },
    {
      "epoch": 2.705300081687569,
      "grad_norm": 0.3029201626777649,
      "learning_rate": 3.647373984911826e-05,
      "loss": 0.0003,
      "step": 56300
    },
    {
      "epoch": 2.7077026572485705,
      "grad_norm": 0.6434975862503052,
      "learning_rate": 3.646172697131325e-05,
      "loss": 0.0002,
      "step": 56350
    },
    {
      "epoch": 2.710105232809572,
      "grad_norm": 0.4068422019481659,
      "learning_rate": 3.644971409350824e-05,
      "loss": 0.0002,
      "step": 56400
    },
    {
      "epoch": 2.712507808370573,
      "grad_norm": 0.2715488076210022,
      "learning_rate": 3.6437701215703236e-05,
      "loss": 0.0002,
      "step": 56450
    },
    {
      "epoch": 2.7149103839315747,
      "grad_norm": 0.19154445827007294,
      "learning_rate": 3.642568833789823e-05,
      "loss": 0.0002,
      "step": 56500
    },
    {
      "epoch": 2.717312959492576,
      "grad_norm": 0.22967258095741272,
      "learning_rate": 3.6413675460093225e-05,
      "loss": 0.0002,
      "step": 56550
    },
    {
      "epoch": 2.7197155350535773,
      "grad_norm": 0.11355671286582947,
      "learning_rate": 3.6401662582288216e-05,
      "loss": 0.0002,
      "step": 56600
    },
    {
      "epoch": 2.722118110614579,
      "grad_norm": 0.29377609491348267,
      "learning_rate": 3.6389649704483206e-05,
      "loss": 0.0002,
      "step": 56650
    },
    {
      "epoch": 2.7245206861755804,
      "grad_norm": 0.7130717635154724,
      "learning_rate": 3.6377636826678204e-05,
      "loss": 0.0003,
      "step": 56700
    },
    {
      "epoch": 2.7269232617365815,
      "grad_norm": 0.40454643964767456,
      "learning_rate": 3.6365623948873195e-05,
      "loss": 0.0002,
      "step": 56750
    },
    {
      "epoch": 2.729325837297583,
      "grad_norm": 0.1842738389968872,
      "learning_rate": 3.6353611071068186e-05,
      "loss": 0.0002,
      "step": 56800
    },
    {
      "epoch": 2.731728412858584,
      "grad_norm": 0.11041238158941269,
      "learning_rate": 3.634159819326318e-05,
      "loss": 0.0002,
      "step": 56850
    },
    {
      "epoch": 2.7341309884195857,
      "grad_norm": 0.20530566573143005,
      "learning_rate": 3.6329585315458174e-05,
      "loss": 0.0002,
      "step": 56900
    },
    {
      "epoch": 2.7365335639805872,
      "grad_norm": 0.16242535412311554,
      "learning_rate": 3.6317572437653165e-05,
      "loss": 0.0002,
      "step": 56950
    },
    {
      "epoch": 2.7389361395415888,
      "grad_norm": 0.5337229371070862,
      "learning_rate": 3.6305559559848156e-05,
      "loss": 0.0002,
      "step": 57000
    },
    {
      "epoch": 2.74133871510259,
      "grad_norm": 0.18833880126476288,
      "learning_rate": 3.6293546682043153e-05,
      "loss": 0.0002,
      "step": 57050
    },
    {
      "epoch": 2.7437412906635914,
      "grad_norm": 0.17174626886844635,
      "learning_rate": 3.6281533804238144e-05,
      "loss": 0.0002,
      "step": 57100
    },
    {
      "epoch": 2.7461438662245925,
      "grad_norm": 0.5926041603088379,
      "learning_rate": 3.6269520926433135e-05,
      "loss": 0.0008,
      "step": 57150
    },
    {
      "epoch": 2.748546441785594,
      "grad_norm": 0.1476212441921234,
      "learning_rate": 3.625750804862813e-05,
      "loss": 0.0001,
      "step": 57200
    },
    {
      "epoch": 2.7509490173465956,
      "grad_norm": 0.15134921669960022,
      "learning_rate": 3.6245495170823123e-05,
      "loss": 0.0002,
      "step": 57250
    },
    {
      "epoch": 2.753351592907597,
      "grad_norm": 0.3502523601055145,
      "learning_rate": 3.6233482293018114e-05,
      "loss": 0.0002,
      "step": 57300
    },
    {
      "epoch": 2.755754168468598,
      "grad_norm": 0.09328344464302063,
      "learning_rate": 3.622146941521311e-05,
      "loss": 0.0002,
      "step": 57350
    },
    {
      "epoch": 2.7581567440295998,
      "grad_norm": 0.29968544840812683,
      "learning_rate": 3.62094565374081e-05,
      "loss": 0.0002,
      "step": 57400
    },
    {
      "epoch": 2.760559319590601,
      "grad_norm": 0.09703841060400009,
      "learning_rate": 3.61974436596031e-05,
      "loss": 0.0002,
      "step": 57450
    },
    {
      "epoch": 2.7629618951516024,
      "grad_norm": 0.3184661567211151,
      "learning_rate": 3.618543078179809e-05,
      "loss": 0.0002,
      "step": 57500
    },
    {
      "epoch": 2.765364470712604,
      "grad_norm": 0.1262846738100052,
      "learning_rate": 3.617341790399308e-05,
      "loss": 0.0002,
      "step": 57550
    },
    {
      "epoch": 2.7677670462736055,
      "grad_norm": 0.1367892026901245,
      "learning_rate": 3.616140502618808e-05,
      "loss": 0.0008,
      "step": 57600
    },
    {
      "epoch": 2.7701696218346066,
      "grad_norm": 0.25438225269317627,
      "learning_rate": 3.614939214838307e-05,
      "loss": 0.0002,
      "step": 57650
    },
    {
      "epoch": 2.772572197395608,
      "grad_norm": 0.16615551710128784,
      "learning_rate": 3.613737927057806e-05,
      "loss": 0.0002,
      "step": 57700
    },
    {
      "epoch": 2.774974772956609,
      "grad_norm": 0.07906908541917801,
      "learning_rate": 3.612536639277305e-05,
      "loss": 0.0002,
      "step": 57750
    },
    {
      "epoch": 2.7773773485176108,
      "grad_norm": 0.46111860871315,
      "learning_rate": 3.611335351496804e-05,
      "loss": 0.0002,
      "step": 57800
    },
    {
      "epoch": 2.7797799240786123,
      "grad_norm": 0.16221585869789124,
      "learning_rate": 3.610134063716304e-05,
      "loss": 0.0002,
      "step": 57850
    },
    {
      "epoch": 2.782182499639614,
      "grad_norm": 0.6254696846008301,
      "learning_rate": 3.608932775935803e-05,
      "loss": 0.0002,
      "step": 57900
    },
    {
      "epoch": 2.784585075200615,
      "grad_norm": 0.038988735526800156,
      "learning_rate": 3.607731488155303e-05,
      "loss": 0.0001,
      "step": 57950
    },
    {
      "epoch": 2.7869876507616165,
      "grad_norm": 0.16308282315731049,
      "learning_rate": 3.606530200374802e-05,
      "loss": 0.0002,
      "step": 58000
    },
    {
      "epoch": 2.7893902263226176,
      "grad_norm": 0.2570508122444153,
      "learning_rate": 3.605328912594301e-05,
      "loss": 0.0001,
      "step": 58050
    },
    {
      "epoch": 2.791792801883619,
      "grad_norm": 0.16837722063064575,
      "learning_rate": 3.604127624813801e-05,
      "loss": 0.0002,
      "step": 58100
    },
    {
      "epoch": 2.7941953774446207,
      "grad_norm": 0.1581439971923828,
      "learning_rate": 3.6029263370333e-05,
      "loss": 0.0002,
      "step": 58150
    },
    {
      "epoch": 2.796597953005622,
      "grad_norm": 0.31480756402015686,
      "learning_rate": 3.601725049252799e-05,
      "loss": 0.0002,
      "step": 58200
    },
    {
      "epoch": 2.7990005285666233,
      "grad_norm": 0.0945596918463707,
      "learning_rate": 3.600523761472299e-05,
      "loss": 0.0002,
      "step": 58250
    },
    {
      "epoch": 2.801403104127625,
      "grad_norm": 0.21057376265525818,
      "learning_rate": 3.599322473691798e-05,
      "loss": 0.0002,
      "step": 58300
    },
    {
      "epoch": 2.8038056796886264,
      "grad_norm": 0.6516306400299072,
      "learning_rate": 3.5981211859112976e-05,
      "loss": 0.0009,
      "step": 58350
    },
    {
      "epoch": 2.8062082552496275,
      "grad_norm": 0.07100121676921844,
      "learning_rate": 3.596919898130797e-05,
      "loss": 0.0002,
      "step": 58400
    },
    {
      "epoch": 2.808610830810629,
      "grad_norm": 0.07046058773994446,
      "learning_rate": 3.595718610350296e-05,
      "loss": 0.0002,
      "step": 58450
    },
    {
      "epoch": 2.8110134063716306,
      "grad_norm": 0.09352494031190872,
      "learning_rate": 3.594517322569795e-05,
      "loss": 0.0001,
      "step": 58500
    },
    {
      "epoch": 2.8134159819326316,
      "grad_norm": 0.10852230340242386,
      "learning_rate": 3.593316034789294e-05,
      "loss": 0.0001,
      "step": 58550
    },
    {
      "epoch": 2.815818557493633,
      "grad_norm": 0.11841177195310593,
      "learning_rate": 3.592114747008794e-05,
      "loss": 0.0002,
      "step": 58600
    },
    {
      "epoch": 2.8182211330546347,
      "grad_norm": 0.16086606681346893,
      "learning_rate": 3.590913459228293e-05,
      "loss": 0.0003,
      "step": 58650
    },
    {
      "epoch": 2.820623708615636,
      "grad_norm": 0.19371920824050903,
      "learning_rate": 3.589712171447792e-05,
      "loss": 0.0001,
      "step": 58700
    },
    {
      "epoch": 2.8230262841766374,
      "grad_norm": 0.1453501582145691,
      "learning_rate": 3.5885108836672916e-05,
      "loss": 0.0003,
      "step": 58750
    },
    {
      "epoch": 2.825428859737639,
      "grad_norm": 0.37206631898880005,
      "learning_rate": 3.587309595886791e-05,
      "loss": 0.0002,
      "step": 58800
    },
    {
      "epoch": 2.82783143529864,
      "grad_norm": 0.3716966211795807,
      "learning_rate": 3.5861083081062904e-05,
      "loss": 0.0002,
      "step": 58850
    },
    {
      "epoch": 2.8302340108596415,
      "grad_norm": 0.34449303150177,
      "learning_rate": 3.5849070203257895e-05,
      "loss": 0.0002,
      "step": 58900
    },
    {
      "epoch": 2.832636586420643,
      "grad_norm": 0.18708401918411255,
      "learning_rate": 3.5837057325452886e-05,
      "loss": 0.0002,
      "step": 58950
    },
    {
      "epoch": 2.835039161981644,
      "grad_norm": 0.2085486650466919,
      "learning_rate": 3.5825044447647884e-05,
      "loss": 0.0002,
      "step": 59000
    },
    {
      "epoch": 2.8374417375426457,
      "grad_norm": 0.1324320286512375,
      "learning_rate": 3.5813031569842874e-05,
      "loss": 0.0002,
      "step": 59050
    },
    {
      "epoch": 2.8398443131036473,
      "grad_norm": 0.16766926646232605,
      "learning_rate": 3.580101869203787e-05,
      "loss": 0.0002,
      "step": 59100
    },
    {
      "epoch": 2.8422468886646484,
      "grad_norm": 0.16323474049568176,
      "learning_rate": 3.5789005814232856e-05,
      "loss": 0.0002,
      "step": 59150
    },
    {
      "epoch": 2.84464946422565,
      "grad_norm": 0.46910062432289124,
      "learning_rate": 3.577699293642785e-05,
      "loss": 0.0007,
      "step": 59200
    },
    {
      "epoch": 2.8470520397866514,
      "grad_norm": 0.2923873960971832,
      "learning_rate": 3.5764980058622845e-05,
      "loss": 0.0002,
      "step": 59250
    },
    {
      "epoch": 2.8494546153476525,
      "grad_norm": 0.24476230144500732,
      "learning_rate": 3.5752967180817835e-05,
      "loss": 0.0002,
      "step": 59300
    },
    {
      "epoch": 2.851857190908654,
      "grad_norm": 0.1372503936290741,
      "learning_rate": 3.574095430301283e-05,
      "loss": 0.0002,
      "step": 59350
    },
    {
      "epoch": 2.8542597664696556,
      "grad_norm": 0.4706153869628906,
      "learning_rate": 3.5728941425207824e-05,
      "loss": 0.0002,
      "step": 59400
    },
    {
      "epoch": 2.8566623420306567,
      "grad_norm": 0.1183856874704361,
      "learning_rate": 3.5716928547402815e-05,
      "loss": 0.0002,
      "step": 59450
    },
    {
      "epoch": 2.8590649175916583,
      "grad_norm": 0.12327495217323303,
      "learning_rate": 3.570491566959781e-05,
      "loss": 0.001,
      "step": 59500
    },
    {
      "epoch": 2.86146749315266,
      "grad_norm": 0.044901229441165924,
      "learning_rate": 3.56929027917928e-05,
      "loss": 0.0002,
      "step": 59550
    },
    {
      "epoch": 2.863870068713661,
      "grad_norm": 0.21138903498649597,
      "learning_rate": 3.5680889913987794e-05,
      "loss": 0.0002,
      "step": 59600
    },
    {
      "epoch": 2.8662726442746624,
      "grad_norm": 0.27145346999168396,
      "learning_rate": 3.566887703618279e-05,
      "loss": 0.0002,
      "step": 59650
    },
    {
      "epoch": 2.868675219835664,
      "grad_norm": 0.22640560567378998,
      "learning_rate": 3.565686415837778e-05,
      "loss": 0.0002,
      "step": 59700
    },
    {
      "epoch": 2.871077795396665,
      "grad_norm": 0.28263911604881287,
      "learning_rate": 3.564485128057278e-05,
      "loss": 0.0006,
      "step": 59750
    },
    {
      "epoch": 2.8734803709576666,
      "grad_norm": 0.32280755043029785,
      "learning_rate": 3.563283840276777e-05,
      "loss": 0.0002,
      "step": 59800
    },
    {
      "epoch": 2.875882946518668,
      "grad_norm": 0.4553782641887665,
      "learning_rate": 3.562082552496276e-05,
      "loss": 0.0002,
      "step": 59850
    },
    {
      "epoch": 2.8782855220796693,
      "grad_norm": 0.23193061351776123,
      "learning_rate": 3.560881264715775e-05,
      "loss": 0.0002,
      "step": 59900
    },
    {
      "epoch": 2.880688097640671,
      "grad_norm": 0.5224104523658752,
      "learning_rate": 3.559679976935274e-05,
      "loss": 0.0002,
      "step": 59950
    },
    {
      "epoch": 2.8830906732016723,
      "grad_norm": 0.27054908871650696,
      "learning_rate": 3.558478689154774e-05,
      "loss": 0.0002,
      "step": 60000
    },
    {
      "epoch": 2.8854932487626734,
      "grad_norm": 0.27312037348747253,
      "learning_rate": 3.557277401374273e-05,
      "loss": 0.0002,
      "step": 60050
    },
    {
      "epoch": 2.887895824323675,
      "grad_norm": 0.14068898558616638,
      "learning_rate": 3.556076113593772e-05,
      "loss": 0.0002,
      "step": 60100
    },
    {
      "epoch": 2.8902983998846765,
      "grad_norm": 0.2500234544277191,
      "learning_rate": 3.554874825813272e-05,
      "loss": 0.0002,
      "step": 60150
    },
    {
      "epoch": 2.8927009754456776,
      "grad_norm": 0.4424035847187042,
      "learning_rate": 3.553673538032771e-05,
      "loss": 0.0002,
      "step": 60200
    },
    {
      "epoch": 2.895103551006679,
      "grad_norm": 0.18191643059253693,
      "learning_rate": 3.552472250252271e-05,
      "loss": 0.0002,
      "step": 60250
    },
    {
      "epoch": 2.8975061265676807,
      "grad_norm": 0.041610389947891235,
      "learning_rate": 3.55127096247177e-05,
      "loss": 0.0007,
      "step": 60300
    },
    {
      "epoch": 2.899908702128682,
      "grad_norm": 0.2714579105377197,
      "learning_rate": 3.550069674691269e-05,
      "loss": 0.0002,
      "step": 60350
    },
    {
      "epoch": 2.9023112776896833,
      "grad_norm": 0.1093023419380188,
      "learning_rate": 3.548868386910769e-05,
      "loss": 0.0001,
      "step": 60400
    },
    {
      "epoch": 2.904713853250685,
      "grad_norm": 0.08560606837272644,
      "learning_rate": 3.547667099130268e-05,
      "loss": 0.0002,
      "step": 60450
    },
    {
      "epoch": 2.907116428811686,
      "grad_norm": 0.3211793005466461,
      "learning_rate": 3.5464658113497676e-05,
      "loss": 0.0002,
      "step": 60500
    },
    {
      "epoch": 2.9095190043726875,
      "grad_norm": 0.16928094625473022,
      "learning_rate": 3.545264523569267e-05,
      "loss": 0.0002,
      "step": 60550
    },
    {
      "epoch": 2.911921579933689,
      "grad_norm": 0.4056202173233032,
      "learning_rate": 3.544063235788766e-05,
      "loss": 0.0002,
      "step": 60600
    },
    {
      "epoch": 2.91432415549469,
      "grad_norm": 0.46441376209259033,
      "learning_rate": 3.542861948008265e-05,
      "loss": 0.0002,
      "step": 60650
    },
    {
      "epoch": 2.9167267310556917,
      "grad_norm": 0.13321079313755035,
      "learning_rate": 3.541660660227764e-05,
      "loss": 0.0003,
      "step": 60700
    },
    {
      "epoch": 2.9191293066166932,
      "grad_norm": 0.3059515357017517,
      "learning_rate": 3.540459372447264e-05,
      "loss": 0.0001,
      "step": 60750
    },
    {
      "epoch": 2.9215318821776943,
      "grad_norm": 0.2622714638710022,
      "learning_rate": 3.539258084666763e-05,
      "loss": 0.0001,
      "step": 60800
    },
    {
      "epoch": 2.923934457738696,
      "grad_norm": 0.05970608443021774,
      "learning_rate": 3.538056796886262e-05,
      "loss": 0.0001,
      "step": 60850
    },
    {
      "epoch": 2.9263370332996974,
      "grad_norm": 0.34604620933532715,
      "learning_rate": 3.5368555091057616e-05,
      "loss": 0.0005,
      "step": 60900
    },
    {
      "epoch": 2.9287396088606985,
      "grad_norm": 0.1529727578163147,
      "learning_rate": 3.535654221325261e-05,
      "loss": 0.0002,
      "step": 60950
    },
    {
      "epoch": 2.9311421844217,
      "grad_norm": 0.1073370948433876,
      "learning_rate": 3.5344529335447605e-05,
      "loss": 0.0004,
      "step": 61000
    },
    {
      "epoch": 2.9335447599827016,
      "grad_norm": 0.25398769974708557,
      "learning_rate": 3.5332516457642596e-05,
      "loss": 0.0002,
      "step": 61050
    },
    {
      "epoch": 2.9359473355437027,
      "grad_norm": 0.2582128047943115,
      "learning_rate": 3.5320503579837586e-05,
      "loss": 0.0002,
      "step": 61100
    },
    {
      "epoch": 2.9383499111047042,
      "grad_norm": 0.39864587783813477,
      "learning_rate": 3.5308490702032584e-05,
      "loss": 0.0002,
      "step": 61150
    },
    {
      "epoch": 2.9407524866657058,
      "grad_norm": 0.12208180129528046,
      "learning_rate": 3.5296477824227575e-05,
      "loss": 0.0002,
      "step": 61200
    },
    {
      "epoch": 2.943155062226707,
      "grad_norm": 0.3631819486618042,
      "learning_rate": 3.5284464946422566e-05,
      "loss": 0.0002,
      "step": 61250
    },
    {
      "epoch": 2.9455576377877084,
      "grad_norm": 0.12332972139120102,
      "learning_rate": 3.527245206861756e-05,
      "loss": 0.0002,
      "step": 61300
    },
    {
      "epoch": 2.94796021334871,
      "grad_norm": 0.051654040813446045,
      "learning_rate": 3.5260439190812554e-05,
      "loss": 0.0002,
      "step": 61350
    },
    {
      "epoch": 2.950362788909711,
      "grad_norm": 0.2394673079252243,
      "learning_rate": 3.5248426313007545e-05,
      "loss": 0.0003,
      "step": 61400
    },
    {
      "epoch": 2.9527653644707126,
      "grad_norm": 0.11441748589277267,
      "learning_rate": 3.5236413435202536e-05,
      "loss": 0.0002,
      "step": 61450
    },
    {
      "epoch": 2.955167940031714,
      "grad_norm": 0.08945976197719574,
      "learning_rate": 3.522440055739753e-05,
      "loss": 0.0002,
      "step": 61500
    },
    {
      "epoch": 2.9575705155927157,
      "grad_norm": 0.46312662959098816,
      "learning_rate": 3.5212387679592524e-05,
      "loss": 0.0003,
      "step": 61550
    },
    {
      "epoch": 2.9599730911537168,
      "grad_norm": 0.19812312722206116,
      "learning_rate": 3.5200374801787515e-05,
      "loss": 0.0006,
      "step": 61600
    },
    {
      "epoch": 2.9623756667147183,
      "grad_norm": 0.06410804390907288,
      "learning_rate": 3.518836192398251e-05,
      "loss": 0.0002,
      "step": 61650
    },
    {
      "epoch": 2.9647782422757194,
      "grad_norm": 0.13809055089950562,
      "learning_rate": 3.5176349046177503e-05,
      "loss": 0.0002,
      "step": 61700
    },
    {
      "epoch": 2.967180817836721,
      "grad_norm": 0.1172914206981659,
      "learning_rate": 3.5164336168372494e-05,
      "loss": 0.0001,
      "step": 61750
    },
    {
      "epoch": 2.9695833933977225,
      "grad_norm": 0.44082123041152954,
      "learning_rate": 3.515232329056749e-05,
      "loss": 0.0003,
      "step": 61800
    },
    {
      "epoch": 2.971985968958724,
      "grad_norm": 0.3162976801395416,
      "learning_rate": 3.514031041276248e-05,
      "loss": 0.0002,
      "step": 61850
    },
    {
      "epoch": 2.974388544519725,
      "grad_norm": 0.5923953056335449,
      "learning_rate": 3.512829753495748e-05,
      "loss": 0.0002,
      "step": 61900
    },
    {
      "epoch": 2.9767911200807267,
      "grad_norm": 0.12321724742650986,
      "learning_rate": 3.511628465715247e-05,
      "loss": 0.0002,
      "step": 61950
    },
    {
      "epoch": 2.9791936956417278,
      "grad_norm": 0.21164323389530182,
      "learning_rate": 3.510427177934746e-05,
      "loss": 0.0001,
      "step": 62000
    },
    {
      "epoch": 2.9815962712027293,
      "grad_norm": 0.45259952545166016,
      "learning_rate": 3.509225890154246e-05,
      "loss": 0.0008,
      "step": 62050
    },
    {
      "epoch": 2.983998846763731,
      "grad_norm": 0.45039987564086914,
      "learning_rate": 3.508024602373745e-05,
      "loss": 0.0002,
      "step": 62100
    },
    {
      "epoch": 2.9864014223247324,
      "grad_norm": 0.22665782272815704,
      "learning_rate": 3.506823314593244e-05,
      "loss": 0.0002,
      "step": 62150
    },
    {
      "epoch": 2.9888039978857335,
      "grad_norm": 0.14388103783130646,
      "learning_rate": 3.505622026812743e-05,
      "loss": 0.0002,
      "step": 62200
    },
    {
      "epoch": 2.991206573446735,
      "grad_norm": 0.5502634048461914,
      "learning_rate": 3.504420739032242e-05,
      "loss": 0.0002,
      "step": 62250
    },
    {
      "epoch": 2.993609149007736,
      "grad_norm": 0.5935516357421875,
      "learning_rate": 3.503219451251742e-05,
      "loss": 0.0002,
      "step": 62300
    },
    {
      "epoch": 2.9960117245687377,
      "grad_norm": 0.17686796188354492,
      "learning_rate": 3.502018163471241e-05,
      "loss": 0.0002,
      "step": 62350
    },
    {
      "epoch": 2.998414300129739,
      "grad_norm": 0.17943738400936127,
      "learning_rate": 3.500816875690741e-05,
      "loss": 0.0007,
      "step": 62400
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0003060135059058666,
      "eval_runtime": 17.4017,
      "eval_samples_per_second": 545.693,
      "eval_steps_per_second": 68.212,
      "step": 62433
    },
    {
      "epoch": 3.0008168756907403,
      "grad_norm": 0.03480887413024902,
      "learning_rate": 3.49961558791024e-05,
      "loss": 0.0002,
      "step": 62450
    },
    {
      "epoch": 3.003219451251742,
      "grad_norm": 0.42605847120285034,
      "learning_rate": 3.498414300129739e-05,
      "loss": 0.0007,
      "step": 62500
    },
    {
      "epoch": 3.0056220268127434,
      "grad_norm": 0.2675262689590454,
      "learning_rate": 3.497213012349239e-05,
      "loss": 0.0002,
      "step": 62550
    },
    {
      "epoch": 3.0080246023737445,
      "grad_norm": 0.24730519950389862,
      "learning_rate": 3.496011724568738e-05,
      "loss": 0.0002,
      "step": 62600
    },
    {
      "epoch": 3.010427177934746,
      "grad_norm": 0.12716704607009888,
      "learning_rate": 3.494810436788237e-05,
      "loss": 0.0002,
      "step": 62650
    },
    {
      "epoch": 3.0128297534957476,
      "grad_norm": 0.2903704047203064,
      "learning_rate": 3.493609149007737e-05,
      "loss": 0.0002,
      "step": 62700
    },
    {
      "epoch": 3.0152323290567487,
      "grad_norm": 0.15963953733444214,
      "learning_rate": 3.492407861227236e-05,
      "loss": 0.0002,
      "step": 62750
    },
    {
      "epoch": 3.01763490461775,
      "grad_norm": 0.2885623574256897,
      "learning_rate": 3.4912065734467356e-05,
      "loss": 0.0002,
      "step": 62800
    },
    {
      "epoch": 3.0200374801787517,
      "grad_norm": 0.6045396327972412,
      "learning_rate": 3.490005285666235e-05,
      "loss": 0.0003,
      "step": 62850
    },
    {
      "epoch": 3.022440055739753,
      "grad_norm": 0.2308439165353775,
      "learning_rate": 3.488803997885734e-05,
      "loss": 0.0002,
      "step": 62900
    },
    {
      "epoch": 3.0248426313007544,
      "grad_norm": 0.0845756083726883,
      "learning_rate": 3.487602710105233e-05,
      "loss": 0.0002,
      "step": 62950
    },
    {
      "epoch": 3.027245206861756,
      "grad_norm": 0.21026870608329773,
      "learning_rate": 3.486401422324732e-05,
      "loss": 0.0006,
      "step": 63000
    },
    {
      "epoch": 3.029647782422757,
      "grad_norm": 0.16177727282047272,
      "learning_rate": 3.485200134544232e-05,
      "loss": 0.0002,
      "step": 63050
    },
    {
      "epoch": 3.0320503579837585,
      "grad_norm": 0.19430842995643616,
      "learning_rate": 3.483998846763731e-05,
      "loss": 0.0002,
      "step": 63100
    },
    {
      "epoch": 3.03445293354476,
      "grad_norm": 0.05971197411417961,
      "learning_rate": 3.48279755898323e-05,
      "loss": 0.0002,
      "step": 63150
    },
    {
      "epoch": 3.036855509105761,
      "grad_norm": 0.11238734424114227,
      "learning_rate": 3.4815962712027296e-05,
      "loss": 0.0002,
      "step": 63200
    },
    {
      "epoch": 3.0392580846667627,
      "grad_norm": 0.2655380368232727,
      "learning_rate": 3.480394983422229e-05,
      "loss": 0.0001,
      "step": 63250
    },
    {
      "epoch": 3.0416606602277643,
      "grad_norm": 0.2309766411781311,
      "learning_rate": 3.4791936956417284e-05,
      "loss": 0.0002,
      "step": 63300
    },
    {
      "epoch": 3.0440632357887654,
      "grad_norm": 0.12229148298501968,
      "learning_rate": 3.4779924078612275e-05,
      "loss": 0.0002,
      "step": 63350
    },
    {
      "epoch": 3.046465811349767,
      "grad_norm": 0.5894283652305603,
      "learning_rate": 3.4767911200807266e-05,
      "loss": 0.0003,
      "step": 63400
    },
    {
      "epoch": 3.0488683869107684,
      "grad_norm": 0.1666773110628128,
      "learning_rate": 3.4755898323002264e-05,
      "loss": 0.0002,
      "step": 63450
    },
    {
      "epoch": 3.0512709624717695,
      "grad_norm": 0.200001060962677,
      "learning_rate": 3.4743885445197254e-05,
      "loss": 0.0002,
      "step": 63500
    },
    {
      "epoch": 3.053673538032771,
      "grad_norm": 0.09668367356061935,
      "learning_rate": 3.4731872567392245e-05,
      "loss": 0.0002,
      "step": 63550
    },
    {
      "epoch": 3.0560761135937726,
      "grad_norm": 0.2559598982334137,
      "learning_rate": 3.471985968958724e-05,
      "loss": 0.0002,
      "step": 63600
    },
    {
      "epoch": 3.0584786891547737,
      "grad_norm": 0.19050070643424988,
      "learning_rate": 3.470784681178223e-05,
      "loss": 0.0002,
      "step": 63650
    },
    {
      "epoch": 3.0608812647157753,
      "grad_norm": 0.43948274850845337,
      "learning_rate": 3.4695833933977225e-05,
      "loss": 0.0002,
      "step": 63700
    },
    {
      "epoch": 3.063283840276777,
      "grad_norm": 0.07604989409446716,
      "learning_rate": 3.4683821056172215e-05,
      "loss": 0.0002,
      "step": 63750
    },
    {
      "epoch": 3.065686415837778,
      "grad_norm": 0.5762559771537781,
      "learning_rate": 3.467180817836721e-05,
      "loss": 0.0002,
      "step": 63800
    },
    {
      "epoch": 3.0680889913987794,
      "grad_norm": 0.3999737799167633,
      "learning_rate": 3.4659795300562204e-05,
      "loss": 0.0005,
      "step": 63850
    },
    {
      "epoch": 3.070491566959781,
      "grad_norm": 0.18833903968334198,
      "learning_rate": 3.4647782422757195e-05,
      "loss": 0.0002,
      "step": 63900
    },
    {
      "epoch": 3.072894142520782,
      "grad_norm": 0.4674208164215088,
      "learning_rate": 3.463576954495219e-05,
      "loss": 0.0003,
      "step": 63950
    },
    {
      "epoch": 3.0752967180817836,
      "grad_norm": 0.3568994104862213,
      "learning_rate": 3.462375666714718e-05,
      "loss": 0.0002,
      "step": 64000
    },
    {
      "epoch": 3.077699293642785,
      "grad_norm": 0.16776008903980255,
      "learning_rate": 3.4611743789342174e-05,
      "loss": 0.0009,
      "step": 64050
    },
    {
      "epoch": 3.0801018692037863,
      "grad_norm": 0.43958935141563416,
      "learning_rate": 3.459973091153717e-05,
      "loss": 0.0002,
      "step": 64100
    },
    {
      "epoch": 3.082504444764788,
      "grad_norm": 0.21471218764781952,
      "learning_rate": 3.458771803373216e-05,
      "loss": 0.0002,
      "step": 64150
    },
    {
      "epoch": 3.0849070203257893,
      "grad_norm": 0.26679521799087524,
      "learning_rate": 3.457570515592716e-05,
      "loss": 0.0002,
      "step": 64200
    },
    {
      "epoch": 3.0873095958867904,
      "grad_norm": 0.07429353147745132,
      "learning_rate": 3.456369227812215e-05,
      "loss": 0.0002,
      "step": 64250
    },
    {
      "epoch": 3.089712171447792,
      "grad_norm": 0.42907869815826416,
      "learning_rate": 3.455167940031714e-05,
      "loss": 0.0002,
      "step": 64300
    },
    {
      "epoch": 3.0921147470087935,
      "grad_norm": 0.19184015691280365,
      "learning_rate": 3.453966652251214e-05,
      "loss": 0.0002,
      "step": 64350
    },
    {
      "epoch": 3.0945173225697946,
      "grad_norm": 0.11650076508522034,
      "learning_rate": 3.452765364470712e-05,
      "loss": 0.0002,
      "step": 64400
    },
    {
      "epoch": 3.096919898130796,
      "grad_norm": 0.2424061894416809,
      "learning_rate": 3.451564076690212e-05,
      "loss": 0.0002,
      "step": 64450
    },
    {
      "epoch": 3.0993224736917977,
      "grad_norm": 0.11264293640851974,
      "learning_rate": 3.450362788909711e-05,
      "loss": 0.0002,
      "step": 64500
    },
    {
      "epoch": 3.101725049252799,
      "grad_norm": 0.09014679491519928,
      "learning_rate": 3.44916150112921e-05,
      "loss": 0.0001,
      "step": 64550
    },
    {
      "epoch": 3.1041276248138003,
      "grad_norm": 0.22413426637649536,
      "learning_rate": 3.44796021334871e-05,
      "loss": 0.0002,
      "step": 64600
    },
    {
      "epoch": 3.106530200374802,
      "grad_norm": 0.03216863423585892,
      "learning_rate": 3.446758925568209e-05,
      "loss": 0.0002,
      "step": 64650
    },
    {
      "epoch": 3.108932775935803,
      "grad_norm": 0.28800880908966064,
      "learning_rate": 3.445557637787709e-05,
      "loss": 0.0001,
      "step": 64700
    },
    {
      "epoch": 3.1113353514968045,
      "grad_norm": 0.16300037503242493,
      "learning_rate": 3.444356350007208e-05,
      "loss": 0.0002,
      "step": 64750
    },
    {
      "epoch": 3.113737927057806,
      "grad_norm": 0.23993182182312012,
      "learning_rate": 3.443155062226707e-05,
      "loss": 0.0002,
      "step": 64800
    },
    {
      "epoch": 3.116140502618807,
      "grad_norm": 0.04453699290752411,
      "learning_rate": 3.441953774446207e-05,
      "loss": 0.0002,
      "step": 64850
    },
    {
      "epoch": 3.1185430781798087,
      "grad_norm": 0.19974131882190704,
      "learning_rate": 3.440752486665706e-05,
      "loss": 0.0001,
      "step": 64900
    },
    {
      "epoch": 3.1209456537408102,
      "grad_norm": 0.43233004212379456,
      "learning_rate": 3.439551198885205e-05,
      "loss": 0.0005,
      "step": 64950
    },
    {
      "epoch": 3.1233482293018113,
      "grad_norm": 0.36974936723709106,
      "learning_rate": 3.438349911104705e-05,
      "loss": 0.0002,
      "step": 65000
    },
    {
      "epoch": 3.125750804862813,
      "grad_norm": 0.37431883811950684,
      "learning_rate": 3.437148623324204e-05,
      "loss": 0.0001,
      "step": 65050
    },
    {
      "epoch": 3.1281533804238144,
      "grad_norm": 0.20019668340682983,
      "learning_rate": 3.435947335543703e-05,
      "loss": 0.0002,
      "step": 65100
    },
    {
      "epoch": 3.130555955984816,
      "grad_norm": 0.4766731262207031,
      "learning_rate": 3.434746047763202e-05,
      "loss": 0.0002,
      "step": 65150
    },
    {
      "epoch": 3.132958531545817,
      "grad_norm": 0.6274141669273376,
      "learning_rate": 3.433544759982702e-05,
      "loss": 0.0002,
      "step": 65200
    },
    {
      "epoch": 3.1353611071068186,
      "grad_norm": 0.13091029226779938,
      "learning_rate": 3.432343472202201e-05,
      "loss": 0.0002,
      "step": 65250
    },
    {
      "epoch": 3.1377636826678197,
      "grad_norm": 0.06608070433139801,
      "learning_rate": 3.4311421844217e-05,
      "loss": 0.0003,
      "step": 65300
    },
    {
      "epoch": 3.1401662582288212,
      "grad_norm": 0.3571909964084625,
      "learning_rate": 3.4299408966411996e-05,
      "loss": 0.0002,
      "step": 65350
    },
    {
      "epoch": 3.1425688337898228,
      "grad_norm": 0.11810340732336044,
      "learning_rate": 3.428739608860699e-05,
      "loss": 0.0002,
      "step": 65400
    },
    {
      "epoch": 3.1449714093508243,
      "grad_norm": 0.29316630959510803,
      "learning_rate": 3.427538321080198e-05,
      "loss": 0.0002,
      "step": 65450
    },
    {
      "epoch": 3.1473739849118254,
      "grad_norm": 0.11296216398477554,
      "learning_rate": 3.4263370332996976e-05,
      "loss": 0.0002,
      "step": 65500
    },
    {
      "epoch": 3.149776560472827,
      "grad_norm": 0.25379055738449097,
      "learning_rate": 3.4251357455191966e-05,
      "loss": 0.0001,
      "step": 65550
    },
    {
      "epoch": 3.152179136033828,
      "grad_norm": 0.04016811028122902,
      "learning_rate": 3.4239344577386964e-05,
      "loss": 0.0002,
      "step": 65600
    },
    {
      "epoch": 3.1545817115948296,
      "grad_norm": 0.6022502779960632,
      "learning_rate": 3.4227331699581955e-05,
      "loss": 0.0002,
      "step": 65650
    },
    {
      "epoch": 3.156984287155831,
      "grad_norm": 0.09929489344358444,
      "learning_rate": 3.4215318821776946e-05,
      "loss": 0.0002,
      "step": 65700
    },
    {
      "epoch": 3.1593868627168327,
      "grad_norm": 0.1417870968580246,
      "learning_rate": 3.420330594397194e-05,
      "loss": 0.0002,
      "step": 65750
    },
    {
      "epoch": 3.1617894382778338,
      "grad_norm": 0.19086942076683044,
      "learning_rate": 3.4191293066166934e-05,
      "loss": 0.0002,
      "step": 65800
    },
    {
      "epoch": 3.1641920138388353,
      "grad_norm": 0.7922292351722717,
      "learning_rate": 3.4179280188361925e-05,
      "loss": 0.0002,
      "step": 65850
    },
    {
      "epoch": 3.1665945893998364,
      "grad_norm": 0.14932219684123993,
      "learning_rate": 3.4167267310556916e-05,
      "loss": 0.0002,
      "step": 65900
    },
    {
      "epoch": 3.168997164960838,
      "grad_norm": 0.058598801493644714,
      "learning_rate": 3.4155254432751907e-05,
      "loss": 0.0002,
      "step": 65950
    },
    {
      "epoch": 3.1713997405218395,
      "grad_norm": 0.4217720329761505,
      "learning_rate": 3.4143241554946904e-05,
      "loss": 0.0002,
      "step": 66000
    },
    {
      "epoch": 3.173802316082841,
      "grad_norm": 0.11918662488460541,
      "learning_rate": 3.4131228677141895e-05,
      "loss": 0.0001,
      "step": 66050
    },
    {
      "epoch": 3.176204891643842,
      "grad_norm": 0.10817435383796692,
      "learning_rate": 3.411921579933689e-05,
      "loss": 0.0002,
      "step": 66100
    },
    {
      "epoch": 3.1786074672048437,
      "grad_norm": 0.16138722002506256,
      "learning_rate": 3.4107202921531883e-05,
      "loss": 0.0003,
      "step": 66150
    },
    {
      "epoch": 3.1810100427658448,
      "grad_norm": 0.07731910049915314,
      "learning_rate": 3.4095190043726874e-05,
      "loss": 0.0008,
      "step": 66200
    },
    {
      "epoch": 3.1834126183268463,
      "grad_norm": 0.6892023086547852,
      "learning_rate": 3.408317716592187e-05,
      "loss": 0.0002,
      "step": 66250
    },
    {
      "epoch": 3.185815193887848,
      "grad_norm": 0.07815859466791153,
      "learning_rate": 3.407116428811686e-05,
      "loss": 0.0002,
      "step": 66300
    },
    {
      "epoch": 3.1882177694488494,
      "grad_norm": 0.11707055568695068,
      "learning_rate": 3.405915141031186e-05,
      "loss": 0.0005,
      "step": 66350
    },
    {
      "epoch": 3.1906203450098505,
      "grad_norm": 0.4135079085826874,
      "learning_rate": 3.404713853250685e-05,
      "loss": 0.0001,
      "step": 66400
    },
    {
      "epoch": 3.193022920570852,
      "grad_norm": 0.09230059385299683,
      "learning_rate": 3.403512565470184e-05,
      "loss": 0.0002,
      "step": 66450
    },
    {
      "epoch": 3.195425496131853,
      "grad_norm": 0.13505405187606812,
      "learning_rate": 3.402311277689684e-05,
      "loss": 0.0002,
      "step": 66500
    },
    {
      "epoch": 3.1978280716928547,
      "grad_norm": 0.4612959027290344,
      "learning_rate": 3.401109989909183e-05,
      "loss": 0.0003,
      "step": 66550
    },
    {
      "epoch": 3.200230647253856,
      "grad_norm": 0.06746574491262436,
      "learning_rate": 3.399908702128682e-05,
      "loss": 0.0002,
      "step": 66600
    },
    {
      "epoch": 3.2026332228148577,
      "grad_norm": 0.08816353231668472,
      "learning_rate": 3.398707414348181e-05,
      "loss": 0.0002,
      "step": 66650
    },
    {
      "epoch": 3.205035798375859,
      "grad_norm": 0.44018256664276123,
      "learning_rate": 3.39750612656768e-05,
      "loss": 0.0002,
      "step": 66700
    },
    {
      "epoch": 3.2074383739368604,
      "grad_norm": 0.2781625986099243,
      "learning_rate": 3.39630483878718e-05,
      "loss": 0.0002,
      "step": 66750
    },
    {
      "epoch": 3.2098409494978615,
      "grad_norm": 0.16403888165950775,
      "learning_rate": 3.395103551006679e-05,
      "loss": 0.0002,
      "step": 66800
    },
    {
      "epoch": 3.212243525058863,
      "grad_norm": 0.32263287901878357,
      "learning_rate": 3.393902263226179e-05,
      "loss": 0.0002,
      "step": 66850
    },
    {
      "epoch": 3.2146461006198646,
      "grad_norm": 0.1790851652622223,
      "learning_rate": 3.392700975445678e-05,
      "loss": 0.0002,
      "step": 66900
    },
    {
      "epoch": 3.217048676180866,
      "grad_norm": 0.12782081961631775,
      "learning_rate": 3.391499687665177e-05,
      "loss": 0.0002,
      "step": 66950
    },
    {
      "epoch": 3.219451251741867,
      "grad_norm": 0.46528947353363037,
      "learning_rate": 3.390298399884677e-05,
      "loss": 0.0002,
      "step": 67000
    },
    {
      "epoch": 3.2218538273028687,
      "grad_norm": 0.13459283113479614,
      "learning_rate": 3.389097112104176e-05,
      "loss": 0.0002,
      "step": 67050
    },
    {
      "epoch": 3.2242564028638703,
      "grad_norm": 0.09678316861391068,
      "learning_rate": 3.387895824323675e-05,
      "loss": 0.0001,
      "step": 67100
    },
    {
      "epoch": 3.2266589784248714,
      "grad_norm": 0.12302923947572708,
      "learning_rate": 3.386694536543175e-05,
      "loss": 0.0002,
      "step": 67150
    },
    {
      "epoch": 3.229061553985873,
      "grad_norm": 0.22979854047298431,
      "learning_rate": 3.385493248762674e-05,
      "loss": 0.0002,
      "step": 67200
    },
    {
      "epoch": 3.2314641295468745,
      "grad_norm": 0.4663960039615631,
      "learning_rate": 3.3842919609821736e-05,
      "loss": 0.0002,
      "step": 67250
    },
    {
      "epoch": 3.2338667051078755,
      "grad_norm": 0.14954759180545807,
      "learning_rate": 3.3830906732016727e-05,
      "loss": 0.0002,
      "step": 67300
    },
    {
      "epoch": 3.236269280668877,
      "grad_norm": 0.09563509374856949,
      "learning_rate": 3.381889385421171e-05,
      "loss": 0.0002,
      "step": 67350
    },
    {
      "epoch": 3.2386718562298786,
      "grad_norm": 0.23401176929473877,
      "learning_rate": 3.380688097640671e-05,
      "loss": 0.0002,
      "step": 67400
    },
    {
      "epoch": 3.2410744317908797,
      "grad_norm": 0.09133243560791016,
      "learning_rate": 3.37948680986017e-05,
      "loss": 0.0002,
      "step": 67450
    },
    {
      "epoch": 3.2434770073518813,
      "grad_norm": 0.11546844989061356,
      "learning_rate": 3.37828552207967e-05,
      "loss": 0.0002,
      "step": 67500
    },
    {
      "epoch": 3.245879582912883,
      "grad_norm": 0.11055778712034225,
      "learning_rate": 3.377084234299169e-05,
      "loss": 0.0001,
      "step": 67550
    },
    {
      "epoch": 3.248282158473884,
      "grad_norm": 0.19994983077049255,
      "learning_rate": 3.375882946518668e-05,
      "loss": 0.0007,
      "step": 67600
    },
    {
      "epoch": 3.2506847340348854,
      "grad_norm": 0.18278281390666962,
      "learning_rate": 3.3746816587381676e-05,
      "loss": 0.0002,
      "step": 67650
    },
    {
      "epoch": 3.2530873095958865,
      "grad_norm": 0.16840089857578278,
      "learning_rate": 3.373480370957667e-05,
      "loss": 0.0007,
      "step": 67700
    },
    {
      "epoch": 3.255489885156888,
      "grad_norm": 0.31387409567832947,
      "learning_rate": 3.3722790831771664e-05,
      "loss": 0.0002,
      "step": 67750
    },
    {
      "epoch": 3.2578924607178896,
      "grad_norm": 0.8362464904785156,
      "learning_rate": 3.3710777953966655e-05,
      "loss": 0.0002,
      "step": 67800
    },
    {
      "epoch": 3.260295036278891,
      "grad_norm": 0.0882222130894661,
      "learning_rate": 3.3698765076161646e-05,
      "loss": 0.0002,
      "step": 67850
    },
    {
      "epoch": 3.2626976118398923,
      "grad_norm": 0.28485107421875,
      "learning_rate": 3.3686752198356644e-05,
      "loss": 0.0001,
      "step": 67900
    },
    {
      "epoch": 3.265100187400894,
      "grad_norm": 0.503307580947876,
      "learning_rate": 3.3674739320551634e-05,
      "loss": 0.0002,
      "step": 67950
    },
    {
      "epoch": 3.267502762961895,
      "grad_norm": 0.1340322494506836,
      "learning_rate": 3.3662726442746625e-05,
      "loss": 0.0002,
      "step": 68000
    },
    {
      "epoch": 3.2699053385228964,
      "grad_norm": 0.07727266848087311,
      "learning_rate": 3.365071356494162e-05,
      "loss": 0.0001,
      "step": 68050
    },
    {
      "epoch": 3.272307914083898,
      "grad_norm": 0.21207135915756226,
      "learning_rate": 3.363870068713661e-05,
      "loss": 0.0002,
      "step": 68100
    },
    {
      "epoch": 3.2747104896448995,
      "grad_norm": 0.1073913648724556,
      "learning_rate": 3.3626687809331604e-05,
      "loss": 0.0001,
      "step": 68150
    },
    {
      "epoch": 3.2771130652059006,
      "grad_norm": 0.18511438369750977,
      "learning_rate": 3.3614674931526595e-05,
      "loss": 0.0002,
      "step": 68200
    },
    {
      "epoch": 3.279515640766902,
      "grad_norm": 0.23996412754058838,
      "learning_rate": 3.360266205372159e-05,
      "loss": 0.0008,
      "step": 68250
    },
    {
      "epoch": 3.2819182163279037,
      "grad_norm": 0.5170571804046631,
      "learning_rate": 3.3590649175916584e-05,
      "loss": 0.0005,
      "step": 68300
    },
    {
      "epoch": 3.284320791888905,
      "grad_norm": 0.2599777281284332,
      "learning_rate": 3.3578636298111575e-05,
      "loss": 0.0002,
      "step": 68350
    },
    {
      "epoch": 3.2867233674499063,
      "grad_norm": 0.3784337043762207,
      "learning_rate": 3.356662342030657e-05,
      "loss": 0.0001,
      "step": 68400
    },
    {
      "epoch": 3.289125943010908,
      "grad_norm": 0.18917448818683624,
      "learning_rate": 3.355461054250156e-05,
      "loss": 0.0002,
      "step": 68450
    },
    {
      "epoch": 3.291528518571909,
      "grad_norm": 0.19773931801319122,
      "learning_rate": 3.3542597664696554e-05,
      "loss": 0.0002,
      "step": 68500
    },
    {
      "epoch": 3.2939310941329105,
      "grad_norm": 0.35972830653190613,
      "learning_rate": 3.353058478689155e-05,
      "loss": 0.0002,
      "step": 68550
    },
    {
      "epoch": 3.296333669693912,
      "grad_norm": 0.08922865241765976,
      "learning_rate": 3.351857190908654e-05,
      "loss": 0.0002,
      "step": 68600
    },
    {
      "epoch": 3.298736245254913,
      "grad_norm": 0.11513316631317139,
      "learning_rate": 3.350655903128154e-05,
      "loss": 0.0002,
      "step": 68650
    },
    {
      "epoch": 3.3011388208159147,
      "grad_norm": 0.2281658947467804,
      "learning_rate": 3.349454615347653e-05,
      "loss": 0.0002,
      "step": 68700
    },
    {
      "epoch": 3.3035413963769162,
      "grad_norm": 0.4053950905799866,
      "learning_rate": 3.348253327567152e-05,
      "loss": 0.0002,
      "step": 68750
    },
    {
      "epoch": 3.3059439719379173,
      "grad_norm": 0.12468192726373672,
      "learning_rate": 3.347052039786652e-05,
      "loss": 0.0002,
      "step": 68800
    },
    {
      "epoch": 3.308346547498919,
      "grad_norm": 0.18242940306663513,
      "learning_rate": 3.34585075200615e-05,
      "loss": 0.0001,
      "step": 68850
    },
    {
      "epoch": 3.3107491230599204,
      "grad_norm": 0.16510650515556335,
      "learning_rate": 3.34464946422565e-05,
      "loss": 0.0002,
      "step": 68900
    },
    {
      "epoch": 3.3131516986209215,
      "grad_norm": 0.6678153276443481,
      "learning_rate": 3.343448176445149e-05,
      "loss": 0.0002,
      "step": 68950
    },
    {
      "epoch": 3.315554274181923,
      "grad_norm": 0.4509502649307251,
      "learning_rate": 3.342246888664648e-05,
      "loss": 0.0002,
      "step": 69000
    },
    {
      "epoch": 3.3179568497429246,
      "grad_norm": 0.09540297836065292,
      "learning_rate": 3.341045600884148e-05,
      "loss": 0.0002,
      "step": 69050
    },
    {
      "epoch": 3.3203594253039257,
      "grad_norm": 0.4988851249217987,
      "learning_rate": 3.339844313103647e-05,
      "loss": 0.0002,
      "step": 69100
    },
    {
      "epoch": 3.3227620008649272,
      "grad_norm": 0.12774714827537537,
      "learning_rate": 3.338643025323147e-05,
      "loss": 0.0002,
      "step": 69150
    },
    {
      "epoch": 3.3251645764259288,
      "grad_norm": 0.18835939466953278,
      "learning_rate": 3.337441737542646e-05,
      "loss": 0.0001,
      "step": 69200
    },
    {
      "epoch": 3.32756715198693,
      "grad_norm": 0.1767510622739792,
      "learning_rate": 3.336240449762145e-05,
      "loss": 0.0002,
      "step": 69250
    },
    {
      "epoch": 3.3299697275479314,
      "grad_norm": 0.18014268577098846,
      "learning_rate": 3.335039161981645e-05,
      "loss": 0.0002,
      "step": 69300
    },
    {
      "epoch": 3.332372303108933,
      "grad_norm": 0.04637010022997856,
      "learning_rate": 3.333837874201144e-05,
      "loss": 0.0002,
      "step": 69350
    },
    {
      "epoch": 3.334774878669934,
      "grad_norm": 0.13770371675491333,
      "learning_rate": 3.332636586420643e-05,
      "loss": 0.0002,
      "step": 69400
    },
    {
      "epoch": 3.3371774542309356,
      "grad_norm": 0.3663744628429413,
      "learning_rate": 3.331435298640143e-05,
      "loss": 0.0002,
      "step": 69450
    },
    {
      "epoch": 3.339580029791937,
      "grad_norm": 0.3740491271018982,
      "learning_rate": 3.330234010859642e-05,
      "loss": 0.0008,
      "step": 69500
    },
    {
      "epoch": 3.3419826053529382,
      "grad_norm": 0.10751349478960037,
      "learning_rate": 3.3290327230791415e-05,
      "loss": 0.0002,
      "step": 69550
    },
    {
      "epoch": 3.3443851809139398,
      "grad_norm": 0.18358194828033447,
      "learning_rate": 3.32783143529864e-05,
      "loss": 0.0002,
      "step": 69600
    },
    {
      "epoch": 3.3467877564749413,
      "grad_norm": 0.19311314821243286,
      "learning_rate": 3.32663014751814e-05,
      "loss": 0.0001,
      "step": 69650
    },
    {
      "epoch": 3.3491903320359424,
      "grad_norm": 0.2702532112598419,
      "learning_rate": 3.325428859737639e-05,
      "loss": 0.0001,
      "step": 69700
    },
    {
      "epoch": 3.351592907596944,
      "grad_norm": 0.22880837321281433,
      "learning_rate": 3.324227571957138e-05,
      "loss": 0.0003,
      "step": 69750
    },
    {
      "epoch": 3.3539954831579455,
      "grad_norm": 0.13599754869937897,
      "learning_rate": 3.3230262841766376e-05,
      "loss": 0.0002,
      "step": 69800
    },
    {
      "epoch": 3.3563980587189466,
      "grad_norm": 0.7672649025917053,
      "learning_rate": 3.321824996396137e-05,
      "loss": 0.0002,
      "step": 69850
    },
    {
      "epoch": 3.358800634279948,
      "grad_norm": 0.24727052450180054,
      "learning_rate": 3.320623708615636e-05,
      "loss": 0.0002,
      "step": 69900
    },
    {
      "epoch": 3.3612032098409497,
      "grad_norm": 0.09402760863304138,
      "learning_rate": 3.3194224208351356e-05,
      "loss": 0.0002,
      "step": 69950
    },
    {
      "epoch": 3.3636057854019508,
      "grad_norm": 0.11526291817426682,
      "learning_rate": 3.3182211330546346e-05,
      "loss": 0.0002,
      "step": 70000
    },
    {
      "epoch": 3.3660083609629523,
      "grad_norm": 0.37746745347976685,
      "learning_rate": 3.3170198452741344e-05,
      "loss": 0.0002,
      "step": 70050
    },
    {
      "epoch": 3.368410936523954,
      "grad_norm": 0.23874016106128693,
      "learning_rate": 3.3158185574936335e-05,
      "loss": 0.0002,
      "step": 70100
    },
    {
      "epoch": 3.370813512084955,
      "grad_norm": 0.0956922098994255,
      "learning_rate": 3.3146172697131326e-05,
      "loss": 0.0001,
      "step": 70150
    },
    {
      "epoch": 3.3732160876459565,
      "grad_norm": 0.6194067597389221,
      "learning_rate": 3.313415981932632e-05,
      "loss": 0.0002,
      "step": 70200
    },
    {
      "epoch": 3.375618663206958,
      "grad_norm": 0.35621923208236694,
      "learning_rate": 3.3122146941521314e-05,
      "loss": 0.0001,
      "step": 70250
    },
    {
      "epoch": 3.378021238767959,
      "grad_norm": 0.09429588913917542,
      "learning_rate": 3.3110134063716305e-05,
      "loss": 0.0003,
      "step": 70300
    },
    {
      "epoch": 3.3804238143289607,
      "grad_norm": 0.18845082819461823,
      "learning_rate": 3.3098121185911296e-05,
      "loss": 0.0002,
      "step": 70350
    },
    {
      "epoch": 3.382826389889962,
      "grad_norm": 0.20123490691184998,
      "learning_rate": 3.3086108308106287e-05,
      "loss": 0.0002,
      "step": 70400
    },
    {
      "epoch": 3.3852289654509633,
      "grad_norm": 0.15772634744644165,
      "learning_rate": 3.3074095430301284e-05,
      "loss": 0.0002,
      "step": 70450
    },
    {
      "epoch": 3.387631541011965,
      "grad_norm": 0.4917242228984833,
      "learning_rate": 3.3062082552496275e-05,
      "loss": 0.0002,
      "step": 70500
    },
    {
      "epoch": 3.3900341165729664,
      "grad_norm": 0.638995885848999,
      "learning_rate": 3.305006967469127e-05,
      "loss": 0.0001,
      "step": 70550
    },
    {
      "epoch": 3.3924366921339675,
      "grad_norm": 0.0846112072467804,
      "learning_rate": 3.303805679688626e-05,
      "loss": 0.0002,
      "step": 70600
    },
    {
      "epoch": 3.394839267694969,
      "grad_norm": 0.2402077317237854,
      "learning_rate": 3.3026043919081254e-05,
      "loss": 0.0002,
      "step": 70650
    },
    {
      "epoch": 3.3972418432559706,
      "grad_norm": 0.38978418707847595,
      "learning_rate": 3.301403104127625e-05,
      "loss": 0.0002,
      "step": 70700
    },
    {
      "epoch": 3.3996444188169717,
      "grad_norm": 0.32664236426353455,
      "learning_rate": 3.300201816347124e-05,
      "loss": 0.0002,
      "step": 70750
    },
    {
      "epoch": 3.402046994377973,
      "grad_norm": 0.17894509434700012,
      "learning_rate": 3.2990005285666233e-05,
      "loss": 0.0002,
      "step": 70800
    },
    {
      "epoch": 3.4044495699389747,
      "grad_norm": 0.48406410217285156,
      "learning_rate": 3.297799240786123e-05,
      "loss": 0.0002,
      "step": 70850
    },
    {
      "epoch": 3.406852145499976,
      "grad_norm": 0.18266309797763824,
      "learning_rate": 3.296597953005622e-05,
      "loss": 0.0002,
      "step": 70900
    },
    {
      "epoch": 3.4092547210609774,
      "grad_norm": 0.08910747617483139,
      "learning_rate": 3.295396665225122e-05,
      "loss": 0.0002,
      "step": 70950
    },
    {
      "epoch": 3.411657296621979,
      "grad_norm": 0.5429915189743042,
      "learning_rate": 3.294195377444621e-05,
      "loss": 0.0002,
      "step": 71000
    },
    {
      "epoch": 3.41405987218298,
      "grad_norm": 0.1660928726196289,
      "learning_rate": 3.29299408966412e-05,
      "loss": 0.0002,
      "step": 71050
    },
    {
      "epoch": 3.4164624477439816,
      "grad_norm": 0.30209672451019287,
      "learning_rate": 3.291792801883619e-05,
      "loss": 0.0002,
      "step": 71100
    },
    {
      "epoch": 3.418865023304983,
      "grad_norm": 0.14877279102802277,
      "learning_rate": 3.290591514103118e-05,
      "loss": 0.0001,
      "step": 71150
    },
    {
      "epoch": 3.421267598865984,
      "grad_norm": 0.3482077121734619,
      "learning_rate": 3.289390226322618e-05,
      "loss": 0.0001,
      "step": 71200
    },
    {
      "epoch": 3.4236701744269857,
      "grad_norm": 0.3039151728153229,
      "learning_rate": 3.288188938542117e-05,
      "loss": 0.0002,
      "step": 71250
    },
    {
      "epoch": 3.4260727499879873,
      "grad_norm": 0.1036776676774025,
      "learning_rate": 3.286987650761616e-05,
      "loss": 0.0002,
      "step": 71300
    },
    {
      "epoch": 3.4284753255489884,
      "grad_norm": 0.07547757774591446,
      "learning_rate": 3.285786362981116e-05,
      "loss": 0.0002,
      "step": 71350
    },
    {
      "epoch": 3.43087790110999,
      "grad_norm": 0.6201515197753906,
      "learning_rate": 3.284585075200615e-05,
      "loss": 0.0002,
      "step": 71400
    },
    {
      "epoch": 3.4332804766709915,
      "grad_norm": 0.32333773374557495,
      "learning_rate": 3.283383787420115e-05,
      "loss": 0.0002,
      "step": 71450
    },
    {
      "epoch": 3.4356830522319926,
      "grad_norm": 0.22951728105545044,
      "learning_rate": 3.282182499639614e-05,
      "loss": 0.0002,
      "step": 71500
    },
    {
      "epoch": 3.438085627792994,
      "grad_norm": 0.11372766643762589,
      "learning_rate": 3.280981211859113e-05,
      "loss": 0.0004,
      "step": 71550
    },
    {
      "epoch": 3.4404882033539956,
      "grad_norm": 0.04639003798365593,
      "learning_rate": 3.279779924078613e-05,
      "loss": 0.0002,
      "step": 71600
    },
    {
      "epoch": 3.4428907789149967,
      "grad_norm": 0.1183927059173584,
      "learning_rate": 3.278578636298112e-05,
      "loss": 0.0002,
      "step": 71650
    },
    {
      "epoch": 3.4452933544759983,
      "grad_norm": 0.5477924942970276,
      "learning_rate": 3.2773773485176116e-05,
      "loss": 0.0001,
      "step": 71700
    },
    {
      "epoch": 3.447695930037,
      "grad_norm": 0.18625739216804504,
      "learning_rate": 3.2761760607371107e-05,
      "loss": 0.0001,
      "step": 71750
    },
    {
      "epoch": 3.450098505598001,
      "grad_norm": 0.2715547978878021,
      "learning_rate": 3.274974772956609e-05,
      "loss": 0.0001,
      "step": 71800
    },
    {
      "epoch": 3.4525010811590024,
      "grad_norm": 0.16805683076381683,
      "learning_rate": 3.273773485176109e-05,
      "loss": 0.0006,
      "step": 71850
    },
    {
      "epoch": 3.454903656720004,
      "grad_norm": 0.579399585723877,
      "learning_rate": 3.272572197395608e-05,
      "loss": 0.0003,
      "step": 71900
    },
    {
      "epoch": 3.457306232281005,
      "grad_norm": 0.27103391289711,
      "learning_rate": 3.271370909615108e-05,
      "loss": 0.0001,
      "step": 71950
    },
    {
      "epoch": 3.4597088078420066,
      "grad_norm": 0.25911447405815125,
      "learning_rate": 3.270169621834607e-05,
      "loss": 0.0001,
      "step": 72000
    },
    {
      "epoch": 3.462111383403008,
      "grad_norm": 0.07059327512979507,
      "learning_rate": 3.268968334054106e-05,
      "loss": 0.0006,
      "step": 72050
    },
    {
      "epoch": 3.4645139589640093,
      "grad_norm": 0.1871422976255417,
      "learning_rate": 3.2677670462736056e-05,
      "loss": 0.0002,
      "step": 72100
    },
    {
      "epoch": 3.466916534525011,
      "grad_norm": 0.11903843283653259,
      "learning_rate": 3.266565758493105e-05,
      "loss": 0.0002,
      "step": 72150
    },
    {
      "epoch": 3.4693191100860123,
      "grad_norm": 3.5448410511016846,
      "learning_rate": 3.2653644707126044e-05,
      "loss": 0.0007,
      "step": 72200
    },
    {
      "epoch": 3.4717216856470134,
      "grad_norm": 0.2272968590259552,
      "learning_rate": 3.2641631829321035e-05,
      "loss": 0.0002,
      "step": 72250
    },
    {
      "epoch": 3.474124261208015,
      "grad_norm": 0.1158047616481781,
      "learning_rate": 3.2629618951516026e-05,
      "loss": 0.0002,
      "step": 72300
    },
    {
      "epoch": 3.4765268367690165,
      "grad_norm": 0.08501649647951126,
      "learning_rate": 3.2617606073711024e-05,
      "loss": 0.0001,
      "step": 72350
    },
    {
      "epoch": 3.4789294123300176,
      "grad_norm": 0.16848421096801758,
      "learning_rate": 3.2605593195906014e-05,
      "loss": 0.0002,
      "step": 72400
    },
    {
      "epoch": 3.481331987891019,
      "grad_norm": 0.21028682589530945,
      "learning_rate": 3.2593580318101005e-05,
      "loss": 0.0006,
      "step": 72450
    },
    {
      "epoch": 3.4837345634520207,
      "grad_norm": 0.07213382422924042,
      "learning_rate": 3.2581567440296e-05,
      "loss": 0.0007,
      "step": 72500
    },
    {
      "epoch": 3.486137139013022,
      "grad_norm": 0.50943523645401,
      "learning_rate": 3.256955456249099e-05,
      "loss": 0.0002,
      "step": 72550
    },
    {
      "epoch": 3.4885397145740233,
      "grad_norm": 0.4749040901660919,
      "learning_rate": 3.2557541684685984e-05,
      "loss": 0.0002,
      "step": 72600
    },
    {
      "epoch": 3.490942290135025,
      "grad_norm": 0.5965206623077393,
      "learning_rate": 3.2545528806880975e-05,
      "loss": 0.0006,
      "step": 72650
    },
    {
      "epoch": 3.493344865696026,
      "grad_norm": 0.5168264508247375,
      "learning_rate": 3.2533515929075966e-05,
      "loss": 0.0005,
      "step": 72700
    },
    {
      "epoch": 3.4957474412570275,
      "grad_norm": 0.18441317975521088,
      "learning_rate": 3.2521503051270964e-05,
      "loss": 0.0002,
      "step": 72750
    },
    {
      "epoch": 3.498150016818029,
      "grad_norm": 0.07264521718025208,
      "learning_rate": 3.2509490173465955e-05,
      "loss": 0.0001,
      "step": 72800
    },
    {
      "epoch": 3.50055259237903,
      "grad_norm": 0.2714274227619171,
      "learning_rate": 3.249747729566095e-05,
      "loss": 0.0002,
      "step": 72850
    },
    {
      "epoch": 3.5029551679400317,
      "grad_norm": 0.23370884358882904,
      "learning_rate": 3.248546441785594e-05,
      "loss": 0.0002,
      "step": 72900
    },
    {
      "epoch": 3.5053577435010332,
      "grad_norm": 0.08160419762134552,
      "learning_rate": 3.2473451540050934e-05,
      "loss": 0.0002,
      "step": 72950
    },
    {
      "epoch": 3.5077603190620343,
      "grad_norm": 0.14273937046527863,
      "learning_rate": 3.246143866224593e-05,
      "loss": 0.0002,
      "step": 73000
    },
    {
      "epoch": 3.510162894623036,
      "grad_norm": 0.10754504799842834,
      "learning_rate": 3.244942578444092e-05,
      "loss": 0.0002,
      "step": 73050
    },
    {
      "epoch": 3.5125654701840374,
      "grad_norm": 0.13660812377929688,
      "learning_rate": 3.243741290663592e-05,
      "loss": 0.0003,
      "step": 73100
    },
    {
      "epoch": 3.5149680457450385,
      "grad_norm": 0.305881530046463,
      "learning_rate": 3.242540002883091e-05,
      "loss": 0.0002,
      "step": 73150
    },
    {
      "epoch": 3.51737062130604,
      "grad_norm": 0.6324952840805054,
      "learning_rate": 3.24133871510259e-05,
      "loss": 0.0002,
      "step": 73200
    },
    {
      "epoch": 3.5197731968670416,
      "grad_norm": 0.1318231225013733,
      "learning_rate": 3.24013742732209e-05,
      "loss": 0.0002,
      "step": 73250
    },
    {
      "epoch": 3.522175772428043,
      "grad_norm": 0.8077219724655151,
      "learning_rate": 3.238936139541588e-05,
      "loss": 0.0002,
      "step": 73300
    },
    {
      "epoch": 3.5245783479890442,
      "grad_norm": 0.4279787838459015,
      "learning_rate": 3.237734851761088e-05,
      "loss": 0.0002,
      "step": 73350
    },
    {
      "epoch": 3.5269809235500458,
      "grad_norm": 0.3972845673561096,
      "learning_rate": 3.236533563980587e-05,
      "loss": 0.0002,
      "step": 73400
    },
    {
      "epoch": 3.529383499111047,
      "grad_norm": 0.8590897917747498,
      "learning_rate": 3.235332276200086e-05,
      "loss": 0.0002,
      "step": 73450
    },
    {
      "epoch": 3.5317860746720484,
      "grad_norm": 0.2769272029399872,
      "learning_rate": 3.234130988419586e-05,
      "loss": 0.0002,
      "step": 73500
    },
    {
      "epoch": 3.53418865023305,
      "grad_norm": 0.10080056637525558,
      "learning_rate": 3.232929700639085e-05,
      "loss": 0.0002,
      "step": 73550
    },
    {
      "epoch": 3.5365912257940515,
      "grad_norm": 0.19535702466964722,
      "learning_rate": 3.231728412858585e-05,
      "loss": 0.0002,
      "step": 73600
    },
    {
      "epoch": 3.5389938013550526,
      "grad_norm": 0.33975812792778015,
      "learning_rate": 3.230527125078084e-05,
      "loss": 0.0002,
      "step": 73650
    },
    {
      "epoch": 3.541396376916054,
      "grad_norm": 0.13655906915664673,
      "learning_rate": 3.229325837297583e-05,
      "loss": 0.0001,
      "step": 73700
    },
    {
      "epoch": 3.5437989524770552,
      "grad_norm": 0.3024974465370178,
      "learning_rate": 3.228124549517083e-05,
      "loss": 0.0007,
      "step": 73750
    },
    {
      "epoch": 3.5462015280380568,
      "grad_norm": 0.2022189348936081,
      "learning_rate": 3.226923261736582e-05,
      "loss": 0.0001,
      "step": 73800
    },
    {
      "epoch": 3.5486041035990583,
      "grad_norm": 0.22114481031894684,
      "learning_rate": 3.225721973956081e-05,
      "loss": 0.0001,
      "step": 73850
    },
    {
      "epoch": 3.55100667916006,
      "grad_norm": 0.20137684047222137,
      "learning_rate": 3.224520686175581e-05,
      "loss": 0.0002,
      "step": 73900
    },
    {
      "epoch": 3.553409254721061,
      "grad_norm": 0.20672988891601562,
      "learning_rate": 3.22331939839508e-05,
      "loss": 0.0002,
      "step": 73950
    },
    {
      "epoch": 3.5558118302820625,
      "grad_norm": 0.193223774433136,
      "learning_rate": 3.2221181106145795e-05,
      "loss": 0.0002,
      "step": 74000
    },
    {
      "epoch": 3.5582144058430636,
      "grad_norm": 0.053766388446092606,
      "learning_rate": 3.220916822834078e-05,
      "loss": 0.0008,
      "step": 74050
    },
    {
      "epoch": 3.560616981404065,
      "grad_norm": 3.1157727241516113,
      "learning_rate": 3.219715535053578e-05,
      "loss": 0.001,
      "step": 74100
    },
    {
      "epoch": 3.5630195569650667,
      "grad_norm": 0.10698531568050385,
      "learning_rate": 3.218514247273077e-05,
      "loss": 0.0001,
      "step": 74150
    },
    {
      "epoch": 3.565422132526068,
      "grad_norm": 0.44906705617904663,
      "learning_rate": 3.217312959492576e-05,
      "loss": 0.0002,
      "step": 74200
    },
    {
      "epoch": 3.5678247080870693,
      "grad_norm": 0.2854323387145996,
      "learning_rate": 3.2161116717120756e-05,
      "loss": 0.0002,
      "step": 74250
    },
    {
      "epoch": 3.570227283648071,
      "grad_norm": 0.11542938649654388,
      "learning_rate": 3.214910383931575e-05,
      "loss": 0.0001,
      "step": 74300
    },
    {
      "epoch": 3.572629859209072,
      "grad_norm": 0.08194637298583984,
      "learning_rate": 3.213709096151074e-05,
      "loss": 0.0002,
      "step": 74350
    },
    {
      "epoch": 3.5750324347700735,
      "grad_norm": 0.018379850313067436,
      "learning_rate": 3.2125078083705735e-05,
      "loss": 0.0002,
      "step": 74400
    },
    {
      "epoch": 3.577435010331075,
      "grad_norm": 0.41451430320739746,
      "learning_rate": 3.2113065205900726e-05,
      "loss": 0.0002,
      "step": 74450
    },
    {
      "epoch": 3.5798375858920766,
      "grad_norm": 0.47477298974990845,
      "learning_rate": 3.2101052328095724e-05,
      "loss": 0.0001,
      "step": 74500
    },
    {
      "epoch": 3.5822401614530777,
      "grad_norm": 0.1735224723815918,
      "learning_rate": 3.2089039450290715e-05,
      "loss": 0.0002,
      "step": 74550
    },
    {
      "epoch": 3.584642737014079,
      "grad_norm": 0.08225169777870178,
      "learning_rate": 3.2077026572485706e-05,
      "loss": 0.0001,
      "step": 74600
    },
    {
      "epoch": 3.5870453125750803,
      "grad_norm": 0.28357282280921936,
      "learning_rate": 3.20650136946807e-05,
      "loss": 0.0002,
      "step": 74650
    },
    {
      "epoch": 3.589447888136082,
      "grad_norm": 0.5114902257919312,
      "learning_rate": 3.2053000816875694e-05,
      "loss": 0.0003,
      "step": 74700
    },
    {
      "epoch": 3.5918504636970834,
      "grad_norm": 0.2296687215566635,
      "learning_rate": 3.2040987939070685e-05,
      "loss": 0.0002,
      "step": 74750
    },
    {
      "epoch": 3.594253039258085,
      "grad_norm": 0.484921395778656,
      "learning_rate": 3.2028975061265676e-05,
      "loss": 0.0002,
      "step": 74800
    },
    {
      "epoch": 3.596655614819086,
      "grad_norm": 0.1059422641992569,
      "learning_rate": 3.2016962183460666e-05,
      "loss": 0.0003,
      "step": 74850
    },
    {
      "epoch": 3.5990581903800876,
      "grad_norm": 0.14517588913440704,
      "learning_rate": 3.2004949305655664e-05,
      "loss": 0.0001,
      "step": 74900
    },
    {
      "epoch": 3.6014607659410887,
      "grad_norm": 0.3674512207508087,
      "learning_rate": 3.1992936427850655e-05,
      "loss": 0.0002,
      "step": 74950
    },
    {
      "epoch": 3.60386334150209,
      "grad_norm": 0.2891803979873657,
      "learning_rate": 3.198092355004565e-05,
      "loss": 0.0003,
      "step": 75000
    },
    {
      "epoch": 3.6062659170630917,
      "grad_norm": 0.133971706032753,
      "learning_rate": 3.196891067224064e-05,
      "loss": 0.0001,
      "step": 75050
    },
    {
      "epoch": 3.6086684926240933,
      "grad_norm": 0.06867432594299316,
      "learning_rate": 3.1956897794435634e-05,
      "loss": 0.0002,
      "step": 75100
    },
    {
      "epoch": 3.6110710681850944,
      "grad_norm": 0.14838965237140656,
      "learning_rate": 3.194488491663063e-05,
      "loss": 0.0002,
      "step": 75150
    },
    {
      "epoch": 3.613473643746096,
      "grad_norm": 0.47958260774612427,
      "learning_rate": 3.193287203882562e-05,
      "loss": 0.0008,
      "step": 75200
    },
    {
      "epoch": 3.615876219307097,
      "grad_norm": 0.2879088222980499,
      "learning_rate": 3.1920859161020613e-05,
      "loss": 0.0006,
      "step": 75250
    },
    {
      "epoch": 3.6182787948680986,
      "grad_norm": 0.2381598800420761,
      "learning_rate": 3.190884628321561e-05,
      "loss": 0.0002,
      "step": 75300
    },
    {
      "epoch": 3.6206813704291,
      "grad_norm": 0.21593280136585236,
      "learning_rate": 3.18968334054106e-05,
      "loss": 0.0002,
      "step": 75350
    },
    {
      "epoch": 3.6230839459901016,
      "grad_norm": 0.30384591221809387,
      "learning_rate": 3.18848205276056e-05,
      "loss": 0.0003,
      "step": 75400
    },
    {
      "epoch": 3.6254865215511027,
      "grad_norm": 0.20171287655830383,
      "learning_rate": 3.187280764980059e-05,
      "loss": 0.0002,
      "step": 75450
    },
    {
      "epoch": 3.6278890971121043,
      "grad_norm": 0.11393486708402634,
      "learning_rate": 3.186079477199558e-05,
      "loss": 0.0001,
      "step": 75500
    },
    {
      "epoch": 3.6302916726731054,
      "grad_norm": 0.15526632964611053,
      "learning_rate": 3.184878189419057e-05,
      "loss": 0.0002,
      "step": 75550
    },
    {
      "epoch": 3.632694248234107,
      "grad_norm": 0.14256829023361206,
      "learning_rate": 3.183676901638556e-05,
      "loss": 0.0001,
      "step": 75600
    },
    {
      "epoch": 3.6350968237951085,
      "grad_norm": 0.27283236384391785,
      "learning_rate": 3.182475613858056e-05,
      "loss": 0.0002,
      "step": 75650
    },
    {
      "epoch": 3.63749939935611,
      "grad_norm": 0.07148148864507675,
      "learning_rate": 3.181274326077555e-05,
      "loss": 0.0002,
      "step": 75700
    },
    {
      "epoch": 3.639901974917111,
      "grad_norm": 0.1877749115228653,
      "learning_rate": 3.180073038297054e-05,
      "loss": 0.0002,
      "step": 75750
    },
    {
      "epoch": 3.6423045504781126,
      "grad_norm": 0.31590262055397034,
      "learning_rate": 3.178871750516554e-05,
      "loss": 0.0002,
      "step": 75800
    },
    {
      "epoch": 3.6447071260391137,
      "grad_norm": 0.11983338743448257,
      "learning_rate": 3.177670462736053e-05,
      "loss": 0.0009,
      "step": 75850
    },
    {
      "epoch": 3.6471097016001153,
      "grad_norm": 0.1764632910490036,
      "learning_rate": 3.176469174955553e-05,
      "loss": 0.0002,
      "step": 75900
    },
    {
      "epoch": 3.649512277161117,
      "grad_norm": 0.08042324334383011,
      "learning_rate": 3.175267887175052e-05,
      "loss": 0.0002,
      "step": 75950
    },
    {
      "epoch": 3.6519148527221184,
      "grad_norm": 0.31466013193130493,
      "learning_rate": 3.174066599394551e-05,
      "loss": 0.0002,
      "step": 76000
    },
    {
      "epoch": 3.6543174282831195,
      "grad_norm": 0.12356320023536682,
      "learning_rate": 3.172865311614051e-05,
      "loss": 0.0002,
      "step": 76050
    },
    {
      "epoch": 3.656720003844121,
      "grad_norm": 0.2984762191772461,
      "learning_rate": 3.17166402383355e-05,
      "loss": 0.0001,
      "step": 76100
    },
    {
      "epoch": 3.659122579405122,
      "grad_norm": 0.40840795636177063,
      "learning_rate": 3.170462736053049e-05,
      "loss": 0.0002,
      "step": 76150
    },
    {
      "epoch": 3.6615251549661236,
      "grad_norm": 0.05577126145362854,
      "learning_rate": 3.1692614482725487e-05,
      "loss": 0.0002,
      "step": 76200
    },
    {
      "epoch": 3.663927730527125,
      "grad_norm": 0.267238050699234,
      "learning_rate": 3.168060160492048e-05,
      "loss": 0.0003,
      "step": 76250
    },
    {
      "epoch": 3.6663303060881267,
      "grad_norm": 0.7670098543167114,
      "learning_rate": 3.166858872711547e-05,
      "loss": 0.0002,
      "step": 76300
    },
    {
      "epoch": 3.668732881649128,
      "grad_norm": 0.12385358661413193,
      "learning_rate": 3.165657584931046e-05,
      "loss": 0.0001,
      "step": 76350
    },
    {
      "epoch": 3.6711354572101293,
      "grad_norm": 0.4306526780128479,
      "learning_rate": 3.1644562971505457e-05,
      "loss": 0.0002,
      "step": 76400
    },
    {
      "epoch": 3.6735380327711304,
      "grad_norm": 0.05656630918383598,
      "learning_rate": 3.163255009370045e-05,
      "loss": 0.0001,
      "step": 76450
    },
    {
      "epoch": 3.675940608332132,
      "grad_norm": 0.10669543594121933,
      "learning_rate": 3.162053721589544e-05,
      "loss": 0.0001,
      "step": 76500
    },
    {
      "epoch": 3.6783431838931335,
      "grad_norm": 0.4954846203327179,
      "learning_rate": 3.1608524338090436e-05,
      "loss": 0.0002,
      "step": 76550
    },
    {
      "epoch": 3.680745759454135,
      "grad_norm": 0.16003604233264923,
      "learning_rate": 3.159651146028543e-05,
      "loss": 0.0002,
      "step": 76600
    },
    {
      "epoch": 3.683148335015136,
      "grad_norm": 0.13028645515441895,
      "learning_rate": 3.158449858248042e-05,
      "loss": 0.0001,
      "step": 76650
    },
    {
      "epoch": 3.6855509105761377,
      "grad_norm": 0.07377266883850098,
      "learning_rate": 3.1572485704675415e-05,
      "loss": 0.0002,
      "step": 76700
    },
    {
      "epoch": 3.687953486137139,
      "grad_norm": 0.15304194390773773,
      "learning_rate": 3.1560472826870406e-05,
      "loss": 0.0001,
      "step": 76750
    },
    {
      "epoch": 3.6903560616981403,
      "grad_norm": 0.1323663592338562,
      "learning_rate": 3.1548459949065404e-05,
      "loss": 0.0006,
      "step": 76800
    },
    {
      "epoch": 3.692758637259142,
      "grad_norm": 0.4339602291584015,
      "learning_rate": 3.1536447071260394e-05,
      "loss": 0.0002,
      "step": 76850
    },
    {
      "epoch": 3.6951612128201434,
      "grad_norm": 0.29007071256637573,
      "learning_rate": 3.1524434193455385e-05,
      "loss": 0.0002,
      "step": 76900
    },
    {
      "epoch": 3.6975637883811445,
      "grad_norm": 0.25132110714912415,
      "learning_rate": 3.151242131565038e-05,
      "loss": 0.0002,
      "step": 76950
    },
    {
      "epoch": 3.699966363942146,
      "grad_norm": 0.05525260791182518,
      "learning_rate": 3.150040843784537e-05,
      "loss": 0.0002,
      "step": 77000
    },
    {
      "epoch": 3.702368939503147,
      "grad_norm": 0.9617757201194763,
      "learning_rate": 3.1488395560040364e-05,
      "loss": 0.0002,
      "step": 77050
    },
    {
      "epoch": 3.7047715150641487,
      "grad_norm": 0.34002062678337097,
      "learning_rate": 3.1476382682235355e-05,
      "loss": 0.0002,
      "step": 77100
    },
    {
      "epoch": 3.7071740906251502,
      "grad_norm": 0.07502054423093796,
      "learning_rate": 3.1464369804430346e-05,
      "loss": 0.0001,
      "step": 77150
    },
    {
      "epoch": 3.709576666186152,
      "grad_norm": 0.085371233522892,
      "learning_rate": 3.1452356926625344e-05,
      "loss": 0.0002,
      "step": 77200
    },
    {
      "epoch": 3.711979241747153,
      "grad_norm": 0.3128458857536316,
      "learning_rate": 3.1440344048820334e-05,
      "loss": 0.0002,
      "step": 77250
    },
    {
      "epoch": 3.7143818173081544,
      "grad_norm": 0.23316596448421478,
      "learning_rate": 3.142833117101533e-05,
      "loss": 0.0002,
      "step": 77300
    },
    {
      "epoch": 3.7167843928691555,
      "grad_norm": 0.34768640995025635,
      "learning_rate": 3.141631829321032e-05,
      "loss": 0.0002,
      "step": 77350
    },
    {
      "epoch": 3.719186968430157,
      "grad_norm": 0.15404437482357025,
      "learning_rate": 3.1404305415405314e-05,
      "loss": 0.0001,
      "step": 77400
    },
    {
      "epoch": 3.7215895439911586,
      "grad_norm": 0.17247188091278076,
      "learning_rate": 3.139229253760031e-05,
      "loss": 0.0002,
      "step": 77450
    },
    {
      "epoch": 3.72399211955216,
      "grad_norm": 0.1333502233028412,
      "learning_rate": 3.13802796597953e-05,
      "loss": 0.0001,
      "step": 77500
    },
    {
      "epoch": 3.7263946951131612,
      "grad_norm": 0.28592848777770996,
      "learning_rate": 3.13682667819903e-05,
      "loss": 0.0002,
      "step": 77550
    },
    {
      "epoch": 3.728797270674163,
      "grad_norm": 0.098714679479599,
      "learning_rate": 3.135625390418529e-05,
      "loss": 0.0002,
      "step": 77600
    },
    {
      "epoch": 3.731199846235164,
      "grad_norm": 0.036031849682331085,
      "learning_rate": 3.134424102638028e-05,
      "loss": 0.0001,
      "step": 77650
    },
    {
      "epoch": 3.7336024217961654,
      "grad_norm": 0.3610025644302368,
      "learning_rate": 3.133222814857528e-05,
      "loss": 0.0007,
      "step": 77700
    },
    {
      "epoch": 3.736004997357167,
      "grad_norm": 0.0800759345293045,
      "learning_rate": 3.132021527077026e-05,
      "loss": 0.0001,
      "step": 77750
    },
    {
      "epoch": 3.7384075729181685,
      "grad_norm": 0.05345657095313072,
      "learning_rate": 3.130820239296526e-05,
      "loss": 0.0002,
      "step": 77800
    },
    {
      "epoch": 3.7408101484791696,
      "grad_norm": 0.3869994282722473,
      "learning_rate": 3.129618951516025e-05,
      "loss": 0.0002,
      "step": 77850
    },
    {
      "epoch": 3.743212724040171,
      "grad_norm": 0.31732168793678284,
      "learning_rate": 3.128417663735524e-05,
      "loss": 0.0002,
      "step": 77900
    },
    {
      "epoch": 3.7456152996011722,
      "grad_norm": 0.06367332488298416,
      "learning_rate": 3.127216375955024e-05,
      "loss": 0.0002,
      "step": 77950
    },
    {
      "epoch": 3.7480178751621738,
      "grad_norm": 0.3969796299934387,
      "learning_rate": 3.126015088174523e-05,
      "loss": 0.0002,
      "step": 78000
    },
    {
      "epoch": 3.7504204507231753,
      "grad_norm": 0.18421640992164612,
      "learning_rate": 3.124813800394022e-05,
      "loss": 0.0001,
      "step": 78050
    },
    {
      "epoch": 3.752823026284177,
      "grad_norm": 0.1235579177737236,
      "learning_rate": 3.123612512613522e-05,
      "loss": 0.0002,
      "step": 78100
    },
    {
      "epoch": 3.755225601845178,
      "grad_norm": 0.42408791184425354,
      "learning_rate": 3.122411224833021e-05,
      "loss": 0.0002,
      "step": 78150
    },
    {
      "epoch": 3.7576281774061795,
      "grad_norm": 0.37332358956336975,
      "learning_rate": 3.121209937052521e-05,
      "loss": 0.0001,
      "step": 78200
    },
    {
      "epoch": 3.7600307529671806,
      "grad_norm": 0.2832050919532776,
      "learning_rate": 3.12000864927202e-05,
      "loss": 0.0001,
      "step": 78250
    },
    {
      "epoch": 3.762433328528182,
      "grad_norm": 0.136345773935318,
      "learning_rate": 3.118807361491519e-05,
      "loss": 0.0002,
      "step": 78300
    },
    {
      "epoch": 3.7648359040891837,
      "grad_norm": 0.13692660629749298,
      "learning_rate": 3.117606073711019e-05,
      "loss": 0.0001,
      "step": 78350
    },
    {
      "epoch": 3.767238479650185,
      "grad_norm": 0.08305259793996811,
      "learning_rate": 3.116404785930518e-05,
      "loss": 0.0001,
      "step": 78400
    },
    {
      "epoch": 3.7696410552111863,
      "grad_norm": 0.14650124311447144,
      "learning_rate": 3.1152034981500175e-05,
      "loss": 0.0002,
      "step": 78450
    },
    {
      "epoch": 3.772043630772188,
      "grad_norm": 0.37565478682518005,
      "learning_rate": 3.114002210369516e-05,
      "loss": 0.0001,
      "step": 78500
    },
    {
      "epoch": 3.774446206333189,
      "grad_norm": 0.4873697757720947,
      "learning_rate": 3.112800922589015e-05,
      "loss": 0.0007,
      "step": 78550
    },
    {
      "epoch": 3.7768487818941905,
      "grad_norm": 0.1321890503168106,
      "learning_rate": 3.111599634808515e-05,
      "loss": 0.0002,
      "step": 78600
    },
    {
      "epoch": 3.779251357455192,
      "grad_norm": 0.48884153366088867,
      "learning_rate": 3.110398347028014e-05,
      "loss": 0.0001,
      "step": 78650
    },
    {
      "epoch": 3.7816539330161936,
      "grad_norm": 0.30544576048851013,
      "learning_rate": 3.1091970592475136e-05,
      "loss": 0.0002,
      "step": 78700
    },
    {
      "epoch": 3.7840565085771947,
      "grad_norm": 0.167744442820549,
      "learning_rate": 3.107995771467013e-05,
      "loss": 0.0002,
      "step": 78750
    },
    {
      "epoch": 3.786459084138196,
      "grad_norm": 0.07048216462135315,
      "learning_rate": 3.106794483686512e-05,
      "loss": 0.0001,
      "step": 78800
    },
    {
      "epoch": 3.7888616596991973,
      "grad_norm": 0.7834168076515198,
      "learning_rate": 3.1055931959060115e-05,
      "loss": 0.0002,
      "step": 78850
    },
    {
      "epoch": 3.791264235260199,
      "grad_norm": 0.8799859881401062,
      "learning_rate": 3.1043919081255106e-05,
      "loss": 0.0002,
      "step": 78900
    },
    {
      "epoch": 3.7936668108212004,
      "grad_norm": 0.21222098171710968,
      "learning_rate": 3.1031906203450104e-05,
      "loss": 0.0001,
      "step": 78950
    },
    {
      "epoch": 3.796069386382202,
      "grad_norm": 0.5052842497825623,
      "learning_rate": 3.1019893325645095e-05,
      "loss": 0.0002,
      "step": 79000
    },
    {
      "epoch": 3.798471961943203,
      "grad_norm": 0.20186565816402435,
      "learning_rate": 3.1007880447840086e-05,
      "loss": 0.0002,
      "step": 79050
    },
    {
      "epoch": 3.8008745375042046,
      "grad_norm": 0.33883365988731384,
      "learning_rate": 3.099586757003508e-05,
      "loss": 0.0002,
      "step": 79100
    },
    {
      "epoch": 3.8032771130652057,
      "grad_norm": 0.40561482310295105,
      "learning_rate": 3.0983854692230074e-05,
      "loss": 0.0002,
      "step": 79150
    },
    {
      "epoch": 3.805679688626207,
      "grad_norm": 0.13112562894821167,
      "learning_rate": 3.0971841814425065e-05,
      "loss": 0.0002,
      "step": 79200
    },
    {
      "epoch": 3.8080822641872087,
      "grad_norm": 0.026464886963367462,
      "learning_rate": 3.0959828936620056e-05,
      "loss": 0.0002,
      "step": 79250
    },
    {
      "epoch": 3.8104848397482103,
      "grad_norm": 0.48852285742759705,
      "learning_rate": 3.0947816058815046e-05,
      "loss": 0.0002,
      "step": 79300
    },
    {
      "epoch": 3.8128874153092114,
      "grad_norm": 0.21679119765758514,
      "learning_rate": 3.0935803181010044e-05,
      "loss": 0.0002,
      "step": 79350
    },
    {
      "epoch": 3.815289990870213,
      "grad_norm": 0.13469350337982178,
      "learning_rate": 3.0923790303205035e-05,
      "loss": 0.0002,
      "step": 79400
    },
    {
      "epoch": 3.817692566431214,
      "grad_norm": 0.34082314372062683,
      "learning_rate": 3.091177742540003e-05,
      "loss": 0.0002,
      "step": 79450
    },
    {
      "epoch": 3.8200951419922156,
      "grad_norm": 0.6585655212402344,
      "learning_rate": 3.089976454759502e-05,
      "loss": 0.0001,
      "step": 79500
    },
    {
      "epoch": 3.822497717553217,
      "grad_norm": 0.1458713561296463,
      "learning_rate": 3.0887751669790014e-05,
      "loss": 0.0001,
      "step": 79550
    },
    {
      "epoch": 3.8249002931142186,
      "grad_norm": 0.23258580267429352,
      "learning_rate": 3.087573879198501e-05,
      "loss": 0.0002,
      "step": 79600
    },
    {
      "epoch": 3.8273028686752197,
      "grad_norm": 0.08169005066156387,
      "learning_rate": 3.086372591418e-05,
      "loss": 0.0002,
      "step": 79650
    },
    {
      "epoch": 3.8297054442362213,
      "grad_norm": 0.07275932282209396,
      "learning_rate": 3.085171303637499e-05,
      "loss": 0.0002,
      "step": 79700
    },
    {
      "epoch": 3.8321080197972224,
      "grad_norm": 0.6028956770896912,
      "learning_rate": 3.083970015856999e-05,
      "loss": 0.0001,
      "step": 79750
    },
    {
      "epoch": 3.834510595358224,
      "grad_norm": 0.5325093269348145,
      "learning_rate": 3.082768728076498e-05,
      "loss": 0.0002,
      "step": 79800
    },
    {
      "epoch": 3.8369131709192255,
      "grad_norm": 0.11184847354888916,
      "learning_rate": 3.081567440295998e-05,
      "loss": 0.0002,
      "step": 79850
    },
    {
      "epoch": 3.839315746480227,
      "grad_norm": 0.31713318824768066,
      "learning_rate": 3.080366152515497e-05,
      "loss": 0.0002,
      "step": 79900
    },
    {
      "epoch": 3.841718322041228,
      "grad_norm": 0.1866745501756668,
      "learning_rate": 3.079164864734996e-05,
      "loss": 0.0002,
      "step": 79950
    },
    {
      "epoch": 3.8441208976022296,
      "grad_norm": 0.09825736284255981,
      "learning_rate": 3.077963576954495e-05,
      "loss": 0.0002,
      "step": 80000
    },
    {
      "epoch": 3.8465234731632307,
      "grad_norm": 0.1788608729839325,
      "learning_rate": 3.076762289173994e-05,
      "loss": 0.0002,
      "step": 80050
    },
    {
      "epoch": 3.8489260487242323,
      "grad_norm": 0.36890533566474915,
      "learning_rate": 3.075561001393494e-05,
      "loss": 0.0002,
      "step": 80100
    },
    {
      "epoch": 3.851328624285234,
      "grad_norm": 0.23024782538414001,
      "learning_rate": 3.074359713612993e-05,
      "loss": 0.0002,
      "step": 80150
    },
    {
      "epoch": 3.8537311998462354,
      "grad_norm": 0.14694102108478546,
      "learning_rate": 3.073158425832492e-05,
      "loss": 0.0002,
      "step": 80200
    },
    {
      "epoch": 3.8561337754072365,
      "grad_norm": 0.2566559314727783,
      "learning_rate": 3.071957138051992e-05,
      "loss": 0.0006,
      "step": 80250
    },
    {
      "epoch": 3.858536350968238,
      "grad_norm": 0.32931578159332275,
      "learning_rate": 3.070755850271491e-05,
      "loss": 0.0002,
      "step": 80300
    },
    {
      "epoch": 3.860938926529239,
      "grad_norm": 0.2779369056224823,
      "learning_rate": 3.069554562490991e-05,
      "loss": 0.0002,
      "step": 80350
    },
    {
      "epoch": 3.8633415020902406,
      "grad_norm": 0.08780699968338013,
      "learning_rate": 3.06835327471049e-05,
      "loss": 0.0001,
      "step": 80400
    },
    {
      "epoch": 3.865744077651242,
      "grad_norm": 0.3160535991191864,
      "learning_rate": 3.067151986929989e-05,
      "loss": 0.0002,
      "step": 80450
    },
    {
      "epoch": 3.8681466532122437,
      "grad_norm": 0.25459104776382446,
      "learning_rate": 3.065950699149489e-05,
      "loss": 0.0001,
      "step": 80500
    },
    {
      "epoch": 3.870549228773245,
      "grad_norm": 0.41484570503234863,
      "learning_rate": 3.064749411368988e-05,
      "loss": 0.0004,
      "step": 80550
    },
    {
      "epoch": 3.8729518043342464,
      "grad_norm": 0.21622174978256226,
      "learning_rate": 3.063548123588487e-05,
      "loss": 0.0001,
      "step": 80600
    },
    {
      "epoch": 3.8753543798952474,
      "grad_norm": 0.1296788603067398,
      "learning_rate": 3.0623468358079866e-05,
      "loss": 0.0002,
      "step": 80650
    },
    {
      "epoch": 3.877756955456249,
      "grad_norm": 0.10752607136964798,
      "learning_rate": 3.061145548027486e-05,
      "loss": 0.0001,
      "step": 80700
    },
    {
      "epoch": 3.8801595310172505,
      "grad_norm": 0.13872063159942627,
      "learning_rate": 3.059944260246985e-05,
      "loss": 0.0002,
      "step": 80750
    },
    {
      "epoch": 3.882562106578252,
      "grad_norm": 0.1719079613685608,
      "learning_rate": 3.058742972466484e-05,
      "loss": 0.0002,
      "step": 80800
    },
    {
      "epoch": 3.884964682139253,
      "grad_norm": 0.3829556703567505,
      "learning_rate": 3.0575416846859837e-05,
      "loss": 0.0002,
      "step": 80850
    },
    {
      "epoch": 3.8873672577002547,
      "grad_norm": 0.17834612727165222,
      "learning_rate": 3.056340396905483e-05,
      "loss": 0.0002,
      "step": 80900
    },
    {
      "epoch": 3.889769833261256,
      "grad_norm": 0.3435460925102234,
      "learning_rate": 3.055139109124982e-05,
      "loss": 0.0002,
      "step": 80950
    },
    {
      "epoch": 3.8921724088222573,
      "grad_norm": 0.21642707288265228,
      "learning_rate": 3.0539378213444816e-05,
      "loss": 0.0002,
      "step": 81000
    },
    {
      "epoch": 3.894574984383259,
      "grad_norm": 0.26214608550071716,
      "learning_rate": 3.052736533563981e-05,
      "loss": 0.0004,
      "step": 81050
    },
    {
      "epoch": 3.8969775599442604,
      "grad_norm": 0.12444494664669037,
      "learning_rate": 3.05153524578348e-05,
      "loss": 0.0002,
      "step": 81100
    },
    {
      "epoch": 3.8993801355052615,
      "grad_norm": 0.37160515785217285,
      "learning_rate": 3.0503339580029795e-05,
      "loss": 0.0006,
      "step": 81150
    },
    {
      "epoch": 3.901782711066263,
      "grad_norm": 0.38289758563041687,
      "learning_rate": 3.0491326702224786e-05,
      "loss": 0.0002,
      "step": 81200
    },
    {
      "epoch": 3.904185286627264,
      "grad_norm": 0.3728344142436981,
      "learning_rate": 3.047931382441978e-05,
      "loss": 0.0001,
      "step": 81250
    },
    {
      "epoch": 3.9065878621882657,
      "grad_norm": 0.099118173122406,
      "learning_rate": 3.0467300946614774e-05,
      "loss": 0.0002,
      "step": 81300
    },
    {
      "epoch": 3.9089904377492672,
      "grad_norm": 0.6498504877090454,
      "learning_rate": 3.045528806880977e-05,
      "loss": 0.0001,
      "step": 81350
    },
    {
      "epoch": 3.911393013310269,
      "grad_norm": 0.06444942206144333,
      "learning_rate": 3.044327519100476e-05,
      "loss": 0.0002,
      "step": 81400
    },
    {
      "epoch": 3.91379558887127,
      "grad_norm": 0.27030637860298157,
      "learning_rate": 3.0431262313199754e-05,
      "loss": 0.0002,
      "step": 81450
    },
    {
      "epoch": 3.9161981644322714,
      "grad_norm": 0.24312372505664825,
      "learning_rate": 3.041924943539474e-05,
      "loss": 0.0002,
      "step": 81500
    },
    {
      "epoch": 3.9186007399932725,
      "grad_norm": 0.11422643810510635,
      "learning_rate": 3.0407236557589735e-05,
      "loss": 0.0001,
      "step": 81550
    },
    {
      "epoch": 3.921003315554274,
      "grad_norm": 0.4349421560764313,
      "learning_rate": 3.039522367978473e-05,
      "loss": 0.0001,
      "step": 81600
    },
    {
      "epoch": 3.9234058911152756,
      "grad_norm": 0.16033737361431122,
      "learning_rate": 3.0383210801979724e-05,
      "loss": 0.0002,
      "step": 81650
    },
    {
      "epoch": 3.925808466676277,
      "grad_norm": 0.21221458911895752,
      "learning_rate": 3.0371197924174714e-05,
      "loss": 0.0001,
      "step": 81700
    },
    {
      "epoch": 3.9282110422372782,
      "grad_norm": 0.10754644870758057,
      "learning_rate": 3.035918504636971e-05,
      "loss": 0.0007,
      "step": 81750
    },
    {
      "epoch": 3.93061361779828,
      "grad_norm": 0.9172319769859314,
      "learning_rate": 3.0347172168564703e-05,
      "loss": 0.0002,
      "step": 81800
    },
    {
      "epoch": 3.933016193359281,
      "grad_norm": 0.15562543272972107,
      "learning_rate": 3.0335159290759697e-05,
      "loss": 0.0002,
      "step": 81850
    },
    {
      "epoch": 3.9354187689202824,
      "grad_norm": 0.4473731219768524,
      "learning_rate": 3.0323146412954688e-05,
      "loss": 0.0002,
      "step": 81900
    },
    {
      "epoch": 3.937821344481284,
      "grad_norm": 1.1565133333206177,
      "learning_rate": 3.0311133535149682e-05,
      "loss": 0.0005,
      "step": 81950
    },
    {
      "epoch": 3.9402239200422855,
      "grad_norm": 0.33441081643104553,
      "learning_rate": 3.0299120657344676e-05,
      "loss": 0.0007,
      "step": 82000
    },
    {
      "epoch": 3.9426264956032866,
      "grad_norm": 0.2886459529399872,
      "learning_rate": 3.028710777953967e-05,
      "loss": 0.0002,
      "step": 82050
    },
    {
      "epoch": 3.945029071164288,
      "grad_norm": 0.12890000641345978,
      "learning_rate": 3.027509490173466e-05,
      "loss": 0.0002,
      "step": 82100
    },
    {
      "epoch": 3.9474316467252892,
      "grad_norm": 0.15231798589229584,
      "learning_rate": 3.0263082023929656e-05,
      "loss": 0.0002,
      "step": 82150
    },
    {
      "epoch": 3.9498342222862908,
      "grad_norm": 0.054932914674282074,
      "learning_rate": 3.025106914612465e-05,
      "loss": 0.0001,
      "step": 82200
    },
    {
      "epoch": 3.9522367978472923,
      "grad_norm": 0.43715205788612366,
      "learning_rate": 3.0239056268319637e-05,
      "loss": 0.0002,
      "step": 82250
    },
    {
      "epoch": 3.954639373408294,
      "grad_norm": 0.2001076191663742,
      "learning_rate": 3.022704339051463e-05,
      "loss": 0.0002,
      "step": 82300
    },
    {
      "epoch": 3.957041948969295,
      "grad_norm": 0.06384094804525375,
      "learning_rate": 3.0215030512709626e-05,
      "loss": 0.0002,
      "step": 82350
    },
    {
      "epoch": 3.9594445245302965,
      "grad_norm": 0.510138750076294,
      "learning_rate": 3.0203017634904617e-05,
      "loss": 0.0001,
      "step": 82400
    },
    {
      "epoch": 3.961847100091298,
      "grad_norm": 0.1257050782442093,
      "learning_rate": 3.019100475709961e-05,
      "loss": 0.0001,
      "step": 82450
    },
    {
      "epoch": 3.964249675652299,
      "grad_norm": 0.07022767513990402,
      "learning_rate": 3.0178991879294605e-05,
      "loss": 0.0002,
      "step": 82500
    },
    {
      "epoch": 3.9666522512133007,
      "grad_norm": 0.062279220670461655,
      "learning_rate": 3.01669790014896e-05,
      "loss": 0.0001,
      "step": 82550
    },
    {
      "epoch": 3.969054826774302,
      "grad_norm": 0.08165571093559265,
      "learning_rate": 3.015496612368459e-05,
      "loss": 0.0001,
      "step": 82600
    },
    {
      "epoch": 3.9714574023353033,
      "grad_norm": 0.2876167893409729,
      "learning_rate": 3.0142953245879584e-05,
      "loss": 0.0001,
      "step": 82650
    },
    {
      "epoch": 3.973859977896305,
      "grad_norm": 0.09098527580499649,
      "learning_rate": 3.013094036807458e-05,
      "loss": 0.0002,
      "step": 82700
    },
    {
      "epoch": 3.9762625534573064,
      "grad_norm": 0.2797016203403473,
      "learning_rate": 3.0118927490269573e-05,
      "loss": 0.0001,
      "step": 82750
    },
    {
      "epoch": 3.9786651290183075,
      "grad_norm": 0.10995380580425262,
      "learning_rate": 3.0106914612464563e-05,
      "loss": 0.0002,
      "step": 82800
    },
    {
      "epoch": 3.981067704579309,
      "grad_norm": 0.23004883527755737,
      "learning_rate": 3.0094901734659558e-05,
      "loss": 0.0001,
      "step": 82850
    },
    {
      "epoch": 3.9834702801403106,
      "grad_norm": 0.21644984185695648,
      "learning_rate": 3.0082888856854552e-05,
      "loss": 0.0002,
      "step": 82900
    },
    {
      "epoch": 3.9858728557013117,
      "grad_norm": 0.31732040643692017,
      "learning_rate": 3.007087597904954e-05,
      "loss": 0.0002,
      "step": 82950
    },
    {
      "epoch": 3.988275431262313,
      "grad_norm": 0.15357500314712524,
      "learning_rate": 3.0058863101244534e-05,
      "loss": 0.0002,
      "step": 83000
    },
    {
      "epoch": 3.9906780068233147,
      "grad_norm": 0.3486384451389313,
      "learning_rate": 3.0046850223439528e-05,
      "loss": 0.0002,
      "step": 83050
    },
    {
      "epoch": 3.993080582384316,
      "grad_norm": 0.5238131880760193,
      "learning_rate": 3.003483734563452e-05,
      "loss": 0.0005,
      "step": 83100
    },
    {
      "epoch": 3.9954831579453174,
      "grad_norm": 0.10081102699041367,
      "learning_rate": 3.0022824467829513e-05,
      "loss": 0.0002,
      "step": 83150
    },
    {
      "epoch": 3.997885733506319,
      "grad_norm": 0.32152098417282104,
      "learning_rate": 3.0010811590024507e-05,
      "loss": 0.0002,
      "step": 83200
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.00019089477427769452,
      "eval_runtime": 17.2654,
      "eval_samples_per_second": 550.001,
      "eval_steps_per_second": 68.75,
      "step": 83244
    },
    {
      "epoch": 4.0002883090673205,
      "grad_norm": 0.19528602063655853,
      "learning_rate": 2.99987987122195e-05,
      "loss": 0.0002,
      "step": 83250
    },
    {
      "epoch": 4.002690884628321,
      "grad_norm": 0.13226693868637085,
      "learning_rate": 2.9986785834414492e-05,
      "loss": 0.0001,
      "step": 83300
    },
    {
      "epoch": 4.005093460189323,
      "grad_norm": 0.3244156837463379,
      "learning_rate": 2.9974772956609486e-05,
      "loss": 0.0002,
      "step": 83350
    },
    {
      "epoch": 4.007496035750324,
      "grad_norm": 0.2835451066493988,
      "learning_rate": 2.996276007880448e-05,
      "loss": 0.0002,
      "step": 83400
    },
    {
      "epoch": 4.009898611311326,
      "grad_norm": 0.13286930322647095,
      "learning_rate": 2.9950747200999475e-05,
      "loss": 0.0001,
      "step": 83450
    },
    {
      "epoch": 4.012301186872327,
      "grad_norm": 0.2021903097629547,
      "learning_rate": 2.993873432319447e-05,
      "loss": 0.0002,
      "step": 83500
    },
    {
      "epoch": 4.014703762433329,
      "grad_norm": 0.46957066655158997,
      "learning_rate": 2.992672144538946e-05,
      "loss": 0.0001,
      "step": 83550
    },
    {
      "epoch": 4.0171063379943295,
      "grad_norm": 0.2842872440814972,
      "learning_rate": 2.9914708567584454e-05,
      "loss": 0.0002,
      "step": 83600
    },
    {
      "epoch": 4.019508913555331,
      "grad_norm": 0.2947591245174408,
      "learning_rate": 2.9902695689779448e-05,
      "loss": 0.0001,
      "step": 83650
    },
    {
      "epoch": 4.021911489116333,
      "grad_norm": 0.12789805233478546,
      "learning_rate": 2.9890682811974436e-05,
      "loss": 0.0001,
      "step": 83700
    },
    {
      "epoch": 4.024314064677334,
      "grad_norm": 0.2776685357093811,
      "learning_rate": 2.987866993416943e-05,
      "loss": 0.0004,
      "step": 83750
    },
    {
      "epoch": 4.026716640238336,
      "grad_norm": 0.1859177201986313,
      "learning_rate": 2.986665705636442e-05,
      "loss": 0.0002,
      "step": 83800
    },
    {
      "epoch": 4.029119215799337,
      "grad_norm": 0.1277722418308258,
      "learning_rate": 2.9854644178559415e-05,
      "loss": 0.0001,
      "step": 83850
    },
    {
      "epoch": 4.031521791360339,
      "grad_norm": 0.1793489307165146,
      "learning_rate": 2.984263130075441e-05,
      "loss": 0.0001,
      "step": 83900
    },
    {
      "epoch": 4.033924366921339,
      "grad_norm": 0.27600714564323425,
      "learning_rate": 2.9830618422949403e-05,
      "loss": 0.0002,
      "step": 83950
    },
    {
      "epoch": 4.036326942482341,
      "grad_norm": 0.20134687423706055,
      "learning_rate": 2.9818605545144394e-05,
      "loss": 0.0002,
      "step": 84000
    },
    {
      "epoch": 4.0387295180433425,
      "grad_norm": 0.5434436798095703,
      "learning_rate": 2.9806592667339388e-05,
      "loss": 0.0002,
      "step": 84050
    },
    {
      "epoch": 4.041132093604344,
      "grad_norm": 0.1316114217042923,
      "learning_rate": 2.9794579789534382e-05,
      "loss": 0.0002,
      "step": 84100
    },
    {
      "epoch": 4.0435346691653455,
      "grad_norm": 0.47484731674194336,
      "learning_rate": 2.9782566911729377e-05,
      "loss": 0.0001,
      "step": 84150
    },
    {
      "epoch": 4.045937244726347,
      "grad_norm": 0.17618505656719208,
      "learning_rate": 2.977055403392437e-05,
      "loss": 0.0006,
      "step": 84200
    },
    {
      "epoch": 4.048339820287348,
      "grad_norm": 0.0756678655743599,
      "learning_rate": 2.9758541156119362e-05,
      "loss": 0.0007,
      "step": 84250
    },
    {
      "epoch": 4.050742395848349,
      "grad_norm": 0.3609107732772827,
      "learning_rate": 2.9746528278314356e-05,
      "loss": 0.0001,
      "step": 84300
    },
    {
      "epoch": 4.053144971409351,
      "grad_norm": 0.046518776565790176,
      "learning_rate": 2.973451540050935e-05,
      "loss": 0.0001,
      "step": 84350
    },
    {
      "epoch": 4.055547546970352,
      "grad_norm": 0.05256599187850952,
      "learning_rate": 2.9722502522704344e-05,
      "loss": 0.0002,
      "step": 84400
    },
    {
      "epoch": 4.057950122531354,
      "grad_norm": 0.22359712421894073,
      "learning_rate": 2.9710489644899332e-05,
      "loss": 0.0001,
      "step": 84450
    },
    {
      "epoch": 4.060352698092355,
      "grad_norm": 0.0826280266046524,
      "learning_rate": 2.9698476767094323e-05,
      "loss": 0.0002,
      "step": 84500
    },
    {
      "epoch": 4.062755273653356,
      "grad_norm": 0.22416304051876068,
      "learning_rate": 2.9686463889289317e-05,
      "loss": 0.0006,
      "step": 84550
    },
    {
      "epoch": 4.065157849214358,
      "grad_norm": 0.09873995929956436,
      "learning_rate": 2.967445101148431e-05,
      "loss": 0.0001,
      "step": 84600
    },
    {
      "epoch": 4.067560424775359,
      "grad_norm": 0.5504237413406372,
      "learning_rate": 2.9662438133679305e-05,
      "loss": 0.0002,
      "step": 84650
    },
    {
      "epoch": 4.069963000336361,
      "grad_norm": 0.1435176581144333,
      "learning_rate": 2.96504252558743e-05,
      "loss": 0.0002,
      "step": 84700
    },
    {
      "epoch": 4.072365575897362,
      "grad_norm": 0.18082350492477417,
      "learning_rate": 2.963841237806929e-05,
      "loss": 0.0002,
      "step": 84750
    },
    {
      "epoch": 4.074768151458364,
      "grad_norm": 0.09441018849611282,
      "learning_rate": 2.9626399500264285e-05,
      "loss": 0.0001,
      "step": 84800
    },
    {
      "epoch": 4.0771707270193644,
      "grad_norm": 0.054655078798532486,
      "learning_rate": 2.961438662245928e-05,
      "loss": 0.0002,
      "step": 84850
    },
    {
      "epoch": 4.079573302580366,
      "grad_norm": 0.4928966760635376,
      "learning_rate": 2.9602373744654273e-05,
      "loss": 0.0002,
      "step": 84900
    },
    {
      "epoch": 4.0819758781413675,
      "grad_norm": 0.3084052801132202,
      "learning_rate": 2.9590360866849264e-05,
      "loss": 0.0002,
      "step": 84950
    },
    {
      "epoch": 4.084378453702369,
      "grad_norm": 0.0660286620259285,
      "learning_rate": 2.9578347989044258e-05,
      "loss": 0.0002,
      "step": 85000
    },
    {
      "epoch": 4.086781029263371,
      "grad_norm": 0.20541197061538696,
      "learning_rate": 2.9566335111239252e-05,
      "loss": 0.0002,
      "step": 85050
    },
    {
      "epoch": 4.089183604824372,
      "grad_norm": 0.3140033185482025,
      "learning_rate": 2.9554322233434246e-05,
      "loss": 0.0002,
      "step": 85100
    },
    {
      "epoch": 4.091586180385373,
      "grad_norm": 0.18090686202049255,
      "learning_rate": 2.9542309355629237e-05,
      "loss": 0.0001,
      "step": 85150
    },
    {
      "epoch": 4.093988755946374,
      "grad_norm": 0.07075680047273636,
      "learning_rate": 2.9530296477824225e-05,
      "loss": 0.0001,
      "step": 85200
    },
    {
      "epoch": 4.096391331507376,
      "grad_norm": 0.2088089883327484,
      "learning_rate": 2.951828360001922e-05,
      "loss": 0.0002,
      "step": 85250
    },
    {
      "epoch": 4.098793907068377,
      "grad_norm": 0.19197507202625275,
      "learning_rate": 2.9506270722214213e-05,
      "loss": 0.0002,
      "step": 85300
    },
    {
      "epoch": 4.101196482629379,
      "grad_norm": 0.12802919745445251,
      "learning_rate": 2.9494257844409207e-05,
      "loss": 0.0002,
      "step": 85350
    },
    {
      "epoch": 4.1035990581903805,
      "grad_norm": 0.19386307895183563,
      "learning_rate": 2.94822449666042e-05,
      "loss": 0.0001,
      "step": 85400
    },
    {
      "epoch": 4.106001633751381,
      "grad_norm": 0.21729519963264465,
      "learning_rate": 2.9470232088799192e-05,
      "loss": 0.0001,
      "step": 85450
    },
    {
      "epoch": 4.108404209312383,
      "grad_norm": 0.08962728828191757,
      "learning_rate": 2.9458219210994187e-05,
      "loss": 0.0001,
      "step": 85500
    },
    {
      "epoch": 4.110806784873384,
      "grad_norm": 0.10812420397996902,
      "learning_rate": 2.944620633318918e-05,
      "loss": 0.0002,
      "step": 85550
    },
    {
      "epoch": 4.113209360434386,
      "grad_norm": 0.3079131245613098,
      "learning_rate": 2.9434193455384175e-05,
      "loss": 0.0002,
      "step": 85600
    },
    {
      "epoch": 4.115611935995387,
      "grad_norm": 0.4289442002773285,
      "learning_rate": 2.9422180577579166e-05,
      "loss": 0.0002,
      "step": 85650
    },
    {
      "epoch": 4.118014511556389,
      "grad_norm": 0.12961415946483612,
      "learning_rate": 2.941016769977416e-05,
      "loss": 0.0002,
      "step": 85700
    },
    {
      "epoch": 4.1204170871173895,
      "grad_norm": 0.1813371181488037,
      "learning_rate": 2.9398154821969154e-05,
      "loss": 0.0002,
      "step": 85750
    },
    {
      "epoch": 4.122819662678391,
      "grad_norm": 0.18130646646022797,
      "learning_rate": 2.938614194416415e-05,
      "loss": 0.0007,
      "step": 85800
    },
    {
      "epoch": 4.125222238239393,
      "grad_norm": 0.34324848651885986,
      "learning_rate": 2.937412906635914e-05,
      "loss": 0.0002,
      "step": 85850
    },
    {
      "epoch": 4.127624813800394,
      "grad_norm": 0.3301664888858795,
      "learning_rate": 2.9362116188554134e-05,
      "loss": 0.0001,
      "step": 85900
    },
    {
      "epoch": 4.130027389361396,
      "grad_norm": 0.0701289102435112,
      "learning_rate": 2.935010331074912e-05,
      "loss": 0.0001,
      "step": 85950
    },
    {
      "epoch": 4.132429964922397,
      "grad_norm": 0.3616761267185211,
      "learning_rate": 2.9338090432944115e-05,
      "loss": 0.0002,
      "step": 86000
    },
    {
      "epoch": 4.134832540483398,
      "grad_norm": 0.3098967969417572,
      "learning_rate": 2.932607755513911e-05,
      "loss": 0.0002,
      "step": 86050
    },
    {
      "epoch": 4.137235116044399,
      "grad_norm": 0.42863765358924866,
      "learning_rate": 2.9314064677334104e-05,
      "loss": 0.0001,
      "step": 86100
    },
    {
      "epoch": 4.139637691605401,
      "grad_norm": 0.7391619682312012,
      "learning_rate": 2.9302051799529094e-05,
      "loss": 0.0002,
      "step": 86150
    },
    {
      "epoch": 4.1420402671664025,
      "grad_norm": 0.2413191795349121,
      "learning_rate": 2.929003892172409e-05,
      "loss": 0.0006,
      "step": 86200
    },
    {
      "epoch": 4.144442842727404,
      "grad_norm": 0.17899030447006226,
      "learning_rate": 2.9278026043919083e-05,
      "loss": 0.0001,
      "step": 86250
    },
    {
      "epoch": 4.146845418288406,
      "grad_norm": 0.41729041934013367,
      "learning_rate": 2.9266013166114077e-05,
      "loss": 0.0001,
      "step": 86300
    },
    {
      "epoch": 4.149247993849406,
      "grad_norm": 0.4405690133571625,
      "learning_rate": 2.9254000288309068e-05,
      "loss": 0.0001,
      "step": 86350
    },
    {
      "epoch": 4.151650569410408,
      "grad_norm": 0.051749907433986664,
      "learning_rate": 2.9241987410504062e-05,
      "loss": 0.0002,
      "step": 86400
    },
    {
      "epoch": 4.154053144971409,
      "grad_norm": 0.1098703145980835,
      "learning_rate": 2.9229974532699056e-05,
      "loss": 0.0001,
      "step": 86450
    },
    {
      "epoch": 4.156455720532411,
      "grad_norm": 0.08243262022733688,
      "learning_rate": 2.921796165489405e-05,
      "loss": 0.0002,
      "step": 86500
    },
    {
      "epoch": 4.158858296093412,
      "grad_norm": 0.14981333911418915,
      "learning_rate": 2.920594877708904e-05,
      "loss": 0.0001,
      "step": 86550
    },
    {
      "epoch": 4.161260871654414,
      "grad_norm": 0.2666153311729431,
      "learning_rate": 2.9193935899284036e-05,
      "loss": 0.0002,
      "step": 86600
    },
    {
      "epoch": 4.163663447215415,
      "grad_norm": 0.17566059529781342,
      "learning_rate": 2.918192302147903e-05,
      "loss": 0.0002,
      "step": 86650
    },
    {
      "epoch": 4.166066022776416,
      "grad_norm": 0.6152411103248596,
      "learning_rate": 2.9169910143674017e-05,
      "loss": 0.0001,
      "step": 86700
    },
    {
      "epoch": 4.168468598337418,
      "grad_norm": 0.054669685661792755,
      "learning_rate": 2.915789726586901e-05,
      "loss": 0.0002,
      "step": 86750
    },
    {
      "epoch": 4.170871173898419,
      "grad_norm": 0.16492755711078644,
      "learning_rate": 2.9145884388064006e-05,
      "loss": 0.0002,
      "step": 86800
    },
    {
      "epoch": 4.173273749459421,
      "grad_norm": 0.7623802423477173,
      "learning_rate": 2.9133871510258996e-05,
      "loss": 0.0002,
      "step": 86850
    },
    {
      "epoch": 4.175676325020422,
      "grad_norm": 0.11378176510334015,
      "learning_rate": 2.912185863245399e-05,
      "loss": 0.0002,
      "step": 86900
    },
    {
      "epoch": 4.178078900581423,
      "grad_norm": 0.0795498937368393,
      "learning_rate": 2.9109845754648985e-05,
      "loss": 0.0002,
      "step": 86950
    },
    {
      "epoch": 4.1804814761424245,
      "grad_norm": 0.5622392892837524,
      "learning_rate": 2.909783287684398e-05,
      "loss": 0.0001,
      "step": 87000
    },
    {
      "epoch": 4.182884051703426,
      "grad_norm": 0.11770854145288467,
      "learning_rate": 2.908581999903897e-05,
      "loss": 0.0001,
      "step": 87050
    },
    {
      "epoch": 4.185286627264428,
      "grad_norm": 0.14452938735485077,
      "learning_rate": 2.9073807121233964e-05,
      "loss": 0.0001,
      "step": 87100
    },
    {
      "epoch": 4.187689202825429,
      "grad_norm": 0.07294788211584091,
      "learning_rate": 2.906179424342896e-05,
      "loss": 0.0002,
      "step": 87150
    },
    {
      "epoch": 4.190091778386431,
      "grad_norm": 0.07827232033014297,
      "learning_rate": 2.9049781365623953e-05,
      "loss": 0.0002,
      "step": 87200
    },
    {
      "epoch": 4.192494353947431,
      "grad_norm": 0.18055786192417145,
      "learning_rate": 2.9037768487818943e-05,
      "loss": 0.0001,
      "step": 87250
    },
    {
      "epoch": 4.194896929508433,
      "grad_norm": 0.17274850606918335,
      "learning_rate": 2.9025755610013938e-05,
      "loss": 0.0002,
      "step": 87300
    },
    {
      "epoch": 4.197299505069434,
      "grad_norm": 0.42548030614852905,
      "learning_rate": 2.9013742732208932e-05,
      "loss": 0.0004,
      "step": 87350
    },
    {
      "epoch": 4.199702080630436,
      "grad_norm": 0.05945342034101486,
      "learning_rate": 2.9001729854403926e-05,
      "loss": 0.0002,
      "step": 87400
    },
    {
      "epoch": 4.2021046561914375,
      "grad_norm": 0.1955726444721222,
      "learning_rate": 2.8989716976598913e-05,
      "loss": 0.0002,
      "step": 87450
    },
    {
      "epoch": 4.204507231752439,
      "grad_norm": 0.08972547203302383,
      "learning_rate": 2.8977704098793908e-05,
      "loss": 0.0001,
      "step": 87500
    },
    {
      "epoch": 4.20690980731344,
      "grad_norm": 0.35918933153152466,
      "learning_rate": 2.89656912209889e-05,
      "loss": 0.0001,
      "step": 87550
    },
    {
      "epoch": 4.209312382874441,
      "grad_norm": 0.14303916692733765,
      "learning_rate": 2.8953678343183893e-05,
      "loss": 0.0002,
      "step": 87600
    },
    {
      "epoch": 4.211714958435443,
      "grad_norm": 0.18644851446151733,
      "learning_rate": 2.8941665465378887e-05,
      "loss": 0.0002,
      "step": 87650
    },
    {
      "epoch": 4.214117533996444,
      "grad_norm": 0.42165127396583557,
      "learning_rate": 2.892965258757388e-05,
      "loss": 0.0002,
      "step": 87700
    },
    {
      "epoch": 4.216520109557446,
      "grad_norm": 0.447394460439682,
      "learning_rate": 2.8917639709768872e-05,
      "loss": 0.0001,
      "step": 87750
    },
    {
      "epoch": 4.218922685118447,
      "grad_norm": 0.49364885687828064,
      "learning_rate": 2.8905626831963866e-05,
      "loss": 0.0002,
      "step": 87800
    },
    {
      "epoch": 4.221325260679448,
      "grad_norm": 0.44471198320388794,
      "learning_rate": 2.889361395415886e-05,
      "loss": 0.0002,
      "step": 87850
    },
    {
      "epoch": 4.22372783624045,
      "grad_norm": 0.1321127861738205,
      "learning_rate": 2.8881601076353855e-05,
      "loss": 0.0001,
      "step": 87900
    },
    {
      "epoch": 4.226130411801451,
      "grad_norm": 0.17921136319637299,
      "learning_rate": 2.8869588198548845e-05,
      "loss": 0.0001,
      "step": 87950
    },
    {
      "epoch": 4.228532987362453,
      "grad_norm": 0.42801377177238464,
      "learning_rate": 2.885757532074384e-05,
      "loss": 0.0001,
      "step": 88000
    },
    {
      "epoch": 4.230935562923454,
      "grad_norm": 0.0812031552195549,
      "learning_rate": 2.8845562442938834e-05,
      "loss": 0.0002,
      "step": 88050
    },
    {
      "epoch": 4.233338138484456,
      "grad_norm": 0.5549756288528442,
      "learning_rate": 2.8833549565133828e-05,
      "loss": 0.0002,
      "step": 88100
    },
    {
      "epoch": 4.235740714045456,
      "grad_norm": 0.3251553773880005,
      "learning_rate": 2.8821536687328822e-05,
      "loss": 0.0001,
      "step": 88150
    },
    {
      "epoch": 4.238143289606458,
      "grad_norm": 0.4280030429363251,
      "learning_rate": 2.880952380952381e-05,
      "loss": 0.0001,
      "step": 88200
    },
    {
      "epoch": 4.2405458651674595,
      "grad_norm": 0.6104806661605835,
      "learning_rate": 2.87975109317188e-05,
      "loss": 0.0002,
      "step": 88250
    },
    {
      "epoch": 4.242948440728461,
      "grad_norm": 0.17808063328266144,
      "learning_rate": 2.8785498053913795e-05,
      "loss": 0.0002,
      "step": 88300
    },
    {
      "epoch": 4.2453510162894625,
      "grad_norm": 0.23877182602882385,
      "learning_rate": 2.877348517610879e-05,
      "loss": 0.0002,
      "step": 88350
    },
    {
      "epoch": 4.247753591850464,
      "grad_norm": 0.10056085884571075,
      "learning_rate": 2.8761472298303783e-05,
      "loss": 0.0002,
      "step": 88400
    },
    {
      "epoch": 4.250156167411465,
      "grad_norm": 0.18748630583286285,
      "learning_rate": 2.8749459420498774e-05,
      "loss": 0.0002,
      "step": 88450
    },
    {
      "epoch": 4.252558742972466,
      "grad_norm": 0.33321326971054077,
      "learning_rate": 2.8737446542693768e-05,
      "loss": 0.0002,
      "step": 88500
    },
    {
      "epoch": 4.254961318533468,
      "grad_norm": 0.32850414514541626,
      "learning_rate": 2.8725433664888762e-05,
      "loss": 0.0002,
      "step": 88550
    },
    {
      "epoch": 4.257363894094469,
      "grad_norm": 0.2967709004878998,
      "learning_rate": 2.8713420787083757e-05,
      "loss": 0.0002,
      "step": 88600
    },
    {
      "epoch": 4.259766469655471,
      "grad_norm": 0.05112811550498009,
      "learning_rate": 2.8701407909278747e-05,
      "loss": 0.0002,
      "step": 88650
    },
    {
      "epoch": 4.262169045216472,
      "grad_norm": 0.11457780748605728,
      "learning_rate": 2.8689395031473742e-05,
      "loss": 0.0003,
      "step": 88700
    },
    {
      "epoch": 4.264571620777473,
      "grad_norm": 0.23010778427124023,
      "learning_rate": 2.8677382153668736e-05,
      "loss": 0.0003,
      "step": 88750
    },
    {
      "epoch": 4.266974196338475,
      "grad_norm": 0.04826534911990166,
      "learning_rate": 2.866536927586373e-05,
      "loss": 0.0001,
      "step": 88800
    },
    {
      "epoch": 4.269376771899476,
      "grad_norm": 0.19805002212524414,
      "learning_rate": 2.8653356398058724e-05,
      "loss": 0.0002,
      "step": 88850
    },
    {
      "epoch": 4.271779347460478,
      "grad_norm": 0.06104095280170441,
      "learning_rate": 2.8641343520253712e-05,
      "loss": 0.0002,
      "step": 88900
    },
    {
      "epoch": 4.274181923021479,
      "grad_norm": 0.06852246820926666,
      "learning_rate": 2.8629330642448703e-05,
      "loss": 0.0002,
      "step": 88950
    },
    {
      "epoch": 4.276584498582481,
      "grad_norm": 0.21932797133922577,
      "learning_rate": 2.8617317764643697e-05,
      "loss": 0.0001,
      "step": 89000
    },
    {
      "epoch": 4.2789870741434815,
      "grad_norm": 0.2689371109008789,
      "learning_rate": 2.860530488683869e-05,
      "loss": 0.0001,
      "step": 89050
    },
    {
      "epoch": 4.281389649704483,
      "grad_norm": 0.2826363146305084,
      "learning_rate": 2.8593292009033685e-05,
      "loss": 0.0001,
      "step": 89100
    },
    {
      "epoch": 4.2837922252654845,
      "grad_norm": 0.5644055008888245,
      "learning_rate": 2.8581279131228676e-05,
      "loss": 0.0001,
      "step": 89150
    },
    {
      "epoch": 4.286194800826486,
      "grad_norm": 0.2886417508125305,
      "learning_rate": 2.856926625342367e-05,
      "loss": 0.0001,
      "step": 89200
    },
    {
      "epoch": 4.288597376387488,
      "grad_norm": 0.526247501373291,
      "learning_rate": 2.8557253375618665e-05,
      "loss": 0.0002,
      "step": 89250
    },
    {
      "epoch": 4.290999951948489,
      "grad_norm": 0.20088621973991394,
      "learning_rate": 2.854524049781366e-05,
      "loss": 0.0002,
      "step": 89300
    },
    {
      "epoch": 4.29340252750949,
      "grad_norm": 0.3095482587814331,
      "learning_rate": 2.853322762000865e-05,
      "loss": 0.0002,
      "step": 89350
    },
    {
      "epoch": 4.295805103070491,
      "grad_norm": 0.10448522120714188,
      "learning_rate": 2.8521214742203644e-05,
      "loss": 0.0002,
      "step": 89400
    },
    {
      "epoch": 4.298207678631493,
      "grad_norm": 0.2760932445526123,
      "learning_rate": 2.8509201864398638e-05,
      "loss": 0.0001,
      "step": 89450
    },
    {
      "epoch": 4.300610254192494,
      "grad_norm": 0.09046759456396103,
      "learning_rate": 2.8497188986593632e-05,
      "loss": 0.0002,
      "step": 89500
    },
    {
      "epoch": 4.303012829753496,
      "grad_norm": 0.12884743511676788,
      "learning_rate": 2.8485176108788626e-05,
      "loss": 0.0001,
      "step": 89550
    },
    {
      "epoch": 4.3054154053144975,
      "grad_norm": 0.08659335970878601,
      "learning_rate": 2.8473163230983617e-05,
      "loss": 0.0004,
      "step": 89600
    },
    {
      "epoch": 4.307817980875498,
      "grad_norm": 0.22593152523040771,
      "learning_rate": 2.8461150353178605e-05,
      "loss": 0.0001,
      "step": 89650
    },
    {
      "epoch": 4.3102205564365,
      "grad_norm": 0.39400607347488403,
      "learning_rate": 2.84491374753736e-05,
      "loss": 0.0002,
      "step": 89700
    },
    {
      "epoch": 4.312623131997501,
      "grad_norm": 2.832449197769165,
      "learning_rate": 2.8437124597568593e-05,
      "loss": 0.0004,
      "step": 89750
    },
    {
      "epoch": 4.315025707558503,
      "grad_norm": 0.07222676277160645,
      "learning_rate": 2.8425111719763587e-05,
      "loss": 0.0001,
      "step": 89800
    },
    {
      "epoch": 4.317428283119504,
      "grad_norm": 0.05606016889214516,
      "learning_rate": 2.8413098841958578e-05,
      "loss": 0.0006,
      "step": 89850
    },
    {
      "epoch": 4.319830858680506,
      "grad_norm": 0.20496906340122223,
      "learning_rate": 2.8401085964153572e-05,
      "loss": 0.0002,
      "step": 89900
    },
    {
      "epoch": 4.3222334342415065,
      "grad_norm": 0.08431585878133774,
      "learning_rate": 2.8389073086348567e-05,
      "loss": 0.0005,
      "step": 89950
    },
    {
      "epoch": 4.324636009802508,
      "grad_norm": 0.3909476101398468,
      "learning_rate": 2.837706020854356e-05,
      "loss": 0.0001,
      "step": 90000
    },
    {
      "epoch": 4.32703858536351,
      "grad_norm": 0.14596609771251678,
      "learning_rate": 2.8365047330738555e-05,
      "loss": 0.0002,
      "step": 90050
    },
    {
      "epoch": 4.329441160924511,
      "grad_norm": 0.42047038674354553,
      "learning_rate": 2.8353034452933546e-05,
      "loss": 0.0002,
      "step": 90100
    },
    {
      "epoch": 4.331843736485513,
      "grad_norm": 0.11670057475566864,
      "learning_rate": 2.834102157512854e-05,
      "loss": 0.0001,
      "step": 90150
    },
    {
      "epoch": 4.334246312046514,
      "grad_norm": 0.1386856585741043,
      "learning_rate": 2.8329008697323534e-05,
      "loss": 0.0002,
      "step": 90200
    },
    {
      "epoch": 4.336648887607515,
      "grad_norm": 0.1511320024728775,
      "learning_rate": 2.831699581951853e-05,
      "loss": 0.0001,
      "step": 90250
    },
    {
      "epoch": 4.339051463168516,
      "grad_norm": 0.6005713939666748,
      "learning_rate": 2.830498294171352e-05,
      "loss": 0.0001,
      "step": 90300
    },
    {
      "epoch": 4.341454038729518,
      "grad_norm": 0.5877485871315002,
      "learning_rate": 2.8292970063908513e-05,
      "loss": 0.0001,
      "step": 90350
    },
    {
      "epoch": 4.3438566142905195,
      "grad_norm": 0.30014652013778687,
      "learning_rate": 2.82809571861035e-05,
      "loss": 0.0002,
      "step": 90400
    },
    {
      "epoch": 4.346259189851521,
      "grad_norm": 0.35288071632385254,
      "learning_rate": 2.8268944308298495e-05,
      "loss": 0.0002,
      "step": 90450
    },
    {
      "epoch": 4.348661765412523,
      "grad_norm": 0.7535459399223328,
      "learning_rate": 2.825693143049349e-05,
      "loss": 0.0001,
      "step": 90500
    },
    {
      "epoch": 4.351064340973523,
      "grad_norm": 0.13625076413154602,
      "learning_rate": 2.824491855268848e-05,
      "loss": 0.0002,
      "step": 90550
    },
    {
      "epoch": 4.353466916534525,
      "grad_norm": 0.2967047393321991,
      "learning_rate": 2.8232905674883474e-05,
      "loss": 0.0001,
      "step": 90600
    },
    {
      "epoch": 4.355869492095526,
      "grad_norm": 0.5220676064491272,
      "learning_rate": 2.822089279707847e-05,
      "loss": 0.0002,
      "step": 90650
    },
    {
      "epoch": 4.358272067656528,
      "grad_norm": 0.15628904104232788,
      "learning_rate": 2.8208879919273463e-05,
      "loss": 0.0002,
      "step": 90700
    },
    {
      "epoch": 4.360674643217529,
      "grad_norm": 0.2746361196041107,
      "learning_rate": 2.8196867041468457e-05,
      "loss": 0.0002,
      "step": 90750
    },
    {
      "epoch": 4.363077218778531,
      "grad_norm": 0.11575720459222794,
      "learning_rate": 2.8184854163663448e-05,
      "loss": 0.0002,
      "step": 90800
    },
    {
      "epoch": 4.365479794339532,
      "grad_norm": 0.29264822602272034,
      "learning_rate": 2.8172841285858442e-05,
      "loss": 0.0002,
      "step": 90850
    },
    {
      "epoch": 4.367882369900533,
      "grad_norm": 0.2733706533908844,
      "learning_rate": 2.8160828408053436e-05,
      "loss": 0.0002,
      "step": 90900
    },
    {
      "epoch": 4.370284945461535,
      "grad_norm": 0.3973160982131958,
      "learning_rate": 2.814881553024843e-05,
      "loss": 0.0001,
      "step": 90950
    },
    {
      "epoch": 4.372687521022536,
      "grad_norm": 0.13462163507938385,
      "learning_rate": 2.813680265244342e-05,
      "loss": 0.0007,
      "step": 91000
    },
    {
      "epoch": 4.375090096583538,
      "grad_norm": 0.16219785809516907,
      "learning_rate": 2.8124789774638416e-05,
      "loss": 0.0002,
      "step": 91050
    },
    {
      "epoch": 4.377492672144539,
      "grad_norm": 0.4354800581932068,
      "learning_rate": 2.811277689683341e-05,
      "loss": 0.0005,
      "step": 91100
    },
    {
      "epoch": 4.37989524770554,
      "grad_norm": 0.0929257944226265,
      "learning_rate": 2.8100764019028397e-05,
      "loss": 0.0001,
      "step": 91150
    },
    {
      "epoch": 4.3822978232665415,
      "grad_norm": 0.17574235796928406,
      "learning_rate": 2.808875114122339e-05,
      "loss": 0.0002,
      "step": 91200
    },
    {
      "epoch": 4.384700398827543,
      "grad_norm": 0.3989427089691162,
      "learning_rate": 2.8076738263418386e-05,
      "loss": 0.0003,
      "step": 91250
    },
    {
      "epoch": 4.387102974388545,
      "grad_norm": 0.8325807452201843,
      "learning_rate": 2.8064725385613376e-05,
      "loss": 0.0002,
      "step": 91300
    },
    {
      "epoch": 4.389505549949546,
      "grad_norm": 0.18113553524017334,
      "learning_rate": 2.805271250780837e-05,
      "loss": 0.0001,
      "step": 91350
    },
    {
      "epoch": 4.391908125510548,
      "grad_norm": 0.3541009724140167,
      "learning_rate": 2.8040699630003365e-05,
      "loss": 0.0005,
      "step": 91400
    },
    {
      "epoch": 4.394310701071548,
      "grad_norm": 0.07668536901473999,
      "learning_rate": 2.802868675219836e-05,
      "loss": 0.0001,
      "step": 91450
    },
    {
      "epoch": 4.39671327663255,
      "grad_norm": 0.5004040598869324,
      "learning_rate": 2.801667387439335e-05,
      "loss": 0.0002,
      "step": 91500
    },
    {
      "epoch": 4.399115852193551,
      "grad_norm": 0.07801192998886108,
      "learning_rate": 2.8004660996588344e-05,
      "loss": 0.0002,
      "step": 91550
    },
    {
      "epoch": 4.401518427754553,
      "grad_norm": 0.3667834997177124,
      "learning_rate": 2.799264811878334e-05,
      "loss": 0.0001,
      "step": 91600
    },
    {
      "epoch": 4.4039210033155545,
      "grad_norm": 0.3840601146221161,
      "learning_rate": 2.7980635240978333e-05,
      "loss": 0.0002,
      "step": 91650
    },
    {
      "epoch": 4.406323578876556,
      "grad_norm": 0.1643623262643814,
      "learning_rate": 2.7968622363173323e-05,
      "loss": 0.0001,
      "step": 91700
    },
    {
      "epoch": 4.408726154437557,
      "grad_norm": 0.3269840180873871,
      "learning_rate": 2.7956609485368318e-05,
      "loss": 0.0001,
      "step": 91750
    },
    {
      "epoch": 4.411128729998558,
      "grad_norm": 0.19963005185127258,
      "learning_rate": 2.7944596607563312e-05,
      "loss": 0.0001,
      "step": 91800
    },
    {
      "epoch": 4.41353130555956,
      "grad_norm": 0.14188727736473083,
      "learning_rate": 2.7932583729758306e-05,
      "loss": 0.0002,
      "step": 91850
    },
    {
      "epoch": 4.415933881120561,
      "grad_norm": 0.2643055319786072,
      "learning_rate": 2.7920570851953293e-05,
      "loss": 0.0001,
      "step": 91900
    },
    {
      "epoch": 4.418336456681563,
      "grad_norm": 0.18100976943969727,
      "learning_rate": 2.7908557974148288e-05,
      "loss": 0.0001,
      "step": 91950
    },
    {
      "epoch": 4.420739032242564,
      "grad_norm": 0.27606678009033203,
      "learning_rate": 2.789654509634328e-05,
      "loss": 0.0002,
      "step": 92000
    },
    {
      "epoch": 4.423141607803565,
      "grad_norm": 0.3943263292312622,
      "learning_rate": 2.7884532218538273e-05,
      "loss": 0.0002,
      "step": 92050
    },
    {
      "epoch": 4.425544183364567,
      "grad_norm": 0.2427351474761963,
      "learning_rate": 2.7872519340733267e-05,
      "loss": 0.0001,
      "step": 92100
    },
    {
      "epoch": 4.427946758925568,
      "grad_norm": 0.5004451274871826,
      "learning_rate": 2.786050646292826e-05,
      "loss": 0.0002,
      "step": 92150
    },
    {
      "epoch": 4.43034933448657,
      "grad_norm": 0.1130577102303505,
      "learning_rate": 2.7848493585123252e-05,
      "loss": 0.0002,
      "step": 92200
    },
    {
      "epoch": 4.432751910047571,
      "grad_norm": 0.27165740728378296,
      "learning_rate": 2.7836480707318246e-05,
      "loss": 0.0002,
      "step": 92250
    },
    {
      "epoch": 4.435154485608573,
      "grad_norm": 0.37202736735343933,
      "learning_rate": 2.782446782951324e-05,
      "loss": 0.0002,
      "step": 92300
    },
    {
      "epoch": 4.437557061169573,
      "grad_norm": 0.26558414101600647,
      "learning_rate": 2.7812454951708235e-05,
      "loss": 0.0001,
      "step": 92350
    },
    {
      "epoch": 4.439959636730575,
      "grad_norm": 0.07039395719766617,
      "learning_rate": 2.7800442073903225e-05,
      "loss": 0.0001,
      "step": 92400
    },
    {
      "epoch": 4.4423622122915765,
      "grad_norm": 0.22014062106609344,
      "learning_rate": 2.778842919609822e-05,
      "loss": 0.0001,
      "step": 92450
    },
    {
      "epoch": 4.444764787852578,
      "grad_norm": 0.11465834826231003,
      "learning_rate": 2.7776416318293214e-05,
      "loss": 0.0002,
      "step": 92500
    },
    {
      "epoch": 4.4471673634135795,
      "grad_norm": 0.4523889124393463,
      "learning_rate": 2.7764403440488208e-05,
      "loss": 0.0001,
      "step": 92550
    },
    {
      "epoch": 4.449569938974581,
      "grad_norm": 0.4455561339855194,
      "learning_rate": 2.77523905626832e-05,
      "loss": 0.0002,
      "step": 92600
    },
    {
      "epoch": 4.451972514535582,
      "grad_norm": 0.06822572648525238,
      "learning_rate": 2.774037768487819e-05,
      "loss": 0.0002,
      "step": 92650
    },
    {
      "epoch": 4.454375090096583,
      "grad_norm": 0.2869769036769867,
      "learning_rate": 2.772836480707318e-05,
      "loss": 0.0001,
      "step": 92700
    },
    {
      "epoch": 4.456777665657585,
      "grad_norm": 0.526334285736084,
      "learning_rate": 2.7716351929268175e-05,
      "loss": 0.0002,
      "step": 92750
    },
    {
      "epoch": 4.459180241218586,
      "grad_norm": 0.19670815765857697,
      "learning_rate": 2.770433905146317e-05,
      "loss": 0.0002,
      "step": 92800
    },
    {
      "epoch": 4.461582816779588,
      "grad_norm": 0.18316437304019928,
      "learning_rate": 2.7692326173658163e-05,
      "loss": 0.0001,
      "step": 92850
    },
    {
      "epoch": 4.463985392340589,
      "grad_norm": 0.07579843699932098,
      "learning_rate": 2.7680313295853154e-05,
      "loss": 0.0001,
      "step": 92900
    },
    {
      "epoch": 4.46638796790159,
      "grad_norm": 0.2031533122062683,
      "learning_rate": 2.7668300418048148e-05,
      "loss": 0.0002,
      "step": 92950
    },
    {
      "epoch": 4.468790543462592,
      "grad_norm": 0.1592789888381958,
      "learning_rate": 2.7656287540243142e-05,
      "loss": 0.0002,
      "step": 93000
    },
    {
      "epoch": 4.471193119023593,
      "grad_norm": 0.3067886233329773,
      "learning_rate": 2.7644274662438137e-05,
      "loss": 0.0002,
      "step": 93050
    },
    {
      "epoch": 4.473595694584595,
      "grad_norm": 0.10029768198728561,
      "learning_rate": 2.7632261784633127e-05,
      "loss": 0.0004,
      "step": 93100
    },
    {
      "epoch": 4.475998270145596,
      "grad_norm": 0.10540364682674408,
      "learning_rate": 2.762024890682812e-05,
      "loss": 0.0002,
      "step": 93150
    },
    {
      "epoch": 4.478400845706598,
      "grad_norm": 0.08266159892082214,
      "learning_rate": 2.7608236029023116e-05,
      "loss": 0.0002,
      "step": 93200
    },
    {
      "epoch": 4.4808034212675985,
      "grad_norm": 0.15384812653064728,
      "learning_rate": 2.759622315121811e-05,
      "loss": 0.0002,
      "step": 93250
    },
    {
      "epoch": 4.4832059968286,
      "grad_norm": 0.15400810539722443,
      "learning_rate": 2.75842102734131e-05,
      "loss": 0.0001,
      "step": 93300
    },
    {
      "epoch": 4.4856085723896015,
      "grad_norm": 0.4277218282222748,
      "learning_rate": 2.7572197395608095e-05,
      "loss": 0.0002,
      "step": 93350
    },
    {
      "epoch": 4.488011147950603,
      "grad_norm": 0.04368109256029129,
      "learning_rate": 2.7560184517803083e-05,
      "loss": 0.0002,
      "step": 93400
    },
    {
      "epoch": 4.490413723511605,
      "grad_norm": 0.1341639906167984,
      "learning_rate": 2.7548171639998077e-05,
      "loss": 0.0006,
      "step": 93450
    },
    {
      "epoch": 4.492816299072606,
      "grad_norm": 0.0797998309135437,
      "learning_rate": 2.753615876219307e-05,
      "loss": 0.0001,
      "step": 93500
    },
    {
      "epoch": 4.495218874633608,
      "grad_norm": 0.14435814321041107,
      "learning_rate": 2.7524145884388065e-05,
      "loss": 0.0002,
      "step": 93550
    },
    {
      "epoch": 4.497621450194608,
      "grad_norm": 0.42105671763420105,
      "learning_rate": 2.7512133006583056e-05,
      "loss": 0.0006,
      "step": 93600
    },
    {
      "epoch": 4.50002402575561,
      "grad_norm": 0.5195721983909607,
      "learning_rate": 2.750012012877805e-05,
      "loss": 0.0002,
      "step": 93650
    },
    {
      "epoch": 4.502426601316611,
      "grad_norm": 0.376438170671463,
      "learning_rate": 2.7488107250973044e-05,
      "loss": 0.0002,
      "step": 93700
    },
    {
      "epoch": 4.504829176877613,
      "grad_norm": 0.30263760685920715,
      "learning_rate": 2.747609437316804e-05,
      "loss": 0.0002,
      "step": 93750
    },
    {
      "epoch": 4.5072317524386145,
      "grad_norm": 0.16990581154823303,
      "learning_rate": 2.746408149536303e-05,
      "loss": 0.0005,
      "step": 93800
    },
    {
      "epoch": 4.509634327999615,
      "grad_norm": 0.27632686495780945,
      "learning_rate": 2.7452068617558024e-05,
      "loss": 0.0002,
      "step": 93850
    },
    {
      "epoch": 4.512036903560617,
      "grad_norm": 0.28133076429367065,
      "learning_rate": 2.7440055739753018e-05,
      "loss": 0.0001,
      "step": 93900
    },
    {
      "epoch": 4.514439479121618,
      "grad_norm": 0.07473411411046982,
      "learning_rate": 2.7428042861948012e-05,
      "loss": 0.0001,
      "step": 93950
    },
    {
      "epoch": 4.51684205468262,
      "grad_norm": 0.2422289252281189,
      "learning_rate": 2.7416029984143003e-05,
      "loss": 0.0001,
      "step": 94000
    },
    {
      "epoch": 4.519244630243621,
      "grad_norm": 0.04883625730872154,
      "learning_rate": 2.7404017106337997e-05,
      "loss": 0.0001,
      "step": 94050
    },
    {
      "epoch": 4.521647205804623,
      "grad_norm": 0.19995708763599396,
      "learning_rate": 2.739200422853299e-05,
      "loss": 0.0002,
      "step": 94100
    },
    {
      "epoch": 4.524049781365624,
      "grad_norm": 0.30087053775787354,
      "learning_rate": 2.737999135072798e-05,
      "loss": 0.0002,
      "step": 94150
    },
    {
      "epoch": 4.526452356926625,
      "grad_norm": 0.0771244615316391,
      "learning_rate": 2.7367978472922973e-05,
      "loss": 0.0002,
      "step": 94200
    },
    {
      "epoch": 4.528854932487627,
      "grad_norm": 0.21390311419963837,
      "learning_rate": 2.7355965595117967e-05,
      "loss": 0.0006,
      "step": 94250
    },
    {
      "epoch": 4.531257508048628,
      "grad_norm": 0.20292304456233978,
      "learning_rate": 2.7343952717312958e-05,
      "loss": 0.0001,
      "step": 94300
    },
    {
      "epoch": 4.53366008360963,
      "grad_norm": 0.2979024052619934,
      "learning_rate": 2.7331939839507952e-05,
      "loss": 0.0001,
      "step": 94350
    },
    {
      "epoch": 4.536062659170631,
      "grad_norm": 0.10662669688463211,
      "learning_rate": 2.7319926961702947e-05,
      "loss": 0.0001,
      "step": 94400
    },
    {
      "epoch": 4.538465234731632,
      "grad_norm": 0.04228668287396431,
      "learning_rate": 2.730791408389794e-05,
      "loss": 0.0002,
      "step": 94450
    },
    {
      "epoch": 4.540867810292633,
      "grad_norm": 0.09924660623073578,
      "learning_rate": 2.729590120609293e-05,
      "loss": 0.0002,
      "step": 94500
    },
    {
      "epoch": 4.543270385853635,
      "grad_norm": 0.18436311185359955,
      "learning_rate": 2.7283888328287926e-05,
      "loss": 0.0002,
      "step": 94550
    },
    {
      "epoch": 4.5456729614146365,
      "grad_norm": 0.3637057840824127,
      "learning_rate": 2.727187545048292e-05,
      "loss": 0.0001,
      "step": 94600
    },
    {
      "epoch": 4.548075536975638,
      "grad_norm": 0.1820722222328186,
      "learning_rate": 2.7259862572677914e-05,
      "loss": 0.0002,
      "step": 94650
    },
    {
      "epoch": 4.55047811253664,
      "grad_norm": 0.06948429346084595,
      "learning_rate": 2.724784969487291e-05,
      "loss": 0.0005,
      "step": 94700
    },
    {
      "epoch": 4.552880688097641,
      "grad_norm": 0.15018682181835175,
      "learning_rate": 2.72358368170679e-05,
      "loss": 0.0002,
      "step": 94750
    },
    {
      "epoch": 4.555283263658642,
      "grad_norm": 0.09723003953695297,
      "learning_rate": 2.7223823939262893e-05,
      "loss": 0.0001,
      "step": 94800
    },
    {
      "epoch": 4.557685839219643,
      "grad_norm": 0.1024126410484314,
      "learning_rate": 2.721181106145788e-05,
      "loss": 0.0003,
      "step": 94850
    },
    {
      "epoch": 4.560088414780645,
      "grad_norm": 0.7172005772590637,
      "learning_rate": 2.7199798183652875e-05,
      "loss": 0.0001,
      "step": 94900
    },
    {
      "epoch": 4.562490990341646,
      "grad_norm": 0.11166567355394363,
      "learning_rate": 2.718778530584787e-05,
      "loss": 0.0001,
      "step": 94950
    },
    {
      "epoch": 4.564893565902648,
      "grad_norm": 0.1509273201227188,
      "learning_rate": 2.717577242804286e-05,
      "loss": 0.0002,
      "step": 95000
    },
    {
      "epoch": 4.567296141463649,
      "grad_norm": 0.11815541237592697,
      "learning_rate": 2.7163759550237854e-05,
      "loss": 0.0002,
      "step": 95050
    },
    {
      "epoch": 4.56969871702465,
      "grad_norm": 0.30776211619377136,
      "learning_rate": 2.715174667243285e-05,
      "loss": 0.0002,
      "step": 95100
    },
    {
      "epoch": 4.572101292585652,
      "grad_norm": 0.30116114020347595,
      "learning_rate": 2.7139733794627843e-05,
      "loss": 0.0001,
      "step": 95150
    },
    {
      "epoch": 4.574503868146653,
      "grad_norm": 0.13409924507141113,
      "learning_rate": 2.7127720916822834e-05,
      "loss": 0.0001,
      "step": 95200
    },
    {
      "epoch": 4.576906443707655,
      "grad_norm": 0.11552246659994125,
      "learning_rate": 2.7115708039017828e-05,
      "loss": 0.0002,
      "step": 95250
    },
    {
      "epoch": 4.579309019268656,
      "grad_norm": 0.2771240770816803,
      "learning_rate": 2.7103695161212822e-05,
      "loss": 0.0002,
      "step": 95300
    },
    {
      "epoch": 4.581711594829658,
      "grad_norm": 0.16185978055000305,
      "learning_rate": 2.7091682283407816e-05,
      "loss": 0.0002,
      "step": 95350
    },
    {
      "epoch": 4.5841141703906585,
      "grad_norm": 0.23181043565273285,
      "learning_rate": 2.707966940560281e-05,
      "loss": 0.0001,
      "step": 95400
    },
    {
      "epoch": 4.58651674595166,
      "grad_norm": 0.023991888388991356,
      "learning_rate": 2.70676565277978e-05,
      "loss": 0.0002,
      "step": 95450
    },
    {
      "epoch": 4.588919321512662,
      "grad_norm": 0.3839353621006012,
      "learning_rate": 2.7055643649992795e-05,
      "loss": 0.0006,
      "step": 95500
    },
    {
      "epoch": 4.591321897073663,
      "grad_norm": 0.15373611450195312,
      "learning_rate": 2.704363077218779e-05,
      "loss": 0.0001,
      "step": 95550
    },
    {
      "epoch": 4.593724472634665,
      "grad_norm": 0.14680825173854828,
      "learning_rate": 2.7031617894382777e-05,
      "loss": 0.0001,
      "step": 95600
    },
    {
      "epoch": 4.596127048195665,
      "grad_norm": 0.3949759602546692,
      "learning_rate": 2.701960501657777e-05,
      "loss": 0.0002,
      "step": 95650
    },
    {
      "epoch": 4.598529623756667,
      "grad_norm": 0.4369228780269623,
      "learning_rate": 2.7007592138772762e-05,
      "loss": 0.0001,
      "step": 95700
    },
    {
      "epoch": 4.600932199317668,
      "grad_norm": 0.19220317900180817,
      "learning_rate": 2.6995579260967756e-05,
      "loss": 0.0001,
      "step": 95750
    },
    {
      "epoch": 4.60333477487867,
      "grad_norm": 0.29837849736213684,
      "learning_rate": 2.698356638316275e-05,
      "loss": 0.0001,
      "step": 95800
    },
    {
      "epoch": 4.6057373504396715,
      "grad_norm": 0.13002455234527588,
      "learning_rate": 2.6971553505357745e-05,
      "loss": 0.0001,
      "step": 95850
    },
    {
      "epoch": 4.608139926000673,
      "grad_norm": 0.44017764925956726,
      "learning_rate": 2.695954062755274e-05,
      "loss": 0.0002,
      "step": 95900
    },
    {
      "epoch": 4.6105425015616746,
      "grad_norm": 0.16291384398937225,
      "learning_rate": 2.694752774974773e-05,
      "loss": 0.0003,
      "step": 95950
    },
    {
      "epoch": 4.612945077122675,
      "grad_norm": 0.14230939745903015,
      "learning_rate": 2.6935514871942724e-05,
      "loss": 0.0002,
      "step": 96000
    },
    {
      "epoch": 4.615347652683677,
      "grad_norm": 0.10168261080980301,
      "learning_rate": 2.6923501994137718e-05,
      "loss": 0.0001,
      "step": 96050
    },
    {
      "epoch": 4.617750228244678,
      "grad_norm": 0.1340157836675644,
      "learning_rate": 2.6911489116332713e-05,
      "loss": 0.0002,
      "step": 96100
    },
    {
      "epoch": 4.62015280380568,
      "grad_norm": 0.4530015289783478,
      "learning_rate": 2.6899476238527703e-05,
      "loss": 0.0002,
      "step": 96150
    },
    {
      "epoch": 4.622555379366681,
      "grad_norm": 0.15863101184368134,
      "learning_rate": 2.6887463360722698e-05,
      "loss": 0.0002,
      "step": 96200
    },
    {
      "epoch": 4.624957954927682,
      "grad_norm": 0.12914776802062988,
      "learning_rate": 2.6875450482917692e-05,
      "loss": 0.0001,
      "step": 96250
    },
    {
      "epoch": 4.627360530488684,
      "grad_norm": 0.333904892206192,
      "learning_rate": 2.6863437605112686e-05,
      "loss": 0.0001,
      "step": 96300
    },
    {
      "epoch": 4.629763106049685,
      "grad_norm": 0.16292639076709747,
      "learning_rate": 2.6851424727307673e-05,
      "loss": 0.0002,
      "step": 96350
    },
    {
      "epoch": 4.632165681610687,
      "grad_norm": 0.23367628455162048,
      "learning_rate": 2.6839411849502664e-05,
      "loss": 0.0002,
      "step": 96400
    },
    {
      "epoch": 4.634568257171688,
      "grad_norm": 0.20078463852405548,
      "learning_rate": 2.682739897169766e-05,
      "loss": 0.0001,
      "step": 96450
    },
    {
      "epoch": 4.63697083273269,
      "grad_norm": 0.12628865242004395,
      "learning_rate": 2.6815386093892653e-05,
      "loss": 0.0002,
      "step": 96500
    },
    {
      "epoch": 4.639373408293691,
      "grad_norm": 0.1748712807893753,
      "learning_rate": 2.6803373216087647e-05,
      "loss": 0.0001,
      "step": 96550
    },
    {
      "epoch": 4.641775983854692,
      "grad_norm": 0.6372785568237305,
      "learning_rate": 2.679136033828264e-05,
      "loss": 0.0001,
      "step": 96600
    },
    {
      "epoch": 4.6441785594156935,
      "grad_norm": 0.10578865557909012,
      "learning_rate": 2.6779347460477632e-05,
      "loss": 0.0002,
      "step": 96650
    },
    {
      "epoch": 4.646581134976695,
      "grad_norm": 0.1615447700023651,
      "learning_rate": 2.6767334582672626e-05,
      "loss": 0.0001,
      "step": 96700
    },
    {
      "epoch": 4.6489837105376965,
      "grad_norm": 0.2801869213581085,
      "learning_rate": 2.675532170486762e-05,
      "loss": 0.0002,
      "step": 96750
    },
    {
      "epoch": 4.651386286098698,
      "grad_norm": 0.21179039776325226,
      "learning_rate": 2.6743308827062615e-05,
      "loss": 0.0006,
      "step": 96800
    },
    {
      "epoch": 4.653788861659699,
      "grad_norm": 0.5550737380981445,
      "learning_rate": 2.6731295949257605e-05,
      "loss": 0.0001,
      "step": 96850
    },
    {
      "epoch": 4.6561914372207,
      "grad_norm": 0.5412064790725708,
      "learning_rate": 2.67192830714526e-05,
      "loss": 0.0001,
      "step": 96900
    },
    {
      "epoch": 4.658594012781702,
      "grad_norm": 0.48973724246025085,
      "learning_rate": 2.6707270193647594e-05,
      "loss": 0.0001,
      "step": 96950
    },
    {
      "epoch": 4.660996588342703,
      "grad_norm": 0.23322556912899017,
      "learning_rate": 2.6695257315842588e-05,
      "loss": 0.0001,
      "step": 97000
    },
    {
      "epoch": 4.663399163903705,
      "grad_norm": 0.41225314140319824,
      "learning_rate": 2.668324443803758e-05,
      "loss": 0.0002,
      "step": 97050
    },
    {
      "epoch": 4.665801739464706,
      "grad_norm": 0.14497458934783936,
      "learning_rate": 2.6671231560232566e-05,
      "loss": 0.0002,
      "step": 97100
    },
    {
      "epoch": 4.668204315025708,
      "grad_norm": 0.2511383891105652,
      "learning_rate": 2.665921868242756e-05,
      "loss": 0.0002,
      "step": 97150
    },
    {
      "epoch": 4.670606890586709,
      "grad_norm": 0.24956464767456055,
      "learning_rate": 2.6647205804622555e-05,
      "loss": 0.0002,
      "step": 97200
    },
    {
      "epoch": 4.67300946614771,
      "grad_norm": 0.3947504162788391,
      "learning_rate": 2.663519292681755e-05,
      "loss": 0.0006,
      "step": 97250
    },
    {
      "epoch": 4.675412041708712,
      "grad_norm": 0.04302771016955376,
      "learning_rate": 2.6623180049012543e-05,
      "loss": 0.0002,
      "step": 97300
    },
    {
      "epoch": 4.677814617269713,
      "grad_norm": 0.05885787308216095,
      "learning_rate": 2.6611167171207534e-05,
      "loss": 0.0001,
      "step": 97350
    },
    {
      "epoch": 4.680217192830715,
      "grad_norm": 0.08293537050485611,
      "learning_rate": 2.6599154293402528e-05,
      "loss": 0.0006,
      "step": 97400
    },
    {
      "epoch": 4.6826197683917155,
      "grad_norm": 0.16089759767055511,
      "learning_rate": 2.6587141415597522e-05,
      "loss": 0.0007,
      "step": 97450
    },
    {
      "epoch": 4.685022343952717,
      "grad_norm": 0.1392420083284378,
      "learning_rate": 2.6575128537792517e-05,
      "loss": 0.0004,
      "step": 97500
    },
    {
      "epoch": 4.6874249195137185,
      "grad_norm": 0.2628653347492218,
      "learning_rate": 2.6563115659987507e-05,
      "loss": 0.0001,
      "step": 97550
    },
    {
      "epoch": 4.68982749507472,
      "grad_norm": 0.5134127140045166,
      "learning_rate": 2.65511027821825e-05,
      "loss": 0.0002,
      "step": 97600
    },
    {
      "epoch": 4.692230070635722,
      "grad_norm": 0.06589929014444351,
      "learning_rate": 2.6539089904377496e-05,
      "loss": 0.0001,
      "step": 97650
    },
    {
      "epoch": 4.694632646196723,
      "grad_norm": 0.8897068500518799,
      "learning_rate": 2.652707702657249e-05,
      "loss": 0.0004,
      "step": 97700
    },
    {
      "epoch": 4.697035221757725,
      "grad_norm": 0.47940805554389954,
      "learning_rate": 2.651506414876748e-05,
      "loss": 0.0002,
      "step": 97750
    },
    {
      "epoch": 4.699437797318725,
      "grad_norm": 0.4275106191635132,
      "learning_rate": 2.6503051270962475e-05,
      "loss": 0.0002,
      "step": 97800
    },
    {
      "epoch": 4.701840372879727,
      "grad_norm": 0.08074025064706802,
      "learning_rate": 2.6491038393157463e-05,
      "loss": 0.0002,
      "step": 97850
    },
    {
      "epoch": 4.704242948440728,
      "grad_norm": 0.12305308133363724,
      "learning_rate": 2.6479025515352457e-05,
      "loss": 0.0002,
      "step": 97900
    },
    {
      "epoch": 4.70664552400173,
      "grad_norm": 0.35563528537750244,
      "learning_rate": 2.646701263754745e-05,
      "loss": 0.0002,
      "step": 97950
    },
    {
      "epoch": 4.7090480995627315,
      "grad_norm": 0.4710516333580017,
      "learning_rate": 2.6454999759742445e-05,
      "loss": 0.0001,
      "step": 98000
    },
    {
      "epoch": 4.711450675123732,
      "grad_norm": 0.3680639863014221,
      "learning_rate": 2.6442986881937436e-05,
      "loss": 0.0001,
      "step": 98050
    },
    {
      "epoch": 4.713853250684734,
      "grad_norm": 0.29797276854515076,
      "learning_rate": 2.643097400413243e-05,
      "loss": 0.0002,
      "step": 98100
    },
    {
      "epoch": 4.716255826245735,
      "grad_norm": 0.29065030813217163,
      "learning_rate": 2.6418961126327424e-05,
      "loss": 0.0001,
      "step": 98150
    },
    {
      "epoch": 4.718658401806737,
      "grad_norm": 0.652589738368988,
      "learning_rate": 2.640694824852242e-05,
      "loss": 0.0002,
      "step": 98200
    },
    {
      "epoch": 4.721060977367738,
      "grad_norm": 0.07580380886793137,
      "learning_rate": 2.639493537071741e-05,
      "loss": 0.0001,
      "step": 98250
    },
    {
      "epoch": 4.72346355292874,
      "grad_norm": 0.1360432356595993,
      "learning_rate": 2.6382922492912404e-05,
      "loss": 0.0002,
      "step": 98300
    },
    {
      "epoch": 4.725866128489741,
      "grad_norm": 0.13843779265880585,
      "learning_rate": 2.6370909615107398e-05,
      "loss": 0.0001,
      "step": 98350
    },
    {
      "epoch": 4.728268704050742,
      "grad_norm": 0.30760282278060913,
      "learning_rate": 2.6358896737302392e-05,
      "loss": 0.0001,
      "step": 98400
    },
    {
      "epoch": 4.730671279611744,
      "grad_norm": 0.25882601737976074,
      "learning_rate": 2.6346883859497383e-05,
      "loss": 0.0002,
      "step": 98450
    },
    {
      "epoch": 4.733073855172745,
      "grad_norm": 0.36378705501556396,
      "learning_rate": 2.6334870981692377e-05,
      "loss": 0.0006,
      "step": 98500
    },
    {
      "epoch": 4.735476430733747,
      "grad_norm": 0.1509931981563568,
      "learning_rate": 2.632285810388737e-05,
      "loss": 0.0002,
      "step": 98550
    },
    {
      "epoch": 4.737879006294748,
      "grad_norm": 0.1522715985774994,
      "learning_rate": 2.631084522608236e-05,
      "loss": 0.0002,
      "step": 98600
    },
    {
      "epoch": 4.740281581855749,
      "grad_norm": 0.5439409017562866,
      "learning_rate": 2.6298832348277353e-05,
      "loss": 0.0002,
      "step": 98650
    },
    {
      "epoch": 4.74268415741675,
      "grad_norm": 0.15032745897769928,
      "learning_rate": 2.6286819470472347e-05,
      "loss": 0.0001,
      "step": 98700
    },
    {
      "epoch": 4.745086732977752,
      "grad_norm": 0.16820767521858215,
      "learning_rate": 2.6274806592667338e-05,
      "loss": 0.0001,
      "step": 98750
    },
    {
      "epoch": 4.7474893085387535,
      "grad_norm": 0.05710111930966377,
      "learning_rate": 2.6262793714862332e-05,
      "loss": 0.0002,
      "step": 98800
    },
    {
      "epoch": 4.749891884099755,
      "grad_norm": 0.45637986063957214,
      "learning_rate": 2.6250780837057326e-05,
      "loss": 0.0001,
      "step": 98850
    },
    {
      "epoch": 4.752294459660757,
      "grad_norm": 0.20702874660491943,
      "learning_rate": 2.623876795925232e-05,
      "loss": 0.0002,
      "step": 98900
    },
    {
      "epoch": 4.754697035221758,
      "grad_norm": 0.1434948444366455,
      "learning_rate": 2.622675508144731e-05,
      "loss": 0.0001,
      "step": 98950
    },
    {
      "epoch": 4.757099610782759,
      "grad_norm": 0.09491530060768127,
      "learning_rate": 2.6214742203642306e-05,
      "loss": 0.0001,
      "step": 99000
    },
    {
      "epoch": 4.75950218634376,
      "grad_norm": 0.1777547299861908,
      "learning_rate": 2.62027293258373e-05,
      "loss": 0.0001,
      "step": 99050
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.4475577473640442,
      "learning_rate": 2.6190716448032294e-05,
      "loss": 0.0006,
      "step": 99100
    },
    {
      "epoch": 4.764307337465763,
      "grad_norm": 0.20119911432266235,
      "learning_rate": 2.6178703570227285e-05,
      "loss": 0.0002,
      "step": 99150
    },
    {
      "epoch": 4.766709913026765,
      "grad_norm": 0.34643393754959106,
      "learning_rate": 2.616669069242228e-05,
      "loss": 0.0001,
      "step": 99200
    },
    {
      "epoch": 4.769112488587766,
      "grad_norm": 0.21664072573184967,
      "learning_rate": 2.6154677814617273e-05,
      "loss": 0.0001,
      "step": 99250
    },
    {
      "epoch": 4.771515064148767,
      "grad_norm": 0.1168510839343071,
      "learning_rate": 2.6142664936812268e-05,
      "loss": 0.0006,
      "step": 99300
    },
    {
      "epoch": 4.773917639709769,
      "grad_norm": 0.2727716267108917,
      "learning_rate": 2.6130652059007255e-05,
      "loss": 0.0001,
      "step": 99350
    },
    {
      "epoch": 4.77632021527077,
      "grad_norm": 0.10666434466838837,
      "learning_rate": 2.611863918120225e-05,
      "loss": 0.0002,
      "step": 99400
    },
    {
      "epoch": 4.778722790831772,
      "grad_norm": 0.07166975736618042,
      "learning_rate": 2.610662630339724e-05,
      "loss": 0.0001,
      "step": 99450
    },
    {
      "epoch": 4.781125366392773,
      "grad_norm": 0.23271924257278442,
      "learning_rate": 2.6094613425592234e-05,
      "loss": 0.0002,
      "step": 99500
    },
    {
      "epoch": 4.783527941953775,
      "grad_norm": 0.09848421066999435,
      "learning_rate": 2.608260054778723e-05,
      "loss": 0.0002,
      "step": 99550
    },
    {
      "epoch": 4.7859305175147755,
      "grad_norm": 0.15611064434051514,
      "learning_rate": 2.6070587669982223e-05,
      "loss": 0.0001,
      "step": 99600
    },
    {
      "epoch": 4.788333093075777,
      "grad_norm": 0.13741309940814972,
      "learning_rate": 2.6058574792177214e-05,
      "loss": 0.0001,
      "step": 99650
    },
    {
      "epoch": 4.790735668636779,
      "grad_norm": 0.22301360964775085,
      "learning_rate": 2.6046561914372208e-05,
      "loss": 0.0001,
      "step": 99700
    },
    {
      "epoch": 4.79313824419778,
      "grad_norm": 0.07380829006433487,
      "learning_rate": 2.6034549036567202e-05,
      "loss": 0.0001,
      "step": 99750
    },
    {
      "epoch": 4.795540819758782,
      "grad_norm": 0.1744447499513626,
      "learning_rate": 2.6022536158762196e-05,
      "loss": 0.0001,
      "step": 99800
    },
    {
      "epoch": 4.797943395319782,
      "grad_norm": 0.3954260051250458,
      "learning_rate": 2.6010523280957187e-05,
      "loss": 0.0001,
      "step": 99850
    },
    {
      "epoch": 4.800345970880784,
      "grad_norm": 0.09730201214551926,
      "learning_rate": 2.599851040315218e-05,
      "loss": 0.0002,
      "step": 99900
    },
    {
      "epoch": 4.802748546441785,
      "grad_norm": 0.33221498131752014,
      "learning_rate": 2.5986497525347175e-05,
      "loss": 0.0001,
      "step": 99950
    },
    {
      "epoch": 4.805151122002787,
      "grad_norm": 0.483230322599411,
      "learning_rate": 2.597448464754217e-05,
      "loss": 0.0001,
      "step": 100000
    },
    {
      "epoch": 4.8075536975637885,
      "grad_norm": 0.4028416574001312,
      "learning_rate": 2.5962471769737164e-05,
      "loss": 0.0002,
      "step": 100050
    },
    {
      "epoch": 4.80995627312479,
      "grad_norm": 0.29727885127067566,
      "learning_rate": 2.595045889193215e-05,
      "loss": 0.0001,
      "step": 100100
    },
    {
      "epoch": 4.812358848685792,
      "grad_norm": 0.26788899302482605,
      "learning_rate": 2.5938446014127142e-05,
      "loss": 0.0002,
      "step": 100150
    },
    {
      "epoch": 4.814761424246792,
      "grad_norm": 0.1931523233652115,
      "learning_rate": 2.5926433136322136e-05,
      "loss": 0.0001,
      "step": 100200
    },
    {
      "epoch": 4.817163999807794,
      "grad_norm": 0.16546614468097687,
      "learning_rate": 2.591442025851713e-05,
      "loss": 0.0001,
      "step": 100250
    },
    {
      "epoch": 4.819566575368795,
      "grad_norm": 0.3576463758945465,
      "learning_rate": 2.5902407380712125e-05,
      "loss": 0.0003,
      "step": 100300
    },
    {
      "epoch": 4.821969150929797,
      "grad_norm": 0.12801969051361084,
      "learning_rate": 2.5890394502907116e-05,
      "loss": 0.0001,
      "step": 100350
    },
    {
      "epoch": 4.824371726490798,
      "grad_norm": 0.16755566000938416,
      "learning_rate": 2.587838162510211e-05,
      "loss": 0.0001,
      "step": 100400
    },
    {
      "epoch": 4.8267743020518,
      "grad_norm": 0.30010172724723816,
      "learning_rate": 2.5866368747297104e-05,
      "loss": 0.0001,
      "step": 100450
    },
    {
      "epoch": 4.829176877612801,
      "grad_norm": 0.05636635050177574,
      "learning_rate": 2.5854355869492098e-05,
      "loss": 0.0001,
      "step": 100500
    },
    {
      "epoch": 4.831579453173802,
      "grad_norm": 0.18864214420318604,
      "learning_rate": 2.584234299168709e-05,
      "loss": 0.0002,
      "step": 100550
    },
    {
      "epoch": 4.833982028734804,
      "grad_norm": 0.09722449630498886,
      "learning_rate": 2.5830330113882083e-05,
      "loss": 0.0002,
      "step": 100600
    },
    {
      "epoch": 4.836384604295805,
      "grad_norm": 0.12891042232513428,
      "learning_rate": 2.5818317236077078e-05,
      "loss": 0.0002,
      "step": 100650
    },
    {
      "epoch": 4.838787179856807,
      "grad_norm": 0.3135765492916107,
      "learning_rate": 2.5806304358272072e-05,
      "loss": 0.0001,
      "step": 100700
    },
    {
      "epoch": 4.841189755417808,
      "grad_norm": 0.1241561621427536,
      "learning_rate": 2.5794291480467066e-05,
      "loss": 0.0002,
      "step": 100750
    },
    {
      "epoch": 4.843592330978809,
      "grad_norm": 0.0749506875872612,
      "learning_rate": 2.5782278602662053e-05,
      "loss": 0.0002,
      "step": 100800
    },
    {
      "epoch": 4.8459949065398105,
      "grad_norm": 0.22305835783481598,
      "learning_rate": 2.5770265724857044e-05,
      "loss": 0.0001,
      "step": 100850
    },
    {
      "epoch": 4.848397482100812,
      "grad_norm": 0.33139893412590027,
      "learning_rate": 2.575825284705204e-05,
      "loss": 0.0001,
      "step": 100900
    },
    {
      "epoch": 4.8508000576618135,
      "grad_norm": 0.33617129921913147,
      "learning_rate": 2.5746239969247033e-05,
      "loss": 0.0001,
      "step": 100950
    },
    {
      "epoch": 4.853202633222815,
      "grad_norm": 0.4008544683456421,
      "learning_rate": 2.5734227091442027e-05,
      "loss": 0.0002,
      "step": 101000
    },
    {
      "epoch": 4.855605208783817,
      "grad_norm": 0.14318320155143738,
      "learning_rate": 2.5722214213637018e-05,
      "loss": 0.0001,
      "step": 101050
    },
    {
      "epoch": 4.858007784344817,
      "grad_norm": 0.2034163624048233,
      "learning_rate": 2.5710201335832012e-05,
      "loss": 0.0002,
      "step": 101100
    },
    {
      "epoch": 4.860410359905819,
      "grad_norm": 0.10447554290294647,
      "learning_rate": 2.5698188458027006e-05,
      "loss": 0.0002,
      "step": 101150
    },
    {
      "epoch": 4.86281293546682,
      "grad_norm": 0.33256879448890686,
      "learning_rate": 2.5686175580222e-05,
      "loss": 0.0002,
      "step": 101200
    },
    {
      "epoch": 4.865215511027822,
      "grad_norm": 0.046020153909921646,
      "learning_rate": 2.5674162702416995e-05,
      "loss": 0.0001,
      "step": 101250
    },
    {
      "epoch": 4.8676180865888234,
      "grad_norm": 0.2366521805524826,
      "learning_rate": 2.5662149824611985e-05,
      "loss": 0.0002,
      "step": 101300
    },
    {
      "epoch": 4.870020662149825,
      "grad_norm": 0.3308855891227722,
      "learning_rate": 2.565013694680698e-05,
      "loss": 0.0002,
      "step": 101350
    },
    {
      "epoch": 4.872423237710826,
      "grad_norm": 0.038632214069366455,
      "learning_rate": 2.5638124069001974e-05,
      "loss": 0.0001,
      "step": 101400
    },
    {
      "epoch": 4.874825813271827,
      "grad_norm": 0.02049795724451542,
      "learning_rate": 2.5626111191196968e-05,
      "loss": 0.0005,
      "step": 101450
    },
    {
      "epoch": 4.877228388832829,
      "grad_norm": 0.26185694336891174,
      "learning_rate": 2.561409831339196e-05,
      "loss": 0.0002,
      "step": 101500
    },
    {
      "epoch": 4.87963096439383,
      "grad_norm": 0.07595466822385788,
      "learning_rate": 2.5602085435586946e-05,
      "loss": 0.0001,
      "step": 101550
    },
    {
      "epoch": 4.882033539954832,
      "grad_norm": 0.15642333030700684,
      "learning_rate": 2.559007255778194e-05,
      "loss": 0.0002,
      "step": 101600
    },
    {
      "epoch": 4.884436115515833,
      "grad_norm": 0.37142980098724365,
      "learning_rate": 2.5578059679976935e-05,
      "loss": 0.0001,
      "step": 101650
    },
    {
      "epoch": 4.886838691076834,
      "grad_norm": 0.19331146776676178,
      "learning_rate": 2.556604680217193e-05,
      "loss": 0.0002,
      "step": 101700
    },
    {
      "epoch": 4.8892412666378355,
      "grad_norm": 0.09791188687086105,
      "learning_rate": 2.555403392436692e-05,
      "loss": 0.0001,
      "step": 101750
    },
    {
      "epoch": 4.891643842198837,
      "grad_norm": 0.11742811650037766,
      "learning_rate": 2.5542021046561914e-05,
      "loss": 0.0002,
      "step": 101800
    },
    {
      "epoch": 4.894046417759839,
      "grad_norm": 0.32955342531204224,
      "learning_rate": 2.5530008168756908e-05,
      "loss": 0.0002,
      "step": 101850
    },
    {
      "epoch": 4.89644899332084,
      "grad_norm": 0.0983932614326477,
      "learning_rate": 2.5517995290951902e-05,
      "loss": 0.0001,
      "step": 101900
    },
    {
      "epoch": 4.898851568881842,
      "grad_norm": 0.07071983069181442,
      "learning_rate": 2.5505982413146897e-05,
      "loss": 0.0002,
      "step": 101950
    },
    {
      "epoch": 4.901254144442842,
      "grad_norm": 0.1291760951280594,
      "learning_rate": 2.5493969535341887e-05,
      "loss": 0.0001,
      "step": 102000
    },
    {
      "epoch": 4.903656720003844,
      "grad_norm": 0.3541775941848755,
      "learning_rate": 2.548195665753688e-05,
      "loss": 0.0002,
      "step": 102050
    },
    {
      "epoch": 4.906059295564845,
      "grad_norm": 0.46761554479599,
      "learning_rate": 2.5469943779731876e-05,
      "loss": 0.0001,
      "step": 102100
    },
    {
      "epoch": 4.908461871125847,
      "grad_norm": 0.12430787831544876,
      "learning_rate": 2.545793090192687e-05,
      "loss": 0.0002,
      "step": 102150
    },
    {
      "epoch": 4.9108644466868485,
      "grad_norm": 0.23111285269260406,
      "learning_rate": 2.544591802412186e-05,
      "loss": 0.0002,
      "step": 102200
    },
    {
      "epoch": 4.91326702224785,
      "grad_norm": 0.04923843964934349,
      "learning_rate": 2.5433905146316855e-05,
      "loss": 0.0002,
      "step": 102250
    },
    {
      "epoch": 4.915669597808851,
      "grad_norm": 0.37384065985679626,
      "learning_rate": 2.5421892268511843e-05,
      "loss": 0.0001,
      "step": 102300
    },
    {
      "epoch": 4.918072173369852,
      "grad_norm": 0.1207059994339943,
      "learning_rate": 2.5409879390706837e-05,
      "loss": 0.0001,
      "step": 102350
    },
    {
      "epoch": 4.920474748930854,
      "grad_norm": 0.1532314121723175,
      "learning_rate": 2.539786651290183e-05,
      "loss": 0.0002,
      "step": 102400
    },
    {
      "epoch": 4.922877324491855,
      "grad_norm": 0.29301294684410095,
      "learning_rate": 2.5385853635096825e-05,
      "loss": 0.0002,
      "step": 102450
    },
    {
      "epoch": 4.925279900052857,
      "grad_norm": 0.0792686715722084,
      "learning_rate": 2.5373840757291816e-05,
      "loss": 0.0001,
      "step": 102500
    },
    {
      "epoch": 4.927682475613858,
      "grad_norm": 0.24065536260604858,
      "learning_rate": 2.536182787948681e-05,
      "loss": 0.0006,
      "step": 102550
    },
    {
      "epoch": 4.930085051174859,
      "grad_norm": 0.2623547315597534,
      "learning_rate": 2.5349815001681804e-05,
      "loss": 0.0002,
      "step": 102600
    },
    {
      "epoch": 4.932487626735861,
      "grad_norm": 0.3166196942329407,
      "learning_rate": 2.53378021238768e-05,
      "loss": 0.0002,
      "step": 102650
    },
    {
      "epoch": 4.934890202296862,
      "grad_norm": 0.12006630003452301,
      "learning_rate": 2.532578924607179e-05,
      "loss": 0.0002,
      "step": 102700
    },
    {
      "epoch": 4.937292777857864,
      "grad_norm": 0.2439900040626526,
      "learning_rate": 2.5313776368266784e-05,
      "loss": 0.0002,
      "step": 102750
    },
    {
      "epoch": 4.939695353418865,
      "grad_norm": 0.3513718545436859,
      "learning_rate": 2.5301763490461778e-05,
      "loss": 0.0001,
      "step": 102800
    },
    {
      "epoch": 4.942097928979867,
      "grad_norm": 0.06826572865247726,
      "learning_rate": 2.5289750612656772e-05,
      "loss": 0.0005,
      "step": 102850
    },
    {
      "epoch": 4.944500504540867,
      "grad_norm": 0.4029598832130432,
      "learning_rate": 2.5277737734851763e-05,
      "loss": 0.0002,
      "step": 102900
    },
    {
      "epoch": 4.946903080101869,
      "grad_norm": 0.13224683701992035,
      "learning_rate": 2.5265724857046757e-05,
      "loss": 0.0001,
      "step": 102950
    },
    {
      "epoch": 4.9493056556628705,
      "grad_norm": 0.5494704246520996,
      "learning_rate": 2.525371197924175e-05,
      "loss": 0.0002,
      "step": 103000
    },
    {
      "epoch": 4.951708231223872,
      "grad_norm": 0.11832258105278015,
      "learning_rate": 2.524169910143674e-05,
      "loss": 0.0003,
      "step": 103050
    },
    {
      "epoch": 4.954110806784874,
      "grad_norm": 0.15421976149082184,
      "learning_rate": 2.5229686223631733e-05,
      "loss": 0.0001,
      "step": 103100
    },
    {
      "epoch": 4.956513382345875,
      "grad_norm": 0.18620668351650238,
      "learning_rate": 2.5217673345826727e-05,
      "loss": 0.0005,
      "step": 103150
    },
    {
      "epoch": 4.958915957906877,
      "grad_norm": 0.6241967082023621,
      "learning_rate": 2.5205660468021718e-05,
      "loss": 0.0001,
      "step": 103200
    },
    {
      "epoch": 4.961318533467877,
      "grad_norm": 0.22065496444702148,
      "learning_rate": 2.5193647590216712e-05,
      "loss": 0.0001,
      "step": 103250
    },
    {
      "epoch": 4.963721109028879,
      "grad_norm": 0.11660108715295792,
      "learning_rate": 2.5181634712411706e-05,
      "loss": 0.0002,
      "step": 103300
    },
    {
      "epoch": 4.96612368458988,
      "grad_norm": 0.20855367183685303,
      "learning_rate": 2.51696218346067e-05,
      "loss": 0.0001,
      "step": 103350
    },
    {
      "epoch": 4.968526260150882,
      "grad_norm": 0.3608478009700775,
      "learning_rate": 2.515760895680169e-05,
      "loss": 0.0001,
      "step": 103400
    },
    {
      "epoch": 4.9709288357118835,
      "grad_norm": 0.09255264699459076,
      "learning_rate": 2.5145596078996686e-05,
      "loss": 0.0001,
      "step": 103450
    },
    {
      "epoch": 4.973331411272884,
      "grad_norm": 0.09406261891126633,
      "learning_rate": 2.513358320119168e-05,
      "loss": 0.0003,
      "step": 103500
    },
    {
      "epoch": 4.975733986833886,
      "grad_norm": 0.2075103521347046,
      "learning_rate": 2.5121570323386674e-05,
      "loss": 0.0002,
      "step": 103550
    },
    {
      "epoch": 4.978136562394887,
      "grad_norm": 0.05385075882077217,
      "learning_rate": 2.5109557445581665e-05,
      "loss": 0.0001,
      "step": 103600
    },
    {
      "epoch": 4.980539137955889,
      "grad_norm": 0.09316235035657883,
      "learning_rate": 2.509754456777666e-05,
      "loss": 0.0001,
      "step": 103650
    },
    {
      "epoch": 4.98294171351689,
      "grad_norm": 0.4088209271430969,
      "learning_rate": 2.5085531689971653e-05,
      "loss": 0.0001,
      "step": 103700
    },
    {
      "epoch": 4.985344289077892,
      "grad_norm": 0.11291961371898651,
      "learning_rate": 2.5073518812166648e-05,
      "loss": 0.0002,
      "step": 103750
    },
    {
      "epoch": 4.987746864638893,
      "grad_norm": 0.3986816108226776,
      "learning_rate": 2.5061505934361635e-05,
      "loss": 0.0001,
      "step": 103800
    },
    {
      "epoch": 4.990149440199894,
      "grad_norm": 0.2701566517353058,
      "learning_rate": 2.504949305655663e-05,
      "loss": 0.0001,
      "step": 103850
    },
    {
      "epoch": 4.992552015760896,
      "grad_norm": 0.32197147607803345,
      "learning_rate": 2.503748017875162e-05,
      "loss": 0.0002,
      "step": 103900
    },
    {
      "epoch": 4.994954591321897,
      "grad_norm": 0.1952255815267563,
      "learning_rate": 2.5025467300946614e-05,
      "loss": 0.0002,
      "step": 103950
    },
    {
      "epoch": 4.997357166882899,
      "grad_norm": 0.3735350966453552,
      "learning_rate": 2.501345442314161e-05,
      "loss": 0.0001,
      "step": 104000
    },
    {
      "epoch": 4.9997597424439,
      "grad_norm": 0.11729761958122253,
      "learning_rate": 2.5001441545336603e-05,
      "loss": 0.0002,
      "step": 104050
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.00030977316782809794,
      "eval_runtime": 17.3675,
      "eval_samples_per_second": 546.769,
      "eval_steps_per_second": 68.346,
      "step": 104055
    },
    {
      "epoch": 5.002162318004901,
      "grad_norm": 0.26243630051612854,
      "learning_rate": 2.4989428667531594e-05,
      "loss": 0.0005,
      "step": 104100
    },
    {
      "epoch": 5.004564893565902,
      "grad_norm": 0.15495185554027557,
      "learning_rate": 2.4977415789726588e-05,
      "loss": 0.0001,
      "step": 104150
    },
    {
      "epoch": 5.006967469126904,
      "grad_norm": 0.03626648709177971,
      "learning_rate": 2.4965402911921582e-05,
      "loss": 0.0001,
      "step": 104200
    },
    {
      "epoch": 5.0093700446879055,
      "grad_norm": 0.2611696124076843,
      "learning_rate": 2.4953390034116576e-05,
      "loss": 0.0001,
      "step": 104250
    },
    {
      "epoch": 5.011772620248907,
      "grad_norm": 0.11981803923845291,
      "learning_rate": 2.4941377156311567e-05,
      "loss": 0.0001,
      "step": 104300
    },
    {
      "epoch": 5.014175195809909,
      "grad_norm": 0.3177061080932617,
      "learning_rate": 2.4929364278506558e-05,
      "loss": 0.0002,
      "step": 104350
    },
    {
      "epoch": 5.016577771370909,
      "grad_norm": 0.35040080547332764,
      "learning_rate": 2.4917351400701552e-05,
      "loss": 0.0002,
      "step": 104400
    },
    {
      "epoch": 5.018980346931911,
      "grad_norm": 0.1005650982260704,
      "learning_rate": 2.4905338522896546e-05,
      "loss": 0.0001,
      "step": 104450
    },
    {
      "epoch": 5.021382922492912,
      "grad_norm": 0.2144772857427597,
      "learning_rate": 2.489332564509154e-05,
      "loss": 0.0001,
      "step": 104500
    },
    {
      "epoch": 5.023785498053914,
      "grad_norm": 0.14443552494049072,
      "learning_rate": 2.488131276728653e-05,
      "loss": 0.0001,
      "step": 104550
    },
    {
      "epoch": 5.026188073614915,
      "grad_norm": 0.07109629362821579,
      "learning_rate": 2.4869299889481526e-05,
      "loss": 0.0002,
      "step": 104600
    },
    {
      "epoch": 5.028590649175917,
      "grad_norm": 0.06867312639951706,
      "learning_rate": 2.485728701167652e-05,
      "loss": 0.0001,
      "step": 104650
    },
    {
      "epoch": 5.030993224736918,
      "grad_norm": 0.4094070792198181,
      "learning_rate": 2.4845274133871514e-05,
      "loss": 0.0001,
      "step": 104700
    },
    {
      "epoch": 5.033395800297919,
      "grad_norm": 0.09828026592731476,
      "learning_rate": 2.4833261256066505e-05,
      "loss": 0.0001,
      "step": 104750
    },
    {
      "epoch": 5.035798375858921,
      "grad_norm": 0.10094355046749115,
      "learning_rate": 2.4821248378261496e-05,
      "loss": 0.0001,
      "step": 104800
    },
    {
      "epoch": 5.038200951419922,
      "grad_norm": 0.08986926078796387,
      "learning_rate": 2.480923550045649e-05,
      "loss": 0.0001,
      "step": 104850
    },
    {
      "epoch": 5.040603526980924,
      "grad_norm": 0.06334110349416733,
      "learning_rate": 2.4797222622651484e-05,
      "loss": 0.0002,
      "step": 104900
    },
    {
      "epoch": 5.043006102541925,
      "grad_norm": 0.10587102919816971,
      "learning_rate": 2.4785209744846478e-05,
      "loss": 0.0002,
      "step": 104950
    },
    {
      "epoch": 5.045408678102926,
      "grad_norm": 0.39634472131729126,
      "learning_rate": 2.477319686704147e-05,
      "loss": 0.0004,
      "step": 105000
    },
    {
      "epoch": 5.0478112536639275,
      "grad_norm": 0.33933210372924805,
      "learning_rate": 2.4761183989236463e-05,
      "loss": 0.0002,
      "step": 105050
    },
    {
      "epoch": 5.050213829224929,
      "grad_norm": 0.42293307185173035,
      "learning_rate": 2.4749171111431454e-05,
      "loss": 0.0001,
      "step": 105100
    },
    {
      "epoch": 5.0526164047859305,
      "grad_norm": 0.11140573024749756,
      "learning_rate": 2.4737158233626448e-05,
      "loss": 0.0001,
      "step": 105150
    },
    {
      "epoch": 5.055018980346932,
      "grad_norm": 0.36820971965789795,
      "learning_rate": 2.4725145355821443e-05,
      "loss": 0.0001,
      "step": 105200
    },
    {
      "epoch": 5.057421555907934,
      "grad_norm": 0.1818459928035736,
      "learning_rate": 2.4713132478016433e-05,
      "loss": 0.0001,
      "step": 105250
    },
    {
      "epoch": 5.059824131468934,
      "grad_norm": 0.40817776322364807,
      "learning_rate": 2.4701119600211428e-05,
      "loss": 0.0006,
      "step": 105300
    },
    {
      "epoch": 5.062226707029936,
      "grad_norm": 0.11705634742975235,
      "learning_rate": 2.4689106722406422e-05,
      "loss": 0.0002,
      "step": 105350
    },
    {
      "epoch": 5.064629282590937,
      "grad_norm": 0.5973635315895081,
      "learning_rate": 2.4677093844601416e-05,
      "loss": 0.0002,
      "step": 105400
    },
    {
      "epoch": 5.067031858151939,
      "grad_norm": 0.16924892365932465,
      "learning_rate": 2.4665080966796407e-05,
      "loss": 0.0001,
      "step": 105450
    },
    {
      "epoch": 5.0694344337129404,
      "grad_norm": 0.1190810576081276,
      "learning_rate": 2.4653068088991398e-05,
      "loss": 0.0001,
      "step": 105500
    },
    {
      "epoch": 5.071837009273942,
      "grad_norm": 0.09158556908369064,
      "learning_rate": 2.4641055211186392e-05,
      "loss": 0.0001,
      "step": 105550
    },
    {
      "epoch": 5.074239584834943,
      "grad_norm": 0.12824252247810364,
      "learning_rate": 2.4629042333381386e-05,
      "loss": 0.0002,
      "step": 105600
    },
    {
      "epoch": 5.076642160395944,
      "grad_norm": 0.12081530690193176,
      "learning_rate": 2.461702945557638e-05,
      "loss": 0.0001,
      "step": 105650
    },
    {
      "epoch": 5.079044735956946,
      "grad_norm": 0.22971859574317932,
      "learning_rate": 2.460501657777137e-05,
      "loss": 0.0002,
      "step": 105700
    },
    {
      "epoch": 5.081447311517947,
      "grad_norm": 0.3189726173877716,
      "learning_rate": 2.4593003699966365e-05,
      "loss": 0.0002,
      "step": 105750
    },
    {
      "epoch": 5.083849887078949,
      "grad_norm": 0.2848525047302246,
      "learning_rate": 2.458099082216136e-05,
      "loss": 0.0001,
      "step": 105800
    },
    {
      "epoch": 5.08625246263995,
      "grad_norm": 0.21882300078868866,
      "learning_rate": 2.456897794435635e-05,
      "loss": 0.0002,
      "step": 105850
    },
    {
      "epoch": 5.088655038200951,
      "grad_norm": 0.25362440943717957,
      "learning_rate": 2.4556965066551345e-05,
      "loss": 0.0004,
      "step": 105900
    },
    {
      "epoch": 5.0910576137619525,
      "grad_norm": 0.498836874961853,
      "learning_rate": 2.4544952188746335e-05,
      "loss": 0.0001,
      "step": 105950
    },
    {
      "epoch": 5.093460189322954,
      "grad_norm": 0.1657494157552719,
      "learning_rate": 2.453293931094133e-05,
      "loss": 0.0001,
      "step": 106000
    },
    {
      "epoch": 5.095862764883956,
      "grad_norm": 0.40256181359291077,
      "learning_rate": 2.4520926433136324e-05,
      "loss": 0.0002,
      "step": 106050
    },
    {
      "epoch": 5.098265340444957,
      "grad_norm": 0.08060427010059357,
      "learning_rate": 2.4508913555331318e-05,
      "loss": 0.0001,
      "step": 106100
    },
    {
      "epoch": 5.100667916005959,
      "grad_norm": 0.24778085947036743,
      "learning_rate": 2.449690067752631e-05,
      "loss": 0.0002,
      "step": 106150
    },
    {
      "epoch": 5.103070491566959,
      "grad_norm": 0.1198396310210228,
      "learning_rate": 2.44848877997213e-05,
      "loss": 0.0001,
      "step": 106200
    },
    {
      "epoch": 5.105473067127961,
      "grad_norm": 0.06271746009588242,
      "learning_rate": 2.4472874921916294e-05,
      "loss": 0.0001,
      "step": 106250
    },
    {
      "epoch": 5.107875642688962,
      "grad_norm": 0.2090759575366974,
      "learning_rate": 2.4460862044111288e-05,
      "loss": 0.0002,
      "step": 106300
    },
    {
      "epoch": 5.110278218249964,
      "grad_norm": 0.0599956177175045,
      "learning_rate": 2.4448849166306282e-05,
      "loss": 0.0001,
      "step": 106350
    },
    {
      "epoch": 5.1126807938109655,
      "grad_norm": 0.06074850633740425,
      "learning_rate": 2.4436836288501273e-05,
      "loss": 0.0001,
      "step": 106400
    },
    {
      "epoch": 5.115083369371967,
      "grad_norm": 0.4920526444911957,
      "learning_rate": 2.4424823410696267e-05,
      "loss": 0.0002,
      "step": 106450
    },
    {
      "epoch": 5.117485944932968,
      "grad_norm": 0.3149243891239166,
      "learning_rate": 2.441281053289126e-05,
      "loss": 0.0002,
      "step": 106500
    },
    {
      "epoch": 5.119888520493969,
      "grad_norm": 0.37419748306274414,
      "learning_rate": 2.4400797655086256e-05,
      "loss": 0.0002,
      "step": 106550
    },
    {
      "epoch": 5.122291096054971,
      "grad_norm": 0.3563491404056549,
      "learning_rate": 2.4388784777281247e-05,
      "loss": 0.0002,
      "step": 106600
    },
    {
      "epoch": 5.124693671615972,
      "grad_norm": 0.2066400945186615,
      "learning_rate": 2.4376771899476237e-05,
      "loss": 0.0001,
      "step": 106650
    },
    {
      "epoch": 5.127096247176974,
      "grad_norm": 0.05231732130050659,
      "learning_rate": 2.436475902167123e-05,
      "loss": 0.0001,
      "step": 106700
    },
    {
      "epoch": 5.129498822737975,
      "grad_norm": 0.026688676327466965,
      "learning_rate": 2.4352746143866226e-05,
      "loss": 0.0001,
      "step": 106750
    },
    {
      "epoch": 5.131901398298977,
      "grad_norm": 0.49982747435569763,
      "learning_rate": 2.434073326606122e-05,
      "loss": 0.0002,
      "step": 106800
    },
    {
      "epoch": 5.134303973859978,
      "grad_norm": 0.37725576758384705,
      "learning_rate": 2.432872038825621e-05,
      "loss": 0.0006,
      "step": 106850
    },
    {
      "epoch": 5.136706549420979,
      "grad_norm": 0.05418090522289276,
      "learning_rate": 2.4316707510451205e-05,
      "loss": 0.0002,
      "step": 106900
    },
    {
      "epoch": 5.139109124981981,
      "grad_norm": 0.2929403483867645,
      "learning_rate": 2.4304694632646196e-05,
      "loss": 0.0001,
      "step": 106950
    },
    {
      "epoch": 5.141511700542982,
      "grad_norm": 0.25468572974205017,
      "learning_rate": 2.429268175484119e-05,
      "loss": 0.0002,
      "step": 107000
    },
    {
      "epoch": 5.143914276103984,
      "grad_norm": 0.4146451950073242,
      "learning_rate": 2.4280668877036184e-05,
      "loss": 0.0001,
      "step": 107050
    },
    {
      "epoch": 5.146316851664984,
      "grad_norm": 0.0738300308585167,
      "learning_rate": 2.4268655999231175e-05,
      "loss": 0.0001,
      "step": 107100
    },
    {
      "epoch": 5.148719427225986,
      "grad_norm": 0.1367557793855667,
      "learning_rate": 2.425664312142617e-05,
      "loss": 0.0001,
      "step": 107150
    },
    {
      "epoch": 5.1511220027869875,
      "grad_norm": 0.27332380414009094,
      "learning_rate": 2.4244630243621164e-05,
      "loss": 0.0001,
      "step": 107200
    },
    {
      "epoch": 5.153524578347989,
      "grad_norm": 0.3408849239349365,
      "learning_rate": 2.4232617365816158e-05,
      "loss": 0.0001,
      "step": 107250
    },
    {
      "epoch": 5.155927153908991,
      "grad_norm": 0.31689760088920593,
      "learning_rate": 2.4220604488011152e-05,
      "loss": 0.0001,
      "step": 107300
    },
    {
      "epoch": 5.158329729469992,
      "grad_norm": 0.10469261556863785,
      "learning_rate": 2.420859161020614e-05,
      "loss": 0.0006,
      "step": 107350
    },
    {
      "epoch": 5.160732305030994,
      "grad_norm": 0.22511854767799377,
      "learning_rate": 2.4196578732401134e-05,
      "loss": 0.0009,
      "step": 107400
    },
    {
      "epoch": 5.163134880591994,
      "grad_norm": 0.17907840013504028,
      "learning_rate": 2.4184565854596128e-05,
      "loss": 0.0002,
      "step": 107450
    },
    {
      "epoch": 5.165537456152996,
      "grad_norm": 0.17321139574050903,
      "learning_rate": 2.4172552976791122e-05,
      "loss": 0.0002,
      "step": 107500
    },
    {
      "epoch": 5.167940031713997,
      "grad_norm": 0.15890361368656158,
      "learning_rate": 2.4160540098986116e-05,
      "loss": 0.0002,
      "step": 107550
    },
    {
      "epoch": 5.170342607274999,
      "grad_norm": 0.09677070379257202,
      "learning_rate": 2.4148527221181107e-05,
      "loss": 0.0001,
      "step": 107600
    },
    {
      "epoch": 5.1727451828360005,
      "grad_norm": 0.04219954088330269,
      "learning_rate": 2.41365143433761e-05,
      "loss": 0.0001,
      "step": 107650
    },
    {
      "epoch": 5.175147758397001,
      "grad_norm": 0.2198457568883896,
      "learning_rate": 2.4124501465571092e-05,
      "loss": 0.0001,
      "step": 107700
    },
    {
      "epoch": 5.177550333958003,
      "grad_norm": 0.1655329167842865,
      "learning_rate": 2.4112488587766086e-05,
      "loss": 0.0002,
      "step": 107750
    },
    {
      "epoch": 5.179952909519004,
      "grad_norm": 0.37051939964294434,
      "learning_rate": 2.410047570996108e-05,
      "loss": 0.0002,
      "step": 107800
    },
    {
      "epoch": 5.182355485080006,
      "grad_norm": 0.09479121118783951,
      "learning_rate": 2.408846283215607e-05,
      "loss": 0.0001,
      "step": 107850
    },
    {
      "epoch": 5.184758060641007,
      "grad_norm": 0.3949718773365021,
      "learning_rate": 2.4076449954351066e-05,
      "loss": 0.0002,
      "step": 107900
    },
    {
      "epoch": 5.187160636202009,
      "grad_norm": 0.09325015544891357,
      "learning_rate": 2.406443707654606e-05,
      "loss": 0.0001,
      "step": 107950
    },
    {
      "epoch": 5.18956321176301,
      "grad_norm": 0.1354554444551468,
      "learning_rate": 2.4052424198741054e-05,
      "loss": 0.0002,
      "step": 108000
    },
    {
      "epoch": 5.191965787324011,
      "grad_norm": 1.0245442390441895,
      "learning_rate": 2.4040411320936045e-05,
      "loss": 0.0002,
      "step": 108050
    },
    {
      "epoch": 5.194368362885013,
      "grad_norm": 0.10842530429363251,
      "learning_rate": 2.4028398443131036e-05,
      "loss": 0.0005,
      "step": 108100
    },
    {
      "epoch": 5.196770938446014,
      "grad_norm": 0.06245812028646469,
      "learning_rate": 2.401638556532603e-05,
      "loss": 0.0002,
      "step": 108150
    },
    {
      "epoch": 5.199173514007016,
      "grad_norm": 0.25446704030036926,
      "learning_rate": 2.4004372687521024e-05,
      "loss": 0.0002,
      "step": 108200
    },
    {
      "epoch": 5.201576089568017,
      "grad_norm": 0.15132558345794678,
      "learning_rate": 2.399235980971602e-05,
      "loss": 0.0002,
      "step": 108250
    },
    {
      "epoch": 5.203978665129018,
      "grad_norm": 0.11135358363389969,
      "learning_rate": 2.398034693191101e-05,
      "loss": 0.0001,
      "step": 108300
    },
    {
      "epoch": 5.206381240690019,
      "grad_norm": 0.31954488158226013,
      "learning_rate": 2.3968334054106003e-05,
      "loss": 0.0001,
      "step": 108350
    },
    {
      "epoch": 5.208783816251021,
      "grad_norm": 0.2967548370361328,
      "learning_rate": 2.3956321176300998e-05,
      "loss": 0.0002,
      "step": 108400
    },
    {
      "epoch": 5.2111863918120225,
      "grad_norm": 0.08192302286624908,
      "learning_rate": 2.394430829849599e-05,
      "loss": 0.0002,
      "step": 108450
    },
    {
      "epoch": 5.213588967373024,
      "grad_norm": 0.47441038489341736,
      "learning_rate": 2.3932295420690983e-05,
      "loss": 0.0001,
      "step": 108500
    },
    {
      "epoch": 5.215991542934026,
      "grad_norm": 0.1399075984954834,
      "learning_rate": 2.3920282542885973e-05,
      "loss": 0.0001,
      "step": 108550
    },
    {
      "epoch": 5.218394118495027,
      "grad_norm": 0.41534891724586487,
      "learning_rate": 2.3908269665080968e-05,
      "loss": 0.0001,
      "step": 108600
    },
    {
      "epoch": 5.220796694056028,
      "grad_norm": 0.10643136501312256,
      "learning_rate": 2.3896256787275962e-05,
      "loss": 0.0006,
      "step": 108650
    },
    {
      "epoch": 5.223199269617029,
      "grad_norm": 0.06871823966503143,
      "learning_rate": 2.3884243909470956e-05,
      "loss": 0.0001,
      "step": 108700
    },
    {
      "epoch": 5.225601845178031,
      "grad_norm": 0.4158387780189514,
      "learning_rate": 2.3872231031665947e-05,
      "loss": 0.0001,
      "step": 108750
    },
    {
      "epoch": 5.228004420739032,
      "grad_norm": 0.29980215430259705,
      "learning_rate": 2.3860218153860938e-05,
      "loss": 0.0001,
      "step": 108800
    },
    {
      "epoch": 5.230406996300034,
      "grad_norm": 0.1172860711812973,
      "learning_rate": 2.3848205276055932e-05,
      "loss": 0.0001,
      "step": 108850
    },
    {
      "epoch": 5.2328095718610355,
      "grad_norm": 0.29728320240974426,
      "learning_rate": 2.3836192398250926e-05,
      "loss": 0.0001,
      "step": 108900
    },
    {
      "epoch": 5.235212147422036,
      "grad_norm": 0.023882202804088593,
      "learning_rate": 2.382417952044592e-05,
      "loss": 0.0002,
      "step": 108950
    },
    {
      "epoch": 5.237614722983038,
      "grad_norm": 0.3141506612300873,
      "learning_rate": 2.381216664264091e-05,
      "loss": 0.0002,
      "step": 109000
    },
    {
      "epoch": 5.240017298544039,
      "grad_norm": 0.29308319091796875,
      "learning_rate": 2.3800153764835905e-05,
      "loss": 0.0002,
      "step": 109050
    },
    {
      "epoch": 5.242419874105041,
      "grad_norm": 0.09955257922410965,
      "learning_rate": 2.37881408870309e-05,
      "loss": 0.0001,
      "step": 109100
    },
    {
      "epoch": 5.244822449666042,
      "grad_norm": 0.38102641701698303,
      "learning_rate": 2.3776128009225894e-05,
      "loss": 0.0002,
      "step": 109150
    },
    {
      "epoch": 5.247225025227044,
      "grad_norm": 0.23847822844982147,
      "learning_rate": 2.3764115131420885e-05,
      "loss": 0.0007,
      "step": 109200
    },
    {
      "epoch": 5.2496276007880445,
      "grad_norm": 0.1206773966550827,
      "learning_rate": 2.3752102253615876e-05,
      "loss": 0.0006,
      "step": 109250
    },
    {
      "epoch": 5.252030176349046,
      "grad_norm": 0.31791478395462036,
      "learning_rate": 2.374008937581087e-05,
      "loss": 0.0002,
      "step": 109300
    },
    {
      "epoch": 5.2544327519100475,
      "grad_norm": 0.035957951098680496,
      "learning_rate": 2.3728076498005864e-05,
      "loss": 0.0001,
      "step": 109350
    },
    {
      "epoch": 5.256835327471049,
      "grad_norm": 0.239891916513443,
      "learning_rate": 2.3716063620200858e-05,
      "loss": 0.0002,
      "step": 109400
    },
    {
      "epoch": 5.259237903032051,
      "grad_norm": 0.35205405950546265,
      "learning_rate": 2.370405074239585e-05,
      "loss": 0.0002,
      "step": 109450
    },
    {
      "epoch": 5.261640478593051,
      "grad_norm": 0.11149128526449203,
      "learning_rate": 2.3692037864590843e-05,
      "loss": 0.0002,
      "step": 109500
    },
    {
      "epoch": 5.264043054154053,
      "grad_norm": 0.4478086233139038,
      "learning_rate": 2.3680024986785834e-05,
      "loss": 0.0002,
      "step": 109550
    },
    {
      "epoch": 5.266445629715054,
      "grad_norm": 0.45434826612472534,
      "learning_rate": 2.3668012108980828e-05,
      "loss": 0.0001,
      "step": 109600
    },
    {
      "epoch": 5.268848205276056,
      "grad_norm": 0.08245004713535309,
      "learning_rate": 2.3655999231175822e-05,
      "loss": 0.0002,
      "step": 109650
    },
    {
      "epoch": 5.2712507808370574,
      "grad_norm": 0.5032276511192322,
      "learning_rate": 2.3643986353370813e-05,
      "loss": 0.0001,
      "step": 109700
    },
    {
      "epoch": 5.273653356398059,
      "grad_norm": 0.2604198753833771,
      "learning_rate": 2.3631973475565808e-05,
      "loss": 0.0002,
      "step": 109750
    },
    {
      "epoch": 5.2760559319590605,
      "grad_norm": 0.1635802686214447,
      "learning_rate": 2.3619960597760802e-05,
      "loss": 0.0001,
      "step": 109800
    },
    {
      "epoch": 5.278458507520061,
      "grad_norm": 0.09931810200214386,
      "learning_rate": 2.3607947719955796e-05,
      "loss": 0.0001,
      "step": 109850
    },
    {
      "epoch": 5.280861083081063,
      "grad_norm": 0.1884315460920334,
      "learning_rate": 2.3595934842150787e-05,
      "loss": 0.0001,
      "step": 109900
    },
    {
      "epoch": 5.283263658642064,
      "grad_norm": 0.36938655376434326,
      "learning_rate": 2.3583921964345778e-05,
      "loss": 0.0001,
      "step": 109950
    },
    {
      "epoch": 5.285666234203066,
      "grad_norm": 0.1959337592124939,
      "learning_rate": 2.3571909086540772e-05,
      "loss": 0.0001,
      "step": 110000
    },
    {
      "epoch": 5.288068809764067,
      "grad_norm": 0.08150425553321838,
      "learning_rate": 2.3559896208735766e-05,
      "loss": 0.0001,
      "step": 110050
    },
    {
      "epoch": 5.290471385325069,
      "grad_norm": 0.12581892311573029,
      "learning_rate": 2.354788333093076e-05,
      "loss": 0.0001,
      "step": 110100
    },
    {
      "epoch": 5.2928739608860695,
      "grad_norm": 0.1691340059041977,
      "learning_rate": 2.353587045312575e-05,
      "loss": 0.0005,
      "step": 110150
    },
    {
      "epoch": 5.295276536447071,
      "grad_norm": 0.3213709890842438,
      "learning_rate": 2.3523857575320745e-05,
      "loss": 0.0002,
      "step": 110200
    },
    {
      "epoch": 5.297679112008073,
      "grad_norm": 0.3925301730632782,
      "learning_rate": 2.351184469751574e-05,
      "loss": 0.0001,
      "step": 110250
    },
    {
      "epoch": 5.300081687569074,
      "grad_norm": 0.28223952651023865,
      "learning_rate": 2.349983181971073e-05,
      "loss": 0.0001,
      "step": 110300
    },
    {
      "epoch": 5.302484263130076,
      "grad_norm": 0.22354519367218018,
      "learning_rate": 2.3487818941905725e-05,
      "loss": 0.0001,
      "step": 110350
    },
    {
      "epoch": 5.304886838691077,
      "grad_norm": 0.22175781428813934,
      "learning_rate": 2.3475806064100715e-05,
      "loss": 0.0001,
      "step": 110400
    },
    {
      "epoch": 5.307289414252078,
      "grad_norm": 0.3274158835411072,
      "learning_rate": 2.346379318629571e-05,
      "loss": 0.0001,
      "step": 110450
    },
    {
      "epoch": 5.309691989813079,
      "grad_norm": 0.1802075356245041,
      "learning_rate": 2.3451780308490704e-05,
      "loss": 0.0002,
      "step": 110500
    },
    {
      "epoch": 5.312094565374081,
      "grad_norm": 0.1224777027964592,
      "learning_rate": 2.3439767430685698e-05,
      "loss": 0.0001,
      "step": 110550
    },
    {
      "epoch": 5.3144971409350825,
      "grad_norm": 0.4517495036125183,
      "learning_rate": 2.342775455288069e-05,
      "loss": 0.0001,
      "step": 110600
    },
    {
      "epoch": 5.316899716496084,
      "grad_norm": 0.5330748558044434,
      "learning_rate": 2.3415741675075683e-05,
      "loss": 0.0001,
      "step": 110650
    },
    {
      "epoch": 5.319302292057086,
      "grad_norm": 0.10451167821884155,
      "learning_rate": 2.3403728797270674e-05,
      "loss": 0.0005,
      "step": 110700
    },
    {
      "epoch": 5.321704867618086,
      "grad_norm": 0.46532610058784485,
      "learning_rate": 2.3391715919465668e-05,
      "loss": 0.0001,
      "step": 110750
    },
    {
      "epoch": 5.324107443179088,
      "grad_norm": 0.2050158679485321,
      "learning_rate": 2.3379703041660662e-05,
      "loss": 0.0001,
      "step": 110800
    },
    {
      "epoch": 5.326510018740089,
      "grad_norm": 0.021946078166365623,
      "learning_rate": 2.3367690163855653e-05,
      "loss": 0.0001,
      "step": 110850
    },
    {
      "epoch": 5.328912594301091,
      "grad_norm": 0.32238176465034485,
      "learning_rate": 2.3355677286050647e-05,
      "loss": 0.0002,
      "step": 110900
    },
    {
      "epoch": 5.331315169862092,
      "grad_norm": 0.2372078001499176,
      "learning_rate": 2.334366440824564e-05,
      "loss": 0.0005,
      "step": 110950
    },
    {
      "epoch": 5.333717745423094,
      "grad_norm": 0.2245142161846161,
      "learning_rate": 2.3331651530440636e-05,
      "loss": 0.0001,
      "step": 111000
    },
    {
      "epoch": 5.336120320984095,
      "grad_norm": 0.20434503257274628,
      "learning_rate": 2.3319638652635627e-05,
      "loss": 0.0001,
      "step": 111050
    },
    {
      "epoch": 5.338522896545096,
      "grad_norm": 0.1461966633796692,
      "learning_rate": 2.3307625774830617e-05,
      "loss": 0.0001,
      "step": 111100
    },
    {
      "epoch": 5.340925472106098,
      "grad_norm": 0.16361624002456665,
      "learning_rate": 2.329561289702561e-05,
      "loss": 0.0001,
      "step": 111150
    },
    {
      "epoch": 5.343328047667099,
      "grad_norm": 0.29067814350128174,
      "learning_rate": 2.3283600019220606e-05,
      "loss": 0.0001,
      "step": 111200
    },
    {
      "epoch": 5.345730623228101,
      "grad_norm": 0.020121993497014046,
      "learning_rate": 2.32715871414156e-05,
      "loss": 0.0001,
      "step": 111250
    },
    {
      "epoch": 5.348133198789102,
      "grad_norm": 0.4231642484664917,
      "learning_rate": 2.325957426361059e-05,
      "loss": 0.0002,
      "step": 111300
    },
    {
      "epoch": 5.350535774350103,
      "grad_norm": 0.04353545978665352,
      "learning_rate": 2.3247561385805585e-05,
      "loss": 0.0001,
      "step": 111350
    },
    {
      "epoch": 5.3529383499111045,
      "grad_norm": 0.10550845414400101,
      "learning_rate": 2.3235548508000576e-05,
      "loss": 0.0001,
      "step": 111400
    },
    {
      "epoch": 5.355340925472106,
      "grad_norm": 0.126661479473114,
      "learning_rate": 2.322353563019557e-05,
      "loss": 0.0001,
      "step": 111450
    },
    {
      "epoch": 5.357743501033108,
      "grad_norm": 0.15795353055000305,
      "learning_rate": 2.3211522752390564e-05,
      "loss": 0.0003,
      "step": 111500
    },
    {
      "epoch": 5.360146076594109,
      "grad_norm": 0.49763980507850647,
      "learning_rate": 2.3199509874585555e-05,
      "loss": 0.0001,
      "step": 111550
    },
    {
      "epoch": 5.362548652155111,
      "grad_norm": 0.1810770481824875,
      "learning_rate": 2.318749699678055e-05,
      "loss": 0.0001,
      "step": 111600
    },
    {
      "epoch": 5.364951227716111,
      "grad_norm": 0.20453187823295593,
      "learning_rate": 2.3175484118975544e-05,
      "loss": 0.0004,
      "step": 111650
    },
    {
      "epoch": 5.367353803277113,
      "grad_norm": 0.13462822139263153,
      "learning_rate": 2.3163471241170538e-05,
      "loss": 0.0001,
      "step": 111700
    },
    {
      "epoch": 5.369756378838114,
      "grad_norm": 0.3793981373310089,
      "learning_rate": 2.315145836336553e-05,
      "loss": 0.0001,
      "step": 111750
    },
    {
      "epoch": 5.372158954399116,
      "grad_norm": 0.19730259478092194,
      "learning_rate": 2.313944548556052e-05,
      "loss": 0.0001,
      "step": 111800
    },
    {
      "epoch": 5.3745615299601175,
      "grad_norm": 0.2629925012588501,
      "learning_rate": 2.3127432607755514e-05,
      "loss": 0.0002,
      "step": 111850
    },
    {
      "epoch": 5.376964105521119,
      "grad_norm": 0.28677311539649963,
      "learning_rate": 2.3115419729950508e-05,
      "loss": 0.0002,
      "step": 111900
    },
    {
      "epoch": 5.37936668108212,
      "grad_norm": 0.4306570291519165,
      "learning_rate": 2.3103406852145502e-05,
      "loss": 0.0001,
      "step": 111950
    },
    {
      "epoch": 5.381769256643121,
      "grad_norm": 0.1607716977596283,
      "learning_rate": 2.3091393974340493e-05,
      "loss": 0.0001,
      "step": 112000
    },
    {
      "epoch": 5.384171832204123,
      "grad_norm": 0.1436566859483719,
      "learning_rate": 2.3079381096535487e-05,
      "loss": 0.0001,
      "step": 112050
    },
    {
      "epoch": 5.386574407765124,
      "grad_norm": 0.27226385474205017,
      "learning_rate": 2.306736821873048e-05,
      "loss": 0.0001,
      "step": 112100
    },
    {
      "epoch": 5.388976983326126,
      "grad_norm": 0.25623396039009094,
      "learning_rate": 2.3055355340925472e-05,
      "loss": 0.0002,
      "step": 112150
    },
    {
      "epoch": 5.391379558887127,
      "grad_norm": 0.30791082978248596,
      "learning_rate": 2.3043342463120466e-05,
      "loss": 0.0001,
      "step": 112200
    },
    {
      "epoch": 5.393782134448128,
      "grad_norm": 0.19168677926063538,
      "learning_rate": 2.3031329585315457e-05,
      "loss": 0.0001,
      "step": 112250
    },
    {
      "epoch": 5.39618471000913,
      "grad_norm": 0.08167587220668793,
      "learning_rate": 2.301931670751045e-05,
      "loss": 0.0002,
      "step": 112300
    },
    {
      "epoch": 5.398587285570131,
      "grad_norm": 0.132297083735466,
      "learning_rate": 2.3007303829705446e-05,
      "loss": 0.0001,
      "step": 112350
    },
    {
      "epoch": 5.400989861131133,
      "grad_norm": 0.11548572033643723,
      "learning_rate": 2.299529095190044e-05,
      "loss": 0.0005,
      "step": 112400
    },
    {
      "epoch": 5.403392436692134,
      "grad_norm": 0.3690628409385681,
      "learning_rate": 2.298327807409543e-05,
      "loss": 0.0002,
      "step": 112450
    },
    {
      "epoch": 5.405795012253136,
      "grad_norm": 0.10019350051879883,
      "learning_rate": 2.2971265196290425e-05,
      "loss": 0.0001,
      "step": 112500
    },
    {
      "epoch": 5.408197587814136,
      "grad_norm": 0.15439379215240479,
      "learning_rate": 2.2959252318485416e-05,
      "loss": 0.0001,
      "step": 112550
    },
    {
      "epoch": 5.410600163375138,
      "grad_norm": 0.30535373091697693,
      "learning_rate": 2.294723944068041e-05,
      "loss": 0.0006,
      "step": 112600
    },
    {
      "epoch": 5.4130027389361395,
      "grad_norm": 0.15825380384922028,
      "learning_rate": 2.2935226562875404e-05,
      "loss": 0.0001,
      "step": 112650
    },
    {
      "epoch": 5.415405314497141,
      "grad_norm": 0.0866541862487793,
      "learning_rate": 2.2923213685070395e-05,
      "loss": 0.0001,
      "step": 112700
    },
    {
      "epoch": 5.417807890058143,
      "grad_norm": 0.54145348072052,
      "learning_rate": 2.291120080726539e-05,
      "loss": 0.0002,
      "step": 112750
    },
    {
      "epoch": 5.420210465619144,
      "grad_norm": 0.11450867354869843,
      "learning_rate": 2.2899187929460383e-05,
      "loss": 0.0002,
      "step": 112800
    },
    {
      "epoch": 5.422613041180145,
      "grad_norm": 0.7082805633544922,
      "learning_rate": 2.2887175051655378e-05,
      "loss": 0.0001,
      "step": 112850
    },
    {
      "epoch": 5.425015616741146,
      "grad_norm": 0.17147834599018097,
      "learning_rate": 2.287516217385037e-05,
      "loss": 0.0001,
      "step": 112900
    },
    {
      "epoch": 5.427418192302148,
      "grad_norm": 0.07642768323421478,
      "learning_rate": 2.286314929604536e-05,
      "loss": 0.0001,
      "step": 112950
    },
    {
      "epoch": 5.429820767863149,
      "grad_norm": 0.08722112327814102,
      "learning_rate": 2.2851136418240353e-05,
      "loss": 0.0001,
      "step": 113000
    },
    {
      "epoch": 5.432223343424151,
      "grad_norm": 0.03982796519994736,
      "learning_rate": 2.2839123540435348e-05,
      "loss": 0.0001,
      "step": 113050
    },
    {
      "epoch": 5.4346259189851525,
      "grad_norm": 0.05509813874959946,
      "learning_rate": 2.2827110662630342e-05,
      "loss": 0.0001,
      "step": 113100
    },
    {
      "epoch": 5.437028494546153,
      "grad_norm": 0.19099505245685577,
      "learning_rate": 2.2815097784825336e-05,
      "loss": 0.0001,
      "step": 113150
    },
    {
      "epoch": 5.439431070107155,
      "grad_norm": 0.11292922496795654,
      "learning_rate": 2.2803084907020327e-05,
      "loss": 0.0001,
      "step": 113200
    },
    {
      "epoch": 5.441833645668156,
      "grad_norm": 0.15323825180530548,
      "learning_rate": 2.279107202921532e-05,
      "loss": 0.0002,
      "step": 113250
    },
    {
      "epoch": 5.444236221229158,
      "grad_norm": 0.0936354324221611,
      "learning_rate": 2.2779059151410312e-05,
      "loss": 0.0001,
      "step": 113300
    },
    {
      "epoch": 5.446638796790159,
      "grad_norm": 0.41530364751815796,
      "learning_rate": 2.2767046273605306e-05,
      "loss": 0.0001,
      "step": 113350
    },
    {
      "epoch": 5.449041372351161,
      "grad_norm": 0.22725047171115875,
      "learning_rate": 2.2755033395800297e-05,
      "loss": 0.0001,
      "step": 113400
    },
    {
      "epoch": 5.4514439479121615,
      "grad_norm": 0.24253232777118683,
      "learning_rate": 2.274302051799529e-05,
      "loss": 0.0001,
      "step": 113450
    },
    {
      "epoch": 5.453846523473163,
      "grad_norm": 0.04649980366230011,
      "learning_rate": 2.2731007640190285e-05,
      "loss": 0.0001,
      "step": 113500
    },
    {
      "epoch": 5.4562490990341646,
      "grad_norm": 0.07555899769067764,
      "learning_rate": 2.271899476238528e-05,
      "loss": 0.0005,
      "step": 113550
    },
    {
      "epoch": 5.458651674595166,
      "grad_norm": 0.34512221813201904,
      "learning_rate": 2.2706981884580274e-05,
      "loss": 0.0001,
      "step": 113600
    },
    {
      "epoch": 5.461054250156168,
      "grad_norm": 0.12273692339658737,
      "learning_rate": 2.269496900677526e-05,
      "loss": 0.0001,
      "step": 113650
    },
    {
      "epoch": 5.463456825717169,
      "grad_norm": 0.1277652531862259,
      "learning_rate": 2.2682956128970256e-05,
      "loss": 0.0001,
      "step": 113700
    },
    {
      "epoch": 5.46585940127817,
      "grad_norm": 0.29348763823509216,
      "learning_rate": 2.267094325116525e-05,
      "loss": 0.0001,
      "step": 113750
    },
    {
      "epoch": 5.468261976839171,
      "grad_norm": 0.20710742473602295,
      "learning_rate": 2.2658930373360244e-05,
      "loss": 0.0001,
      "step": 113800
    },
    {
      "epoch": 5.470664552400173,
      "grad_norm": 0.14225967228412628,
      "learning_rate": 2.2646917495555238e-05,
      "loss": 0.0001,
      "step": 113850
    },
    {
      "epoch": 5.4730671279611744,
      "grad_norm": 0.05117889866232872,
      "learning_rate": 2.263490461775023e-05,
      "loss": 0.0001,
      "step": 113900
    },
    {
      "epoch": 5.475469703522176,
      "grad_norm": 0.266744464635849,
      "learning_rate": 2.2622891739945223e-05,
      "loss": 0.0001,
      "step": 113950
    },
    {
      "epoch": 5.4778722790831775,
      "grad_norm": 0.18527759611606598,
      "learning_rate": 2.2610878862140217e-05,
      "loss": 0.0001,
      "step": 114000
    },
    {
      "epoch": 5.480274854644178,
      "grad_norm": 0.05605414882302284,
      "learning_rate": 2.2598865984335208e-05,
      "loss": 0.0001,
      "step": 114050
    },
    {
      "epoch": 5.48267743020518,
      "grad_norm": 0.05597791075706482,
      "learning_rate": 2.2586853106530202e-05,
      "loss": 0.0001,
      "step": 114100
    },
    {
      "epoch": 5.485080005766181,
      "grad_norm": 0.3744845986366272,
      "learning_rate": 2.2574840228725193e-05,
      "loss": 0.0001,
      "step": 114150
    },
    {
      "epoch": 5.487482581327183,
      "grad_norm": 0.28564897179603577,
      "learning_rate": 2.2562827350920187e-05,
      "loss": 0.0001,
      "step": 114200
    },
    {
      "epoch": 5.489885156888184,
      "grad_norm": 0.07508744299411774,
      "learning_rate": 2.255081447311518e-05,
      "loss": 0.0002,
      "step": 114250
    },
    {
      "epoch": 5.492287732449186,
      "grad_norm": 0.02961045503616333,
      "learning_rate": 2.2538801595310176e-05,
      "loss": 0.0001,
      "step": 114300
    },
    {
      "epoch": 5.4946903080101865,
      "grad_norm": 0.31851184368133545,
      "learning_rate": 2.2526788717505167e-05,
      "loss": 0.0002,
      "step": 114350
    },
    {
      "epoch": 5.497092883571188,
      "grad_norm": 0.5888496041297913,
      "learning_rate": 2.2514775839700158e-05,
      "loss": 0.0001,
      "step": 114400
    },
    {
      "epoch": 5.49949545913219,
      "grad_norm": 0.13977479934692383,
      "learning_rate": 2.2502762961895152e-05,
      "loss": 0.0002,
      "step": 114450
    },
    {
      "epoch": 5.501898034693191,
      "grad_norm": 0.47038137912750244,
      "learning_rate": 2.2490750084090146e-05,
      "loss": 0.0002,
      "step": 114500
    },
    {
      "epoch": 5.504300610254193,
      "grad_norm": 0.0715307667851448,
      "learning_rate": 2.247873720628514e-05,
      "loss": 0.0001,
      "step": 114550
    },
    {
      "epoch": 5.506703185815194,
      "grad_norm": 0.1816778928041458,
      "learning_rate": 2.246672432848013e-05,
      "loss": 0.0001,
      "step": 114600
    },
    {
      "epoch": 5.509105761376195,
      "grad_norm": 0.14792627096176147,
      "learning_rate": 2.2454711450675125e-05,
      "loss": 0.0001,
      "step": 114650
    },
    {
      "epoch": 5.511508336937196,
      "grad_norm": 0.364676833152771,
      "learning_rate": 2.244269857287012e-05,
      "loss": 0.0001,
      "step": 114700
    },
    {
      "epoch": 5.513910912498198,
      "grad_norm": 0.5020818710327148,
      "learning_rate": 2.243068569506511e-05,
      "loss": 0.0001,
      "step": 114750
    },
    {
      "epoch": 5.5163134880591995,
      "grad_norm": 0.25186896324157715,
      "learning_rate": 2.2418672817260104e-05,
      "loss": 0.0002,
      "step": 114800
    },
    {
      "epoch": 5.518716063620201,
      "grad_norm": 0.30746328830718994,
      "learning_rate": 2.2406659939455095e-05,
      "loss": 0.0002,
      "step": 114850
    },
    {
      "epoch": 5.521118639181203,
      "grad_norm": 0.2740491032600403,
      "learning_rate": 2.239464706165009e-05,
      "loss": 0.0001,
      "step": 114900
    },
    {
      "epoch": 5.523521214742203,
      "grad_norm": 0.11382931470870972,
      "learning_rate": 2.2382634183845084e-05,
      "loss": 0.0001,
      "step": 114950
    },
    {
      "epoch": 5.525923790303205,
      "grad_norm": 0.21435631811618805,
      "learning_rate": 2.2370621306040078e-05,
      "loss": 0.0001,
      "step": 115000
    },
    {
      "epoch": 5.528326365864206,
      "grad_norm": 0.11038263142108917,
      "learning_rate": 2.235860842823507e-05,
      "loss": 0.0002,
      "step": 115050
    },
    {
      "epoch": 5.530728941425208,
      "grad_norm": 0.285691499710083,
      "learning_rate": 2.2346595550430063e-05,
      "loss": 0.0001,
      "step": 115100
    },
    {
      "epoch": 5.533131516986209,
      "grad_norm": 0.46437257528305054,
      "learning_rate": 2.2334582672625054e-05,
      "loss": 0.0006,
      "step": 115150
    },
    {
      "epoch": 5.535534092547211,
      "grad_norm": 0.21516481041908264,
      "learning_rate": 2.2322569794820048e-05,
      "loss": 0.0001,
      "step": 115200
    },
    {
      "epoch": 5.5379366681082125,
      "grad_norm": 0.26938334107398987,
      "learning_rate": 2.2310556917015042e-05,
      "loss": 0.0007,
      "step": 115250
    },
    {
      "epoch": 5.540339243669213,
      "grad_norm": 0.10687392950057983,
      "learning_rate": 2.2298544039210033e-05,
      "loss": 0.0001,
      "step": 115300
    },
    {
      "epoch": 5.542741819230215,
      "grad_norm": 0.09256556630134583,
      "learning_rate": 2.2286531161405027e-05,
      "loss": 0.0001,
      "step": 115350
    },
    {
      "epoch": 5.545144394791216,
      "grad_norm": 0.19939745962619781,
      "learning_rate": 2.227451828360002e-05,
      "loss": 0.0001,
      "step": 115400
    },
    {
      "epoch": 5.547546970352218,
      "grad_norm": 0.05715711787343025,
      "learning_rate": 2.2262505405795016e-05,
      "loss": 0.0001,
      "step": 115450
    },
    {
      "epoch": 5.549949545913219,
      "grad_norm": 0.22961269319057465,
      "learning_rate": 2.2250492527990007e-05,
      "loss": 0.0001,
      "step": 115500
    },
    {
      "epoch": 5.55235212147422,
      "grad_norm": 0.04930577427148819,
      "learning_rate": 2.2238479650184997e-05,
      "loss": 0.0001,
      "step": 115550
    },
    {
      "epoch": 5.5547546970352215,
      "grad_norm": 0.15395782887935638,
      "learning_rate": 2.222646677237999e-05,
      "loss": 0.0001,
      "step": 115600
    },
    {
      "epoch": 5.557157272596223,
      "grad_norm": 0.14145620167255402,
      "learning_rate": 2.2214453894574986e-05,
      "loss": 0.0001,
      "step": 115650
    },
    {
      "epoch": 5.559559848157225,
      "grad_norm": 0.20162831246852875,
      "learning_rate": 2.220244101676998e-05,
      "loss": 0.0001,
      "step": 115700
    },
    {
      "epoch": 5.561962423718226,
      "grad_norm": 0.42553776502609253,
      "learning_rate": 2.219042813896497e-05,
      "loss": 0.0002,
      "step": 115750
    },
    {
      "epoch": 5.564364999279228,
      "grad_norm": 0.13149991631507874,
      "learning_rate": 2.2178415261159965e-05,
      "loss": 0.0001,
      "step": 115800
    },
    {
      "epoch": 5.566767574840229,
      "grad_norm": 0.18773038685321808,
      "learning_rate": 2.216640238335496e-05,
      "loss": 0.0001,
      "step": 115850
    },
    {
      "epoch": 5.56917015040123,
      "grad_norm": 0.6505317687988281,
      "learning_rate": 2.215438950554995e-05,
      "loss": 0.0001,
      "step": 115900
    },
    {
      "epoch": 5.571572725962231,
      "grad_norm": 0.35053062438964844,
      "learning_rate": 2.2142376627744944e-05,
      "loss": 0.0002,
      "step": 115950
    },
    {
      "epoch": 5.573975301523233,
      "grad_norm": 0.31338199973106384,
      "learning_rate": 2.2130363749939935e-05,
      "loss": 0.0001,
      "step": 116000
    },
    {
      "epoch": 5.5763778770842345,
      "grad_norm": 0.3253434896469116,
      "learning_rate": 2.211835087213493e-05,
      "loss": 0.0002,
      "step": 116050
    },
    {
      "epoch": 5.578780452645236,
      "grad_norm": 0.2376563549041748,
      "learning_rate": 2.2106337994329924e-05,
      "loss": 0.0001,
      "step": 116100
    },
    {
      "epoch": 5.581183028206237,
      "grad_norm": 0.11011692881584167,
      "learning_rate": 2.2094325116524918e-05,
      "loss": 0.0001,
      "step": 116150
    },
    {
      "epoch": 5.583585603767238,
      "grad_norm": 0.3834645450115204,
      "learning_rate": 2.208231223871991e-05,
      "loss": 0.0002,
      "step": 116200
    },
    {
      "epoch": 5.58598817932824,
      "grad_norm": 0.34371358156204224,
      "learning_rate": 2.20702993609149e-05,
      "loss": 0.0001,
      "step": 116250
    },
    {
      "epoch": 5.588390754889241,
      "grad_norm": 0.32095345854759216,
      "learning_rate": 2.2058286483109894e-05,
      "loss": 0.001,
      "step": 116300
    },
    {
      "epoch": 5.590793330450243,
      "grad_norm": 0.9963683485984802,
      "learning_rate": 2.2046273605304888e-05,
      "loss": 0.0002,
      "step": 116350
    },
    {
      "epoch": 5.593195906011244,
      "grad_norm": 0.1258607804775238,
      "learning_rate": 2.2034260727499882e-05,
      "loss": 0.0005,
      "step": 116400
    },
    {
      "epoch": 5.595598481572246,
      "grad_norm": 0.09443993866443634,
      "learning_rate": 2.2022247849694873e-05,
      "loss": 0.0002,
      "step": 116450
    },
    {
      "epoch": 5.598001057133247,
      "grad_norm": 0.04112476855516434,
      "learning_rate": 2.2010234971889867e-05,
      "loss": 0.0001,
      "step": 116500
    },
    {
      "epoch": 5.600403632694248,
      "grad_norm": 0.3009711503982544,
      "learning_rate": 2.199822209408486e-05,
      "loss": 0.0002,
      "step": 116550
    },
    {
      "epoch": 5.60280620825525,
      "grad_norm": 0.263612300157547,
      "learning_rate": 2.1986209216279856e-05,
      "loss": 0.0001,
      "step": 116600
    },
    {
      "epoch": 5.605208783816251,
      "grad_norm": 0.4357015788555145,
      "learning_rate": 2.1974196338474846e-05,
      "loss": 0.0001,
      "step": 116650
    },
    {
      "epoch": 5.607611359377253,
      "grad_norm": 0.14708967506885529,
      "learning_rate": 2.1962183460669837e-05,
      "loss": 0.0002,
      "step": 116700
    },
    {
      "epoch": 5.610013934938253,
      "grad_norm": 0.2619175612926483,
      "learning_rate": 2.195017058286483e-05,
      "loss": 0.0001,
      "step": 116750
    },
    {
      "epoch": 5.612416510499255,
      "grad_norm": 0.59516441822052,
      "learning_rate": 2.1938157705059826e-05,
      "loss": 0.0001,
      "step": 116800
    },
    {
      "epoch": 5.6148190860602565,
      "grad_norm": 0.15602441132068634,
      "learning_rate": 2.192614482725482e-05,
      "loss": 0.0001,
      "step": 116850
    },
    {
      "epoch": 5.617221661621258,
      "grad_norm": 0.08754412084817886,
      "learning_rate": 2.191413194944981e-05,
      "loss": 0.0001,
      "step": 116900
    },
    {
      "epoch": 5.61962423718226,
      "grad_norm": 0.1592313051223755,
      "learning_rate": 2.1902119071644805e-05,
      "loss": 0.0009,
      "step": 116950
    },
    {
      "epoch": 5.622026812743261,
      "grad_norm": 0.24361251294612885,
      "learning_rate": 2.1890106193839796e-05,
      "loss": 0.0004,
      "step": 117000
    },
    {
      "epoch": 5.624429388304263,
      "grad_norm": 0.11113208532333374,
      "learning_rate": 2.187809331603479e-05,
      "loss": 0.0002,
      "step": 117050
    },
    {
      "epoch": 5.626831963865263,
      "grad_norm": 0.15960712730884552,
      "learning_rate": 2.1866080438229784e-05,
      "loss": 0.0001,
      "step": 117100
    },
    {
      "epoch": 5.629234539426265,
      "grad_norm": 0.0893254429101944,
      "learning_rate": 2.1854067560424775e-05,
      "loss": 0.0001,
      "step": 117150
    },
    {
      "epoch": 5.631637114987266,
      "grad_norm": 0.3428993821144104,
      "learning_rate": 2.184205468261977e-05,
      "loss": 0.0002,
      "step": 117200
    },
    {
      "epoch": 5.634039690548268,
      "grad_norm": 0.06063413992524147,
      "learning_rate": 2.1830041804814763e-05,
      "loss": 0.0001,
      "step": 117250
    },
    {
      "epoch": 5.6364422661092695,
      "grad_norm": 0.20001299679279327,
      "learning_rate": 2.1818028927009758e-05,
      "loss": 0.0002,
      "step": 117300
    },
    {
      "epoch": 5.63884484167027,
      "grad_norm": 0.4819735288619995,
      "learning_rate": 2.180601604920475e-05,
      "loss": 0.0002,
      "step": 117350
    },
    {
      "epoch": 5.641247417231272,
      "grad_norm": 0.10254903137683868,
      "learning_rate": 2.179400317139974e-05,
      "loss": 0.0002,
      "step": 117400
    },
    {
      "epoch": 5.643649992792273,
      "grad_norm": 0.29142892360687256,
      "learning_rate": 2.1781990293594733e-05,
      "loss": 0.0002,
      "step": 117450
    },
    {
      "epoch": 5.646052568353275,
      "grad_norm": 0.1265476644039154,
      "learning_rate": 2.1769977415789728e-05,
      "loss": 0.0002,
      "step": 117500
    },
    {
      "epoch": 5.648455143914276,
      "grad_norm": 0.3953699767589569,
      "learning_rate": 2.1757964537984722e-05,
      "loss": 0.0001,
      "step": 117550
    },
    {
      "epoch": 5.650857719475278,
      "grad_norm": 0.3447744846343994,
      "learning_rate": 2.1745951660179713e-05,
      "loss": 0.0001,
      "step": 117600
    },
    {
      "epoch": 5.653260295036279,
      "grad_norm": 0.24963022768497467,
      "learning_rate": 2.1733938782374707e-05,
      "loss": 0.0001,
      "step": 117650
    },
    {
      "epoch": 5.65566287059728,
      "grad_norm": 0.40172940492630005,
      "learning_rate": 2.17219259045697e-05,
      "loss": 0.0001,
      "step": 117700
    },
    {
      "epoch": 5.6580654461582816,
      "grad_norm": 0.1082201823592186,
      "learning_rate": 2.1709913026764692e-05,
      "loss": 0.0002,
      "step": 117750
    },
    {
      "epoch": 5.660468021719283,
      "grad_norm": 0.19298340380191803,
      "learning_rate": 2.1697900148959686e-05,
      "loss": 0.0002,
      "step": 117800
    },
    {
      "epoch": 5.662870597280285,
      "grad_norm": 0.17538540065288544,
      "learning_rate": 2.1685887271154677e-05,
      "loss": 0.0001,
      "step": 117850
    },
    {
      "epoch": 5.665273172841286,
      "grad_norm": 0.3306306302547455,
      "learning_rate": 2.167387439334967e-05,
      "loss": 0.0002,
      "step": 117900
    },
    {
      "epoch": 5.667675748402287,
      "grad_norm": 0.23829972743988037,
      "learning_rate": 2.1661861515544665e-05,
      "loss": 0.0001,
      "step": 117950
    },
    {
      "epoch": 5.670078323963288,
      "grad_norm": 0.08667586743831635,
      "learning_rate": 2.164984863773966e-05,
      "loss": 0.0001,
      "step": 118000
    },
    {
      "epoch": 5.67248089952429,
      "grad_norm": 0.15628840029239655,
      "learning_rate": 2.163783575993465e-05,
      "loss": 0.0001,
      "step": 118050
    },
    {
      "epoch": 5.6748834750852915,
      "grad_norm": 0.07729820162057877,
      "learning_rate": 2.162582288212964e-05,
      "loss": 0.0002,
      "step": 118100
    },
    {
      "epoch": 5.677286050646293,
      "grad_norm": 0.2620669901371002,
      "learning_rate": 2.1613810004324635e-05,
      "loss": 0.0002,
      "step": 118150
    },
    {
      "epoch": 5.6796886262072945,
      "grad_norm": 0.26257845759391785,
      "learning_rate": 2.160179712651963e-05,
      "loss": 0.0001,
      "step": 118200
    },
    {
      "epoch": 5.682091201768296,
      "grad_norm": 0.18101617693901062,
      "learning_rate": 2.1589784248714624e-05,
      "loss": 0.0005,
      "step": 118250
    },
    {
      "epoch": 5.684493777329297,
      "grad_norm": 0.30382269620895386,
      "learning_rate": 2.1577771370909615e-05,
      "loss": 0.0001,
      "step": 118300
    },
    {
      "epoch": 5.686896352890298,
      "grad_norm": 0.05670221894979477,
      "learning_rate": 2.156575849310461e-05,
      "loss": 0.0001,
      "step": 118350
    },
    {
      "epoch": 5.6892989284513,
      "grad_norm": 0.43844640254974365,
      "learning_rate": 2.1553745615299603e-05,
      "loss": 0.0002,
      "step": 118400
    },
    {
      "epoch": 5.691701504012301,
      "grad_norm": 0.27573084831237793,
      "learning_rate": 2.1541732737494597e-05,
      "loss": 0.0001,
      "step": 118450
    },
    {
      "epoch": 5.694104079573303,
      "grad_norm": 0.20855450630187988,
      "learning_rate": 2.1529719859689588e-05,
      "loss": 0.0001,
      "step": 118500
    },
    {
      "epoch": 5.6965066551343035,
      "grad_norm": 0.10318323224782944,
      "learning_rate": 2.151770698188458e-05,
      "loss": 0.0001,
      "step": 118550
    },
    {
      "epoch": 5.698909230695305,
      "grad_norm": 0.2618405222892761,
      "learning_rate": 2.1505694104079573e-05,
      "loss": 0.0001,
      "step": 118600
    },
    {
      "epoch": 5.701311806256307,
      "grad_norm": 0.13444308936595917,
      "learning_rate": 2.1493681226274567e-05,
      "loss": 0.0001,
      "step": 118650
    },
    {
      "epoch": 5.703714381817308,
      "grad_norm": 0.3496532738208771,
      "learning_rate": 2.148166834846956e-05,
      "loss": 0.0001,
      "step": 118700
    },
    {
      "epoch": 5.70611695737831,
      "grad_norm": 0.03800483047962189,
      "learning_rate": 2.1469655470664556e-05,
      "loss": 0.0001,
      "step": 118750
    },
    {
      "epoch": 5.708519532939311,
      "grad_norm": 0.24244335293769836,
      "learning_rate": 2.1457642592859547e-05,
      "loss": 0.0006,
      "step": 118800
    },
    {
      "epoch": 5.710922108500313,
      "grad_norm": 0.35601678490638733,
      "learning_rate": 2.1445629715054538e-05,
      "loss": 0.0001,
      "step": 118850
    },
    {
      "epoch": 5.713324684061313,
      "grad_norm": 0.24330945312976837,
      "learning_rate": 2.1433616837249532e-05,
      "loss": 0.0001,
      "step": 118900
    },
    {
      "epoch": 5.715727259622315,
      "grad_norm": 0.1127958819270134,
      "learning_rate": 2.1421603959444526e-05,
      "loss": 0.0001,
      "step": 118950
    },
    {
      "epoch": 5.7181298351833165,
      "grad_norm": 0.38111841678619385,
      "learning_rate": 2.1409591081639517e-05,
      "loss": 0.0001,
      "step": 119000
    },
    {
      "epoch": 5.720532410744318,
      "grad_norm": 0.10317406058311462,
      "learning_rate": 2.139757820383451e-05,
      "loss": 0.0001,
      "step": 119050
    },
    {
      "epoch": 5.72293498630532,
      "grad_norm": 0.2343944013118744,
      "learning_rate": 2.1385565326029505e-05,
      "loss": 0.0001,
      "step": 119100
    },
    {
      "epoch": 5.72533756186632,
      "grad_norm": 0.2409137487411499,
      "learning_rate": 2.13735524482245e-05,
      "loss": 0.0001,
      "step": 119150
    },
    {
      "epoch": 5.727740137427322,
      "grad_norm": 0.18118058145046234,
      "learning_rate": 2.1361539570419494e-05,
      "loss": 0.0001,
      "step": 119200
    },
    {
      "epoch": 5.730142712988323,
      "grad_norm": 0.0777580663561821,
      "learning_rate": 2.134952669261448e-05,
      "loss": 0.0001,
      "step": 119250
    },
    {
      "epoch": 5.732545288549325,
      "grad_norm": 0.17985256016254425,
      "learning_rate": 2.1337513814809475e-05,
      "loss": 0.0001,
      "step": 119300
    },
    {
      "epoch": 5.734947864110326,
      "grad_norm": 0.30336958169937134,
      "learning_rate": 2.132550093700447e-05,
      "loss": 0.0001,
      "step": 119350
    },
    {
      "epoch": 5.737350439671328,
      "grad_norm": 0.45451849699020386,
      "learning_rate": 2.1313488059199464e-05,
      "loss": 0.0006,
      "step": 119400
    },
    {
      "epoch": 5.7397530152323295,
      "grad_norm": 0.2990350127220154,
      "learning_rate": 2.1301475181394458e-05,
      "loss": 0.0001,
      "step": 119450
    },
    {
      "epoch": 5.74215559079333,
      "grad_norm": 0.0944405347108841,
      "learning_rate": 2.128946230358945e-05,
      "loss": 0.0001,
      "step": 119500
    },
    {
      "epoch": 5.744558166354332,
      "grad_norm": 0.2569974660873413,
      "learning_rate": 2.1277449425784443e-05,
      "loss": 0.0002,
      "step": 119550
    },
    {
      "epoch": 5.746960741915333,
      "grad_norm": 0.4743201732635498,
      "learning_rate": 2.1265436547979434e-05,
      "loss": 0.0001,
      "step": 119600
    },
    {
      "epoch": 5.749363317476335,
      "grad_norm": 0.18875038623809814,
      "learning_rate": 2.1253423670174428e-05,
      "loss": 0.0001,
      "step": 119650
    },
    {
      "epoch": 5.751765893037336,
      "grad_norm": 0.2485593855381012,
      "learning_rate": 2.1241410792369422e-05,
      "loss": 0.0002,
      "step": 119700
    },
    {
      "epoch": 5.754168468598337,
      "grad_norm": 0.17038197815418243,
      "learning_rate": 2.1229397914564413e-05,
      "loss": 0.0001,
      "step": 119750
    },
    {
      "epoch": 5.7565710441593385,
      "grad_norm": 0.6462656855583191,
      "learning_rate": 2.1217385036759407e-05,
      "loss": 0.0001,
      "step": 119800
    },
    {
      "epoch": 5.75897361972034,
      "grad_norm": 0.2216554433107376,
      "learning_rate": 2.12053721589544e-05,
      "loss": 0.0002,
      "step": 119850
    },
    {
      "epoch": 5.761376195281342,
      "grad_norm": 0.05323953926563263,
      "learning_rate": 2.1193359281149396e-05,
      "loss": 0.0001,
      "step": 119900
    },
    {
      "epoch": 5.763778770842343,
      "grad_norm": 0.0447368361055851,
      "learning_rate": 2.1181346403344386e-05,
      "loss": 0.0001,
      "step": 119950
    },
    {
      "epoch": 5.766181346403345,
      "grad_norm": 0.3706691861152649,
      "learning_rate": 2.1169333525539377e-05,
      "loss": 0.0001,
      "step": 120000
    },
    {
      "epoch": 5.768583921964346,
      "grad_norm": 0.2619541883468628,
      "learning_rate": 2.115732064773437e-05,
      "loss": 0.0005,
      "step": 120050
    },
    {
      "epoch": 5.770986497525347,
      "grad_norm": 0.2729268968105316,
      "learning_rate": 2.1145307769929366e-05,
      "loss": 0.0001,
      "step": 120100
    },
    {
      "epoch": 5.773389073086348,
      "grad_norm": 0.34439119696617126,
      "learning_rate": 2.113329489212436e-05,
      "loss": 0.0001,
      "step": 120150
    },
    {
      "epoch": 5.77579164864735,
      "grad_norm": 0.07964678108692169,
      "learning_rate": 2.112128201431935e-05,
      "loss": 0.0001,
      "step": 120200
    },
    {
      "epoch": 5.7781942242083515,
      "grad_norm": 0.06533300131559372,
      "learning_rate": 2.1109269136514345e-05,
      "loss": 0.0001,
      "step": 120250
    },
    {
      "epoch": 5.780596799769353,
      "grad_norm": 0.09092829376459122,
      "learning_rate": 2.109725625870934e-05,
      "loss": 0.0002,
      "step": 120300
    },
    {
      "epoch": 5.782999375330354,
      "grad_norm": 0.2043762505054474,
      "learning_rate": 2.108524338090433e-05,
      "loss": 0.0001,
      "step": 120350
    },
    {
      "epoch": 5.785401950891355,
      "grad_norm": 0.06279310584068298,
      "learning_rate": 2.1073230503099324e-05,
      "loss": 0.0001,
      "step": 120400
    },
    {
      "epoch": 5.787804526452357,
      "grad_norm": 0.4283542335033417,
      "learning_rate": 2.1061217625294315e-05,
      "loss": 0.0001,
      "step": 120450
    },
    {
      "epoch": 5.790207102013358,
      "grad_norm": 0.13965487480163574,
      "learning_rate": 2.104920474748931e-05,
      "loss": 0.0001,
      "step": 120500
    },
    {
      "epoch": 5.79260967757436,
      "grad_norm": 0.8657809495925903,
      "learning_rate": 2.1037191869684304e-05,
      "loss": 0.0002,
      "step": 120550
    },
    {
      "epoch": 5.795012253135361,
      "grad_norm": 0.07306888699531555,
      "learning_rate": 2.1025178991879298e-05,
      "loss": 0.0001,
      "step": 120600
    },
    {
      "epoch": 5.797414828696363,
      "grad_norm": 0.09862799942493439,
      "learning_rate": 2.101316611407429e-05,
      "loss": 0.0002,
      "step": 120650
    },
    {
      "epoch": 5.799817404257364,
      "grad_norm": 0.12443281710147858,
      "learning_rate": 2.100115323626928e-05,
      "loss": 0.0001,
      "step": 120700
    },
    {
      "epoch": 5.802219979818365,
      "grad_norm": 0.14601869881153107,
      "learning_rate": 2.0989140358464274e-05,
      "loss": 0.0001,
      "step": 120750
    },
    {
      "epoch": 5.804622555379367,
      "grad_norm": 0.8518025875091553,
      "learning_rate": 2.0977127480659268e-05,
      "loss": 0.0002,
      "step": 120800
    },
    {
      "epoch": 5.807025130940368,
      "grad_norm": 0.03902566805481911,
      "learning_rate": 2.0965114602854262e-05,
      "loss": 0.0001,
      "step": 120850
    },
    {
      "epoch": 5.80942770650137,
      "grad_norm": 0.09413091093301773,
      "learning_rate": 2.0953101725049253e-05,
      "loss": 0.0001,
      "step": 120900
    },
    {
      "epoch": 5.81183028206237,
      "grad_norm": 0.08425482362508774,
      "learning_rate": 2.0941088847244247e-05,
      "loss": 0.0001,
      "step": 120950
    },
    {
      "epoch": 5.814232857623372,
      "grad_norm": 0.08343444019556046,
      "learning_rate": 2.092907596943924e-05,
      "loss": 0.0001,
      "step": 121000
    },
    {
      "epoch": 5.8166354331843735,
      "grad_norm": 0.1969417780637741,
      "learning_rate": 2.0917063091634235e-05,
      "loss": 0.0001,
      "step": 121050
    },
    {
      "epoch": 5.819038008745375,
      "grad_norm": 0.13358452916145325,
      "learning_rate": 2.0905050213829226e-05,
      "loss": 0.0002,
      "step": 121100
    },
    {
      "epoch": 5.821440584306377,
      "grad_norm": 0.49046269059181213,
      "learning_rate": 2.0893037336024217e-05,
      "loss": 0.0001,
      "step": 121150
    },
    {
      "epoch": 5.823843159867378,
      "grad_norm": 0.9179259538650513,
      "learning_rate": 2.088102445821921e-05,
      "loss": 0.0002,
      "step": 121200
    },
    {
      "epoch": 5.82624573542838,
      "grad_norm": 0.21288622915744781,
      "learning_rate": 2.0869011580414206e-05,
      "loss": 0.0002,
      "step": 121250
    },
    {
      "epoch": 5.82864831098938,
      "grad_norm": 0.4135842025279999,
      "learning_rate": 2.08569987026092e-05,
      "loss": 0.0002,
      "step": 121300
    },
    {
      "epoch": 5.831050886550382,
      "grad_norm": 0.7326626181602478,
      "learning_rate": 2.084498582480419e-05,
      "loss": 0.0002,
      "step": 121350
    },
    {
      "epoch": 5.833453462111383,
      "grad_norm": 0.09650328755378723,
      "learning_rate": 2.0832972946999185e-05,
      "loss": 0.0001,
      "step": 121400
    },
    {
      "epoch": 5.835856037672385,
      "grad_norm": 0.5124801397323608,
      "learning_rate": 2.0820960069194176e-05,
      "loss": 0.0001,
      "step": 121450
    },
    {
      "epoch": 5.8382586132333865,
      "grad_norm": 0.13269741833209991,
      "learning_rate": 2.080894719138917e-05,
      "loss": 0.0001,
      "step": 121500
    },
    {
      "epoch": 5.840661188794387,
      "grad_norm": 0.3273065388202667,
      "learning_rate": 2.0796934313584164e-05,
      "loss": 0.0001,
      "step": 121550
    },
    {
      "epoch": 5.843063764355389,
      "grad_norm": 0.33529844880104065,
      "learning_rate": 2.0784921435779155e-05,
      "loss": 0.0001,
      "step": 121600
    },
    {
      "epoch": 5.84546633991639,
      "grad_norm": 0.3709432780742645,
      "learning_rate": 2.077290855797415e-05,
      "loss": 0.0002,
      "step": 121650
    },
    {
      "epoch": 5.847868915477392,
      "grad_norm": 0.19739249348640442,
      "learning_rate": 2.0760895680169143e-05,
      "loss": 0.0001,
      "step": 121700
    },
    {
      "epoch": 5.850271491038393,
      "grad_norm": 0.18067975342273712,
      "learning_rate": 2.0748882802364138e-05,
      "loss": 0.0001,
      "step": 121750
    },
    {
      "epoch": 5.852674066599395,
      "grad_norm": 0.08915320783853531,
      "learning_rate": 2.073686992455913e-05,
      "loss": 0.0001,
      "step": 121800
    },
    {
      "epoch": 5.855076642160396,
      "grad_norm": 0.21033039689064026,
      "learning_rate": 2.072485704675412e-05,
      "loss": 0.0001,
      "step": 121850
    },
    {
      "epoch": 5.857479217721397,
      "grad_norm": 0.22491899132728577,
      "learning_rate": 2.0712844168949113e-05,
      "loss": 0.0001,
      "step": 121900
    },
    {
      "epoch": 5.8598817932823986,
      "grad_norm": 0.5272160768508911,
      "learning_rate": 2.0700831291144108e-05,
      "loss": 0.0001,
      "step": 121950
    },
    {
      "epoch": 5.8622843688434,
      "grad_norm": 0.1168302595615387,
      "learning_rate": 2.0688818413339102e-05,
      "loss": 0.0004,
      "step": 122000
    },
    {
      "epoch": 5.864686944404402,
      "grad_norm": 0.04984435439109802,
      "learning_rate": 2.0676805535534093e-05,
      "loss": 0.0001,
      "step": 122050
    },
    {
      "epoch": 5.867089519965403,
      "grad_norm": 0.08265438675880432,
      "learning_rate": 2.0664792657729087e-05,
      "loss": 0.0001,
      "step": 122100
    },
    {
      "epoch": 5.869492095526404,
      "grad_norm": 0.08453051745891571,
      "learning_rate": 2.065277977992408e-05,
      "loss": 0.0002,
      "step": 122150
    },
    {
      "epoch": 5.871894671087405,
      "grad_norm": 0.1980063021183014,
      "learning_rate": 2.0640766902119072e-05,
      "loss": 0.0001,
      "step": 122200
    },
    {
      "epoch": 5.874297246648407,
      "grad_norm": 0.07833146303892136,
      "learning_rate": 2.0628754024314066e-05,
      "loss": 0.0001,
      "step": 122250
    },
    {
      "epoch": 5.8766998222094085,
      "grad_norm": 0.2894875705242157,
      "learning_rate": 2.0616741146509057e-05,
      "loss": 0.0001,
      "step": 122300
    },
    {
      "epoch": 5.87910239777041,
      "grad_norm": 0.16788427531719208,
      "learning_rate": 2.060472826870405e-05,
      "loss": 0.0002,
      "step": 122350
    },
    {
      "epoch": 5.8815049733314115,
      "grad_norm": 0.17598256468772888,
      "learning_rate": 2.0592715390899045e-05,
      "loss": 0.0001,
      "step": 122400
    },
    {
      "epoch": 5.883907548892413,
      "grad_norm": 0.1353551596403122,
      "learning_rate": 2.058070251309404e-05,
      "loss": 0.0002,
      "step": 122450
    },
    {
      "epoch": 5.886310124453414,
      "grad_norm": 0.1514580249786377,
      "learning_rate": 2.056868963528903e-05,
      "loss": 0.0001,
      "step": 122500
    },
    {
      "epoch": 5.888712700014415,
      "grad_norm": 0.09224209189414978,
      "learning_rate": 2.0556676757484025e-05,
      "loss": 0.0001,
      "step": 122550
    },
    {
      "epoch": 5.891115275575417,
      "grad_norm": 0.03756770119071007,
      "learning_rate": 2.0544663879679015e-05,
      "loss": 0.0006,
      "step": 122600
    },
    {
      "epoch": 5.893517851136418,
      "grad_norm": 0.13941387832164764,
      "learning_rate": 2.053265100187401e-05,
      "loss": 0.0002,
      "step": 122650
    },
    {
      "epoch": 5.89592042669742,
      "grad_norm": 0.22271384298801422,
      "learning_rate": 2.0520638124069004e-05,
      "loss": 0.0001,
      "step": 122700
    },
    {
      "epoch": 5.8983230022584205,
      "grad_norm": 0.07388311624526978,
      "learning_rate": 2.0508625246263995e-05,
      "loss": 0.0001,
      "step": 122750
    },
    {
      "epoch": 5.900725577819422,
      "grad_norm": 0.1581459790468216,
      "learning_rate": 2.049661236845899e-05,
      "loss": 0.0001,
      "step": 122800
    },
    {
      "epoch": 5.903128153380424,
      "grad_norm": 0.3264966905117035,
      "learning_rate": 2.0484599490653983e-05,
      "loss": 0.0002,
      "step": 122850
    },
    {
      "epoch": 5.905530728941425,
      "grad_norm": 0.10809773951768875,
      "learning_rate": 2.0472586612848977e-05,
      "loss": 0.0002,
      "step": 122900
    },
    {
      "epoch": 5.907933304502427,
      "grad_norm": 0.1136653795838356,
      "learning_rate": 2.0460573735043968e-05,
      "loss": 0.0001,
      "step": 122950
    },
    {
      "epoch": 5.910335880063428,
      "grad_norm": 0.08628708124160767,
      "learning_rate": 2.044856085723896e-05,
      "loss": 0.0001,
      "step": 123000
    },
    {
      "epoch": 5.91273845562443,
      "grad_norm": 0.2708759903907776,
      "learning_rate": 2.0436547979433953e-05,
      "loss": 0.0002,
      "step": 123050
    },
    {
      "epoch": 5.91514103118543,
      "grad_norm": 0.09574195742607117,
      "learning_rate": 2.0424535101628947e-05,
      "loss": 0.0004,
      "step": 123100
    },
    {
      "epoch": 5.917543606746432,
      "grad_norm": 0.14944927394390106,
      "learning_rate": 2.041252222382394e-05,
      "loss": 0.0002,
      "step": 123150
    },
    {
      "epoch": 5.9199461823074335,
      "grad_norm": 0.12328283488750458,
      "learning_rate": 2.0400509346018932e-05,
      "loss": 0.0001,
      "step": 123200
    },
    {
      "epoch": 5.922348757868435,
      "grad_norm": 0.06708794087171555,
      "learning_rate": 2.0388496468213927e-05,
      "loss": 0.0001,
      "step": 123250
    },
    {
      "epoch": 5.924751333429437,
      "grad_norm": 0.5798024535179138,
      "learning_rate": 2.0376483590408917e-05,
      "loss": 0.0001,
      "step": 123300
    },
    {
      "epoch": 5.927153908990437,
      "grad_norm": 0.07098425179719925,
      "learning_rate": 2.036447071260391e-05,
      "loss": 0.0005,
      "step": 123350
    },
    {
      "epoch": 5.929556484551439,
      "grad_norm": 0.6878874897956848,
      "learning_rate": 2.0352457834798906e-05,
      "loss": 0.0001,
      "step": 123400
    },
    {
      "epoch": 5.93195906011244,
      "grad_norm": 0.4609083831310272,
      "learning_rate": 2.0340444956993897e-05,
      "loss": 0.0001,
      "step": 123450
    },
    {
      "epoch": 5.934361635673442,
      "grad_norm": 0.15753626823425293,
      "learning_rate": 2.032843207918889e-05,
      "loss": 0.0001,
      "step": 123500
    },
    {
      "epoch": 5.936764211234443,
      "grad_norm": 0.2511012554168701,
      "learning_rate": 2.0316419201383885e-05,
      "loss": 0.0001,
      "step": 123550
    },
    {
      "epoch": 5.939166786795445,
      "grad_norm": 0.2860722541809082,
      "learning_rate": 2.030440632357888e-05,
      "loss": 0.0001,
      "step": 123600
    },
    {
      "epoch": 5.9415693623564465,
      "grad_norm": 0.43629419803619385,
      "learning_rate": 2.029239344577387e-05,
      "loss": 0.0001,
      "step": 123650
    },
    {
      "epoch": 5.943971937917447,
      "grad_norm": 0.3028777837753296,
      "learning_rate": 2.028038056796886e-05,
      "loss": 0.0001,
      "step": 123700
    },
    {
      "epoch": 5.946374513478449,
      "grad_norm": 0.12809409201145172,
      "learning_rate": 2.0268367690163855e-05,
      "loss": 0.0001,
      "step": 123750
    },
    {
      "epoch": 5.94877708903945,
      "grad_norm": 0.16142453253269196,
      "learning_rate": 2.025635481235885e-05,
      "loss": 0.0001,
      "step": 123800
    },
    {
      "epoch": 5.951179664600452,
      "grad_norm": 0.06598852574825287,
      "learning_rate": 2.0244341934553844e-05,
      "loss": 0.0001,
      "step": 123850
    },
    {
      "epoch": 5.953582240161453,
      "grad_norm": 0.2806403636932373,
      "learning_rate": 2.0232329056748834e-05,
      "loss": 0.0001,
      "step": 123900
    },
    {
      "epoch": 5.955984815722454,
      "grad_norm": 0.28028666973114014,
      "learning_rate": 2.022031617894383e-05,
      "loss": 0.0001,
      "step": 123950
    },
    {
      "epoch": 5.9583873912834555,
      "grad_norm": 0.2749302089214325,
      "learning_rate": 2.0208303301138823e-05,
      "loss": 0.0002,
      "step": 124000
    },
    {
      "epoch": 5.960789966844457,
      "grad_norm": 0.3368953764438629,
      "learning_rate": 2.0196290423333814e-05,
      "loss": 0.0001,
      "step": 124050
    },
    {
      "epoch": 5.963192542405459,
      "grad_norm": 0.3502770662307739,
      "learning_rate": 2.0184277545528808e-05,
      "loss": 0.0001,
      "step": 124100
    },
    {
      "epoch": 5.96559511796646,
      "grad_norm": 0.06884754449129105,
      "learning_rate": 2.01722646677238e-05,
      "loss": 0.0001,
      "step": 124150
    },
    {
      "epoch": 5.967997693527462,
      "grad_norm": 0.044969744980335236,
      "learning_rate": 2.0160251789918793e-05,
      "loss": 0.0001,
      "step": 124200
    },
    {
      "epoch": 5.970400269088463,
      "grad_norm": 0.10617079585790634,
      "learning_rate": 2.0148238912113787e-05,
      "loss": 0.0001,
      "step": 124250
    },
    {
      "epoch": 5.972802844649464,
      "grad_norm": 0.3114030063152313,
      "learning_rate": 2.013622603430878e-05,
      "loss": 0.0001,
      "step": 124300
    },
    {
      "epoch": 5.975205420210465,
      "grad_norm": 0.06475943326950073,
      "learning_rate": 2.0124213156503772e-05,
      "loss": 0.0001,
      "step": 124350
    },
    {
      "epoch": 5.977607995771467,
      "grad_norm": 0.24498559534549713,
      "learning_rate": 2.0112200278698766e-05,
      "loss": 0.0001,
      "step": 124400
    },
    {
      "epoch": 5.9800105713324685,
      "grad_norm": 0.11596508324146271,
      "learning_rate": 2.0100187400893757e-05,
      "loss": 0.0001,
      "step": 124450
    },
    {
      "epoch": 5.98241314689347,
      "grad_norm": 0.15726494789123535,
      "learning_rate": 2.008817452308875e-05,
      "loss": 0.0004,
      "step": 124500
    },
    {
      "epoch": 5.984815722454472,
      "grad_norm": 0.47774091362953186,
      "learning_rate": 2.0076161645283746e-05,
      "loss": 0.0002,
      "step": 124550
    },
    {
      "epoch": 5.987218298015472,
      "grad_norm": 0.22990001738071442,
      "learning_rate": 2.0064148767478737e-05,
      "loss": 0.0003,
      "step": 124600
    },
    {
      "epoch": 5.989620873576474,
      "grad_norm": 0.08706247806549072,
      "learning_rate": 2.005213588967373e-05,
      "loss": 0.0001,
      "step": 124650
    },
    {
      "epoch": 5.992023449137475,
      "grad_norm": 0.25162574648857117,
      "learning_rate": 2.0040123011868725e-05,
      "loss": 0.0003,
      "step": 124700
    },
    {
      "epoch": 5.994426024698477,
      "grad_norm": 0.3286253809928894,
      "learning_rate": 2.002811013406372e-05,
      "loss": 0.0001,
      "step": 124750
    },
    {
      "epoch": 5.996828600259478,
      "grad_norm": 0.14475688338279724,
      "learning_rate": 2.001609725625871e-05,
      "loss": 0.0002,
      "step": 124800
    },
    {
      "epoch": 5.99923117582048,
      "grad_norm": 0.3583279252052307,
      "learning_rate": 2.00040843784537e-05,
      "loss": 0.0001,
      "step": 124850
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.0001382339105475694,
      "eval_runtime": 17.3852,
      "eval_samples_per_second": 546.213,
      "eval_steps_per_second": 68.277,
      "step": 124866
    },
    {
      "epoch": 6.001633751381481,
      "grad_norm": 0.5121785402297974,
      "learning_rate": 1.9992071500648695e-05,
      "loss": 0.0001,
      "step": 124900
    },
    {
      "epoch": 6.004036326942482,
      "grad_norm": 0.11509636789560318,
      "learning_rate": 1.998005862284369e-05,
      "loss": 0.0001,
      "step": 124950
    },
    {
      "epoch": 6.006438902503484,
      "grad_norm": 0.17722706496715546,
      "learning_rate": 1.9968045745038683e-05,
      "loss": 0.0001,
      "step": 125000
    },
    {
      "epoch": 6.008841478064485,
      "grad_norm": 0.3037470877170563,
      "learning_rate": 1.9956032867233678e-05,
      "loss": 0.0001,
      "step": 125050
    },
    {
      "epoch": 6.011244053625487,
      "grad_norm": 0.048222821205854416,
      "learning_rate": 1.994401998942867e-05,
      "loss": 0.0002,
      "step": 125100
    },
    {
      "epoch": 6.013646629186488,
      "grad_norm": 0.15245060622692108,
      "learning_rate": 1.9932007111623663e-05,
      "loss": 0.0002,
      "step": 125150
    },
    {
      "epoch": 6.016049204747489,
      "grad_norm": 0.06858523935079575,
      "learning_rate": 1.9919994233818654e-05,
      "loss": 0.0001,
      "step": 125200
    },
    {
      "epoch": 6.0184517803084905,
      "grad_norm": 0.2308911681175232,
      "learning_rate": 1.9907981356013648e-05,
      "loss": 0.0005,
      "step": 125250
    },
    {
      "epoch": 6.020854355869492,
      "grad_norm": 0.1934337019920349,
      "learning_rate": 1.9895968478208642e-05,
      "loss": 0.0001,
      "step": 125300
    },
    {
      "epoch": 6.023256931430494,
      "grad_norm": 0.25939321517944336,
      "learning_rate": 1.9883955600403633e-05,
      "loss": 0.0002,
      "step": 125350
    },
    {
      "epoch": 6.025659506991495,
      "grad_norm": 0.061502423137426376,
      "learning_rate": 1.9871942722598627e-05,
      "loss": 0.0001,
      "step": 125400
    },
    {
      "epoch": 6.028062082552497,
      "grad_norm": 0.3028688430786133,
      "learning_rate": 1.985992984479362e-05,
      "loss": 0.0001,
      "step": 125450
    },
    {
      "epoch": 6.030464658113497,
      "grad_norm": 0.07400723546743393,
      "learning_rate": 1.9847916966988615e-05,
      "loss": 0.0001,
      "step": 125500
    },
    {
      "epoch": 6.032867233674499,
      "grad_norm": 0.10755080729722977,
      "learning_rate": 1.9835904089183603e-05,
      "loss": 0.0001,
      "step": 125550
    },
    {
      "epoch": 6.0352698092355,
      "grad_norm": 0.0748654454946518,
      "learning_rate": 1.9823891211378597e-05,
      "loss": 0.0001,
      "step": 125600
    },
    {
      "epoch": 6.037672384796502,
      "grad_norm": 0.11687394976615906,
      "learning_rate": 1.981187833357359e-05,
      "loss": 0.0001,
      "step": 125650
    },
    {
      "epoch": 6.0400749603575035,
      "grad_norm": 0.11226969212293625,
      "learning_rate": 1.9799865455768586e-05,
      "loss": 0.0002,
      "step": 125700
    },
    {
      "epoch": 6.042477535918505,
      "grad_norm": 0.5164704322814941,
      "learning_rate": 1.978785257796358e-05,
      "loss": 0.0002,
      "step": 125750
    },
    {
      "epoch": 6.044880111479506,
      "grad_norm": 0.060801729559898376,
      "learning_rate": 1.977583970015857e-05,
      "loss": 0.0001,
      "step": 125800
    },
    {
      "epoch": 6.047282687040507,
      "grad_norm": 0.5526299476623535,
      "learning_rate": 1.9763826822353565e-05,
      "loss": 0.0001,
      "step": 125850
    },
    {
      "epoch": 6.049685262601509,
      "grad_norm": 0.21617060899734497,
      "learning_rate": 1.975181394454856e-05,
      "loss": 0.0002,
      "step": 125900
    },
    {
      "epoch": 6.05208783816251,
      "grad_norm": 0.22940655052661896,
      "learning_rate": 1.973980106674355e-05,
      "loss": 0.0001,
      "step": 125950
    },
    {
      "epoch": 6.054490413723512,
      "grad_norm": 0.1019551157951355,
      "learning_rate": 1.9727788188938544e-05,
      "loss": 0.0001,
      "step": 126000
    },
    {
      "epoch": 6.056892989284513,
      "grad_norm": 0.05486978590488434,
      "learning_rate": 1.9715775311133535e-05,
      "loss": 0.0001,
      "step": 126050
    },
    {
      "epoch": 6.059295564845514,
      "grad_norm": 0.018870389088988304,
      "learning_rate": 1.970376243332853e-05,
      "loss": 0.0002,
      "step": 126100
    },
    {
      "epoch": 6.0616981404065156,
      "grad_norm": 0.4030102491378784,
      "learning_rate": 1.9691749555523523e-05,
      "loss": 0.0001,
      "step": 126150
    },
    {
      "epoch": 6.064100715967517,
      "grad_norm": 0.2035244107246399,
      "learning_rate": 1.9679736677718517e-05,
      "loss": 0.0001,
      "step": 126200
    },
    {
      "epoch": 6.066503291528519,
      "grad_norm": 0.175560861825943,
      "learning_rate": 1.966772379991351e-05,
      "loss": 0.0001,
      "step": 126250
    },
    {
      "epoch": 6.06890586708952,
      "grad_norm": 0.12477342039346695,
      "learning_rate": 1.96557109221085e-05,
      "loss": 0.0005,
      "step": 126300
    },
    {
      "epoch": 6.071308442650522,
      "grad_norm": 0.10108957439661026,
      "learning_rate": 1.9643698044303493e-05,
      "loss": 0.0001,
      "step": 126350
    },
    {
      "epoch": 6.073711018211522,
      "grad_norm": 0.226363867521286,
      "learning_rate": 1.9631685166498488e-05,
      "loss": 0.0001,
      "step": 126400
    },
    {
      "epoch": 6.076113593772524,
      "grad_norm": 0.08804595470428467,
      "learning_rate": 1.9619672288693482e-05,
      "loss": 0.0001,
      "step": 126450
    },
    {
      "epoch": 6.0785161693335255,
      "grad_norm": 0.470859557390213,
      "learning_rate": 1.9607659410888473e-05,
      "loss": 0.0002,
      "step": 126500
    },
    {
      "epoch": 6.080918744894527,
      "grad_norm": 0.2753264009952545,
      "learning_rate": 1.9595646533083467e-05,
      "loss": 0.0001,
      "step": 126550
    },
    {
      "epoch": 6.0833213204555285,
      "grad_norm": 0.1164839118719101,
      "learning_rate": 1.958363365527846e-05,
      "loss": 0.0001,
      "step": 126600
    },
    {
      "epoch": 6.08572389601653,
      "grad_norm": 0.12090063095092773,
      "learning_rate": 1.9571620777473452e-05,
      "loss": 0.0001,
      "step": 126650
    },
    {
      "epoch": 6.088126471577531,
      "grad_norm": 0.11423895508050919,
      "learning_rate": 1.9559607899668446e-05,
      "loss": 0.0001,
      "step": 126700
    },
    {
      "epoch": 6.090529047138532,
      "grad_norm": 0.1562499850988388,
      "learning_rate": 1.9547595021863437e-05,
      "loss": 0.0001,
      "step": 126750
    },
    {
      "epoch": 6.092931622699534,
      "grad_norm": 0.11190442740917206,
      "learning_rate": 1.953558214405843e-05,
      "loss": 0.0001,
      "step": 126800
    },
    {
      "epoch": 6.095334198260535,
      "grad_norm": 0.13895131647586823,
      "learning_rate": 1.9523569266253425e-05,
      "loss": 0.0002,
      "step": 126850
    },
    {
      "epoch": 6.097736773821537,
      "grad_norm": 0.2944563925266266,
      "learning_rate": 1.951155638844842e-05,
      "loss": 0.0001,
      "step": 126900
    },
    {
      "epoch": 6.100139349382538,
      "grad_norm": 0.397222638130188,
      "learning_rate": 1.949954351064341e-05,
      "loss": 0.0003,
      "step": 126950
    },
    {
      "epoch": 6.102541924943539,
      "grad_norm": 0.180932879447937,
      "learning_rate": 1.9487530632838405e-05,
      "loss": 0.0001,
      "step": 127000
    },
    {
      "epoch": 6.104944500504541,
      "grad_norm": 0.24585266411304474,
      "learning_rate": 1.9475517755033395e-05,
      "loss": 0.0001,
      "step": 127050
    },
    {
      "epoch": 6.107347076065542,
      "grad_norm": 0.1564018577337265,
      "learning_rate": 1.946350487722839e-05,
      "loss": 0.0001,
      "step": 127100
    },
    {
      "epoch": 6.109749651626544,
      "grad_norm": 0.11268838495016098,
      "learning_rate": 1.9451491999423384e-05,
      "loss": 0.0001,
      "step": 127150
    },
    {
      "epoch": 6.112152227187545,
      "grad_norm": 0.48921388387680054,
      "learning_rate": 1.9439479121618375e-05,
      "loss": 0.0002,
      "step": 127200
    },
    {
      "epoch": 6.114554802748547,
      "grad_norm": 0.03942841291427612,
      "learning_rate": 1.942746624381337e-05,
      "loss": 0.0001,
      "step": 127250
    },
    {
      "epoch": 6.116957378309547,
      "grad_norm": 0.07317835837602615,
      "learning_rate": 1.9415453366008363e-05,
      "loss": 0.0001,
      "step": 127300
    },
    {
      "epoch": 6.119359953870549,
      "grad_norm": 0.5598053932189941,
      "learning_rate": 1.9403440488203357e-05,
      "loss": 0.0001,
      "step": 127350
    },
    {
      "epoch": 6.1217625294315505,
      "grad_norm": 0.14402545988559723,
      "learning_rate": 1.9391427610398348e-05,
      "loss": 0.0001,
      "step": 127400
    },
    {
      "epoch": 6.124165104992552,
      "grad_norm": 0.07309979945421219,
      "learning_rate": 1.937941473259334e-05,
      "loss": 0.0001,
      "step": 127450
    },
    {
      "epoch": 6.126567680553554,
      "grad_norm": 0.4679150879383087,
      "learning_rate": 1.9367401854788333e-05,
      "loss": 0.0001,
      "step": 127500
    },
    {
      "epoch": 6.128970256114555,
      "grad_norm": 0.21198241412639618,
      "learning_rate": 1.9355388976983327e-05,
      "loss": 0.0001,
      "step": 127550
    },
    {
      "epoch": 6.131372831675556,
      "grad_norm": 0.08036427199840546,
      "learning_rate": 1.934337609917832e-05,
      "loss": 0.0001,
      "step": 127600
    },
    {
      "epoch": 6.133775407236557,
      "grad_norm": 0.5277147889137268,
      "learning_rate": 1.9331363221373312e-05,
      "loss": 0.0001,
      "step": 127650
    },
    {
      "epoch": 6.136177982797559,
      "grad_norm": 0.12168201804161072,
      "learning_rate": 1.9319350343568307e-05,
      "loss": 0.0001,
      "step": 127700
    },
    {
      "epoch": 6.13858055835856,
      "grad_norm": 0.1979934722185135,
      "learning_rate": 1.93073374657633e-05,
      "loss": 0.0001,
      "step": 127750
    },
    {
      "epoch": 6.140983133919562,
      "grad_norm": 0.2239929437637329,
      "learning_rate": 1.929532458795829e-05,
      "loss": 0.0001,
      "step": 127800
    },
    {
      "epoch": 6.1433857094805635,
      "grad_norm": 0.1984988898038864,
      "learning_rate": 1.9283311710153286e-05,
      "loss": 0.0001,
      "step": 127850
    },
    {
      "epoch": 6.145788285041564,
      "grad_norm": 0.10844974219799042,
      "learning_rate": 1.9271298832348277e-05,
      "loss": 0.0001,
      "step": 127900
    },
    {
      "epoch": 6.148190860602566,
      "grad_norm": 0.44937533140182495,
      "learning_rate": 1.925928595454327e-05,
      "loss": 0.0001,
      "step": 127950
    },
    {
      "epoch": 6.150593436163567,
      "grad_norm": 0.13687929511070251,
      "learning_rate": 1.9247273076738265e-05,
      "loss": 0.0002,
      "step": 128000
    },
    {
      "epoch": 6.152996011724569,
      "grad_norm": 0.027714485302567482,
      "learning_rate": 1.923526019893326e-05,
      "loss": 0.0001,
      "step": 128050
    },
    {
      "epoch": 6.15539858728557,
      "grad_norm": 0.07951478660106659,
      "learning_rate": 1.922324732112825e-05,
      "loss": 0.0001,
      "step": 128100
    },
    {
      "epoch": 6.157801162846572,
      "grad_norm": 0.2287420779466629,
      "learning_rate": 1.921123444332324e-05,
      "loss": 0.0006,
      "step": 128150
    },
    {
      "epoch": 6.1602037384075725,
      "grad_norm": 0.406470388174057,
      "learning_rate": 1.9199221565518235e-05,
      "loss": 0.0001,
      "step": 128200
    },
    {
      "epoch": 6.162606313968574,
      "grad_norm": 0.35665255784988403,
      "learning_rate": 1.918720868771323e-05,
      "loss": 0.0001,
      "step": 128250
    },
    {
      "epoch": 6.165008889529576,
      "grad_norm": 0.045673321932554245,
      "learning_rate": 1.9175195809908224e-05,
      "loss": 0.0001,
      "step": 128300
    },
    {
      "epoch": 6.167411465090577,
      "grad_norm": 0.08221396058797836,
      "learning_rate": 1.9163182932103214e-05,
      "loss": 0.0001,
      "step": 128350
    },
    {
      "epoch": 6.169814040651579,
      "grad_norm": 0.4727121889591217,
      "learning_rate": 1.915117005429821e-05,
      "loss": 0.0002,
      "step": 128400
    },
    {
      "epoch": 6.17221661621258,
      "grad_norm": 0.35343560576438904,
      "learning_rate": 1.9139157176493203e-05,
      "loss": 0.0001,
      "step": 128450
    },
    {
      "epoch": 6.174619191773581,
      "grad_norm": 0.12407063692808151,
      "learning_rate": 1.9127144298688197e-05,
      "loss": 0.0001,
      "step": 128500
    },
    {
      "epoch": 6.177021767334582,
      "grad_norm": 0.09057576209306717,
      "learning_rate": 1.9115131420883188e-05,
      "loss": 0.0002,
      "step": 128550
    },
    {
      "epoch": 6.179424342895584,
      "grad_norm": 0.5635732412338257,
      "learning_rate": 1.910311854307818e-05,
      "loss": 0.0001,
      "step": 128600
    },
    {
      "epoch": 6.1818269184565855,
      "grad_norm": 0.14813132584095,
      "learning_rate": 1.9091105665273173e-05,
      "loss": 0.0001,
      "step": 128650
    },
    {
      "epoch": 6.184229494017587,
      "grad_norm": 0.231122225522995,
      "learning_rate": 1.9079092787468167e-05,
      "loss": 0.0005,
      "step": 128700
    },
    {
      "epoch": 6.186632069578589,
      "grad_norm": 0.17260916531085968,
      "learning_rate": 1.906707990966316e-05,
      "loss": 0.0002,
      "step": 128750
    },
    {
      "epoch": 6.189034645139589,
      "grad_norm": 0.5023479461669922,
      "learning_rate": 1.9055067031858152e-05,
      "loss": 0.0001,
      "step": 128800
    },
    {
      "epoch": 6.191437220700591,
      "grad_norm": 0.4448416829109192,
      "learning_rate": 1.9043054154053146e-05,
      "loss": 0.0001,
      "step": 128850
    },
    {
      "epoch": 6.193839796261592,
      "grad_norm": 0.05856449529528618,
      "learning_rate": 1.9031041276248137e-05,
      "loss": 0.0005,
      "step": 128900
    },
    {
      "epoch": 6.196242371822594,
      "grad_norm": 0.0854744166135788,
      "learning_rate": 1.901902839844313e-05,
      "loss": 0.0001,
      "step": 128950
    },
    {
      "epoch": 6.198644947383595,
      "grad_norm": 0.11329706758260727,
      "learning_rate": 1.9007015520638126e-05,
      "loss": 0.0001,
      "step": 129000
    },
    {
      "epoch": 6.201047522944597,
      "grad_norm": 0.042337872087955475,
      "learning_rate": 1.8995002642833116e-05,
      "loss": 0.0001,
      "step": 129050
    },
    {
      "epoch": 6.203450098505598,
      "grad_norm": 0.6739971041679382,
      "learning_rate": 1.898298976502811e-05,
      "loss": 0.0001,
      "step": 129100
    },
    {
      "epoch": 6.205852674066599,
      "grad_norm": 0.15915809571743011,
      "learning_rate": 1.8970976887223105e-05,
      "loss": 0.0002,
      "step": 129150
    },
    {
      "epoch": 6.208255249627601,
      "grad_norm": 0.46435752511024475,
      "learning_rate": 1.89589640094181e-05,
      "loss": 0.0002,
      "step": 129200
    },
    {
      "epoch": 6.210657825188602,
      "grad_norm": 0.19798843562602997,
      "learning_rate": 1.894695113161309e-05,
      "loss": 0.0001,
      "step": 129250
    },
    {
      "epoch": 6.213060400749604,
      "grad_norm": 0.18758104741573334,
      "learning_rate": 1.893493825380808e-05,
      "loss": 0.0002,
      "step": 129300
    },
    {
      "epoch": 6.215462976310605,
      "grad_norm": 0.04571692273020744,
      "learning_rate": 1.8922925376003075e-05,
      "loss": 0.0001,
      "step": 129350
    },
    {
      "epoch": 6.217865551871606,
      "grad_norm": 0.04015654698014259,
      "learning_rate": 1.891091249819807e-05,
      "loss": 0.0001,
      "step": 129400
    },
    {
      "epoch": 6.2202681274326075,
      "grad_norm": 0.4612230658531189,
      "learning_rate": 1.8898899620393063e-05,
      "loss": 0.0001,
      "step": 129450
    },
    {
      "epoch": 6.222670702993609,
      "grad_norm": 0.09327492117881775,
      "learning_rate": 1.8886886742588054e-05,
      "loss": 0.0002,
      "step": 129500
    },
    {
      "epoch": 6.225073278554611,
      "grad_norm": 0.3579130172729492,
      "learning_rate": 1.887487386478305e-05,
      "loss": 0.0002,
      "step": 129550
    },
    {
      "epoch": 6.227475854115612,
      "grad_norm": 0.07708870619535446,
      "learning_rate": 1.8862860986978043e-05,
      "loss": 0.0001,
      "step": 129600
    },
    {
      "epoch": 6.229878429676614,
      "grad_norm": 0.08756686002016068,
      "learning_rate": 1.8850848109173034e-05,
      "loss": 0.0001,
      "step": 129650
    },
    {
      "epoch": 6.232281005237614,
      "grad_norm": 0.11059442907571793,
      "learning_rate": 1.8838835231368028e-05,
      "loss": 0.0001,
      "step": 129700
    },
    {
      "epoch": 6.234683580798616,
      "grad_norm": 0.10396957397460938,
      "learning_rate": 1.882682235356302e-05,
      "loss": 0.0001,
      "step": 129750
    },
    {
      "epoch": 6.237086156359617,
      "grad_norm": 0.4175136387348175,
      "learning_rate": 1.8814809475758013e-05,
      "loss": 0.0001,
      "step": 129800
    },
    {
      "epoch": 6.239488731920619,
      "grad_norm": 0.09325001388788223,
      "learning_rate": 1.8802796597953007e-05,
      "loss": 0.0002,
      "step": 129850
    },
    {
      "epoch": 6.2418913074816205,
      "grad_norm": 0.32427963614463806,
      "learning_rate": 1.8790783720148e-05,
      "loss": 0.0001,
      "step": 129900
    },
    {
      "epoch": 6.244293883042622,
      "grad_norm": 0.21634608507156372,
      "learning_rate": 1.8778770842342992e-05,
      "loss": 0.0001,
      "step": 129950
    },
    {
      "epoch": 6.246696458603623,
      "grad_norm": 0.11229259520769119,
      "learning_rate": 1.8766757964537983e-05,
      "loss": 0.0001,
      "step": 130000
    },
    {
      "epoch": 6.249099034164624,
      "grad_norm": 0.07664384692907333,
      "learning_rate": 1.8754745086732977e-05,
      "loss": 0.0001,
      "step": 130050
    },
    {
      "epoch": 6.251501609725626,
      "grad_norm": 0.07142717391252518,
      "learning_rate": 1.874273220892797e-05,
      "loss": 0.0001,
      "step": 130100
    },
    {
      "epoch": 6.253904185286627,
      "grad_norm": 0.36289292573928833,
      "learning_rate": 1.8730719331122965e-05,
      "loss": 0.0001,
      "step": 130150
    },
    {
      "epoch": 6.256306760847629,
      "grad_norm": 0.3861747682094574,
      "learning_rate": 1.8718706453317956e-05,
      "loss": 0.0001,
      "step": 130200
    },
    {
      "epoch": 6.25870933640863,
      "grad_norm": 0.18833866715431213,
      "learning_rate": 1.870669357551295e-05,
      "loss": 0.0001,
      "step": 130250
    },
    {
      "epoch": 6.261111911969632,
      "grad_norm": 0.13177445530891418,
      "learning_rate": 1.8694680697707945e-05,
      "loss": 0.0001,
      "step": 130300
    },
    {
      "epoch": 6.263514487530633,
      "grad_norm": 0.0912337601184845,
      "learning_rate": 1.868266781990294e-05,
      "loss": 0.0001,
      "step": 130350
    },
    {
      "epoch": 6.265917063091634,
      "grad_norm": 0.25724226236343384,
      "learning_rate": 1.867065494209793e-05,
      "loss": 0.0002,
      "step": 130400
    },
    {
      "epoch": 6.268319638652636,
      "grad_norm": 0.09828288108110428,
      "learning_rate": 1.865864206429292e-05,
      "loss": 0.0001,
      "step": 130450
    },
    {
      "epoch": 6.270722214213637,
      "grad_norm": 0.23069745302200317,
      "learning_rate": 1.8646629186487915e-05,
      "loss": 0.0001,
      "step": 130500
    },
    {
      "epoch": 6.273124789774639,
      "grad_norm": 0.05061084032058716,
      "learning_rate": 1.863461630868291e-05,
      "loss": 0.0001,
      "step": 130550
    },
    {
      "epoch": 6.275527365335639,
      "grad_norm": 0.20807959139347076,
      "learning_rate": 1.8622603430877903e-05,
      "loss": 0.0001,
      "step": 130600
    },
    {
      "epoch": 6.277929940896641,
      "grad_norm": 0.14611566066741943,
      "learning_rate": 1.8610590553072897e-05,
      "loss": 0.0001,
      "step": 130650
    },
    {
      "epoch": 6.2803325164576425,
      "grad_norm": 0.26539552211761475,
      "learning_rate": 1.8598577675267888e-05,
      "loss": 0.0001,
      "step": 130700
    },
    {
      "epoch": 6.282735092018644,
      "grad_norm": 0.10257980972528458,
      "learning_rate": 1.858656479746288e-05,
      "loss": 0.0001,
      "step": 130750
    },
    {
      "epoch": 6.2851376675796455,
      "grad_norm": 0.18131090700626373,
      "learning_rate": 1.8574551919657873e-05,
      "loss": 0.0002,
      "step": 130800
    },
    {
      "epoch": 6.287540243140647,
      "grad_norm": 0.44530701637268066,
      "learning_rate": 1.8562539041852868e-05,
      "loss": 0.0001,
      "step": 130850
    },
    {
      "epoch": 6.289942818701649,
      "grad_norm": 0.23449012637138367,
      "learning_rate": 1.855052616404786e-05,
      "loss": 0.0006,
      "step": 130900
    },
    {
      "epoch": 6.292345394262649,
      "grad_norm": 0.24670164287090302,
      "learning_rate": 1.8538513286242853e-05,
      "loss": 0.0001,
      "step": 130950
    },
    {
      "epoch": 6.294747969823651,
      "grad_norm": 0.08235560357570648,
      "learning_rate": 1.8526500408437847e-05,
      "loss": 0.0002,
      "step": 131000
    },
    {
      "epoch": 6.297150545384652,
      "grad_norm": 0.1608528196811676,
      "learning_rate": 1.851448753063284e-05,
      "loss": 0.0001,
      "step": 131050
    },
    {
      "epoch": 6.299553120945654,
      "grad_norm": 0.14994609355926514,
      "learning_rate": 1.8502474652827835e-05,
      "loss": 0.0001,
      "step": 131100
    },
    {
      "epoch": 6.301955696506655,
      "grad_norm": 0.25496533513069153,
      "learning_rate": 1.8490461775022823e-05,
      "loss": 0.0006,
      "step": 131150
    },
    {
      "epoch": 6.304358272067656,
      "grad_norm": 0.11446388065814972,
      "learning_rate": 1.8478448897217817e-05,
      "loss": 0.0001,
      "step": 131200
    },
    {
      "epoch": 6.306760847628658,
      "grad_norm": 0.22629211843013763,
      "learning_rate": 1.846643601941281e-05,
      "loss": 0.0002,
      "step": 131250
    },
    {
      "epoch": 6.309163423189659,
      "grad_norm": 0.45300620794296265,
      "learning_rate": 1.8454423141607805e-05,
      "loss": 0.0002,
      "step": 131300
    },
    {
      "epoch": 6.311565998750661,
      "grad_norm": 0.22783882915973663,
      "learning_rate": 1.84424102638028e-05,
      "loss": 0.0001,
      "step": 131350
    },
    {
      "epoch": 6.313968574311662,
      "grad_norm": 0.30043238401412964,
      "learning_rate": 1.843039738599779e-05,
      "loss": 0.0003,
      "step": 131400
    },
    {
      "epoch": 6.316371149872664,
      "grad_norm": 0.3686692714691162,
      "learning_rate": 1.8418384508192785e-05,
      "loss": 0.0002,
      "step": 131450
    },
    {
      "epoch": 6.318773725433665,
      "grad_norm": 0.22731903195381165,
      "learning_rate": 1.8406371630387775e-05,
      "loss": 0.0001,
      "step": 131500
    },
    {
      "epoch": 6.321176300994666,
      "grad_norm": 0.13972242176532745,
      "learning_rate": 1.839435875258277e-05,
      "loss": 0.0001,
      "step": 131550
    },
    {
      "epoch": 6.3235788765556675,
      "grad_norm": 0.1288420706987381,
      "learning_rate": 1.8382345874777764e-05,
      "loss": 0.0001,
      "step": 131600
    },
    {
      "epoch": 6.325981452116669,
      "grad_norm": 0.14556850492954254,
      "learning_rate": 1.8370332996972755e-05,
      "loss": 0.0003,
      "step": 131650
    },
    {
      "epoch": 6.328384027677671,
      "grad_norm": 0.08273941278457642,
      "learning_rate": 1.835832011916775e-05,
      "loss": 0.0001,
      "step": 131700
    },
    {
      "epoch": 6.330786603238672,
      "grad_norm": 0.10272020101547241,
      "learning_rate": 1.8346307241362743e-05,
      "loss": 0.0001,
      "step": 131750
    },
    {
      "epoch": 6.333189178799673,
      "grad_norm": 0.29447221755981445,
      "learning_rate": 1.8334294363557737e-05,
      "loss": 0.0001,
      "step": 131800
    },
    {
      "epoch": 6.335591754360674,
      "grad_norm": 0.541584312915802,
      "learning_rate": 1.8322281485752728e-05,
      "loss": 0.0002,
      "step": 131850
    },
    {
      "epoch": 6.337994329921676,
      "grad_norm": 0.20423457026481628,
      "learning_rate": 1.831026860794772e-05,
      "loss": 0.0001,
      "step": 131900
    },
    {
      "epoch": 6.340396905482677,
      "grad_norm": 0.07532486319541931,
      "learning_rate": 1.8298255730142713e-05,
      "loss": 0.0001,
      "step": 131950
    },
    {
      "epoch": 6.342799481043679,
      "grad_norm": 0.4724864661693573,
      "learning_rate": 1.8286242852337707e-05,
      "loss": 0.0002,
      "step": 132000
    },
    {
      "epoch": 6.3452020566046805,
      "grad_norm": 0.08050958812236786,
      "learning_rate": 1.82742299745327e-05,
      "loss": 0.0001,
      "step": 132050
    },
    {
      "epoch": 6.347604632165682,
      "grad_norm": 0.4258626699447632,
      "learning_rate": 1.8262217096727692e-05,
      "loss": 0.0001,
      "step": 132100
    },
    {
      "epoch": 6.350007207726683,
      "grad_norm": 0.039128877222537994,
      "learning_rate": 1.8250204218922687e-05,
      "loss": 0.0001,
      "step": 132150
    },
    {
      "epoch": 6.352409783287684,
      "grad_norm": 0.0873044803738594,
      "learning_rate": 1.823819134111768e-05,
      "loss": 0.0001,
      "step": 132200
    },
    {
      "epoch": 6.354812358848686,
      "grad_norm": 0.23706702888011932,
      "learning_rate": 1.822617846331267e-05,
      "loss": 0.0001,
      "step": 132250
    },
    {
      "epoch": 6.357214934409687,
      "grad_norm": 0.0819479450583458,
      "learning_rate": 1.8214165585507666e-05,
      "loss": 0.0001,
      "step": 132300
    },
    {
      "epoch": 6.359617509970689,
      "grad_norm": 0.1374352127313614,
      "learning_rate": 1.8202152707702657e-05,
      "loss": 0.0001,
      "step": 132350
    },
    {
      "epoch": 6.3620200855316895,
      "grad_norm": 0.32928478717803955,
      "learning_rate": 1.819013982989765e-05,
      "loss": 0.0001,
      "step": 132400
    },
    {
      "epoch": 6.364422661092691,
      "grad_norm": 0.2876192033290863,
      "learning_rate": 1.8178126952092645e-05,
      "loss": 0.0001,
      "step": 132450
    },
    {
      "epoch": 6.366825236653693,
      "grad_norm": 0.0939851850271225,
      "learning_rate": 1.816611407428764e-05,
      "loss": 0.0001,
      "step": 132500
    },
    {
      "epoch": 6.369227812214694,
      "grad_norm": 0.057658351957798004,
      "learning_rate": 1.815410119648263e-05,
      "loss": 0.0001,
      "step": 132550
    },
    {
      "epoch": 6.371630387775696,
      "grad_norm": 0.4752644896507263,
      "learning_rate": 1.814208831867762e-05,
      "loss": 0.0001,
      "step": 132600
    },
    {
      "epoch": 6.374032963336697,
      "grad_norm": 0.1233634278178215,
      "learning_rate": 1.8130075440872615e-05,
      "loss": 0.0001,
      "step": 132650
    },
    {
      "epoch": 6.376435538897699,
      "grad_norm": 0.2491973638534546,
      "learning_rate": 1.811806256306761e-05,
      "loss": 0.0001,
      "step": 132700
    },
    {
      "epoch": 6.378838114458699,
      "grad_norm": 0.050837960094213486,
      "learning_rate": 1.8106049685262604e-05,
      "loss": 0.0001,
      "step": 132750
    },
    {
      "epoch": 6.381240690019701,
      "grad_norm": 0.14323820173740387,
      "learning_rate": 1.8094036807457594e-05,
      "loss": 0.0002,
      "step": 132800
    },
    {
      "epoch": 6.3836432655807025,
      "grad_norm": 0.10014642775058746,
      "learning_rate": 1.808202392965259e-05,
      "loss": 0.0001,
      "step": 132850
    },
    {
      "epoch": 6.386045841141704,
      "grad_norm": 0.6749870777130127,
      "learning_rate": 1.8070011051847583e-05,
      "loss": 0.0002,
      "step": 132900
    },
    {
      "epoch": 6.388448416702706,
      "grad_norm": 0.15946316719055176,
      "learning_rate": 1.8057998174042577e-05,
      "loss": 0.0005,
      "step": 132950
    },
    {
      "epoch": 6.390850992263706,
      "grad_norm": 0.4038885235786438,
      "learning_rate": 1.8045985296237568e-05,
      "loss": 0.0001,
      "step": 133000
    },
    {
      "epoch": 6.393253567824708,
      "grad_norm": 0.4082212448120117,
      "learning_rate": 1.803397241843256e-05,
      "loss": 0.0001,
      "step": 133050
    },
    {
      "epoch": 6.395656143385709,
      "grad_norm": 0.27405425906181335,
      "learning_rate": 1.8021959540627553e-05,
      "loss": 0.0001,
      "step": 133100
    },
    {
      "epoch": 6.398058718946711,
      "grad_norm": 0.22640962898731232,
      "learning_rate": 1.8009946662822547e-05,
      "loss": 0.0001,
      "step": 133150
    },
    {
      "epoch": 6.400461294507712,
      "grad_norm": 0.11126557737588882,
      "learning_rate": 1.799793378501754e-05,
      "loss": 0.0001,
      "step": 133200
    },
    {
      "epoch": 6.402863870068714,
      "grad_norm": 0.26938843727111816,
      "learning_rate": 1.7985920907212532e-05,
      "loss": 0.0004,
      "step": 133250
    },
    {
      "epoch": 6.4052664456297155,
      "grad_norm": 0.33240166306495667,
      "learning_rate": 1.7973908029407526e-05,
      "loss": 0.0006,
      "step": 133300
    },
    {
      "epoch": 6.407669021190716,
      "grad_norm": 0.2233443558216095,
      "learning_rate": 1.7961895151602517e-05,
      "loss": 0.0001,
      "step": 133350
    },
    {
      "epoch": 6.410071596751718,
      "grad_norm": 0.7348628044128418,
      "learning_rate": 1.794988227379751e-05,
      "loss": 0.0005,
      "step": 133400
    },
    {
      "epoch": 6.412474172312719,
      "grad_norm": 0.06551425158977509,
      "learning_rate": 1.7937869395992506e-05,
      "loss": 0.0003,
      "step": 133450
    },
    {
      "epoch": 6.414876747873721,
      "grad_norm": 0.04592423141002655,
      "learning_rate": 1.7925856518187496e-05,
      "loss": 0.0001,
      "step": 133500
    },
    {
      "epoch": 6.417279323434722,
      "grad_norm": 0.18390777707099915,
      "learning_rate": 1.791384364038249e-05,
      "loss": 0.0001,
      "step": 133550
    },
    {
      "epoch": 6.419681898995723,
      "grad_norm": 0.6877168416976929,
      "learning_rate": 1.7901830762577485e-05,
      "loss": 0.0002,
      "step": 133600
    },
    {
      "epoch": 6.4220844745567245,
      "grad_norm": 0.34215036034584045,
      "learning_rate": 1.788981788477248e-05,
      "loss": 0.0002,
      "step": 133650
    },
    {
      "epoch": 6.424487050117726,
      "grad_norm": 0.2593131363391876,
      "learning_rate": 1.787780500696747e-05,
      "loss": 0.0001,
      "step": 133700
    },
    {
      "epoch": 6.426889625678728,
      "grad_norm": 0.4811227023601532,
      "learning_rate": 1.786579212916246e-05,
      "loss": 0.0001,
      "step": 133750
    },
    {
      "epoch": 6.429292201239729,
      "grad_norm": 0.09660197794437408,
      "learning_rate": 1.7853779251357455e-05,
      "loss": 0.0001,
      "step": 133800
    },
    {
      "epoch": 6.431694776800731,
      "grad_norm": 0.5419576168060303,
      "learning_rate": 1.784176637355245e-05,
      "loss": 0.0001,
      "step": 133850
    },
    {
      "epoch": 6.434097352361732,
      "grad_norm": 0.09197241812944412,
      "learning_rate": 1.7829753495747443e-05,
      "loss": 0.0001,
      "step": 133900
    },
    {
      "epoch": 6.436499927922733,
      "grad_norm": 0.2481326460838318,
      "learning_rate": 1.7817740617942434e-05,
      "loss": 0.0001,
      "step": 133950
    },
    {
      "epoch": 6.438902503483734,
      "grad_norm": 0.11737629771232605,
      "learning_rate": 1.780572774013743e-05,
      "loss": 0.0001,
      "step": 134000
    },
    {
      "epoch": 6.441305079044736,
      "grad_norm": 0.18138110637664795,
      "learning_rate": 1.7793714862332423e-05,
      "loss": 0.0001,
      "step": 134050
    },
    {
      "epoch": 6.4437076546057375,
      "grad_norm": 0.45607709884643555,
      "learning_rate": 1.7781701984527413e-05,
      "loss": 0.0001,
      "step": 134100
    },
    {
      "epoch": 6.446110230166739,
      "grad_norm": 0.23574873805046082,
      "learning_rate": 1.7769689106722408e-05,
      "loss": 0.0001,
      "step": 134150
    },
    {
      "epoch": 6.4485128057277405,
      "grad_norm": 0.17132191359996796,
      "learning_rate": 1.77576762289174e-05,
      "loss": 0.0001,
      "step": 134200
    },
    {
      "epoch": 6.450915381288741,
      "grad_norm": 0.049363695085048676,
      "learning_rate": 1.7745663351112393e-05,
      "loss": 0.0001,
      "step": 134250
    },
    {
      "epoch": 6.453317956849743,
      "grad_norm": 0.15696753561496735,
      "learning_rate": 1.7733650473307387e-05,
      "loss": 0.0001,
      "step": 134300
    },
    {
      "epoch": 6.455720532410744,
      "grad_norm": 0.1128811240196228,
      "learning_rate": 1.772163759550238e-05,
      "loss": 0.0005,
      "step": 134350
    },
    {
      "epoch": 6.458123107971746,
      "grad_norm": 0.10487926751375198,
      "learning_rate": 1.7709624717697372e-05,
      "loss": 0.0001,
      "step": 134400
    },
    {
      "epoch": 6.460525683532747,
      "grad_norm": 0.19964691996574402,
      "learning_rate": 1.7697611839892366e-05,
      "loss": 0.0001,
      "step": 134450
    },
    {
      "epoch": 6.462928259093749,
      "grad_norm": 0.06582420319318771,
      "learning_rate": 1.7685598962087357e-05,
      "loss": 0.0001,
      "step": 134500
    },
    {
      "epoch": 6.46533083465475,
      "grad_norm": 0.13782332837581635,
      "learning_rate": 1.767358608428235e-05,
      "loss": 0.0001,
      "step": 134550
    },
    {
      "epoch": 6.467733410215751,
      "grad_norm": 0.08142273128032684,
      "learning_rate": 1.7661573206477345e-05,
      "loss": 0.0006,
      "step": 134600
    },
    {
      "epoch": 6.470135985776753,
      "grad_norm": 0.21174710988998413,
      "learning_rate": 1.7649560328672336e-05,
      "loss": 0.0001,
      "step": 134650
    },
    {
      "epoch": 6.472538561337754,
      "grad_norm": 0.36705201864242554,
      "learning_rate": 1.763754745086733e-05,
      "loss": 0.0001,
      "step": 134700
    },
    {
      "epoch": 6.474941136898756,
      "grad_norm": 0.1043703705072403,
      "learning_rate": 1.7625534573062325e-05,
      "loss": 0.0001,
      "step": 134750
    },
    {
      "epoch": 6.477343712459757,
      "grad_norm": 0.4741447865962982,
      "learning_rate": 1.761352169525732e-05,
      "loss": 0.0002,
      "step": 134800
    },
    {
      "epoch": 6.479746288020758,
      "grad_norm": 0.2926101088523865,
      "learning_rate": 1.760150881745231e-05,
      "loss": 0.0002,
      "step": 134850
    },
    {
      "epoch": 6.4821488635817595,
      "grad_norm": 0.16073410212993622,
      "learning_rate": 1.75894959396473e-05,
      "loss": 0.0001,
      "step": 134900
    },
    {
      "epoch": 6.484551439142761,
      "grad_norm": 0.19355078041553497,
      "learning_rate": 1.7577483061842295e-05,
      "loss": 0.0001,
      "step": 134950
    },
    {
      "epoch": 6.4869540147037625,
      "grad_norm": 0.23606573045253754,
      "learning_rate": 1.756547018403729e-05,
      "loss": 0.0001,
      "step": 135000
    },
    {
      "epoch": 6.489356590264764,
      "grad_norm": 0.34854602813720703,
      "learning_rate": 1.7553457306232283e-05,
      "loss": 0.0001,
      "step": 135050
    },
    {
      "epoch": 6.491759165825766,
      "grad_norm": 0.189479798078537,
      "learning_rate": 1.7541444428427274e-05,
      "loss": 0.0001,
      "step": 135100
    },
    {
      "epoch": 6.494161741386766,
      "grad_norm": 0.2254709005355835,
      "learning_rate": 1.7529431550622268e-05,
      "loss": 0.0001,
      "step": 135150
    },
    {
      "epoch": 6.496564316947768,
      "grad_norm": 0.25570812821388245,
      "learning_rate": 1.751741867281726e-05,
      "loss": 0.0001,
      "step": 135200
    },
    {
      "epoch": 6.498966892508769,
      "grad_norm": 0.13437195122241974,
      "learning_rate": 1.7505405795012253e-05,
      "loss": 0.0001,
      "step": 135250
    },
    {
      "epoch": 6.501369468069771,
      "grad_norm": 0.2459309846162796,
      "learning_rate": 1.7493392917207247e-05,
      "loss": 0.0005,
      "step": 135300
    },
    {
      "epoch": 6.503772043630772,
      "grad_norm": 0.12868529558181763,
      "learning_rate": 1.748138003940224e-05,
      "loss": 0.0001,
      "step": 135350
    },
    {
      "epoch": 6.506174619191773,
      "grad_norm": 0.07935814559459686,
      "learning_rate": 1.7469367161597233e-05,
      "loss": 0.0006,
      "step": 135400
    },
    {
      "epoch": 6.508577194752775,
      "grad_norm": 0.10818377882242203,
      "learning_rate": 1.7457354283792227e-05,
      "loss": 0.0002,
      "step": 135450
    },
    {
      "epoch": 6.510979770313776,
      "grad_norm": 0.04833656921982765,
      "learning_rate": 1.744534140598722e-05,
      "loss": 0.0001,
      "step": 135500
    },
    {
      "epoch": 6.513382345874778,
      "grad_norm": 0.19378794729709625,
      "learning_rate": 1.7433328528182212e-05,
      "loss": 0.0001,
      "step": 135550
    },
    {
      "epoch": 6.515784921435779,
      "grad_norm": 0.3335507810115814,
      "learning_rate": 1.7421315650377203e-05,
      "loss": 0.0002,
      "step": 135600
    },
    {
      "epoch": 6.518187496996781,
      "grad_norm": 0.04689841717481613,
      "learning_rate": 1.7409302772572197e-05,
      "loss": 0.0002,
      "step": 135650
    },
    {
      "epoch": 6.520590072557782,
      "grad_norm": 0.04287208989262581,
      "learning_rate": 1.739728989476719e-05,
      "loss": 0.0002,
      "step": 135700
    },
    {
      "epoch": 6.522992648118783,
      "grad_norm": 0.2284073680639267,
      "learning_rate": 1.7385277016962185e-05,
      "loss": 0.0001,
      "step": 135750
    },
    {
      "epoch": 6.5253952236797845,
      "grad_norm": 0.31690382957458496,
      "learning_rate": 1.7373264139157176e-05,
      "loss": 0.0001,
      "step": 135800
    },
    {
      "epoch": 6.527797799240786,
      "grad_norm": 0.44379228353500366,
      "learning_rate": 1.736125126135217e-05,
      "loss": 0.0001,
      "step": 135850
    },
    {
      "epoch": 6.530200374801788,
      "grad_norm": 0.1355631798505783,
      "learning_rate": 1.7349238383547164e-05,
      "loss": 0.0001,
      "step": 135900
    },
    {
      "epoch": 6.532602950362789,
      "grad_norm": 0.15538862347602844,
      "learning_rate": 1.7337225505742155e-05,
      "loss": 0.0001,
      "step": 135950
    },
    {
      "epoch": 6.53500552592379,
      "grad_norm": 0.017681755125522614,
      "learning_rate": 1.732521262793715e-05,
      "loss": 0.0001,
      "step": 136000
    },
    {
      "epoch": 6.537408101484791,
      "grad_norm": 0.16074073314666748,
      "learning_rate": 1.731319975013214e-05,
      "loss": 0.0002,
      "step": 136050
    },
    {
      "epoch": 6.539810677045793,
      "grad_norm": 0.16642427444458008,
      "learning_rate": 1.7301186872327135e-05,
      "loss": 0.0001,
      "step": 136100
    },
    {
      "epoch": 6.542213252606794,
      "grad_norm": 0.040009740740060806,
      "learning_rate": 1.728917399452213e-05,
      "loss": 0.0001,
      "step": 136150
    },
    {
      "epoch": 6.544615828167796,
      "grad_norm": 0.26146233081817627,
      "learning_rate": 1.7277161116717123e-05,
      "loss": 0.0001,
      "step": 136200
    },
    {
      "epoch": 6.5470184037287975,
      "grad_norm": 0.36993512511253357,
      "learning_rate": 1.7265148238912117e-05,
      "loss": 0.0005,
      "step": 136250
    },
    {
      "epoch": 6.549420979289799,
      "grad_norm": 0.28498759865760803,
      "learning_rate": 1.7253135361107108e-05,
      "loss": 0.0001,
      "step": 136300
    },
    {
      "epoch": 6.5518235548508,
      "grad_norm": 0.33084040880203247,
      "learning_rate": 1.72411224833021e-05,
      "loss": 0.0001,
      "step": 136350
    },
    {
      "epoch": 6.554226130411801,
      "grad_norm": 0.22376911342144012,
      "learning_rate": 1.7229109605497093e-05,
      "loss": 0.0001,
      "step": 136400
    },
    {
      "epoch": 6.556628705972803,
      "grad_norm": 0.14530311524868011,
      "learning_rate": 1.7217096727692087e-05,
      "loss": 0.0005,
      "step": 136450
    },
    {
      "epoch": 6.559031281533804,
      "grad_norm": 0.1261327564716339,
      "learning_rate": 1.7205083849887078e-05,
      "loss": 0.0001,
      "step": 136500
    },
    {
      "epoch": 6.561433857094806,
      "grad_norm": 0.16246671974658966,
      "learning_rate": 1.7193070972082072e-05,
      "loss": 0.0001,
      "step": 136550
    },
    {
      "epoch": 6.563836432655807,
      "grad_norm": 0.591511070728302,
      "learning_rate": 1.7181058094277067e-05,
      "loss": 0.0001,
      "step": 136600
    },
    {
      "epoch": 6.566239008216808,
      "grad_norm": 0.05617478862404823,
      "learning_rate": 1.716904521647206e-05,
      "loss": 0.0001,
      "step": 136650
    },
    {
      "epoch": 6.56864158377781,
      "grad_norm": 0.24603869020938873,
      "learning_rate": 1.715703233866705e-05,
      "loss": 0.0001,
      "step": 136700
    },
    {
      "epoch": 6.571044159338811,
      "grad_norm": 0.21972818672657013,
      "learning_rate": 1.7145019460862042e-05,
      "loss": 0.0001,
      "step": 136750
    },
    {
      "epoch": 6.573446734899813,
      "grad_norm": 0.17652998864650726,
      "learning_rate": 1.7133006583057037e-05,
      "loss": 0.0001,
      "step": 136800
    },
    {
      "epoch": 6.575849310460814,
      "grad_norm": 0.05093063414096832,
      "learning_rate": 1.712099370525203e-05,
      "loss": 0.0001,
      "step": 136850
    },
    {
      "epoch": 6.578251886021816,
      "grad_norm": 0.11569606512784958,
      "learning_rate": 1.7108980827447025e-05,
      "loss": 0.0003,
      "step": 136900
    },
    {
      "epoch": 6.580654461582816,
      "grad_norm": 0.3686594069004059,
      "learning_rate": 1.709696794964202e-05,
      "loss": 0.0002,
      "step": 136950
    },
    {
      "epoch": 6.583057037143818,
      "grad_norm": 0.1839098334312439,
      "learning_rate": 1.708495507183701e-05,
      "loss": 0.0001,
      "step": 137000
    },
    {
      "epoch": 6.5854596127048195,
      "grad_norm": 0.09033866226673126,
      "learning_rate": 1.7072942194032004e-05,
      "loss": 0.0001,
      "step": 137050
    },
    {
      "epoch": 6.587862188265821,
      "grad_norm": 0.2725735604763031,
      "learning_rate": 1.7060929316226995e-05,
      "loss": 0.0001,
      "step": 137100
    },
    {
      "epoch": 6.590264763826823,
      "grad_norm": 0.17256133258342743,
      "learning_rate": 1.704891643842199e-05,
      "loss": 0.0001,
      "step": 137150
    },
    {
      "epoch": 6.592667339387824,
      "grad_norm": 0.12335246801376343,
      "learning_rate": 1.7036903560616984e-05,
      "loss": 0.0001,
      "step": 137200
    },
    {
      "epoch": 6.595069914948825,
      "grad_norm": 0.05530235171318054,
      "learning_rate": 1.7024890682811974e-05,
      "loss": 0.0001,
      "step": 137250
    },
    {
      "epoch": 6.597472490509826,
      "grad_norm": 0.45190486311912537,
      "learning_rate": 1.701287780500697e-05,
      "loss": 0.0001,
      "step": 137300
    },
    {
      "epoch": 6.599875066070828,
      "grad_norm": 0.523161768913269,
      "learning_rate": 1.7000864927201963e-05,
      "loss": 0.0001,
      "step": 137350
    },
    {
      "epoch": 6.602277641631829,
      "grad_norm": 0.32799074053764343,
      "learning_rate": 1.6988852049396957e-05,
      "loss": 0.0001,
      "step": 137400
    },
    {
      "epoch": 6.604680217192831,
      "grad_norm": 0.1550181359052658,
      "learning_rate": 1.6976839171591944e-05,
      "loss": 0.0001,
      "step": 137450
    },
    {
      "epoch": 6.6070827927538325,
      "grad_norm": 0.19536326825618744,
      "learning_rate": 1.696482629378694e-05,
      "loss": 0.0001,
      "step": 137500
    },
    {
      "epoch": 6.609485368314833,
      "grad_norm": 0.15535970032215118,
      "learning_rate": 1.6952813415981933e-05,
      "loss": 0.0001,
      "step": 137550
    },
    {
      "epoch": 6.611887943875835,
      "grad_norm": 0.3047086298465729,
      "learning_rate": 1.6940800538176927e-05,
      "loss": 0.0001,
      "step": 137600
    },
    {
      "epoch": 6.614290519436836,
      "grad_norm": 0.13249054551124573,
      "learning_rate": 1.692878766037192e-05,
      "loss": 0.0002,
      "step": 137650
    },
    {
      "epoch": 6.616693094997838,
      "grad_norm": 0.09355130791664124,
      "learning_rate": 1.6916774782566912e-05,
      "loss": 0.0001,
      "step": 137700
    },
    {
      "epoch": 6.619095670558839,
      "grad_norm": 0.24752987921237946,
      "learning_rate": 1.6904761904761906e-05,
      "loss": 0.0001,
      "step": 137750
    },
    {
      "epoch": 6.621498246119841,
      "grad_norm": 0.07247112691402435,
      "learning_rate": 1.68927490269569e-05,
      "loss": 0.0001,
      "step": 137800
    },
    {
      "epoch": 6.6239008216808415,
      "grad_norm": 0.13990281522274017,
      "learning_rate": 1.688073614915189e-05,
      "loss": 0.0001,
      "step": 137850
    },
    {
      "epoch": 6.626303397241843,
      "grad_norm": 0.27389398217201233,
      "learning_rate": 1.6868723271346886e-05,
      "loss": 0.0004,
      "step": 137900
    },
    {
      "epoch": 6.628705972802845,
      "grad_norm": 0.07993581146001816,
      "learning_rate": 1.6856710393541876e-05,
      "loss": 0.0001,
      "step": 137950
    },
    {
      "epoch": 6.631108548363846,
      "grad_norm": 0.27012383937835693,
      "learning_rate": 1.684469751573687e-05,
      "loss": 0.0001,
      "step": 138000
    },
    {
      "epoch": 6.633511123924848,
      "grad_norm": 0.18854834139347076,
      "learning_rate": 1.6832684637931865e-05,
      "loss": 0.0001,
      "step": 138050
    },
    {
      "epoch": 6.635913699485849,
      "grad_norm": 0.41694173216819763,
      "learning_rate": 1.682067176012686e-05,
      "loss": 0.0004,
      "step": 138100
    },
    {
      "epoch": 6.63831627504685,
      "grad_norm": 0.13632725179195404,
      "learning_rate": 1.680865888232185e-05,
      "loss": 0.0001,
      "step": 138150
    },
    {
      "epoch": 6.640718850607851,
      "grad_norm": 0.1627987027168274,
      "learning_rate": 1.679664600451684e-05,
      "loss": 0.0001,
      "step": 138200
    },
    {
      "epoch": 6.643121426168853,
      "grad_norm": 0.35653573274612427,
      "learning_rate": 1.6784633126711835e-05,
      "loss": 0.0002,
      "step": 138250
    },
    {
      "epoch": 6.6455240017298545,
      "grad_norm": 0.15362319350242615,
      "learning_rate": 1.677262024890683e-05,
      "loss": 0.0001,
      "step": 138300
    },
    {
      "epoch": 6.647926577290856,
      "grad_norm": 0.15111777186393738,
      "learning_rate": 1.6760607371101823e-05,
      "loss": 0.0001,
      "step": 138350
    },
    {
      "epoch": 6.6503291528518576,
      "grad_norm": 0.07834082841873169,
      "learning_rate": 1.6748594493296814e-05,
      "loss": 0.0001,
      "step": 138400
    },
    {
      "epoch": 6.652731728412858,
      "grad_norm": 0.06768140941858292,
      "learning_rate": 1.673658161549181e-05,
      "loss": 0.0001,
      "step": 138450
    },
    {
      "epoch": 6.65513430397386,
      "grad_norm": 0.29674482345581055,
      "learning_rate": 1.6724568737686803e-05,
      "loss": 0.0001,
      "step": 138500
    },
    {
      "epoch": 6.657536879534861,
      "grad_norm": 0.07438712567090988,
      "learning_rate": 1.6712555859881793e-05,
      "loss": 0.0001,
      "step": 138550
    },
    {
      "epoch": 6.659939455095863,
      "grad_norm": 0.2043173760175705,
      "learning_rate": 1.6700542982076788e-05,
      "loss": 0.0001,
      "step": 138600
    },
    {
      "epoch": 6.662342030656864,
      "grad_norm": 0.1791674643754959,
      "learning_rate": 1.668853010427178e-05,
      "loss": 0.0001,
      "step": 138650
    },
    {
      "epoch": 6.664744606217866,
      "grad_norm": 0.1356315165758133,
      "learning_rate": 1.6676517226466773e-05,
      "loss": 0.0001,
      "step": 138700
    },
    {
      "epoch": 6.667147181778867,
      "grad_norm": 0.05020719766616821,
      "learning_rate": 1.6664504348661767e-05,
      "loss": 0.0001,
      "step": 138750
    },
    {
      "epoch": 6.669549757339868,
      "grad_norm": 0.22050556540489197,
      "learning_rate": 1.665249147085676e-05,
      "loss": 0.0001,
      "step": 138800
    },
    {
      "epoch": 6.67195233290087,
      "grad_norm": 0.27322328090667725,
      "learning_rate": 1.6640478593051752e-05,
      "loss": 0.0001,
      "step": 138850
    },
    {
      "epoch": 6.674354908461871,
      "grad_norm": 0.33115217089653015,
      "learning_rate": 1.6628465715246746e-05,
      "loss": 0.0001,
      "step": 138900
    },
    {
      "epoch": 6.676757484022873,
      "grad_norm": 0.09298596531152725,
      "learning_rate": 1.6616452837441737e-05,
      "loss": 0.0001,
      "step": 138950
    },
    {
      "epoch": 6.679160059583874,
      "grad_norm": 0.36201226711273193,
      "learning_rate": 1.660443995963673e-05,
      "loss": 0.0001,
      "step": 139000
    },
    {
      "epoch": 6.681562635144875,
      "grad_norm": 0.12060629576444626,
      "learning_rate": 1.6592427081831725e-05,
      "loss": 0.0001,
      "step": 139050
    },
    {
      "epoch": 6.6839652107058765,
      "grad_norm": 0.2171117663383484,
      "learning_rate": 1.6580414204026716e-05,
      "loss": 0.0001,
      "step": 139100
    },
    {
      "epoch": 6.686367786266878,
      "grad_norm": 0.40151941776275635,
      "learning_rate": 1.656840132622171e-05,
      "loss": 0.0001,
      "step": 139150
    },
    {
      "epoch": 6.6887703618278795,
      "grad_norm": 0.5282145738601685,
      "learning_rate": 1.6556388448416705e-05,
      "loss": 0.0001,
      "step": 139200
    },
    {
      "epoch": 6.691172937388881,
      "grad_norm": 0.3332364559173584,
      "learning_rate": 1.65443755706117e-05,
      "loss": 0.0001,
      "step": 139250
    },
    {
      "epoch": 6.693575512949883,
      "grad_norm": 0.09245411306619644,
      "learning_rate": 1.653236269280669e-05,
      "loss": 0.0001,
      "step": 139300
    },
    {
      "epoch": 6.695978088510884,
      "grad_norm": 0.0995551347732544,
      "learning_rate": 1.652034981500168e-05,
      "loss": 0.0001,
      "step": 139350
    },
    {
      "epoch": 6.698380664071885,
      "grad_norm": 0.2902826964855194,
      "learning_rate": 1.6508336937196675e-05,
      "loss": 0.0001,
      "step": 139400
    },
    {
      "epoch": 6.700783239632886,
      "grad_norm": 0.2132938653230667,
      "learning_rate": 1.649632405939167e-05,
      "loss": 0.0004,
      "step": 139450
    },
    {
      "epoch": 6.703185815193888,
      "grad_norm": 0.12064244598150253,
      "learning_rate": 1.6484311181586663e-05,
      "loss": 0.0001,
      "step": 139500
    },
    {
      "epoch": 6.705588390754889,
      "grad_norm": 0.23830243945121765,
      "learning_rate": 1.6472298303781654e-05,
      "loss": 0.0001,
      "step": 139550
    },
    {
      "epoch": 6.707990966315891,
      "grad_norm": 0.19162942469120026,
      "learning_rate": 1.6460285425976648e-05,
      "loss": 0.0001,
      "step": 139600
    },
    {
      "epoch": 6.710393541876892,
      "grad_norm": 0.16356755793094635,
      "learning_rate": 1.6448272548171642e-05,
      "loss": 0.0001,
      "step": 139650
    },
    {
      "epoch": 6.712796117437893,
      "grad_norm": 0.238149955868721,
      "learning_rate": 1.6436259670366633e-05,
      "loss": 0.0001,
      "step": 139700
    },
    {
      "epoch": 6.715198692998895,
      "grad_norm": 0.2623845636844635,
      "learning_rate": 1.6424246792561627e-05,
      "loss": 0.0001,
      "step": 139750
    },
    {
      "epoch": 6.717601268559896,
      "grad_norm": 0.18157775700092316,
      "learning_rate": 1.6412233914756618e-05,
      "loss": 0.0001,
      "step": 139800
    },
    {
      "epoch": 6.720003844120898,
      "grad_norm": 0.1246725469827652,
      "learning_rate": 1.6400221036951612e-05,
      "loss": 0.0001,
      "step": 139850
    },
    {
      "epoch": 6.722406419681899,
      "grad_norm": 0.1549915224313736,
      "learning_rate": 1.6388208159146607e-05,
      "loss": 0.0001,
      "step": 139900
    },
    {
      "epoch": 6.724808995242901,
      "grad_norm": 0.3232339322566986,
      "learning_rate": 1.63761952813416e-05,
      "loss": 0.0006,
      "step": 139950
    },
    {
      "epoch": 6.7272115708039015,
      "grad_norm": 0.7104821801185608,
      "learning_rate": 1.6364182403536592e-05,
      "loss": 0.0001,
      "step": 140000
    },
    {
      "epoch": 6.729614146364903,
      "grad_norm": 0.31726858019828796,
      "learning_rate": 1.6352169525731583e-05,
      "loss": 0.0001,
      "step": 140050
    },
    {
      "epoch": 6.732016721925905,
      "grad_norm": 0.36254438757896423,
      "learning_rate": 1.6340156647926577e-05,
      "loss": 0.0001,
      "step": 140100
    },
    {
      "epoch": 6.734419297486906,
      "grad_norm": 0.11438818275928497,
      "learning_rate": 1.632814377012157e-05,
      "loss": 0.0001,
      "step": 140150
    },
    {
      "epoch": 6.736821873047908,
      "grad_norm": 0.1572515070438385,
      "learning_rate": 1.6316130892316565e-05,
      "loss": 0.0001,
      "step": 140200
    },
    {
      "epoch": 6.739224448608908,
      "grad_norm": 0.244090273976326,
      "learning_rate": 1.6304118014511556e-05,
      "loss": 0.0001,
      "step": 140250
    },
    {
      "epoch": 6.74162702416991,
      "grad_norm": 0.18807964026927948,
      "learning_rate": 1.629210513670655e-05,
      "loss": 0.0001,
      "step": 140300
    },
    {
      "epoch": 6.744029599730911,
      "grad_norm": 0.2689705491065979,
      "learning_rate": 1.6280092258901544e-05,
      "loss": 0.0001,
      "step": 140350
    },
    {
      "epoch": 6.746432175291913,
      "grad_norm": 0.17073224484920502,
      "learning_rate": 1.626807938109654e-05,
      "loss": 0.0006,
      "step": 140400
    },
    {
      "epoch": 6.7488347508529145,
      "grad_norm": 0.1448303461074829,
      "learning_rate": 1.625606650329153e-05,
      "loss": 0.0001,
      "step": 140450
    },
    {
      "epoch": 6.751237326413916,
      "grad_norm": 0.023526066914200783,
      "learning_rate": 1.624405362548652e-05,
      "loss": 0.0001,
      "step": 140500
    },
    {
      "epoch": 6.753639901974918,
      "grad_norm": 0.2827804684638977,
      "learning_rate": 1.6232040747681515e-05,
      "loss": 0.0001,
      "step": 140550
    },
    {
      "epoch": 6.756042477535918,
      "grad_norm": 0.2512974739074707,
      "learning_rate": 1.622002786987651e-05,
      "loss": 0.0001,
      "step": 140600
    },
    {
      "epoch": 6.75844505309692,
      "grad_norm": 0.19248269498348236,
      "learning_rate": 1.6208014992071503e-05,
      "loss": 0.0001,
      "step": 140650
    },
    {
      "epoch": 6.760847628657921,
      "grad_norm": 0.10037761926651001,
      "learning_rate": 1.6196002114266494e-05,
      "loss": 0.0002,
      "step": 140700
    },
    {
      "epoch": 6.763250204218923,
      "grad_norm": 0.23546099662780762,
      "learning_rate": 1.6183989236461488e-05,
      "loss": 0.0001,
      "step": 140750
    },
    {
      "epoch": 6.765652779779924,
      "grad_norm": 0.571936309337616,
      "learning_rate": 1.617197635865648e-05,
      "loss": 0.0003,
      "step": 140800
    },
    {
      "epoch": 6.768055355340925,
      "grad_norm": 0.16871538758277893,
      "learning_rate": 1.6159963480851473e-05,
      "loss": 0.0001,
      "step": 140850
    },
    {
      "epoch": 6.770457930901927,
      "grad_norm": 0.4565521478652954,
      "learning_rate": 1.6147950603046467e-05,
      "loss": 0.0001,
      "step": 140900
    },
    {
      "epoch": 6.772860506462928,
      "grad_norm": 0.32012537121772766,
      "learning_rate": 1.6135937725241458e-05,
      "loss": 0.0001,
      "step": 140950
    },
    {
      "epoch": 6.77526308202393,
      "grad_norm": 0.16970683634281158,
      "learning_rate": 1.6123924847436452e-05,
      "loss": 0.0001,
      "step": 141000
    },
    {
      "epoch": 6.777665657584931,
      "grad_norm": 0.17080055177211761,
      "learning_rate": 1.6111911969631447e-05,
      "loss": 0.0001,
      "step": 141050
    },
    {
      "epoch": 6.780068233145933,
      "grad_norm": 0.2149178832769394,
      "learning_rate": 1.609989909182644e-05,
      "loss": 0.0001,
      "step": 141100
    },
    {
      "epoch": 6.782470808706934,
      "grad_norm": 0.3204849064350128,
      "learning_rate": 1.608788621402143e-05,
      "loss": 0.0001,
      "step": 141150
    },
    {
      "epoch": 6.784873384267935,
      "grad_norm": 0.15150825679302216,
      "learning_rate": 1.6075873336216422e-05,
      "loss": 0.0001,
      "step": 141200
    },
    {
      "epoch": 6.7872759598289365,
      "grad_norm": 0.20313379168510437,
      "learning_rate": 1.6063860458411417e-05,
      "loss": 0.0001,
      "step": 141250
    },
    {
      "epoch": 6.789678535389938,
      "grad_norm": 0.06273245066404343,
      "learning_rate": 1.605184758060641e-05,
      "loss": 0.0001,
      "step": 141300
    },
    {
      "epoch": 6.79208111095094,
      "grad_norm": 0.14223262667655945,
      "learning_rate": 1.6039834702801405e-05,
      "loss": 0.0002,
      "step": 141350
    },
    {
      "epoch": 6.794483686511941,
      "grad_norm": 0.16119706630706787,
      "learning_rate": 1.6027821824996396e-05,
      "loss": 0.0001,
      "step": 141400
    },
    {
      "epoch": 6.796886262072942,
      "grad_norm": 0.13093873858451843,
      "learning_rate": 1.601580894719139e-05,
      "loss": 0.0001,
      "step": 141450
    },
    {
      "epoch": 6.799288837633943,
      "grad_norm": 0.2530502378940582,
      "learning_rate": 1.6003796069386384e-05,
      "loss": 0.0001,
      "step": 141500
    },
    {
      "epoch": 6.801691413194945,
      "grad_norm": 0.33182230591773987,
      "learning_rate": 1.5991783191581375e-05,
      "loss": 0.0001,
      "step": 141550
    },
    {
      "epoch": 6.804093988755946,
      "grad_norm": 0.10117057710886002,
      "learning_rate": 1.597977031377637e-05,
      "loss": 0.0001,
      "step": 141600
    },
    {
      "epoch": 6.806496564316948,
      "grad_norm": 0.6918947696685791,
      "learning_rate": 1.596775743597136e-05,
      "loss": 0.0001,
      "step": 141650
    },
    {
      "epoch": 6.8088991398779495,
      "grad_norm": 0.07506980746984482,
      "learning_rate": 1.5955744558166354e-05,
      "loss": 0.0001,
      "step": 141700
    },
    {
      "epoch": 6.811301715438951,
      "grad_norm": 0.13253119587898254,
      "learning_rate": 1.594373168036135e-05,
      "loss": 0.0001,
      "step": 141750
    },
    {
      "epoch": 6.813704290999952,
      "grad_norm": 0.4079100787639618,
      "learning_rate": 1.5931718802556343e-05,
      "loss": 0.0001,
      "step": 141800
    },
    {
      "epoch": 6.816106866560953,
      "grad_norm": 0.5035882592201233,
      "learning_rate": 1.5919705924751334e-05,
      "loss": 0.0001,
      "step": 141850
    },
    {
      "epoch": 6.818509442121955,
      "grad_norm": 0.19748732447624207,
      "learning_rate": 1.5907693046946324e-05,
      "loss": 0.0001,
      "step": 141900
    },
    {
      "epoch": 6.820912017682956,
      "grad_norm": 0.1553928554058075,
      "learning_rate": 1.589568016914132e-05,
      "loss": 0.0001,
      "step": 141950
    },
    {
      "epoch": 6.823314593243958,
      "grad_norm": 0.07301394641399384,
      "learning_rate": 1.5883667291336313e-05,
      "loss": 0.0007,
      "step": 142000
    },
    {
      "epoch": 6.8257171688049585,
      "grad_norm": 0.2421012967824936,
      "learning_rate": 1.5871654413531307e-05,
      "loss": 0.0001,
      "step": 142050
    },
    {
      "epoch": 6.82811974436596,
      "grad_norm": 0.12886165082454681,
      "learning_rate": 1.5859641535726298e-05,
      "loss": 0.0001,
      "step": 142100
    },
    {
      "epoch": 6.830522319926962,
      "grad_norm": 0.07248592376708984,
      "learning_rate": 1.5847628657921292e-05,
      "loss": 0.0002,
      "step": 142150
    },
    {
      "epoch": 6.832924895487963,
      "grad_norm": 0.10540340840816498,
      "learning_rate": 1.5835615780116286e-05,
      "loss": 0.0001,
      "step": 142200
    },
    {
      "epoch": 6.835327471048965,
      "grad_norm": 0.1388062983751297,
      "learning_rate": 1.582360290231128e-05,
      "loss": 0.0001,
      "step": 142250
    },
    {
      "epoch": 6.837730046609966,
      "grad_norm": 0.23974788188934326,
      "learning_rate": 1.581159002450627e-05,
      "loss": 0.0001,
      "step": 142300
    },
    {
      "epoch": 6.840132622170968,
      "grad_norm": 0.09984764456748962,
      "learning_rate": 1.5799577146701262e-05,
      "loss": 0.0001,
      "step": 142350
    },
    {
      "epoch": 6.842535197731968,
      "grad_norm": 0.16391560435295105,
      "learning_rate": 1.5787564268896256e-05,
      "loss": 0.0001,
      "step": 142400
    },
    {
      "epoch": 6.84493777329297,
      "grad_norm": 0.0595603883266449,
      "learning_rate": 1.577555139109125e-05,
      "loss": 0.0001,
      "step": 142450
    },
    {
      "epoch": 6.8473403488539715,
      "grad_norm": 0.11062093079090118,
      "learning_rate": 1.5763538513286245e-05,
      "loss": 0.0006,
      "step": 142500
    },
    {
      "epoch": 6.849742924414973,
      "grad_norm": 0.060317713767290115,
      "learning_rate": 1.575152563548124e-05,
      "loss": 0.0001,
      "step": 142550
    },
    {
      "epoch": 6.8521454999759746,
      "grad_norm": 0.06283523887395859,
      "learning_rate": 1.573951275767623e-05,
      "loss": 0.0001,
      "step": 142600
    },
    {
      "epoch": 6.854548075536975,
      "grad_norm": 0.21586710214614868,
      "learning_rate": 1.572749987987122e-05,
      "loss": 0.0001,
      "step": 142650
    },
    {
      "epoch": 6.856950651097977,
      "grad_norm": 0.21935658156871796,
      "learning_rate": 1.5715487002066215e-05,
      "loss": 0.0001,
      "step": 142700
    },
    {
      "epoch": 6.859353226658978,
      "grad_norm": 0.33738377690315247,
      "learning_rate": 1.570347412426121e-05,
      "loss": 0.0001,
      "step": 142750
    },
    {
      "epoch": 6.86175580221998,
      "grad_norm": 0.04954427480697632,
      "learning_rate": 1.5691461246456203e-05,
      "loss": 0.0001,
      "step": 142800
    },
    {
      "epoch": 6.864158377780981,
      "grad_norm": 0.08098188787698746,
      "learning_rate": 1.5679448368651194e-05,
      "loss": 0.0001,
      "step": 142850
    },
    {
      "epoch": 6.866560953341983,
      "grad_norm": 0.1141335740685463,
      "learning_rate": 1.566743549084619e-05,
      "loss": 0.0001,
      "step": 142900
    },
    {
      "epoch": 6.8689635289029845,
      "grad_norm": 0.366912841796875,
      "learning_rate": 1.5655422613041183e-05,
      "loss": 0.0001,
      "step": 142950
    },
    {
      "epoch": 6.871366104463985,
      "grad_norm": 0.0549711138010025,
      "learning_rate": 1.5643409735236177e-05,
      "loss": 0.0001,
      "step": 143000
    },
    {
      "epoch": 6.873768680024987,
      "grad_norm": 0.26773375272750854,
      "learning_rate": 1.5631396857431164e-05,
      "loss": 0.0005,
      "step": 143050
    },
    {
      "epoch": 6.876171255585988,
      "grad_norm": 0.08780816197395325,
      "learning_rate": 1.561938397962616e-05,
      "loss": 0.0001,
      "step": 143100
    },
    {
      "epoch": 6.87857383114699,
      "grad_norm": 0.17441581189632416,
      "learning_rate": 1.5607371101821153e-05,
      "loss": 0.0001,
      "step": 143150
    },
    {
      "epoch": 6.880976406707991,
      "grad_norm": 0.2148897796869278,
      "learning_rate": 1.5595358224016147e-05,
      "loss": 0.0002,
      "step": 143200
    },
    {
      "epoch": 6.883378982268992,
      "grad_norm": 0.15234309434890747,
      "learning_rate": 1.558334534621114e-05,
      "loss": 0.0001,
      "step": 143250
    },
    {
      "epoch": 6.8857815578299935,
      "grad_norm": 0.056594379246234894,
      "learning_rate": 1.5571332468406132e-05,
      "loss": 0.0005,
      "step": 143300
    },
    {
      "epoch": 6.888184133390995,
      "grad_norm": 0.2559308707714081,
      "learning_rate": 1.5559319590601126e-05,
      "loss": 0.0001,
      "step": 143350
    },
    {
      "epoch": 6.8905867089519965,
      "grad_norm": 0.09558425843715668,
      "learning_rate": 1.5547306712796117e-05,
      "loss": 0.0001,
      "step": 143400
    },
    {
      "epoch": 6.892989284512998,
      "grad_norm": 0.2864135801792145,
      "learning_rate": 1.553529383499111e-05,
      "loss": 0.0001,
      "step": 143450
    },
    {
      "epoch": 6.895391860074,
      "grad_norm": 0.260108083486557,
      "learning_rate": 1.5523280957186105e-05,
      "loss": 0.0001,
      "step": 143500
    },
    {
      "epoch": 6.897794435635001,
      "grad_norm": 0.10883643478155136,
      "learning_rate": 1.5511268079381096e-05,
      "loss": 0.0002,
      "step": 143550
    },
    {
      "epoch": 6.900197011196002,
      "grad_norm": 0.11225280165672302,
      "learning_rate": 1.549925520157609e-05,
      "loss": 0.0003,
      "step": 143600
    },
    {
      "epoch": 6.902599586757003,
      "grad_norm": 0.31439846754074097,
      "learning_rate": 1.5487242323771085e-05,
      "loss": 0.0001,
      "step": 143650
    },
    {
      "epoch": 6.905002162318005,
      "grad_norm": 0.11846214532852173,
      "learning_rate": 1.547522944596608e-05,
      "loss": 0.0001,
      "step": 143700
    },
    {
      "epoch": 6.907404737879006,
      "grad_norm": 0.09167858958244324,
      "learning_rate": 1.546321656816107e-05,
      "loss": 0.0004,
      "step": 143750
    },
    {
      "epoch": 6.909807313440008,
      "grad_norm": 0.05206715688109398,
      "learning_rate": 1.545120369035606e-05,
      "loss": 0.0001,
      "step": 143800
    },
    {
      "epoch": 6.912209889001009,
      "grad_norm": 0.23500452935695648,
      "learning_rate": 1.5439190812551055e-05,
      "loss": 0.0005,
      "step": 143850
    },
    {
      "epoch": 6.91461246456201,
      "grad_norm": 0.35436156392097473,
      "learning_rate": 1.542717793474605e-05,
      "loss": 0.0001,
      "step": 143900
    },
    {
      "epoch": 6.917015040123012,
      "grad_norm": 0.4798383116722107,
      "learning_rate": 1.5415165056941043e-05,
      "loss": 0.0004,
      "step": 143950
    },
    {
      "epoch": 6.919417615684013,
      "grad_norm": 0.12798625230789185,
      "learning_rate": 1.5403152179136034e-05,
      "loss": 0.0001,
      "step": 144000
    },
    {
      "epoch": 6.921820191245015,
      "grad_norm": 0.34966564178466797,
      "learning_rate": 1.5391139301331028e-05,
      "loss": 0.0001,
      "step": 144050
    },
    {
      "epoch": 6.924222766806016,
      "grad_norm": 0.06011452525854111,
      "learning_rate": 1.5379126423526022e-05,
      "loss": 0.0004,
      "step": 144100
    },
    {
      "epoch": 6.926625342367018,
      "grad_norm": 0.0817471370100975,
      "learning_rate": 1.5367113545721013e-05,
      "loss": 0.0005,
      "step": 144150
    },
    {
      "epoch": 6.9290279179280185,
      "grad_norm": 0.4484996497631073,
      "learning_rate": 1.5355100667916007e-05,
      "loss": 0.0001,
      "step": 144200
    },
    {
      "epoch": 6.93143049348902,
      "grad_norm": 0.08833197504281998,
      "learning_rate": 1.5343087790110998e-05,
      "loss": 0.0001,
      "step": 144250
    },
    {
      "epoch": 6.933833069050022,
      "grad_norm": 0.2436123490333557,
      "learning_rate": 1.5331074912305992e-05,
      "loss": 0.0001,
      "step": 144300
    },
    {
      "epoch": 6.936235644611023,
      "grad_norm": 0.28221118450164795,
      "learning_rate": 1.5319062034500987e-05,
      "loss": 0.0001,
      "step": 144350
    },
    {
      "epoch": 6.938638220172025,
      "grad_norm": 0.4179973900318146,
      "learning_rate": 1.530704915669598e-05,
      "loss": 0.0002,
      "step": 144400
    },
    {
      "epoch": 6.941040795733025,
      "grad_norm": 0.11271017044782639,
      "learning_rate": 1.5295036278890972e-05,
      "loss": 0.0005,
      "step": 144450
    },
    {
      "epoch": 6.943443371294027,
      "grad_norm": 0.16064885258674622,
      "learning_rate": 1.5283023401085963e-05,
      "loss": 0.0001,
      "step": 144500
    },
    {
      "epoch": 6.945845946855028,
      "grad_norm": 0.45405256748199463,
      "learning_rate": 1.5271010523280957e-05,
      "loss": 0.0001,
      "step": 144550
    },
    {
      "epoch": 6.94824852241603,
      "grad_norm": 0.05898447707295418,
      "learning_rate": 1.525899764547595e-05,
      "loss": 0.0001,
      "step": 144600
    },
    {
      "epoch": 6.9506510979770315,
      "grad_norm": 0.26811856031417847,
      "learning_rate": 1.5246984767670943e-05,
      "loss": 0.0001,
      "step": 144650
    },
    {
      "epoch": 6.953053673538033,
      "grad_norm": 0.04759860411286354,
      "learning_rate": 1.5234971889865938e-05,
      "loss": 0.0002,
      "step": 144700
    },
    {
      "epoch": 6.955456249099035,
      "grad_norm": 0.07063976675271988,
      "learning_rate": 1.522295901206093e-05,
      "loss": 0.0001,
      "step": 144750
    },
    {
      "epoch": 6.957858824660035,
      "grad_norm": 0.2403319776058197,
      "learning_rate": 1.5210946134255924e-05,
      "loss": 0.0001,
      "step": 144800
    },
    {
      "epoch": 6.960261400221037,
      "grad_norm": 0.16603823006153107,
      "learning_rate": 1.5198933256450917e-05,
      "loss": 0.0001,
      "step": 144850
    },
    {
      "epoch": 6.962663975782038,
      "grad_norm": 0.8402897715568542,
      "learning_rate": 1.5186920378645908e-05,
      "loss": 0.0001,
      "step": 144900
    },
    {
      "epoch": 6.96506655134304,
      "grad_norm": 0.4028826355934143,
      "learning_rate": 1.5174907500840902e-05,
      "loss": 0.0001,
      "step": 144950
    },
    {
      "epoch": 6.967469126904041,
      "grad_norm": 0.4242820739746094,
      "learning_rate": 1.5162894623035894e-05,
      "loss": 0.0002,
      "step": 145000
    },
    {
      "epoch": 6.969871702465042,
      "grad_norm": 0.08630676567554474,
      "learning_rate": 1.5150881745230889e-05,
      "loss": 0.0001,
      "step": 145050
    },
    {
      "epoch": 6.972274278026044,
      "grad_norm": 0.15032635629177094,
      "learning_rate": 1.5138868867425881e-05,
      "loss": 0.0001,
      "step": 145100
    },
    {
      "epoch": 6.974676853587045,
      "grad_norm": 0.28038713335990906,
      "learning_rate": 1.5126855989620875e-05,
      "loss": 0.0002,
      "step": 145150
    },
    {
      "epoch": 6.977079429148047,
      "grad_norm": 0.24250808358192444,
      "learning_rate": 1.5114843111815868e-05,
      "loss": 0.0001,
      "step": 145200
    },
    {
      "epoch": 6.979482004709048,
      "grad_norm": 0.17002879083156586,
      "learning_rate": 1.5102830234010859e-05,
      "loss": 0.0001,
      "step": 145250
    },
    {
      "epoch": 6.98188458027005,
      "grad_norm": 0.07882287353277206,
      "learning_rate": 1.5090817356205853e-05,
      "loss": 0.0001,
      "step": 145300
    },
    {
      "epoch": 6.984287155831051,
      "grad_norm": 0.3067351281642914,
      "learning_rate": 1.5078804478400846e-05,
      "loss": 0.0001,
      "step": 145350
    },
    {
      "epoch": 6.986689731392052,
      "grad_norm": 0.4022854268550873,
      "learning_rate": 1.506679160059584e-05,
      "loss": 0.0001,
      "step": 145400
    },
    {
      "epoch": 6.9890923069530535,
      "grad_norm": 0.27643105387687683,
      "learning_rate": 1.5054778722790832e-05,
      "loss": 0.0001,
      "step": 145450
    },
    {
      "epoch": 6.991494882514055,
      "grad_norm": 0.909250020980835,
      "learning_rate": 1.5042765844985826e-05,
      "loss": 0.0002,
      "step": 145500
    },
    {
      "epoch": 6.993897458075057,
      "grad_norm": 0.08518755435943604,
      "learning_rate": 1.5030752967180819e-05,
      "loss": 0.0001,
      "step": 145550
    },
    {
      "epoch": 6.996300033636058,
      "grad_norm": 0.335418701171875,
      "learning_rate": 1.5018740089375813e-05,
      "loss": 0.0001,
      "step": 145600
    },
    {
      "epoch": 6.998702609197059,
      "grad_norm": 0.5030021071434021,
      "learning_rate": 1.5006727211570804e-05,
      "loss": 0.0001,
      "step": 145650
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.00011828333663288504,
      "eval_runtime": 17.3016,
      "eval_samples_per_second": 548.852,
      "eval_steps_per_second": 68.607,
      "step": 145677
    },
    {
      "epoch": 7.00110518475806,
      "grad_norm": 0.1915207952260971,
      "learning_rate": 1.4994714333765797e-05,
      "loss": 0.0002,
      "step": 145700
    },
    {
      "epoch": 7.003507760319062,
      "grad_norm": 0.19599325954914093,
      "learning_rate": 1.498270145596079e-05,
      "loss": 0.0001,
      "step": 145750
    },
    {
      "epoch": 7.005910335880063,
      "grad_norm": 0.0788322389125824,
      "learning_rate": 1.4970688578155783e-05,
      "loss": 0.0001,
      "step": 145800
    },
    {
      "epoch": 7.008312911441065,
      "grad_norm": 0.1247217133641243,
      "learning_rate": 1.4958675700350777e-05,
      "loss": 0.0002,
      "step": 145850
    },
    {
      "epoch": 7.0107154870020665,
      "grad_norm": 0.14228877425193787,
      "learning_rate": 1.494666282254577e-05,
      "loss": 0.0001,
      "step": 145900
    },
    {
      "epoch": 7.013118062563068,
      "grad_norm": 0.2791184186935425,
      "learning_rate": 1.4934649944740764e-05,
      "loss": 0.0001,
      "step": 145950
    },
    {
      "epoch": 7.015520638124069,
      "grad_norm": 0.2905205190181732,
      "learning_rate": 1.4922637066935755e-05,
      "loss": 0.0001,
      "step": 146000
    },
    {
      "epoch": 7.01792321368507,
      "grad_norm": 0.12718872725963593,
      "learning_rate": 1.4910624189130748e-05,
      "loss": 0.0001,
      "step": 146050
    },
    {
      "epoch": 7.020325789246072,
      "grad_norm": 0.10392273962497711,
      "learning_rate": 1.4898611311325742e-05,
      "loss": 0.0001,
      "step": 146100
    },
    {
      "epoch": 7.022728364807073,
      "grad_norm": 0.16507577896118164,
      "learning_rate": 1.4886598433520734e-05,
      "loss": 0.0005,
      "step": 146150
    },
    {
      "epoch": 7.025130940368075,
      "grad_norm": 0.37232837080955505,
      "learning_rate": 1.4874585555715729e-05,
      "loss": 0.0001,
      "step": 146200
    },
    {
      "epoch": 7.027533515929076,
      "grad_norm": 0.38560765981674194,
      "learning_rate": 1.4862572677910721e-05,
      "loss": 0.0001,
      "step": 146250
    },
    {
      "epoch": 7.029936091490077,
      "grad_norm": 0.2337706983089447,
      "learning_rate": 1.4850559800105715e-05,
      "loss": 0.0001,
      "step": 146300
    },
    {
      "epoch": 7.032338667051079,
      "grad_norm": 0.07079731673002243,
      "learning_rate": 1.4838546922300708e-05,
      "loss": 0.0001,
      "step": 146350
    },
    {
      "epoch": 7.03474124261208,
      "grad_norm": 0.11570949852466583,
      "learning_rate": 1.4826534044495699e-05,
      "loss": 0.0001,
      "step": 146400
    },
    {
      "epoch": 7.037143818173082,
      "grad_norm": 0.1437947154045105,
      "learning_rate": 1.4814521166690693e-05,
      "loss": 0.0001,
      "step": 146450
    },
    {
      "epoch": 7.039546393734083,
      "grad_norm": 0.12024497240781784,
      "learning_rate": 1.4802508288885685e-05,
      "loss": 0.0001,
      "step": 146500
    },
    {
      "epoch": 7.041948969295085,
      "grad_norm": 0.11660493910312653,
      "learning_rate": 1.479049541108068e-05,
      "loss": 0.0001,
      "step": 146550
    },
    {
      "epoch": 7.044351544856085,
      "grad_norm": 0.11143414676189423,
      "learning_rate": 1.4778482533275672e-05,
      "loss": 0.0001,
      "step": 146600
    },
    {
      "epoch": 7.046754120417087,
      "grad_norm": 0.2891680598258972,
      "learning_rate": 1.4766469655470666e-05,
      "loss": 0.0001,
      "step": 146650
    },
    {
      "epoch": 7.0491566959780885,
      "grad_norm": 0.19608493149280548,
      "learning_rate": 1.4754456777665659e-05,
      "loss": 0.0001,
      "step": 146700
    },
    {
      "epoch": 7.05155927153909,
      "grad_norm": 0.09815163165330887,
      "learning_rate": 1.474244389986065e-05,
      "loss": 0.0001,
      "step": 146750
    },
    {
      "epoch": 7.0539618471000916,
      "grad_norm": 0.056584082543849945,
      "learning_rate": 1.4730431022055644e-05,
      "loss": 0.0001,
      "step": 146800
    },
    {
      "epoch": 7.056364422661093,
      "grad_norm": 0.32357826828956604,
      "learning_rate": 1.4718418144250636e-05,
      "loss": 0.0001,
      "step": 146850
    },
    {
      "epoch": 7.058766998222094,
      "grad_norm": 0.11638674885034561,
      "learning_rate": 1.470640526644563e-05,
      "loss": 0.0001,
      "step": 146900
    },
    {
      "epoch": 7.061169573783095,
      "grad_norm": 0.08585094660520554,
      "learning_rate": 1.4694392388640623e-05,
      "loss": 0.0001,
      "step": 146950
    },
    {
      "epoch": 7.063572149344097,
      "grad_norm": 0.25211086869239807,
      "learning_rate": 1.4682379510835617e-05,
      "loss": 0.0001,
      "step": 147000
    },
    {
      "epoch": 7.065974724905098,
      "grad_norm": 0.12544570863246918,
      "learning_rate": 1.467036663303061e-05,
      "loss": 0.0002,
      "step": 147050
    },
    {
      "epoch": 7.0683773004661,
      "grad_norm": 0.09440560638904572,
      "learning_rate": 1.46583537552256e-05,
      "loss": 0.0001,
      "step": 147100
    },
    {
      "epoch": 7.0707798760271015,
      "grad_norm": 0.3138534128665924,
      "learning_rate": 1.4646340877420595e-05,
      "loss": 0.0001,
      "step": 147150
    },
    {
      "epoch": 7.073182451588102,
      "grad_norm": 0.2735346555709839,
      "learning_rate": 1.4634327999615587e-05,
      "loss": 0.0001,
      "step": 147200
    },
    {
      "epoch": 7.075585027149104,
      "grad_norm": 0.20399636030197144,
      "learning_rate": 1.4622315121810582e-05,
      "loss": 0.0001,
      "step": 147250
    },
    {
      "epoch": 7.077987602710105,
      "grad_norm": 0.3693765699863434,
      "learning_rate": 1.4610302244005574e-05,
      "loss": 0.0001,
      "step": 147300
    },
    {
      "epoch": 7.080390178271107,
      "grad_norm": 0.1472536325454712,
      "learning_rate": 1.4598289366200568e-05,
      "loss": 0.0001,
      "step": 147350
    },
    {
      "epoch": 7.082792753832108,
      "grad_norm": 0.06723521649837494,
      "learning_rate": 1.458627648839556e-05,
      "loss": 0.0001,
      "step": 147400
    },
    {
      "epoch": 7.08519532939311,
      "grad_norm": 0.20298589766025543,
      "learning_rate": 1.4574263610590555e-05,
      "loss": 0.0006,
      "step": 147450
    },
    {
      "epoch": 7.0875979049541105,
      "grad_norm": 0.2513465881347656,
      "learning_rate": 1.4562250732785546e-05,
      "loss": 0.0001,
      "step": 147500
    },
    {
      "epoch": 7.090000480515112,
      "grad_norm": 0.28605151176452637,
      "learning_rate": 1.4550237854980538e-05,
      "loss": 0.0001,
      "step": 147550
    },
    {
      "epoch": 7.0924030560761135,
      "grad_norm": 0.08081776648759842,
      "learning_rate": 1.4538224977175533e-05,
      "loss": 0.0001,
      "step": 147600
    },
    {
      "epoch": 7.094805631637115,
      "grad_norm": 0.13408532738685608,
      "learning_rate": 1.4526212099370525e-05,
      "loss": 0.0001,
      "step": 147650
    },
    {
      "epoch": 7.097208207198117,
      "grad_norm": 0.15826530754566193,
      "learning_rate": 1.451419922156552e-05,
      "loss": 0.0005,
      "step": 147700
    },
    {
      "epoch": 7.099610782759118,
      "grad_norm": 0.22799281775951385,
      "learning_rate": 1.4502186343760512e-05,
      "loss": 0.0001,
      "step": 147750
    },
    {
      "epoch": 7.102013358320119,
      "grad_norm": 2.4958086013793945,
      "learning_rate": 1.4490173465955506e-05,
      "loss": 0.0003,
      "step": 147800
    },
    {
      "epoch": 7.10441593388112,
      "grad_norm": 0.28256601095199585,
      "learning_rate": 1.4478160588150497e-05,
      "loss": 0.0004,
      "step": 147850
    },
    {
      "epoch": 7.106818509442122,
      "grad_norm": 0.174539715051651,
      "learning_rate": 1.446614771034549e-05,
      "loss": 0.0004,
      "step": 147900
    },
    {
      "epoch": 7.109221085003123,
      "grad_norm": 0.30783477425575256,
      "learning_rate": 1.4454134832540484e-05,
      "loss": 0.0001,
      "step": 147950
    },
    {
      "epoch": 7.111623660564125,
      "grad_norm": 0.24772955477237701,
      "learning_rate": 1.4442121954735476e-05,
      "loss": 0.0002,
      "step": 148000
    },
    {
      "epoch": 7.1140262361251265,
      "grad_norm": 0.3106124699115753,
      "learning_rate": 1.443010907693047e-05,
      "loss": 0.0001,
      "step": 148050
    },
    {
      "epoch": 7.116428811686127,
      "grad_norm": 0.17633742094039917,
      "learning_rate": 1.4418096199125463e-05,
      "loss": 0.0001,
      "step": 148100
    },
    {
      "epoch": 7.118831387247129,
      "grad_norm": 0.09364275634288788,
      "learning_rate": 1.4406083321320457e-05,
      "loss": 0.0001,
      "step": 148150
    },
    {
      "epoch": 7.12123396280813,
      "grad_norm": 0.4839063286781311,
      "learning_rate": 1.4394070443515451e-05,
      "loss": 0.0001,
      "step": 148200
    },
    {
      "epoch": 7.123636538369132,
      "grad_norm": 0.3622119426727295,
      "learning_rate": 1.438205756571044e-05,
      "loss": 0.0001,
      "step": 148250
    },
    {
      "epoch": 7.126039113930133,
      "grad_norm": 0.8364692330360413,
      "learning_rate": 1.4370044687905435e-05,
      "loss": 0.0001,
      "step": 148300
    },
    {
      "epoch": 7.128441689491135,
      "grad_norm": 0.12246490269899368,
      "learning_rate": 1.4358031810100427e-05,
      "loss": 0.0001,
      "step": 148350
    },
    {
      "epoch": 7.1308442650521355,
      "grad_norm": 0.4232933223247528,
      "learning_rate": 1.4346018932295421e-05,
      "loss": 0.0001,
      "step": 148400
    },
    {
      "epoch": 7.133246840613137,
      "grad_norm": 0.3273903727531433,
      "learning_rate": 1.4334006054490416e-05,
      "loss": 0.0001,
      "step": 148450
    },
    {
      "epoch": 7.135649416174139,
      "grad_norm": 0.0704938992857933,
      "learning_rate": 1.4321993176685408e-05,
      "loss": 0.0001,
      "step": 148500
    },
    {
      "epoch": 7.13805199173514,
      "grad_norm": 0.23411305248737335,
      "learning_rate": 1.4309980298880402e-05,
      "loss": 0.0001,
      "step": 148550
    },
    {
      "epoch": 7.140454567296142,
      "grad_norm": 0.3577766418457031,
      "learning_rate": 1.4297967421075391e-05,
      "loss": 0.0002,
      "step": 148600
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.2795701026916504,
      "learning_rate": 1.4285954543270386e-05,
      "loss": 0.0001,
      "step": 148650
    },
    {
      "epoch": 7.145259718418144,
      "grad_norm": 0.17979298532009125,
      "learning_rate": 1.4273941665465378e-05,
      "loss": 0.0001,
      "step": 148700
    },
    {
      "epoch": 7.147662293979145,
      "grad_norm": 0.4010511338710785,
      "learning_rate": 1.4261928787660372e-05,
      "loss": 0.0001,
      "step": 148750
    },
    {
      "epoch": 7.150064869540147,
      "grad_norm": 0.27634871006011963,
      "learning_rate": 1.4249915909855367e-05,
      "loss": 0.0001,
      "step": 148800
    },
    {
      "epoch": 7.1524674451011485,
      "grad_norm": 0.974359929561615,
      "learning_rate": 1.4237903032050359e-05,
      "loss": 0.0001,
      "step": 148850
    },
    {
      "epoch": 7.15487002066215,
      "grad_norm": 0.08187402039766312,
      "learning_rate": 1.4225890154245353e-05,
      "loss": 0.0002,
      "step": 148900
    },
    {
      "epoch": 7.157272596223152,
      "grad_norm": 0.1874515861272812,
      "learning_rate": 1.4213877276440346e-05,
      "loss": 0.0001,
      "step": 148950
    },
    {
      "epoch": 7.159675171784152,
      "grad_norm": 0.19927246868610382,
      "learning_rate": 1.4201864398635337e-05,
      "loss": 0.0001,
      "step": 149000
    },
    {
      "epoch": 7.162077747345154,
      "grad_norm": 0.1422928273677826,
      "learning_rate": 1.4189851520830331e-05,
      "loss": 0.0001,
      "step": 149050
    },
    {
      "epoch": 7.164480322906155,
      "grad_norm": 0.13307219743728638,
      "learning_rate": 1.4177838643025323e-05,
      "loss": 0.0001,
      "step": 149100
    },
    {
      "epoch": 7.166882898467157,
      "grad_norm": 0.1930006444454193,
      "learning_rate": 1.4165825765220318e-05,
      "loss": 0.0001,
      "step": 149150
    },
    {
      "epoch": 7.169285474028158,
      "grad_norm": 0.3407723903656006,
      "learning_rate": 1.415381288741531e-05,
      "loss": 0.0001,
      "step": 149200
    },
    {
      "epoch": 7.17168804958916,
      "grad_norm": 0.0693601593375206,
      "learning_rate": 1.4141800009610304e-05,
      "loss": 0.0001,
      "step": 149250
    },
    {
      "epoch": 7.174090625150161,
      "grad_norm": 0.0942772850394249,
      "learning_rate": 1.4129787131805297e-05,
      "loss": 0.0001,
      "step": 149300
    },
    {
      "epoch": 7.176493200711162,
      "grad_norm": 0.2220267355442047,
      "learning_rate": 1.4117774254000288e-05,
      "loss": 0.0001,
      "step": 149350
    },
    {
      "epoch": 7.178895776272164,
      "grad_norm": 0.08553433418273926,
      "learning_rate": 1.4105761376195282e-05,
      "loss": 0.0001,
      "step": 149400
    },
    {
      "epoch": 7.181298351833165,
      "grad_norm": 0.24756671488285065,
      "learning_rate": 1.4093748498390274e-05,
      "loss": 0.0002,
      "step": 149450
    },
    {
      "epoch": 7.183700927394167,
      "grad_norm": 0.15829002857208252,
      "learning_rate": 1.4081735620585269e-05,
      "loss": 0.0001,
      "step": 149500
    },
    {
      "epoch": 7.186103502955168,
      "grad_norm": 0.24885262548923492,
      "learning_rate": 1.4069722742780261e-05,
      "loss": 0.0001,
      "step": 149550
    },
    {
      "epoch": 7.188506078516169,
      "grad_norm": 0.11911066621541977,
      "learning_rate": 1.4057709864975255e-05,
      "loss": 0.0001,
      "step": 149600
    },
    {
      "epoch": 7.1909086540771705,
      "grad_norm": 0.5110197067260742,
      "learning_rate": 1.4045696987170248e-05,
      "loss": 0.0003,
      "step": 149650
    },
    {
      "epoch": 7.193311229638172,
      "grad_norm": 0.07889100909233093,
      "learning_rate": 1.4033684109365242e-05,
      "loss": 0.0001,
      "step": 149700
    },
    {
      "epoch": 7.195713805199174,
      "grad_norm": 0.22348977625370026,
      "learning_rate": 1.4021671231560233e-05,
      "loss": 0.0001,
      "step": 149750
    },
    {
      "epoch": 7.198116380760175,
      "grad_norm": 0.056713663041591644,
      "learning_rate": 1.4009658353755225e-05,
      "loss": 0.0001,
      "step": 149800
    },
    {
      "epoch": 7.200518956321177,
      "grad_norm": 0.20191259682178497,
      "learning_rate": 1.399764547595022e-05,
      "loss": 0.0001,
      "step": 149850
    },
    {
      "epoch": 7.202921531882177,
      "grad_norm": 0.19396156072616577,
      "learning_rate": 1.3985632598145212e-05,
      "loss": 0.0001,
      "step": 149900
    },
    {
      "epoch": 7.205324107443179,
      "grad_norm": 0.33992940187454224,
      "learning_rate": 1.3973619720340206e-05,
      "loss": 0.0001,
      "step": 149950
    },
    {
      "epoch": 7.20772668300418,
      "grad_norm": 0.22106227278709412,
      "learning_rate": 1.3961606842535199e-05,
      "loss": 0.0001,
      "step": 150000
    },
    {
      "epoch": 7.210129258565182,
      "grad_norm": 0.06331023573875427,
      "learning_rate": 1.3949593964730193e-05,
      "loss": 0.0001,
      "step": 150050
    },
    {
      "epoch": 7.2125318341261835,
      "grad_norm": 0.33994823694229126,
      "learning_rate": 1.3937581086925184e-05,
      "loss": 0.0001,
      "step": 150100
    },
    {
      "epoch": 7.214934409687185,
      "grad_norm": 0.09027591347694397,
      "learning_rate": 1.3925568209120177e-05,
      "loss": 0.0001,
      "step": 150150
    },
    {
      "epoch": 7.217336985248186,
      "grad_norm": 0.14461436867713928,
      "learning_rate": 1.391355533131517e-05,
      "loss": 0.0001,
      "step": 150200
    },
    {
      "epoch": 7.219739560809187,
      "grad_norm": 0.1073419377207756,
      "learning_rate": 1.3901542453510163e-05,
      "loss": 0.0001,
      "step": 150250
    },
    {
      "epoch": 7.222142136370189,
      "grad_norm": 0.06102176383137703,
      "learning_rate": 1.3889529575705157e-05,
      "loss": 0.0001,
      "step": 150300
    },
    {
      "epoch": 7.22454471193119,
      "grad_norm": 0.35460859537124634,
      "learning_rate": 1.387751669790015e-05,
      "loss": 0.0001,
      "step": 150350
    },
    {
      "epoch": 7.226947287492192,
      "grad_norm": 0.41330209374427795,
      "learning_rate": 1.3865503820095144e-05,
      "loss": 0.0001,
      "step": 150400
    },
    {
      "epoch": 7.229349863053193,
      "grad_norm": 0.12341754138469696,
      "learning_rate": 1.3853490942290135e-05,
      "loss": 0.0004,
      "step": 150450
    },
    {
      "epoch": 7.231752438614194,
      "grad_norm": 0.0873018279671669,
      "learning_rate": 1.3841478064485128e-05,
      "loss": 0.0002,
      "step": 150500
    },
    {
      "epoch": 7.234155014175196,
      "grad_norm": 0.10118460655212402,
      "learning_rate": 1.3829465186680122e-05,
      "loss": 0.0001,
      "step": 150550
    },
    {
      "epoch": 7.236557589736197,
      "grad_norm": 0.16966724395751953,
      "learning_rate": 1.3817452308875114e-05,
      "loss": 0.0001,
      "step": 150600
    },
    {
      "epoch": 7.238960165297199,
      "grad_norm": 0.1565583050251007,
      "learning_rate": 1.3805439431070108e-05,
      "loss": 0.0001,
      "step": 150650
    },
    {
      "epoch": 7.2413627408582,
      "grad_norm": 0.041281089186668396,
      "learning_rate": 1.3793426553265101e-05,
      "loss": 0.0001,
      "step": 150700
    },
    {
      "epoch": 7.243765316419202,
      "grad_norm": 0.12837935984134674,
      "learning_rate": 1.3781413675460095e-05,
      "loss": 0.0001,
      "step": 150750
    },
    {
      "epoch": 7.246167891980202,
      "grad_norm": 0.14931999146938324,
      "learning_rate": 1.3769400797655088e-05,
      "loss": 0.0001,
      "step": 150800
    },
    {
      "epoch": 7.248570467541204,
      "grad_norm": 0.1626323014497757,
      "learning_rate": 1.3757387919850079e-05,
      "loss": 0.0001,
      "step": 150850
    },
    {
      "epoch": 7.2509730431022055,
      "grad_norm": 0.11278440803289413,
      "learning_rate": 1.3745375042045073e-05,
      "loss": 0.0001,
      "step": 150900
    },
    {
      "epoch": 7.253375618663207,
      "grad_norm": 0.36344054341316223,
      "learning_rate": 1.3733362164240065e-05,
      "loss": 0.0001,
      "step": 150950
    },
    {
      "epoch": 7.2557781942242086,
      "grad_norm": 0.18320555984973907,
      "learning_rate": 1.372134928643506e-05,
      "loss": 0.0001,
      "step": 151000
    },
    {
      "epoch": 7.25818076978521,
      "grad_norm": 0.10036490112543106,
      "learning_rate": 1.3709336408630052e-05,
      "loss": 0.0001,
      "step": 151050
    },
    {
      "epoch": 7.260583345346211,
      "grad_norm": 0.4688822627067566,
      "learning_rate": 1.3697323530825046e-05,
      "loss": 0.0002,
      "step": 151100
    },
    {
      "epoch": 7.262985920907212,
      "grad_norm": 0.08430370688438416,
      "learning_rate": 1.3685310653020039e-05,
      "loss": 0.0005,
      "step": 151150
    },
    {
      "epoch": 7.265388496468214,
      "grad_norm": 0.10456334054470062,
      "learning_rate": 1.367329777521503e-05,
      "loss": 0.0001,
      "step": 151200
    },
    {
      "epoch": 7.267791072029215,
      "grad_norm": 0.6046757698059082,
      "learning_rate": 1.3661284897410024e-05,
      "loss": 0.0003,
      "step": 151250
    },
    {
      "epoch": 7.270193647590217,
      "grad_norm": 0.21522356569766998,
      "learning_rate": 1.3649272019605016e-05,
      "loss": 0.0005,
      "step": 151300
    },
    {
      "epoch": 7.2725962231512185,
      "grad_norm": 0.11973748356103897,
      "learning_rate": 1.363725914180001e-05,
      "loss": 0.0001,
      "step": 151350
    },
    {
      "epoch": 7.274998798712219,
      "grad_norm": 0.18999210000038147,
      "learning_rate": 1.3625246263995003e-05,
      "loss": 0.0001,
      "step": 151400
    },
    {
      "epoch": 7.277401374273221,
      "grad_norm": 0.05482795462012291,
      "learning_rate": 1.3613233386189997e-05,
      "loss": 0.0001,
      "step": 151450
    },
    {
      "epoch": 7.279803949834222,
      "grad_norm": 0.14742374420166016,
      "learning_rate": 1.360122050838499e-05,
      "loss": 0.0001,
      "step": 151500
    },
    {
      "epoch": 7.282206525395224,
      "grad_norm": 0.4473094046115875,
      "learning_rate": 1.3589207630579984e-05,
      "loss": 0.0001,
      "step": 151550
    },
    {
      "epoch": 7.284609100956225,
      "grad_norm": 0.13567760586738586,
      "learning_rate": 1.3577194752774975e-05,
      "loss": 0.0001,
      "step": 151600
    },
    {
      "epoch": 7.287011676517227,
      "grad_norm": 0.05980084091424942,
      "learning_rate": 1.3565181874969967e-05,
      "loss": 0.0001,
      "step": 151650
    },
    {
      "epoch": 7.2894142520782275,
      "grad_norm": 0.08048354834318161,
      "learning_rate": 1.3553168997164962e-05,
      "loss": 0.0001,
      "step": 151700
    },
    {
      "epoch": 7.291816827639229,
      "grad_norm": 0.2155430167913437,
      "learning_rate": 1.3541156119359954e-05,
      "loss": 0.0001,
      "step": 151750
    },
    {
      "epoch": 7.2942194032002305,
      "grad_norm": 0.07867663353681564,
      "learning_rate": 1.3529143241554948e-05,
      "loss": 0.0001,
      "step": 151800
    },
    {
      "epoch": 7.296621978761232,
      "grad_norm": 0.7539714574813843,
      "learning_rate": 1.351713036374994e-05,
      "loss": 0.0001,
      "step": 151850
    },
    {
      "epoch": 7.299024554322234,
      "grad_norm": 0.12578721344470978,
      "learning_rate": 1.3505117485944935e-05,
      "loss": 0.0001,
      "step": 151900
    },
    {
      "epoch": 7.301427129883235,
      "grad_norm": 0.06014147773385048,
      "learning_rate": 1.3493104608139926e-05,
      "loss": 0.0001,
      "step": 151950
    },
    {
      "epoch": 7.303829705444236,
      "grad_norm": 0.07615909725427628,
      "learning_rate": 1.3481091730334918e-05,
      "loss": 0.0001,
      "step": 152000
    },
    {
      "epoch": 7.306232281005237,
      "grad_norm": 0.2922128736972809,
      "learning_rate": 1.3469078852529913e-05,
      "loss": 0.0001,
      "step": 152050
    },
    {
      "epoch": 7.308634856566239,
      "grad_norm": 0.14143264293670654,
      "learning_rate": 1.3457065974724905e-05,
      "loss": 0.0001,
      "step": 152100
    },
    {
      "epoch": 7.31103743212724,
      "grad_norm": 0.1979786604642868,
      "learning_rate": 1.34450530969199e-05,
      "loss": 0.0001,
      "step": 152150
    },
    {
      "epoch": 7.313440007688242,
      "grad_norm": 0.117549367249012,
      "learning_rate": 1.3433040219114892e-05,
      "loss": 0.0001,
      "step": 152200
    },
    {
      "epoch": 7.3158425832492435,
      "grad_norm": 0.132588192820549,
      "learning_rate": 1.3421027341309886e-05,
      "loss": 0.0001,
      "step": 152250
    },
    {
      "epoch": 7.318245158810244,
      "grad_norm": 0.3749161958694458,
      "learning_rate": 1.3409014463504879e-05,
      "loss": 0.001,
      "step": 152300
    },
    {
      "epoch": 7.320647734371246,
      "grad_norm": 0.13711848855018616,
      "learning_rate": 1.339700158569987e-05,
      "loss": 0.0001,
      "step": 152350
    },
    {
      "epoch": 7.323050309932247,
      "grad_norm": 0.2572847902774811,
      "learning_rate": 1.3384988707894864e-05,
      "loss": 0.0004,
      "step": 152400
    },
    {
      "epoch": 7.325452885493249,
      "grad_norm": 0.11695011705160141,
      "learning_rate": 1.3372975830089856e-05,
      "loss": 0.0001,
      "step": 152450
    },
    {
      "epoch": 7.32785546105425,
      "grad_norm": 0.04750363901257515,
      "learning_rate": 1.336096295228485e-05,
      "loss": 0.0001,
      "step": 152500
    },
    {
      "epoch": 7.330258036615252,
      "grad_norm": 0.2105480432510376,
      "learning_rate": 1.3348950074479843e-05,
      "loss": 0.0001,
      "step": 152550
    },
    {
      "epoch": 7.3326606121762525,
      "grad_norm": 0.14669689536094666,
      "learning_rate": 1.3336937196674837e-05,
      "loss": 0.0001,
      "step": 152600
    },
    {
      "epoch": 7.335063187737254,
      "grad_norm": 0.11277230083942413,
      "learning_rate": 1.332492431886983e-05,
      "loss": 0.0001,
      "step": 152650
    },
    {
      "epoch": 7.337465763298256,
      "grad_norm": 0.2803879976272583,
      "learning_rate": 1.331291144106482e-05,
      "loss": 0.0001,
      "step": 152700
    },
    {
      "epoch": 7.339868338859257,
      "grad_norm": 0.06735792756080627,
      "learning_rate": 1.3300898563259815e-05,
      "loss": 0.0001,
      "step": 152750
    },
    {
      "epoch": 7.342270914420259,
      "grad_norm": 0.2684204578399658,
      "learning_rate": 1.3288885685454807e-05,
      "loss": 0.0001,
      "step": 152800
    },
    {
      "epoch": 7.34467348998126,
      "grad_norm": 0.3952936828136444,
      "learning_rate": 1.3276872807649801e-05,
      "loss": 0.0001,
      "step": 152850
    },
    {
      "epoch": 7.347076065542261,
      "grad_norm": 0.14821113646030426,
      "learning_rate": 1.3264859929844794e-05,
      "loss": 0.0001,
      "step": 152900
    },
    {
      "epoch": 7.349478641103262,
      "grad_norm": 0.12609758973121643,
      "learning_rate": 1.3252847052039788e-05,
      "loss": 0.0001,
      "step": 152950
    },
    {
      "epoch": 7.351881216664264,
      "grad_norm": 0.30937570333480835,
      "learning_rate": 1.324083417423478e-05,
      "loss": 0.0004,
      "step": 153000
    },
    {
      "epoch": 7.3542837922252655,
      "grad_norm": 0.35238173604011536,
      "learning_rate": 1.3228821296429771e-05,
      "loss": 0.0001,
      "step": 153050
    },
    {
      "epoch": 7.356686367786267,
      "grad_norm": 0.061311811208724976,
      "learning_rate": 1.3216808418624766e-05,
      "loss": 0.0001,
      "step": 153100
    },
    {
      "epoch": 7.359088943347269,
      "grad_norm": 0.18950796127319336,
      "learning_rate": 1.3204795540819758e-05,
      "loss": 0.0002,
      "step": 153150
    },
    {
      "epoch": 7.361491518908269,
      "grad_norm": 0.09413270652294159,
      "learning_rate": 1.3192782663014752e-05,
      "loss": 0.0001,
      "step": 153200
    },
    {
      "epoch": 7.363894094469271,
      "grad_norm": 0.1652064174413681,
      "learning_rate": 1.3180769785209745e-05,
      "loss": 0.0001,
      "step": 153250
    },
    {
      "epoch": 7.366296670030272,
      "grad_norm": 0.08920707553625107,
      "learning_rate": 1.3168756907404739e-05,
      "loss": 0.0001,
      "step": 153300
    },
    {
      "epoch": 7.368699245591274,
      "grad_norm": 0.1002701073884964,
      "learning_rate": 1.3156744029599732e-05,
      "loss": 0.0001,
      "step": 153350
    },
    {
      "epoch": 7.371101821152275,
      "grad_norm": 0.16002359986305237,
      "learning_rate": 1.3144731151794726e-05,
      "loss": 0.0003,
      "step": 153400
    },
    {
      "epoch": 7.373504396713277,
      "grad_norm": 0.3221217691898346,
      "learning_rate": 1.3132718273989717e-05,
      "loss": 0.0001,
      "step": 153450
    },
    {
      "epoch": 7.375906972274278,
      "grad_norm": 0.16201499104499817,
      "learning_rate": 1.312070539618471e-05,
      "loss": 0.0002,
      "step": 153500
    },
    {
      "epoch": 7.378309547835279,
      "grad_norm": 0.07129719853401184,
      "learning_rate": 1.3108692518379703e-05,
      "loss": 0.0001,
      "step": 153550
    },
    {
      "epoch": 7.380712123396281,
      "grad_norm": 0.12888579070568085,
      "learning_rate": 1.3096679640574696e-05,
      "loss": 0.0001,
      "step": 153600
    },
    {
      "epoch": 7.383114698957282,
      "grad_norm": 0.10424072295427322,
      "learning_rate": 1.308466676276969e-05,
      "loss": 0.0001,
      "step": 153650
    },
    {
      "epoch": 7.385517274518284,
      "grad_norm": 0.38745152950286865,
      "learning_rate": 1.3072653884964683e-05,
      "loss": 0.0001,
      "step": 153700
    },
    {
      "epoch": 7.387919850079285,
      "grad_norm": 0.18483829498291016,
      "learning_rate": 1.3060641007159677e-05,
      "loss": 0.0001,
      "step": 153750
    },
    {
      "epoch": 7.390322425640287,
      "grad_norm": 0.31388962268829346,
      "learning_rate": 1.3048628129354668e-05,
      "loss": 0.0001,
      "step": 153800
    },
    {
      "epoch": 7.3927250012012875,
      "grad_norm": 0.05351219326257706,
      "learning_rate": 1.303661525154966e-05,
      "loss": 0.0001,
      "step": 153850
    },
    {
      "epoch": 7.395127576762289,
      "grad_norm": 0.46878278255462646,
      "learning_rate": 1.3024602373744654e-05,
      "loss": 0.0001,
      "step": 153900
    },
    {
      "epoch": 7.397530152323291,
      "grad_norm": 0.15481100976467133,
      "learning_rate": 1.3012589495939647e-05,
      "loss": 0.0002,
      "step": 153950
    },
    {
      "epoch": 7.399932727884292,
      "grad_norm": 0.038532208651304245,
      "learning_rate": 1.3000576618134641e-05,
      "loss": 0.0001,
      "step": 154000
    },
    {
      "epoch": 7.402335303445294,
      "grad_norm": 0.21395601332187653,
      "learning_rate": 1.2988563740329634e-05,
      "loss": 0.0001,
      "step": 154050
    },
    {
      "epoch": 7.404737879006294,
      "grad_norm": 0.46677350997924805,
      "learning_rate": 1.2976550862524628e-05,
      "loss": 0.0001,
      "step": 154100
    },
    {
      "epoch": 7.407140454567296,
      "grad_norm": 0.28243228793144226,
      "learning_rate": 1.2964537984719622e-05,
      "loss": 0.0001,
      "step": 154150
    },
    {
      "epoch": 7.409543030128297,
      "grad_norm": 0.1414005011320114,
      "learning_rate": 1.2952525106914611e-05,
      "loss": 0.0001,
      "step": 154200
    },
    {
      "epoch": 7.411945605689299,
      "grad_norm": 0.1653634011745453,
      "learning_rate": 1.2940512229109605e-05,
      "loss": 0.0001,
      "step": 154250
    },
    {
      "epoch": 7.4143481812503005,
      "grad_norm": 0.08829870074987411,
      "learning_rate": 1.2928499351304598e-05,
      "loss": 0.0001,
      "step": 154300
    },
    {
      "epoch": 7.416750756811302,
      "grad_norm": 0.44934898614883423,
      "learning_rate": 1.2916486473499592e-05,
      "loss": 0.0001,
      "step": 154350
    },
    {
      "epoch": 7.419153332372304,
      "grad_norm": 0.07214759290218353,
      "learning_rate": 1.2904473595694586e-05,
      "loss": 0.0001,
      "step": 154400
    },
    {
      "epoch": 7.421555907933304,
      "grad_norm": 0.25138789415359497,
      "learning_rate": 1.2892460717889579e-05,
      "loss": 0.0001,
      "step": 154450
    },
    {
      "epoch": 7.423958483494306,
      "grad_norm": 0.22211158275604248,
      "learning_rate": 1.2880447840084573e-05,
      "loss": 0.0001,
      "step": 154500
    },
    {
      "epoch": 7.426361059055307,
      "grad_norm": 0.14636476337909698,
      "learning_rate": 1.2868434962279562e-05,
      "loss": 0.0001,
      "step": 154550
    },
    {
      "epoch": 7.428763634616309,
      "grad_norm": 0.11251947283744812,
      "learning_rate": 1.2856422084474556e-05,
      "loss": 0.0001,
      "step": 154600
    },
    {
      "epoch": 7.43116621017731,
      "grad_norm": 0.07316429167985916,
      "learning_rate": 1.2844409206669549e-05,
      "loss": 0.0001,
      "step": 154650
    },
    {
      "epoch": 7.433568785738311,
      "grad_norm": 0.2392011284828186,
      "learning_rate": 1.2832396328864543e-05,
      "loss": 0.0001,
      "step": 154700
    },
    {
      "epoch": 7.435971361299313,
      "grad_norm": 0.46982380747795105,
      "learning_rate": 1.2820383451059537e-05,
      "loss": 0.0001,
      "step": 154750
    },
    {
      "epoch": 7.438373936860314,
      "grad_norm": 0.08591165393590927,
      "learning_rate": 1.280837057325453e-05,
      "loss": 0.0001,
      "step": 154800
    },
    {
      "epoch": 7.440776512421316,
      "grad_norm": 0.31886786222457886,
      "learning_rate": 1.2796357695449524e-05,
      "loss": 0.0001,
      "step": 154850
    },
    {
      "epoch": 7.443179087982317,
      "grad_norm": 0.044571757316589355,
      "learning_rate": 1.2784344817644517e-05,
      "loss": 0.0001,
      "step": 154900
    },
    {
      "epoch": 7.445581663543319,
      "grad_norm": 0.11125653237104416,
      "learning_rate": 1.2772331939839507e-05,
      "loss": 0.0001,
      "step": 154950
    },
    {
      "epoch": 7.44798423910432,
      "grad_norm": 0.08351215720176697,
      "learning_rate": 1.2760319062034502e-05,
      "loss": 0.0002,
      "step": 155000
    },
    {
      "epoch": 7.450386814665321,
      "grad_norm": 0.29322460293769836,
      "learning_rate": 1.2748306184229494e-05,
      "loss": 0.0001,
      "step": 155050
    },
    {
      "epoch": 7.4527893902263225,
      "grad_norm": 0.23609477281570435,
      "learning_rate": 1.2736293306424488e-05,
      "loss": 0.0001,
      "step": 155100
    },
    {
      "epoch": 7.455191965787324,
      "grad_norm": 0.2296406328678131,
      "learning_rate": 1.2724280428619481e-05,
      "loss": 0.0001,
      "step": 155150
    },
    {
      "epoch": 7.457594541348326,
      "grad_norm": 0.1187601089477539,
      "learning_rate": 1.2712267550814475e-05,
      "loss": 0.0002,
      "step": 155200
    },
    {
      "epoch": 7.459997116909327,
      "grad_norm": 0.050492025911808014,
      "learning_rate": 1.2700254673009468e-05,
      "loss": 0.0001,
      "step": 155250
    },
    {
      "epoch": 7.462399692470328,
      "grad_norm": 0.07128483802080154,
      "learning_rate": 1.2688241795204459e-05,
      "loss": 0.0001,
      "step": 155300
    },
    {
      "epoch": 7.464802268031329,
      "grad_norm": 0.1224185973405838,
      "learning_rate": 1.2676228917399453e-05,
      "loss": 0.0005,
      "step": 155350
    },
    {
      "epoch": 7.467204843592331,
      "grad_norm": 0.239796981215477,
      "learning_rate": 1.2664216039594445e-05,
      "loss": 0.0001,
      "step": 155400
    },
    {
      "epoch": 7.469607419153332,
      "grad_norm": 0.09052915126085281,
      "learning_rate": 1.265220316178944e-05,
      "loss": 0.0001,
      "step": 155450
    },
    {
      "epoch": 7.472009994714334,
      "grad_norm": 0.33592239022254944,
      "learning_rate": 1.2640190283984432e-05,
      "loss": 0.0001,
      "step": 155500
    },
    {
      "epoch": 7.4744125702753355,
      "grad_norm": 0.21272476017475128,
      "learning_rate": 1.2628177406179426e-05,
      "loss": 0.0001,
      "step": 155550
    },
    {
      "epoch": 7.476815145836337,
      "grad_norm": 0.4719564616680145,
      "learning_rate": 1.2616164528374419e-05,
      "loss": 0.0002,
      "step": 155600
    },
    {
      "epoch": 7.479217721397338,
      "grad_norm": 0.06727917492389679,
      "learning_rate": 1.2604151650569413e-05,
      "loss": 0.0001,
      "step": 155650
    },
    {
      "epoch": 7.481620296958339,
      "grad_norm": 0.20292823016643524,
      "learning_rate": 1.2592138772764404e-05,
      "loss": 0.0001,
      "step": 155700
    },
    {
      "epoch": 7.484022872519341,
      "grad_norm": 0.06179644539952278,
      "learning_rate": 1.2580125894959396e-05,
      "loss": 0.0001,
      "step": 155750
    },
    {
      "epoch": 7.486425448080342,
      "grad_norm": 0.07363387197256088,
      "learning_rate": 1.256811301715439e-05,
      "loss": 0.0001,
      "step": 155800
    },
    {
      "epoch": 7.488828023641344,
      "grad_norm": 0.08949557691812515,
      "learning_rate": 1.2556100139349383e-05,
      "loss": 0.0001,
      "step": 155850
    },
    {
      "epoch": 7.4912305992023445,
      "grad_norm": 0.2406771034002304,
      "learning_rate": 1.2544087261544377e-05,
      "loss": 0.0002,
      "step": 155900
    },
    {
      "epoch": 7.493633174763346,
      "grad_norm": 0.06461050361394882,
      "learning_rate": 1.253207438373937e-05,
      "loss": 0.0001,
      "step": 155950
    },
    {
      "epoch": 7.4960357503243475,
      "grad_norm": 0.2894236147403717,
      "learning_rate": 1.2520061505934364e-05,
      "loss": 0.0002,
      "step": 156000
    },
    {
      "epoch": 7.498438325885349,
      "grad_norm": 0.48918357491493225,
      "learning_rate": 1.2508048628129355e-05,
      "loss": 0.0001,
      "step": 156050
    },
    {
      "epoch": 7.500840901446351,
      "grad_norm": 0.2561270594596863,
      "learning_rate": 1.2496035750324349e-05,
      "loss": 0.0001,
      "step": 156100
    },
    {
      "epoch": 7.503243477007352,
      "grad_norm": 0.31958118081092834,
      "learning_rate": 1.2484022872519342e-05,
      "loss": 0.0001,
      "step": 156150
    },
    {
      "epoch": 7.505646052568354,
      "grad_norm": 0.10269518941640854,
      "learning_rate": 1.2472009994714334e-05,
      "loss": 0.0002,
      "step": 156200
    },
    {
      "epoch": 7.508048628129354,
      "grad_norm": 0.07560496032238007,
      "learning_rate": 1.2459997116909328e-05,
      "loss": 0.0001,
      "step": 156250
    },
    {
      "epoch": 7.510451203690356,
      "grad_norm": 0.21842168271541595,
      "learning_rate": 1.244798423910432e-05,
      "loss": 0.0001,
      "step": 156300
    },
    {
      "epoch": 7.5128537792513574,
      "grad_norm": 0.0955803170800209,
      "learning_rate": 1.2435971361299313e-05,
      "loss": 0.0001,
      "step": 156350
    },
    {
      "epoch": 7.515256354812359,
      "grad_norm": 0.27179935574531555,
      "learning_rate": 1.2423958483494306e-05,
      "loss": 0.0001,
      "step": 156400
    },
    {
      "epoch": 7.5176589303733605,
      "grad_norm": 0.23801840841770172,
      "learning_rate": 1.24119456056893e-05,
      "loss": 0.0001,
      "step": 156450
    },
    {
      "epoch": 7.520061505934361,
      "grad_norm": 0.09297085553407669,
      "learning_rate": 1.2399932727884293e-05,
      "loss": 0.0001,
      "step": 156500
    },
    {
      "epoch": 7.522464081495363,
      "grad_norm": 0.12409205734729767,
      "learning_rate": 1.2387919850079285e-05,
      "loss": 0.0001,
      "step": 156550
    },
    {
      "epoch": 7.524866657056364,
      "grad_norm": 0.4003851115703583,
      "learning_rate": 1.237590697227428e-05,
      "loss": 0.0001,
      "step": 156600
    },
    {
      "epoch": 7.527269232617366,
      "grad_norm": 0.23691220581531525,
      "learning_rate": 1.2363894094469272e-05,
      "loss": 0.0001,
      "step": 156650
    },
    {
      "epoch": 7.529671808178367,
      "grad_norm": 0.19186438620090485,
      "learning_rate": 1.2351881216664264e-05,
      "loss": 0.0001,
      "step": 156700
    },
    {
      "epoch": 7.532074383739369,
      "grad_norm": 0.09543080627918243,
      "learning_rate": 1.2339868338859257e-05,
      "loss": 0.0001,
      "step": 156750
    },
    {
      "epoch": 7.53447695930037,
      "grad_norm": 0.5092090964317322,
      "learning_rate": 1.2327855461054251e-05,
      "loss": 0.0001,
      "step": 156800
    },
    {
      "epoch": 7.536879534861371,
      "grad_norm": 0.3916325271129608,
      "learning_rate": 1.2315842583249244e-05,
      "loss": 0.0001,
      "step": 156850
    },
    {
      "epoch": 7.539282110422373,
      "grad_norm": 0.11626560986042023,
      "learning_rate": 1.2303829705444236e-05,
      "loss": 0.0001,
      "step": 156900
    },
    {
      "epoch": 7.541684685983374,
      "grad_norm": 0.35347649455070496,
      "learning_rate": 1.229181682763923e-05,
      "loss": 0.0001,
      "step": 156950
    },
    {
      "epoch": 7.544087261544376,
      "grad_norm": 0.5387669801712036,
      "learning_rate": 1.2279803949834223e-05,
      "loss": 0.0001,
      "step": 157000
    },
    {
      "epoch": 7.546489837105377,
      "grad_norm": 0.4008912742137909,
      "learning_rate": 1.2267791072029215e-05,
      "loss": 0.0001,
      "step": 157050
    },
    {
      "epoch": 7.548892412666378,
      "grad_norm": 0.3245534300804138,
      "learning_rate": 1.2255778194224208e-05,
      "loss": 0.0002,
      "step": 157100
    },
    {
      "epoch": 7.551294988227379,
      "grad_norm": 0.4142826199531555,
      "learning_rate": 1.2243765316419202e-05,
      "loss": 0.0001,
      "step": 157150
    },
    {
      "epoch": 7.553697563788381,
      "grad_norm": 0.10926991701126099,
      "learning_rate": 1.2231752438614196e-05,
      "loss": 0.0001,
      "step": 157200
    },
    {
      "epoch": 7.5561001393493825,
      "grad_norm": 0.1313808560371399,
      "learning_rate": 1.2219739560809187e-05,
      "loss": 0.0001,
      "step": 157250
    },
    {
      "epoch": 7.558502714910384,
      "grad_norm": 0.0920882448554039,
      "learning_rate": 1.2207726683004181e-05,
      "loss": 0.0001,
      "step": 157300
    },
    {
      "epoch": 7.560905290471386,
      "grad_norm": 0.20425686240196228,
      "learning_rate": 1.2195713805199174e-05,
      "loss": 0.0001,
      "step": 157350
    },
    {
      "epoch": 7.563307866032387,
      "grad_norm": 0.4197680652141571,
      "learning_rate": 1.2183700927394168e-05,
      "loss": 0.0001,
      "step": 157400
    },
    {
      "epoch": 7.565710441593388,
      "grad_norm": 0.1637229323387146,
      "learning_rate": 1.2171688049589159e-05,
      "loss": 0.0001,
      "step": 157450
    },
    {
      "epoch": 7.568113017154389,
      "grad_norm": 0.2747155427932739,
      "learning_rate": 1.2159675171784153e-05,
      "loss": 0.0001,
      "step": 157500
    },
    {
      "epoch": 7.570515592715391,
      "grad_norm": 0.10202325135469437,
      "learning_rate": 1.2147662293979147e-05,
      "loss": 0.0005,
      "step": 157550
    },
    {
      "epoch": 7.572918168276392,
      "grad_norm": 0.13814681768417358,
      "learning_rate": 1.213564941617414e-05,
      "loss": 0.0001,
      "step": 157600
    },
    {
      "epoch": 7.575320743837394,
      "grad_norm": 0.3177718222141266,
      "learning_rate": 1.2123636538369132e-05,
      "loss": 0.0001,
      "step": 157650
    },
    {
      "epoch": 7.577723319398395,
      "grad_norm": 0.4915485084056854,
      "learning_rate": 1.2111623660564125e-05,
      "loss": 0.0001,
      "step": 157700
    },
    {
      "epoch": 7.580125894959396,
      "grad_norm": 0.1521790325641632,
      "learning_rate": 1.2099610782759119e-05,
      "loss": 0.0001,
      "step": 157750
    },
    {
      "epoch": 7.582528470520398,
      "grad_norm": 0.21892954409122467,
      "learning_rate": 1.2087597904954112e-05,
      "loss": 0.0001,
      "step": 157800
    },
    {
      "epoch": 7.584931046081399,
      "grad_norm": 0.08705083280801773,
      "learning_rate": 1.2075585027149104e-05,
      "loss": 0.0001,
      "step": 157850
    },
    {
      "epoch": 7.587333621642401,
      "grad_norm": 0.42079636454582214,
      "learning_rate": 1.2063572149344098e-05,
      "loss": 0.0001,
      "step": 157900
    },
    {
      "epoch": 7.589736197203402,
      "grad_norm": 0.24103674292564392,
      "learning_rate": 1.205155927153909e-05,
      "loss": 0.0003,
      "step": 157950
    },
    {
      "epoch": 7.592138772764404,
      "grad_norm": 0.08745536208152771,
      "learning_rate": 1.2039546393734083e-05,
      "loss": 0.0001,
      "step": 158000
    },
    {
      "epoch": 7.5945413483254045,
      "grad_norm": 0.0347486212849617,
      "learning_rate": 1.2027533515929076e-05,
      "loss": 0.0007,
      "step": 158050
    },
    {
      "epoch": 7.596943923886406,
      "grad_norm": 0.21675190329551697,
      "learning_rate": 1.201552063812407e-05,
      "loss": 0.0001,
      "step": 158100
    },
    {
      "epoch": 7.599346499447408,
      "grad_norm": 0.15942956507205963,
      "learning_rate": 1.2003507760319063e-05,
      "loss": 0.0001,
      "step": 158150
    },
    {
      "epoch": 7.601749075008409,
      "grad_norm": 0.171621173620224,
      "learning_rate": 1.1991494882514055e-05,
      "loss": 0.0001,
      "step": 158200
    },
    {
      "epoch": 7.604151650569411,
      "grad_norm": 0.2799686789512634,
      "learning_rate": 1.197948200470905e-05,
      "loss": 0.0001,
      "step": 158250
    },
    {
      "epoch": 7.606554226130411,
      "grad_norm": 0.08635582029819489,
      "learning_rate": 1.1967469126904042e-05,
      "loss": 0.0003,
      "step": 158300
    },
    {
      "epoch": 7.608956801691413,
      "grad_norm": 0.24665583670139313,
      "learning_rate": 1.1955456249099034e-05,
      "loss": 0.0001,
      "step": 158350
    },
    {
      "epoch": 7.611359377252414,
      "grad_norm": 0.4901714026927948,
      "learning_rate": 1.1943443371294027e-05,
      "loss": 0.0002,
      "step": 158400
    },
    {
      "epoch": 7.613761952813416,
      "grad_norm": 0.047424666583538055,
      "learning_rate": 1.1931430493489021e-05,
      "loss": 0.0001,
      "step": 158450
    },
    {
      "epoch": 7.6161645283744175,
      "grad_norm": 0.09874708205461502,
      "learning_rate": 1.1919417615684014e-05,
      "loss": 0.0001,
      "step": 158500
    },
    {
      "epoch": 7.618567103935419,
      "grad_norm": 0.14133141934871674,
      "learning_rate": 1.1907404737879006e-05,
      "loss": 0.0001,
      "step": 158550
    },
    {
      "epoch": 7.620969679496421,
      "grad_norm": 0.1495770364999771,
      "learning_rate": 1.1895391860074e-05,
      "loss": 0.0001,
      "step": 158600
    },
    {
      "epoch": 7.623372255057421,
      "grad_norm": 0.17483343183994293,
      "learning_rate": 1.1883378982268993e-05,
      "loss": 0.0001,
      "step": 158650
    },
    {
      "epoch": 7.625774830618423,
      "grad_norm": 0.04387192055583,
      "learning_rate": 1.1871366104463987e-05,
      "loss": 0.0001,
      "step": 158700
    },
    {
      "epoch": 7.628177406179424,
      "grad_norm": 0.09319410473108292,
      "learning_rate": 1.1859353226658978e-05,
      "loss": 0.0001,
      "step": 158750
    },
    {
      "epoch": 7.630579981740426,
      "grad_norm": 0.07260963320732117,
      "learning_rate": 1.1847340348853972e-05,
      "loss": 0.0001,
      "step": 158800
    },
    {
      "epoch": 7.632982557301427,
      "grad_norm": 0.08040660619735718,
      "learning_rate": 1.1835327471048965e-05,
      "loss": 0.0001,
      "step": 158850
    },
    {
      "epoch": 7.635385132862428,
      "grad_norm": 0.2297372668981552,
      "learning_rate": 1.1823314593243959e-05,
      "loss": 0.0001,
      "step": 158900
    },
    {
      "epoch": 7.63778770842343,
      "grad_norm": 0.46432235836982727,
      "learning_rate": 1.1811301715438951e-05,
      "loss": 0.0002,
      "step": 158950
    },
    {
      "epoch": 7.640190283984431,
      "grad_norm": 0.39598971605300903,
      "learning_rate": 1.1799288837633944e-05,
      "loss": 0.0001,
      "step": 159000
    },
    {
      "epoch": 7.642592859545433,
      "grad_norm": 0.10744845122098923,
      "learning_rate": 1.1787275959828938e-05,
      "loss": 0.0001,
      "step": 159050
    },
    {
      "epoch": 7.644995435106434,
      "grad_norm": 0.14126557111740112,
      "learning_rate": 1.1775263082023929e-05,
      "loss": 0.0004,
      "step": 159100
    },
    {
      "epoch": 7.647398010667436,
      "grad_norm": 0.3270665407180786,
      "learning_rate": 1.1763250204218923e-05,
      "loss": 0.0001,
      "step": 159150
    },
    {
      "epoch": 7.649800586228437,
      "grad_norm": 0.24019849300384521,
      "learning_rate": 1.1751237326413916e-05,
      "loss": 0.0001,
      "step": 159200
    },
    {
      "epoch": 7.652203161789438,
      "grad_norm": 0.21133312582969666,
      "learning_rate": 1.173922444860891e-05,
      "loss": 0.0001,
      "step": 159250
    },
    {
      "epoch": 7.6546057373504395,
      "grad_norm": 0.05088670551776886,
      "learning_rate": 1.1727211570803902e-05,
      "loss": 0.0004,
      "step": 159300
    },
    {
      "epoch": 7.657008312911441,
      "grad_norm": 0.1700604259967804,
      "learning_rate": 1.1715198692998895e-05,
      "loss": 0.0001,
      "step": 159350
    },
    {
      "epoch": 7.659410888472443,
      "grad_norm": 0.11317083239555359,
      "learning_rate": 1.170318581519389e-05,
      "loss": 0.0001,
      "step": 159400
    },
    {
      "epoch": 7.661813464033444,
      "grad_norm": 0.15519046783447266,
      "learning_rate": 1.1691172937388882e-05,
      "loss": 0.0001,
      "step": 159450
    },
    {
      "epoch": 7.664216039594445,
      "grad_norm": 0.24284546077251434,
      "learning_rate": 1.1679160059583874e-05,
      "loss": 0.0002,
      "step": 159500
    },
    {
      "epoch": 7.666618615155446,
      "grad_norm": 0.06344564259052277,
      "learning_rate": 1.1667147181778867e-05,
      "loss": 0.0001,
      "step": 159550
    },
    {
      "epoch": 7.669021190716448,
      "grad_norm": 0.22957034409046173,
      "learning_rate": 1.1655134303973861e-05,
      "loss": 0.0001,
      "step": 159600
    },
    {
      "epoch": 7.671423766277449,
      "grad_norm": 0.09959174692630768,
      "learning_rate": 1.1643121426168853e-05,
      "loss": 0.0001,
      "step": 159650
    },
    {
      "epoch": 7.673826341838451,
      "grad_norm": 3.4765713214874268,
      "learning_rate": 1.1631108548363846e-05,
      "loss": 0.0005,
      "step": 159700
    },
    {
      "epoch": 7.6762289173994525,
      "grad_norm": 0.11944464594125748,
      "learning_rate": 1.161909567055884e-05,
      "loss": 0.0001,
      "step": 159750
    },
    {
      "epoch": 7.678631492960454,
      "grad_norm": 0.18568867444992065,
      "learning_rate": 1.1607082792753833e-05,
      "loss": 0.0005,
      "step": 159800
    },
    {
      "epoch": 7.681034068521455,
      "grad_norm": 0.40540042519569397,
      "learning_rate": 1.1595069914948825e-05,
      "loss": 0.0001,
      "step": 159850
    },
    {
      "epoch": 7.683436644082456,
      "grad_norm": 0.2124454379081726,
      "learning_rate": 1.1583057037143818e-05,
      "loss": 0.0001,
      "step": 159900
    },
    {
      "epoch": 7.685839219643458,
      "grad_norm": 0.1013246700167656,
      "learning_rate": 1.1571044159338812e-05,
      "loss": 0.0001,
      "step": 159950
    },
    {
      "epoch": 7.688241795204459,
      "grad_norm": 0.34538528323173523,
      "learning_rate": 1.1559031281533806e-05,
      "loss": 0.0001,
      "step": 160000
    },
    {
      "epoch": 7.690644370765461,
      "grad_norm": 0.17228202521800995,
      "learning_rate": 1.1547018403728797e-05,
      "loss": 0.0001,
      "step": 160050
    },
    {
      "epoch": 7.693046946326462,
      "grad_norm": 0.21778208017349243,
      "learning_rate": 1.1535005525923791e-05,
      "loss": 0.0001,
      "step": 160100
    },
    {
      "epoch": 7.695449521887463,
      "grad_norm": 0.15447895228862762,
      "learning_rate": 1.1522992648118784e-05,
      "loss": 0.0002,
      "step": 160150
    },
    {
      "epoch": 7.6978520974484645,
      "grad_norm": 0.13556168973445892,
      "learning_rate": 1.1510979770313778e-05,
      "loss": 0.0001,
      "step": 160200
    },
    {
      "epoch": 7.700254673009466,
      "grad_norm": 0.31165698170661926,
      "learning_rate": 1.1498966892508769e-05,
      "loss": 0.0001,
      "step": 160250
    },
    {
      "epoch": 7.702657248570468,
      "grad_norm": 0.21804139018058777,
      "learning_rate": 1.1486954014703763e-05,
      "loss": 0.0001,
      "step": 160300
    },
    {
      "epoch": 7.705059824131469,
      "grad_norm": 0.19084328413009644,
      "learning_rate": 1.1474941136898757e-05,
      "loss": 0.0004,
      "step": 160350
    },
    {
      "epoch": 7.707462399692471,
      "grad_norm": 0.08203573524951935,
      "learning_rate": 1.1462928259093748e-05,
      "loss": 0.0001,
      "step": 160400
    },
    {
      "epoch": 7.709864975253471,
      "grad_norm": 0.2424832135438919,
      "learning_rate": 1.1450915381288742e-05,
      "loss": 0.0001,
      "step": 160450
    },
    {
      "epoch": 7.712267550814473,
      "grad_norm": 0.16734221577644348,
      "learning_rate": 1.1438902503483735e-05,
      "loss": 0.0001,
      "step": 160500
    },
    {
      "epoch": 7.7146701263754744,
      "grad_norm": 0.15367667376995087,
      "learning_rate": 1.1426889625678729e-05,
      "loss": 0.0005,
      "step": 160550
    },
    {
      "epoch": 7.717072701936476,
      "grad_norm": 0.2487553358078003,
      "learning_rate": 1.1414876747873721e-05,
      "loss": 0.0001,
      "step": 160600
    },
    {
      "epoch": 7.7194752774974775,
      "grad_norm": 0.16483069956302643,
      "learning_rate": 1.1402863870068714e-05,
      "loss": 0.0001,
      "step": 160650
    },
    {
      "epoch": 7.721877853058479,
      "grad_norm": 0.22614015638828278,
      "learning_rate": 1.1390850992263708e-05,
      "loss": 0.0001,
      "step": 160700
    },
    {
      "epoch": 7.72428042861948,
      "grad_norm": 0.10713192820549011,
      "learning_rate": 1.13788381144587e-05,
      "loss": 0.0001,
      "step": 160750
    },
    {
      "epoch": 7.726683004180481,
      "grad_norm": 0.4787319600582123,
      "learning_rate": 1.1366825236653693e-05,
      "loss": 0.0001,
      "step": 160800
    },
    {
      "epoch": 7.729085579741483,
      "grad_norm": 0.09557188302278519,
      "learning_rate": 1.1354812358848686e-05,
      "loss": 0.0001,
      "step": 160850
    },
    {
      "epoch": 7.731488155302484,
      "grad_norm": 0.07748020440340042,
      "learning_rate": 1.134279948104368e-05,
      "loss": 0.0001,
      "step": 160900
    },
    {
      "epoch": 7.733890730863486,
      "grad_norm": 0.06265518069267273,
      "learning_rate": 1.1330786603238673e-05,
      "loss": 0.0001,
      "step": 160950
    },
    {
      "epoch": 7.736293306424487,
      "grad_norm": 0.13769546151161194,
      "learning_rate": 1.1318773725433665e-05,
      "loss": 0.0001,
      "step": 161000
    },
    {
      "epoch": 7.738695881985488,
      "grad_norm": 0.11348302662372589,
      "learning_rate": 1.130676084762866e-05,
      "loss": 0.0001,
      "step": 161050
    },
    {
      "epoch": 7.74109845754649,
      "grad_norm": 0.2028288096189499,
      "learning_rate": 1.1294747969823652e-05,
      "loss": 0.0001,
      "step": 161100
    },
    {
      "epoch": 7.743501033107491,
      "grad_norm": 0.263592928647995,
      "learning_rate": 1.1282735092018644e-05,
      "loss": 0.0005,
      "step": 161150
    },
    {
      "epoch": 7.745903608668493,
      "grad_norm": 0.048068344593048096,
      "learning_rate": 1.1270722214213637e-05,
      "loss": 0.0001,
      "step": 161200
    },
    {
      "epoch": 7.748306184229494,
      "grad_norm": 0.18024149537086487,
      "learning_rate": 1.1258709336408631e-05,
      "loss": 0.0001,
      "step": 161250
    },
    {
      "epoch": 7.750708759790496,
      "grad_norm": 0.6313629150390625,
      "learning_rate": 1.1246696458603624e-05,
      "loss": 0.0001,
      "step": 161300
    },
    {
      "epoch": 7.753111335351496,
      "grad_norm": 0.17906153202056885,
      "learning_rate": 1.1234683580798616e-05,
      "loss": 0.0002,
      "step": 161350
    },
    {
      "epoch": 7.755513910912498,
      "grad_norm": 0.28238117694854736,
      "learning_rate": 1.122267070299361e-05,
      "loss": 0.0001,
      "step": 161400
    },
    {
      "epoch": 7.7579164864734995,
      "grad_norm": 0.12943565845489502,
      "learning_rate": 1.1210657825188603e-05,
      "loss": 0.0001,
      "step": 161450
    },
    {
      "epoch": 7.760319062034501,
      "grad_norm": 0.08692904561758041,
      "learning_rate": 1.1198644947383597e-05,
      "loss": 0.0001,
      "step": 161500
    },
    {
      "epoch": 7.762721637595503,
      "grad_norm": 0.21234764158725739,
      "learning_rate": 1.1186632069578588e-05,
      "loss": 0.0001,
      "step": 161550
    },
    {
      "epoch": 7.765124213156504,
      "grad_norm": 0.39830726385116577,
      "learning_rate": 1.1174619191773582e-05,
      "loss": 0.0001,
      "step": 161600
    },
    {
      "epoch": 7.767526788717505,
      "grad_norm": 0.07096657902002335,
      "learning_rate": 1.1162606313968575e-05,
      "loss": 0.0001,
      "step": 161650
    },
    {
      "epoch": 7.769929364278506,
      "grad_norm": 0.2192889302968979,
      "learning_rate": 1.1150593436163567e-05,
      "loss": 0.0001,
      "step": 161700
    },
    {
      "epoch": 7.772331939839508,
      "grad_norm": 0.24821051955223083,
      "learning_rate": 1.1138580558358561e-05,
      "loss": 0.0001,
      "step": 161750
    },
    {
      "epoch": 7.774734515400509,
      "grad_norm": 0.09166722744703293,
      "learning_rate": 1.1126567680553554e-05,
      "loss": 0.0001,
      "step": 161800
    },
    {
      "epoch": 7.777137090961511,
      "grad_norm": 0.056027188897132874,
      "learning_rate": 1.1114554802748548e-05,
      "loss": 0.0001,
      "step": 161850
    },
    {
      "epoch": 7.7795396665225125,
      "grad_norm": 0.08470030128955841,
      "learning_rate": 1.1102541924943539e-05,
      "loss": 0.0001,
      "step": 161900
    },
    {
      "epoch": 7.781942242083513,
      "grad_norm": 0.15040819346904755,
      "learning_rate": 1.1090529047138533e-05,
      "loss": 0.0001,
      "step": 161950
    },
    {
      "epoch": 7.784344817644515,
      "grad_norm": 0.0843915343284607,
      "learning_rate": 1.1078516169333526e-05,
      "loss": 0.0001,
      "step": 162000
    },
    {
      "epoch": 7.786747393205516,
      "grad_norm": 0.3768998682498932,
      "learning_rate": 1.106650329152852e-05,
      "loss": 0.0001,
      "step": 162050
    },
    {
      "epoch": 7.789149968766518,
      "grad_norm": 0.2885444462299347,
      "learning_rate": 1.1054490413723512e-05,
      "loss": 0.0005,
      "step": 162100
    },
    {
      "epoch": 7.791552544327519,
      "grad_norm": 0.19880887866020203,
      "learning_rate": 1.1042477535918505e-05,
      "loss": 0.0001,
      "step": 162150
    },
    {
      "epoch": 7.793955119888521,
      "grad_norm": 0.12660080194473267,
      "learning_rate": 1.1030464658113499e-05,
      "loss": 0.0001,
      "step": 162200
    },
    {
      "epoch": 7.7963576954495215,
      "grad_norm": 0.09925813972949982,
      "learning_rate": 1.1018451780308492e-05,
      "loss": 0.0001,
      "step": 162250
    },
    {
      "epoch": 7.798760271010523,
      "grad_norm": 0.1442309319972992,
      "learning_rate": 1.1006438902503484e-05,
      "loss": 0.0001,
      "step": 162300
    },
    {
      "epoch": 7.801162846571525,
      "grad_norm": 0.2600908875465393,
      "learning_rate": 1.0994426024698477e-05,
      "loss": 0.0001,
      "step": 162350
    },
    {
      "epoch": 7.803565422132526,
      "grad_norm": 0.2939909100532532,
      "learning_rate": 1.098241314689347e-05,
      "loss": 0.0001,
      "step": 162400
    },
    {
      "epoch": 7.805967997693528,
      "grad_norm": 0.10773145407438278,
      "learning_rate": 1.0970400269088463e-05,
      "loss": 0.0001,
      "step": 162450
    },
    {
      "epoch": 7.808370573254529,
      "grad_norm": 0.12034811824560165,
      "learning_rate": 1.0958387391283456e-05,
      "loss": 0.0001,
      "step": 162500
    },
    {
      "epoch": 7.81077314881553,
      "grad_norm": 0.2757195830345154,
      "learning_rate": 1.094637451347845e-05,
      "loss": 0.0001,
      "step": 162550
    },
    {
      "epoch": 7.813175724376531,
      "grad_norm": 0.0888330340385437,
      "learning_rate": 1.0934361635673443e-05,
      "loss": 0.0001,
      "step": 162600
    },
    {
      "epoch": 7.815578299937533,
      "grad_norm": 0.5389723777770996,
      "learning_rate": 1.0922348757868435e-05,
      "loss": 0.0001,
      "step": 162650
    },
    {
      "epoch": 7.8179808754985345,
      "grad_norm": 0.24669064581394196,
      "learning_rate": 1.0910335880063428e-05,
      "loss": 0.0005,
      "step": 162700
    },
    {
      "epoch": 7.820383451059536,
      "grad_norm": 0.3318242132663727,
      "learning_rate": 1.0898323002258422e-05,
      "loss": 0.0001,
      "step": 162750
    },
    {
      "epoch": 7.822786026620538,
      "grad_norm": 0.20226489007472992,
      "learning_rate": 1.0886310124453414e-05,
      "loss": 0.0001,
      "step": 162800
    },
    {
      "epoch": 7.825188602181538,
      "grad_norm": 0.08206316083669662,
      "learning_rate": 1.0874297246648407e-05,
      "loss": 0.0001,
      "step": 162850
    },
    {
      "epoch": 7.82759117774254,
      "grad_norm": 0.03885240852832794,
      "learning_rate": 1.0862284368843401e-05,
      "loss": 0.0001,
      "step": 162900
    },
    {
      "epoch": 7.829993753303541,
      "grad_norm": 0.048685912042856216,
      "learning_rate": 1.0850271491038394e-05,
      "loss": 0.0001,
      "step": 162950
    },
    {
      "epoch": 7.832396328864543,
      "grad_norm": 0.26565590500831604,
      "learning_rate": 1.0838258613233386e-05,
      "loss": 0.0001,
      "step": 163000
    },
    {
      "epoch": 7.834798904425544,
      "grad_norm": 0.051681432873010635,
      "learning_rate": 1.0826245735428379e-05,
      "loss": 0.0001,
      "step": 163050
    },
    {
      "epoch": 7.837201479986546,
      "grad_norm": 0.213851660490036,
      "learning_rate": 1.0814232857623373e-05,
      "loss": 0.0001,
      "step": 163100
    },
    {
      "epoch": 7.839604055547547,
      "grad_norm": 0.08693376928567886,
      "learning_rate": 1.0802219979818367e-05,
      "loss": 0.0001,
      "step": 163150
    },
    {
      "epoch": 7.842006631108548,
      "grad_norm": 0.1488761603832245,
      "learning_rate": 1.0790207102013358e-05,
      "loss": 0.0001,
      "step": 163200
    },
    {
      "epoch": 7.84440920666955,
      "grad_norm": 0.11076821386814117,
      "learning_rate": 1.0778194224208352e-05,
      "loss": 0.0001,
      "step": 163250
    },
    {
      "epoch": 7.846811782230551,
      "grad_norm": 0.20819362998008728,
      "learning_rate": 1.0766181346403345e-05,
      "loss": 0.0001,
      "step": 163300
    },
    {
      "epoch": 7.849214357791553,
      "grad_norm": 0.6097304821014404,
      "learning_rate": 1.0754168468598339e-05,
      "loss": 0.0001,
      "step": 163350
    },
    {
      "epoch": 7.851616933352554,
      "grad_norm": 0.05874205380678177,
      "learning_rate": 1.074215559079333e-05,
      "loss": 0.0001,
      "step": 163400
    },
    {
      "epoch": 7.854019508913556,
      "grad_norm": 0.36570975184440613,
      "learning_rate": 1.0730142712988324e-05,
      "loss": 0.0001,
      "step": 163450
    },
    {
      "epoch": 7.8564220844745565,
      "grad_norm": 0.15597908198833466,
      "learning_rate": 1.0718129835183318e-05,
      "loss": 0.0001,
      "step": 163500
    },
    {
      "epoch": 7.858824660035558,
      "grad_norm": 0.18896755576133728,
      "learning_rate": 1.070611695737831e-05,
      "loss": 0.0005,
      "step": 163550
    },
    {
      "epoch": 7.86122723559656,
      "grad_norm": 0.11003117263317108,
      "learning_rate": 1.0694104079573303e-05,
      "loss": 0.0001,
      "step": 163600
    },
    {
      "epoch": 7.863629811157561,
      "grad_norm": 0.10711740702390671,
      "learning_rate": 1.0682091201768296e-05,
      "loss": 0.0001,
      "step": 163650
    },
    {
      "epoch": 7.866032386718563,
      "grad_norm": 0.20245900750160217,
      "learning_rate": 1.067007832396329e-05,
      "loss": 0.0001,
      "step": 163700
    },
    {
      "epoch": 7.868434962279563,
      "grad_norm": 0.12122149765491486,
      "learning_rate": 1.0658065446158282e-05,
      "loss": 0.0001,
      "step": 163750
    },
    {
      "epoch": 7.870837537840565,
      "grad_norm": 0.2897588014602661,
      "learning_rate": 1.0646052568353275e-05,
      "loss": 0.0001,
      "step": 163800
    },
    {
      "epoch": 7.873240113401566,
      "grad_norm": 0.16577233374118805,
      "learning_rate": 1.0634039690548269e-05,
      "loss": 0.0001,
      "step": 163850
    },
    {
      "epoch": 7.875642688962568,
      "grad_norm": 0.43167802691459656,
      "learning_rate": 1.0622026812743262e-05,
      "loss": 0.0001,
      "step": 163900
    },
    {
      "epoch": 7.8780452645235695,
      "grad_norm": 0.03875360265374184,
      "learning_rate": 1.0610013934938254e-05,
      "loss": 0.0001,
      "step": 163950
    },
    {
      "epoch": 7.880447840084571,
      "grad_norm": 0.2536375820636749,
      "learning_rate": 1.0598001057133247e-05,
      "loss": 0.0001,
      "step": 164000
    },
    {
      "epoch": 7.8828504156455725,
      "grad_norm": 0.052055664360523224,
      "learning_rate": 1.0585988179328241e-05,
      "loss": 0.0001,
      "step": 164050
    },
    {
      "epoch": 7.885252991206573,
      "grad_norm": 0.14423629641532898,
      "learning_rate": 1.0573975301523233e-05,
      "loss": 0.0001,
      "step": 164100
    },
    {
      "epoch": 7.887655566767575,
      "grad_norm": 0.11136709898710251,
      "learning_rate": 1.0561962423718226e-05,
      "loss": 0.0005,
      "step": 164150
    },
    {
      "epoch": 7.890058142328576,
      "grad_norm": 0.1221417486667633,
      "learning_rate": 1.054994954591322e-05,
      "loss": 0.0001,
      "step": 164200
    },
    {
      "epoch": 7.892460717889578,
      "grad_norm": 0.26807960867881775,
      "learning_rate": 1.0537936668108213e-05,
      "loss": 0.0001,
      "step": 164250
    },
    {
      "epoch": 7.894863293450579,
      "grad_norm": 0.13039536774158478,
      "learning_rate": 1.0525923790303205e-05,
      "loss": 0.0001,
      "step": 164300
    },
    {
      "epoch": 7.89726586901158,
      "grad_norm": 0.31999313831329346,
      "learning_rate": 1.0513910912498198e-05,
      "loss": 0.0004,
      "step": 164350
    },
    {
      "epoch": 7.8996684445725815,
      "grad_norm": 0.17186938226222992,
      "learning_rate": 1.0501898034693192e-05,
      "loss": 0.0001,
      "step": 164400
    },
    {
      "epoch": 7.902071020133583,
      "grad_norm": 0.13630756735801697,
      "learning_rate": 1.0489885156888184e-05,
      "loss": 0.0001,
      "step": 164450
    },
    {
      "epoch": 7.904473595694585,
      "grad_norm": 0.22013433277606964,
      "learning_rate": 1.0477872279083177e-05,
      "loss": 0.0001,
      "step": 164500
    },
    {
      "epoch": 7.906876171255586,
      "grad_norm": 0.14686590433120728,
      "learning_rate": 1.0465859401278171e-05,
      "loss": 0.0001,
      "step": 164550
    },
    {
      "epoch": 7.909278746816588,
      "grad_norm": 0.17527393996715546,
      "learning_rate": 1.0453846523473164e-05,
      "loss": 0.0001,
      "step": 164600
    },
    {
      "epoch": 7.911681322377589,
      "grad_norm": 0.19219638407230377,
      "learning_rate": 1.0441833645668158e-05,
      "loss": 0.0001,
      "step": 164650
    },
    {
      "epoch": 7.91408389793859,
      "grad_norm": 0.2574617862701416,
      "learning_rate": 1.0429820767863149e-05,
      "loss": 0.0001,
      "step": 164700
    },
    {
      "epoch": 7.9164864734995914,
      "grad_norm": 0.13547612726688385,
      "learning_rate": 1.0417807890058143e-05,
      "loss": 0.0001,
      "step": 164750
    },
    {
      "epoch": 7.918889049060593,
      "grad_norm": 0.05789150297641754,
      "learning_rate": 1.0405795012253135e-05,
      "loss": 0.0001,
      "step": 164800
    },
    {
      "epoch": 7.9212916246215945,
      "grad_norm": 0.04065113514661789,
      "learning_rate": 1.039378213444813e-05,
      "loss": 0.0001,
      "step": 164850
    },
    {
      "epoch": 7.923694200182596,
      "grad_norm": 0.14382272958755493,
      "learning_rate": 1.0381769256643122e-05,
      "loss": 0.0001,
      "step": 164900
    },
    {
      "epoch": 7.926096775743597,
      "grad_norm": 0.08324776589870453,
      "learning_rate": 1.0369756378838115e-05,
      "loss": 0.0001,
      "step": 164950
    },
    {
      "epoch": 7.928499351304598,
      "grad_norm": 0.07800488919019699,
      "learning_rate": 1.0357743501033109e-05,
      "loss": 0.0001,
      "step": 165000
    },
    {
      "epoch": 7.9309019268656,
      "grad_norm": 0.07774600386619568,
      "learning_rate": 1.03457306232281e-05,
      "loss": 0.0003,
      "step": 165050
    },
    {
      "epoch": 7.933304502426601,
      "grad_norm": 0.3176218569278717,
      "learning_rate": 1.0333717745423094e-05,
      "loss": 0.0001,
      "step": 165100
    },
    {
      "epoch": 7.935707077987603,
      "grad_norm": 0.15814648568630219,
      "learning_rate": 1.0321704867618086e-05,
      "loss": 0.0001,
      "step": 165150
    },
    {
      "epoch": 7.938109653548604,
      "grad_norm": 0.2681638300418854,
      "learning_rate": 1.030969198981308e-05,
      "loss": 0.0001,
      "step": 165200
    },
    {
      "epoch": 7.940512229109606,
      "grad_norm": 0.2857615053653717,
      "learning_rate": 1.0297679112008073e-05,
      "loss": 0.0001,
      "step": 165250
    },
    {
      "epoch": 7.942914804670607,
      "grad_norm": 0.07182159274816513,
      "learning_rate": 1.0285666234203066e-05,
      "loss": 0.0001,
      "step": 165300
    },
    {
      "epoch": 7.945317380231608,
      "grad_norm": 0.12452604621648788,
      "learning_rate": 1.027365335639806e-05,
      "loss": 0.0001,
      "step": 165350
    },
    {
      "epoch": 7.94771995579261,
      "grad_norm": 0.05710475519299507,
      "learning_rate": 1.0261640478593052e-05,
      "loss": 0.0001,
      "step": 165400
    },
    {
      "epoch": 7.950122531353611,
      "grad_norm": 0.07394735515117645,
      "learning_rate": 1.0249627600788045e-05,
      "loss": 0.0005,
      "step": 165450
    },
    {
      "epoch": 7.952525106914613,
      "grad_norm": 0.11704932898283005,
      "learning_rate": 1.0237614722983038e-05,
      "loss": 0.0001,
      "step": 165500
    },
    {
      "epoch": 7.954927682475613,
      "grad_norm": 0.24828249216079712,
      "learning_rate": 1.0225601845178032e-05,
      "loss": 0.0001,
      "step": 165550
    },
    {
      "epoch": 7.957330258036615,
      "grad_norm": 0.17931564152240753,
      "learning_rate": 1.0213588967373024e-05,
      "loss": 0.0001,
      "step": 165600
    },
    {
      "epoch": 7.9597328335976165,
      "grad_norm": 0.13814856112003326,
      "learning_rate": 1.0201576089568017e-05,
      "loss": 0.0001,
      "step": 165650
    },
    {
      "epoch": 7.962135409158618,
      "grad_norm": 0.6511759757995605,
      "learning_rate": 1.0189563211763011e-05,
      "loss": 0.0001,
      "step": 165700
    },
    {
      "epoch": 7.96453798471962,
      "grad_norm": 0.3713430166244507,
      "learning_rate": 1.0177550333958003e-05,
      "loss": 0.0001,
      "step": 165750
    },
    {
      "epoch": 7.966940560280621,
      "grad_norm": 0.2992282509803772,
      "learning_rate": 1.0165537456152996e-05,
      "loss": 0.0003,
      "step": 165800
    },
    {
      "epoch": 7.969343135841623,
      "grad_norm": 0.3136287033557892,
      "learning_rate": 1.0153524578347989e-05,
      "loss": 0.0001,
      "step": 165850
    },
    {
      "epoch": 7.971745711402623,
      "grad_norm": 0.32805848121643066,
      "learning_rate": 1.0141511700542983e-05,
      "loss": 0.0001,
      "step": 165900
    },
    {
      "epoch": 7.974148286963625,
      "grad_norm": 0.5228884220123291,
      "learning_rate": 1.0129498822737977e-05,
      "loss": 0.0004,
      "step": 165950
    },
    {
      "epoch": 7.976550862524626,
      "grad_norm": 0.11068679392337799,
      "learning_rate": 1.0117485944932968e-05,
      "loss": 0.0001,
      "step": 166000
    },
    {
      "epoch": 7.978953438085628,
      "grad_norm": 0.22405260801315308,
      "learning_rate": 1.0105473067127962e-05,
      "loss": 0.0001,
      "step": 166050
    },
    {
      "epoch": 7.9813560136466295,
      "grad_norm": 0.22993886470794678,
      "learning_rate": 1.0093460189322955e-05,
      "loss": 0.0001,
      "step": 166100
    },
    {
      "epoch": 7.98375858920763,
      "grad_norm": 0.19860805571079254,
      "learning_rate": 1.0081447311517949e-05,
      "loss": 0.0001,
      "step": 166150
    },
    {
      "epoch": 7.986161164768632,
      "grad_norm": 0.0673617273569107,
      "learning_rate": 1.006943443371294e-05,
      "loss": 0.0001,
      "step": 166200
    },
    {
      "epoch": 7.988563740329633,
      "grad_norm": 0.11506280303001404,
      "learning_rate": 1.0057421555907934e-05,
      "loss": 0.0001,
      "step": 166250
    },
    {
      "epoch": 7.990966315890635,
      "grad_norm": 0.10121160745620728,
      "learning_rate": 1.0045408678102928e-05,
      "loss": 0.0001,
      "step": 166300
    },
    {
      "epoch": 7.993368891451636,
      "grad_norm": 0.2325587123632431,
      "learning_rate": 1.0033395800297919e-05,
      "loss": 0.0001,
      "step": 166350
    },
    {
      "epoch": 7.995771467012638,
      "grad_norm": 0.2537347972393036,
      "learning_rate": 1.0021382922492913e-05,
      "loss": 0.0001,
      "step": 166400
    },
    {
      "epoch": 7.998174042573639,
      "grad_norm": 0.16954003274440765,
      "learning_rate": 1.0009370044687906e-05,
      "loss": 0.0001,
      "step": 166450
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.0001558842632221058,
      "eval_runtime": 17.4709,
      "eval_samples_per_second": 543.532,
      "eval_steps_per_second": 67.942,
      "step": 166488
    },
    {
      "epoch": 8.000576618134641,
      "grad_norm": 0.06423216313123703,
      "learning_rate": 9.9973571668829e-06,
      "loss": 0.0001,
      "step": 166500
    },
    {
      "epoch": 8.002979193695642,
      "grad_norm": 0.051263295114040375,
      "learning_rate": 9.985344289077892e-06,
      "loss": 0.0001,
      "step": 166550
    },
    {
      "epoch": 8.005381769256642,
      "grad_norm": 0.1319946050643921,
      "learning_rate": 9.973331411272885e-06,
      "loss": 0.0001,
      "step": 166600
    },
    {
      "epoch": 8.007784344817644,
      "grad_norm": 0.10926616936922073,
      "learning_rate": 9.961318533467879e-06,
      "loss": 0.0001,
      "step": 166650
    },
    {
      "epoch": 8.010186920378645,
      "grad_norm": 0.42533379793167114,
      "learning_rate": 9.949305655662872e-06,
      "loss": 0.0001,
      "step": 166700
    },
    {
      "epoch": 8.012589495939647,
      "grad_norm": 0.39450615644454956,
      "learning_rate": 9.937292777857864e-06,
      "loss": 0.0001,
      "step": 166750
    },
    {
      "epoch": 8.014992071500648,
      "grad_norm": 0.12075070291757584,
      "learning_rate": 9.925279900052857e-06,
      "loss": 0.0001,
      "step": 166800
    },
    {
      "epoch": 8.01739464706165,
      "grad_norm": 0.30082568526268005,
      "learning_rate": 9.91326702224785e-06,
      "loss": 0.0001,
      "step": 166850
    },
    {
      "epoch": 8.019797222622651,
      "grad_norm": 0.30684852600097656,
      "learning_rate": 9.901254144442843e-06,
      "loss": 0.0001,
      "step": 166900
    },
    {
      "epoch": 8.022199798183653,
      "grad_norm": 0.3252985179424286,
      "learning_rate": 9.889241266637836e-06,
      "loss": 0.0004,
      "step": 166950
    },
    {
      "epoch": 8.024602373744655,
      "grad_norm": 0.1064184159040451,
      "learning_rate": 9.87722838883283e-06,
      "loss": 0.0001,
      "step": 167000
    },
    {
      "epoch": 8.027004949305656,
      "grad_norm": 0.1841965913772583,
      "learning_rate": 9.865215511027823e-06,
      "loss": 0.0001,
      "step": 167050
    },
    {
      "epoch": 8.029407524866658,
      "grad_norm": 0.07074690610170364,
      "learning_rate": 9.853202633222815e-06,
      "loss": 0.0001,
      "step": 167100
    },
    {
      "epoch": 8.03181010042766,
      "grad_norm": 0.02130727283656597,
      "learning_rate": 9.841189755417808e-06,
      "loss": 0.0001,
      "step": 167150
    },
    {
      "epoch": 8.034212675988659,
      "grad_norm": 0.3667187988758087,
      "learning_rate": 9.829176877612802e-06,
      "loss": 0.0001,
      "step": 167200
    },
    {
      "epoch": 8.03661525154966,
      "grad_norm": 0.12387387454509735,
      "learning_rate": 9.817163999807794e-06,
      "loss": 0.0001,
      "step": 167250
    },
    {
      "epoch": 8.039017827110662,
      "grad_norm": 0.13297049701213837,
      "learning_rate": 9.805151122002787e-06,
      "loss": 0.0001,
      "step": 167300
    },
    {
      "epoch": 8.041420402671664,
      "grad_norm": 0.02218628115952015,
      "learning_rate": 9.793138244197781e-06,
      "loss": 0.0003,
      "step": 167350
    },
    {
      "epoch": 8.043822978232665,
      "grad_norm": 0.1017124131321907,
      "learning_rate": 9.781125366392774e-06,
      "loss": 0.0001,
      "step": 167400
    },
    {
      "epoch": 8.046225553793667,
      "grad_norm": 0.2100793868303299,
      "learning_rate": 9.769112488587768e-06,
      "loss": 0.0001,
      "step": 167450
    },
    {
      "epoch": 8.048628129354668,
      "grad_norm": 0.0853913426399231,
      "learning_rate": 9.757099610782759e-06,
      "loss": 0.0001,
      "step": 167500
    },
    {
      "epoch": 8.05103070491567,
      "grad_norm": 0.11049667745828629,
      "learning_rate": 9.745086732977753e-06,
      "loss": 0.0001,
      "step": 167550
    },
    {
      "epoch": 8.053433280476671,
      "grad_norm": 0.2942520081996918,
      "learning_rate": 9.733073855172745e-06,
      "loss": 0.0001,
      "step": 167600
    },
    {
      "epoch": 8.055835856037673,
      "grad_norm": 0.09234454482793808,
      "learning_rate": 9.721060977367738e-06,
      "loss": 0.0001,
      "step": 167650
    },
    {
      "epoch": 8.058238431598674,
      "grad_norm": 0.37135326862335205,
      "learning_rate": 9.709048099562732e-06,
      "loss": 0.0001,
      "step": 167700
    },
    {
      "epoch": 8.060641007159676,
      "grad_norm": 0.4062865078449249,
      "learning_rate": 9.697035221757725e-06,
      "loss": 0.0002,
      "step": 167750
    },
    {
      "epoch": 8.063043582720677,
      "grad_norm": 0.04346586391329765,
      "learning_rate": 9.685022343952719e-06,
      "loss": 0.0001,
      "step": 167800
    },
    {
      "epoch": 8.065446158281677,
      "grad_norm": 0.23356708884239197,
      "learning_rate": 9.67300946614771e-06,
      "loss": 0.0004,
      "step": 167850
    },
    {
      "epoch": 8.067848733842679,
      "grad_norm": 0.23494277894496918,
      "learning_rate": 9.660996588342704e-06,
      "loss": 0.0001,
      "step": 167900
    },
    {
      "epoch": 8.07025130940368,
      "grad_norm": 0.2807988226413727,
      "learning_rate": 9.648983710537696e-06,
      "loss": 0.0001,
      "step": 167950
    },
    {
      "epoch": 8.072653884964682,
      "grad_norm": 0.06978853046894073,
      "learning_rate": 9.63697083273269e-06,
      "loss": 0.0001,
      "step": 168000
    },
    {
      "epoch": 8.075056460525683,
      "grad_norm": 0.22559498250484467,
      "learning_rate": 9.624957954927683e-06,
      "loss": 0.0001,
      "step": 168050
    },
    {
      "epoch": 8.077459036086685,
      "grad_norm": 0.07661863416433334,
      "learning_rate": 9.612945077122676e-06,
      "loss": 0.0004,
      "step": 168100
    },
    {
      "epoch": 8.079861611647686,
      "grad_norm": 0.11762620508670807,
      "learning_rate": 9.60093219931767e-06,
      "loss": 0.0001,
      "step": 168150
    },
    {
      "epoch": 8.082264187208688,
      "grad_norm": 0.029051972553133965,
      "learning_rate": 9.588919321512662e-06,
      "loss": 0.0001,
      "step": 168200
    },
    {
      "epoch": 8.08466676276969,
      "grad_norm": 0.08491602540016174,
      "learning_rate": 9.576906443707655e-06,
      "loss": 0.0001,
      "step": 168250
    },
    {
      "epoch": 8.087069338330691,
      "grad_norm": 0.15005064010620117,
      "learning_rate": 9.564893565902647e-06,
      "loss": 0.0001,
      "step": 168300
    },
    {
      "epoch": 8.089471913891693,
      "grad_norm": 0.05387597903609276,
      "learning_rate": 9.552880688097642e-06,
      "loss": 0.0001,
      "step": 168350
    },
    {
      "epoch": 8.091874489452694,
      "grad_norm": 0.20576901733875275,
      "learning_rate": 9.540867810292634e-06,
      "loss": 0.0001,
      "step": 168400
    },
    {
      "epoch": 8.094277065013694,
      "grad_norm": 0.0870218500494957,
      "learning_rate": 9.528854932487627e-06,
      "loss": 0.0001,
      "step": 168450
    },
    {
      "epoch": 8.096679640574695,
      "grad_norm": 0.08108720928430557,
      "learning_rate": 9.516842054682621e-06,
      "loss": 0.0001,
      "step": 168500
    },
    {
      "epoch": 8.099082216135697,
      "grad_norm": 0.12362784147262573,
      "learning_rate": 9.504829176877613e-06,
      "loss": 0.0001,
      "step": 168550
    },
    {
      "epoch": 8.101484791696699,
      "grad_norm": 0.09663435071706772,
      "learning_rate": 9.492816299072606e-06,
      "loss": 0.0001,
      "step": 168600
    },
    {
      "epoch": 8.1038873672577,
      "grad_norm": 0.0506078377366066,
      "learning_rate": 9.480803421267598e-06,
      "loss": 0.0001,
      "step": 168650
    },
    {
      "epoch": 8.106289942818702,
      "grad_norm": 0.13139252364635468,
      "learning_rate": 9.468790543462593e-06,
      "loss": 0.0001,
      "step": 168700
    },
    {
      "epoch": 8.108692518379703,
      "grad_norm": 0.0729379877448082,
      "learning_rate": 9.456777665657587e-06,
      "loss": 0.0001,
      "step": 168750
    },
    {
      "epoch": 8.111095093940705,
      "grad_norm": 0.12962275743484497,
      "learning_rate": 9.444764787852578e-06,
      "loss": 0.0001,
      "step": 168800
    },
    {
      "epoch": 8.113497669501706,
      "grad_norm": 0.06433236598968506,
      "learning_rate": 9.432751910047572e-06,
      "loss": 0.0001,
      "step": 168850
    },
    {
      "epoch": 8.115900245062708,
      "grad_norm": 0.1730998158454895,
      "learning_rate": 9.420739032242564e-06,
      "loss": 0.0001,
      "step": 168900
    },
    {
      "epoch": 8.11830282062371,
      "grad_norm": 0.20747673511505127,
      "learning_rate": 9.408726154437557e-06,
      "loss": 0.0001,
      "step": 168950
    },
    {
      "epoch": 8.12070539618471,
      "grad_norm": 0.053390372544527054,
      "learning_rate": 9.39671327663255e-06,
      "loss": 0.0001,
      "step": 169000
    },
    {
      "epoch": 8.12310797174571,
      "grad_norm": 0.20785829424858093,
      "learning_rate": 9.384700398827544e-06,
      "loss": 0.0001,
      "step": 169050
    },
    {
      "epoch": 8.125510547306712,
      "grad_norm": 0.12896309792995453,
      "learning_rate": 9.372687521022538e-06,
      "loss": 0.0005,
      "step": 169100
    },
    {
      "epoch": 8.127913122867714,
      "grad_norm": 0.1486077457666397,
      "learning_rate": 9.360674643217529e-06,
      "loss": 0.0001,
      "step": 169150
    },
    {
      "epoch": 8.130315698428715,
      "grad_norm": 0.1401039958000183,
      "learning_rate": 9.348661765412523e-06,
      "loss": 0.0001,
      "step": 169200
    },
    {
      "epoch": 8.132718273989717,
      "grad_norm": 0.21424651145935059,
      "learning_rate": 9.336648887607515e-06,
      "loss": 0.0001,
      "step": 169250
    },
    {
      "epoch": 8.135120849550718,
      "grad_norm": 0.02376672811806202,
      "learning_rate": 9.32463600980251e-06,
      "loss": 0.0001,
      "step": 169300
    },
    {
      "epoch": 8.13752342511172,
      "grad_norm": 0.09956170618534088,
      "learning_rate": 9.312623131997502e-06,
      "loss": 0.0001,
      "step": 169350
    },
    {
      "epoch": 8.139926000672721,
      "grad_norm": 0.06824376434087753,
      "learning_rate": 9.300610254192495e-06,
      "loss": 0.0001,
      "step": 169400
    },
    {
      "epoch": 8.142328576233723,
      "grad_norm": 0.44268032908439636,
      "learning_rate": 9.288597376387489e-06,
      "loss": 0.0005,
      "step": 169450
    },
    {
      "epoch": 8.144731151794725,
      "grad_norm": 0.11944884806871414,
      "learning_rate": 9.276584498582481e-06,
      "loss": 0.0001,
      "step": 169500
    },
    {
      "epoch": 8.147133727355726,
      "grad_norm": 0.15259337425231934,
      "learning_rate": 9.264571620777474e-06,
      "loss": 0.0001,
      "step": 169550
    },
    {
      "epoch": 8.149536302916728,
      "grad_norm": 0.3754540681838989,
      "learning_rate": 9.252558742972466e-06,
      "loss": 0.0001,
      "step": 169600
    },
    {
      "epoch": 8.151938878477727,
      "grad_norm": 0.13266681134700775,
      "learning_rate": 9.24054586516746e-06,
      "loss": 0.0001,
      "step": 169650
    },
    {
      "epoch": 8.154341454038729,
      "grad_norm": 0.051804568618535995,
      "learning_rate": 9.228532987362453e-06,
      "loss": 0.0001,
      "step": 169700
    },
    {
      "epoch": 8.15674402959973,
      "grad_norm": 0.18796692788600922,
      "learning_rate": 9.216520109557446e-06,
      "loss": 0.0001,
      "step": 169750
    },
    {
      "epoch": 8.159146605160732,
      "grad_norm": 0.43085673451423645,
      "learning_rate": 9.20450723175244e-06,
      "loss": 0.0001,
      "step": 169800
    },
    {
      "epoch": 8.161549180721734,
      "grad_norm": 0.049439623951911926,
      "learning_rate": 9.192494353947432e-06,
      "loss": 0.0001,
      "step": 169850
    },
    {
      "epoch": 8.163951756282735,
      "grad_norm": 0.2197132259607315,
      "learning_rate": 9.180481476142425e-06,
      "loss": 0.0005,
      "step": 169900
    },
    {
      "epoch": 8.166354331843737,
      "grad_norm": 0.5076773762702942,
      "learning_rate": 9.168468598337417e-06,
      "loss": 0.0005,
      "step": 169950
    },
    {
      "epoch": 8.168756907404738,
      "grad_norm": 0.25054052472114563,
      "learning_rate": 9.156455720532412e-06,
      "loss": 0.0001,
      "step": 170000
    },
    {
      "epoch": 8.17115948296574,
      "grad_norm": 0.2895820438861847,
      "learning_rate": 9.144442842727404e-06,
      "loss": 0.0001,
      "step": 170050
    },
    {
      "epoch": 8.173562058526741,
      "grad_norm": 0.564238429069519,
      "learning_rate": 9.132429964922397e-06,
      "loss": 0.0001,
      "step": 170100
    },
    {
      "epoch": 8.175964634087743,
      "grad_norm": 0.21671901643276215,
      "learning_rate": 9.120417087117391e-06,
      "loss": 0.0001,
      "step": 170150
    },
    {
      "epoch": 8.178367209648744,
      "grad_norm": 0.07559492439031601,
      "learning_rate": 9.108404209312383e-06,
      "loss": 0.0001,
      "step": 170200
    },
    {
      "epoch": 8.180769785209744,
      "grad_norm": 0.06660357117652893,
      "learning_rate": 9.096391331507376e-06,
      "loss": 0.0001,
      "step": 170250
    },
    {
      "epoch": 8.183172360770746,
      "grad_norm": 0.05972178280353546,
      "learning_rate": 9.084378453702368e-06,
      "loss": 0.0001,
      "step": 170300
    },
    {
      "epoch": 8.185574936331747,
      "grad_norm": 0.14364027976989746,
      "learning_rate": 9.072365575897363e-06,
      "loss": 0.0001,
      "step": 170350
    },
    {
      "epoch": 8.187977511892749,
      "grad_norm": 0.42803311347961426,
      "learning_rate": 9.060352698092355e-06,
      "loss": 0.0001,
      "step": 170400
    },
    {
      "epoch": 8.19038008745375,
      "grad_norm": 0.16680152714252472,
      "learning_rate": 9.048339820287348e-06,
      "loss": 0.0001,
      "step": 170450
    },
    {
      "epoch": 8.192782663014752,
      "grad_norm": 0.43268898129463196,
      "learning_rate": 9.036326942482342e-06,
      "loss": 0.0001,
      "step": 170500
    },
    {
      "epoch": 8.195185238575753,
      "grad_norm": 0.04712429270148277,
      "learning_rate": 9.024314064677334e-06,
      "loss": 0.0001,
      "step": 170550
    },
    {
      "epoch": 8.197587814136755,
      "grad_norm": 0.08136040717363358,
      "learning_rate": 9.012301186872329e-06,
      "loss": 0.0001,
      "step": 170600
    },
    {
      "epoch": 8.199990389697756,
      "grad_norm": 0.11057724058628082,
      "learning_rate": 9.00028830906732e-06,
      "loss": 0.0001,
      "step": 170650
    },
    {
      "epoch": 8.202392965258758,
      "grad_norm": 0.13865265250205994,
      "learning_rate": 8.988275431262314e-06,
      "loss": 0.0001,
      "step": 170700
    },
    {
      "epoch": 8.20479554081976,
      "grad_norm": 0.27102991938591003,
      "learning_rate": 8.976262553457306e-06,
      "loss": 0.0005,
      "step": 170750
    },
    {
      "epoch": 8.207198116380761,
      "grad_norm": 0.08418931066989899,
      "learning_rate": 8.9642496756523e-06,
      "loss": 0.0003,
      "step": 170800
    },
    {
      "epoch": 8.20960069194176,
      "grad_norm": 0.04935568943619728,
      "learning_rate": 8.952236797847293e-06,
      "loss": 0.0001,
      "step": 170850
    },
    {
      "epoch": 8.212003267502762,
      "grad_norm": 0.3555375635623932,
      "learning_rate": 8.940223920042285e-06,
      "loss": 0.0001,
      "step": 170900
    },
    {
      "epoch": 8.214405843063764,
      "grad_norm": 0.08969774097204208,
      "learning_rate": 8.92821104223728e-06,
      "loss": 0.0004,
      "step": 170950
    },
    {
      "epoch": 8.216808418624765,
      "grad_norm": 0.08934944123029709,
      "learning_rate": 8.91619816443227e-06,
      "loss": 0.0001,
      "step": 171000
    },
    {
      "epoch": 8.219210994185767,
      "grad_norm": 0.18804119527339935,
      "learning_rate": 8.904185286627265e-06,
      "loss": 0.0004,
      "step": 171050
    },
    {
      "epoch": 8.221613569746768,
      "grad_norm": 0.04933643713593483,
      "learning_rate": 8.892172408822257e-06,
      "loss": 0.0002,
      "step": 171100
    },
    {
      "epoch": 8.22401614530777,
      "grad_norm": 0.39064741134643555,
      "learning_rate": 8.880159531017251e-06,
      "loss": 0.0001,
      "step": 171150
    },
    {
      "epoch": 8.226418720868772,
      "grad_norm": 0.0813370868563652,
      "learning_rate": 8.868146653212244e-06,
      "loss": 0.0001,
      "step": 171200
    },
    {
      "epoch": 8.228821296429773,
      "grad_norm": 0.21135836839675903,
      "learning_rate": 8.856133775407237e-06,
      "loss": 0.0001,
      "step": 171250
    },
    {
      "epoch": 8.231223871990775,
      "grad_norm": 0.14217543601989746,
      "learning_rate": 8.84412089760223e-06,
      "loss": 0.0001,
      "step": 171300
    },
    {
      "epoch": 8.233626447551776,
      "grad_norm": 0.06499575078487396,
      "learning_rate": 8.832108019797223e-06,
      "loss": 0.0001,
      "step": 171350
    },
    {
      "epoch": 8.236029023112778,
      "grad_norm": 0.17466503381729126,
      "learning_rate": 8.820095141992216e-06,
      "loss": 0.0001,
      "step": 171400
    },
    {
      "epoch": 8.238431598673778,
      "grad_norm": 0.16511313617229462,
      "learning_rate": 8.808082264187208e-06,
      "loss": 0.0001,
      "step": 171450
    },
    {
      "epoch": 8.240834174234779,
      "grad_norm": 0.48612460494041443,
      "learning_rate": 8.796069386382203e-06,
      "loss": 0.0001,
      "step": 171500
    },
    {
      "epoch": 8.24323674979578,
      "grad_norm": 0.2783888578414917,
      "learning_rate": 8.784056508577195e-06,
      "loss": 0.0001,
      "step": 171550
    },
    {
      "epoch": 8.245639325356782,
      "grad_norm": 0.16822855174541473,
      "learning_rate": 8.772043630772188e-06,
      "loss": 0.0001,
      "step": 171600
    },
    {
      "epoch": 8.248041900917784,
      "grad_norm": 0.21379095315933228,
      "learning_rate": 8.760030752967182e-06,
      "loss": 0.0001,
      "step": 171650
    },
    {
      "epoch": 8.250444476478785,
      "grad_norm": 0.21260927617549896,
      "learning_rate": 8.748017875162174e-06,
      "loss": 0.0001,
      "step": 171700
    },
    {
      "epoch": 8.252847052039787,
      "grad_norm": 0.08358436822891235,
      "learning_rate": 8.736004997357167e-06,
      "loss": 0.0001,
      "step": 171750
    },
    {
      "epoch": 8.255249627600788,
      "grad_norm": 0.31521257758140564,
      "learning_rate": 8.72399211955216e-06,
      "loss": 0.0005,
      "step": 171800
    },
    {
      "epoch": 8.25765220316179,
      "grad_norm": 0.339826762676239,
      "learning_rate": 8.711979241747154e-06,
      "loss": 0.0001,
      "step": 171850
    },
    {
      "epoch": 8.260054778722791,
      "grad_norm": 0.9794837236404419,
      "learning_rate": 8.699966363942148e-06,
      "loss": 0.0001,
      "step": 171900
    },
    {
      "epoch": 8.262457354283793,
      "grad_norm": 0.1791783720254898,
      "learning_rate": 8.687953486137139e-06,
      "loss": 0.0001,
      "step": 171950
    },
    {
      "epoch": 8.264859929844794,
      "grad_norm": 0.17257238924503326,
      "learning_rate": 8.675940608332133e-06,
      "loss": 0.0001,
      "step": 172000
    },
    {
      "epoch": 8.267262505405794,
      "grad_norm": 0.24611273407936096,
      "learning_rate": 8.663927730527125e-06,
      "loss": 0.0001,
      "step": 172050
    },
    {
      "epoch": 8.269665080966796,
      "grad_norm": 0.07383197546005249,
      "learning_rate": 8.65191485272212e-06,
      "loss": 0.0001,
      "step": 172100
    },
    {
      "epoch": 8.272067656527797,
      "grad_norm": 0.15835148096084595,
      "learning_rate": 8.63990197491711e-06,
      "loss": 0.0001,
      "step": 172150
    },
    {
      "epoch": 8.274470232088799,
      "grad_norm": 0.17058706283569336,
      "learning_rate": 8.627889097112105e-06,
      "loss": 0.0001,
      "step": 172200
    },
    {
      "epoch": 8.2768728076498,
      "grad_norm": 0.1720910370349884,
      "learning_rate": 8.615876219307099e-06,
      "loss": 0.0001,
      "step": 172250
    },
    {
      "epoch": 8.279275383210802,
      "grad_norm": 0.11460564285516739,
      "learning_rate": 8.60386334150209e-06,
      "loss": 0.0001,
      "step": 172300
    },
    {
      "epoch": 8.281677958771803,
      "grad_norm": 0.270902156829834,
      "learning_rate": 8.591850463697084e-06,
      "loss": 0.0001,
      "step": 172350
    },
    {
      "epoch": 8.284080534332805,
      "grad_norm": 0.3236255645751953,
      "learning_rate": 8.579837585892076e-06,
      "loss": 0.0003,
      "step": 172400
    },
    {
      "epoch": 8.286483109893807,
      "grad_norm": 0.111040860414505,
      "learning_rate": 8.56782470808707e-06,
      "loss": 0.0001,
      "step": 172450
    },
    {
      "epoch": 8.288885685454808,
      "grad_norm": 0.208542600274086,
      "learning_rate": 8.555811830282063e-06,
      "loss": 0.0001,
      "step": 172500
    },
    {
      "epoch": 8.29128826101581,
      "grad_norm": 0.09963900595903397,
      "learning_rate": 8.543798952477056e-06,
      "loss": 0.0001,
      "step": 172550
    },
    {
      "epoch": 8.293690836576811,
      "grad_norm": 0.05851378291845322,
      "learning_rate": 8.53178607467205e-06,
      "loss": 0.0001,
      "step": 172600
    },
    {
      "epoch": 8.296093412137811,
      "grad_norm": 0.16920031607151031,
      "learning_rate": 8.519773196867042e-06,
      "loss": 0.0001,
      "step": 172650
    },
    {
      "epoch": 8.298495987698812,
      "grad_norm": 0.0348128117620945,
      "learning_rate": 8.507760319062035e-06,
      "loss": 0.0001,
      "step": 172700
    },
    {
      "epoch": 8.300898563259814,
      "grad_norm": 0.19175304472446442,
      "learning_rate": 8.495747441257027e-06,
      "loss": 0.0001,
      "step": 172750
    },
    {
      "epoch": 8.303301138820816,
      "grad_norm": 0.09075908362865448,
      "learning_rate": 8.483734563452022e-06,
      "loss": 0.0001,
      "step": 172800
    },
    {
      "epoch": 8.305703714381817,
      "grad_norm": 0.11559352278709412,
      "learning_rate": 8.471721685647014e-06,
      "loss": 0.0001,
      "step": 172850
    },
    {
      "epoch": 8.308106289942819,
      "grad_norm": 0.06647396087646484,
      "learning_rate": 8.459708807842007e-06,
      "loss": 0.0001,
      "step": 172900
    },
    {
      "epoch": 8.31050886550382,
      "grad_norm": 0.1292772889137268,
      "learning_rate": 8.447695930037e-06,
      "loss": 0.0001,
      "step": 172950
    },
    {
      "epoch": 8.312911441064822,
      "grad_norm": 0.07805266976356506,
      "learning_rate": 8.435683052231993e-06,
      "loss": 0.0001,
      "step": 173000
    },
    {
      "epoch": 8.315314016625823,
      "grad_norm": 0.0540039986371994,
      "learning_rate": 8.423670174426986e-06,
      "loss": 0.0001,
      "step": 173050
    },
    {
      "epoch": 8.317716592186825,
      "grad_norm": 0.07127464562654495,
      "learning_rate": 8.411657296621978e-06,
      "loss": 0.0001,
      "step": 173100
    },
    {
      "epoch": 8.320119167747826,
      "grad_norm": 0.15435710549354553,
      "learning_rate": 8.399644418816973e-06,
      "loss": 0.0001,
      "step": 173150
    },
    {
      "epoch": 8.322521743308828,
      "grad_norm": 0.09726034849882126,
      "learning_rate": 8.387631541011965e-06,
      "loss": 0.0001,
      "step": 173200
    },
    {
      "epoch": 8.324924318869828,
      "grad_norm": 0.22294098138809204,
      "learning_rate": 8.375618663206958e-06,
      "loss": 0.0001,
      "step": 173250
    },
    {
      "epoch": 8.32732689443083,
      "grad_norm": 0.057281799614429474,
      "learning_rate": 8.363605785401952e-06,
      "loss": 0.0001,
      "step": 173300
    },
    {
      "epoch": 8.32972946999183,
      "grad_norm": 0.38549476861953735,
      "learning_rate": 8.351592907596944e-06,
      "loss": 0.0001,
      "step": 173350
    },
    {
      "epoch": 8.332132045552832,
      "grad_norm": 0.1564507782459259,
      "learning_rate": 8.339580029791939e-06,
      "loss": 0.0001,
      "step": 173400
    },
    {
      "epoch": 8.334534621113834,
      "grad_norm": 0.18481795489788055,
      "learning_rate": 8.32756715198693e-06,
      "loss": 0.0001,
      "step": 173450
    },
    {
      "epoch": 8.336937196674835,
      "grad_norm": 0.3061487078666687,
      "learning_rate": 8.315554274181924e-06,
      "loss": 0.0003,
      "step": 173500
    },
    {
      "epoch": 8.339339772235837,
      "grad_norm": 0.16769669950008392,
      "learning_rate": 8.303541396376916e-06,
      "loss": 0.0001,
      "step": 173550
    },
    {
      "epoch": 8.341742347796838,
      "grad_norm": 0.2862241864204407,
      "learning_rate": 8.291528518571909e-06,
      "loss": 0.0001,
      "step": 173600
    },
    {
      "epoch": 8.34414492335784,
      "grad_norm": 0.1042705774307251,
      "learning_rate": 8.279515640766903e-06,
      "loss": 0.0001,
      "step": 173650
    },
    {
      "epoch": 8.346547498918842,
      "grad_norm": 0.12607833743095398,
      "learning_rate": 8.267502762961895e-06,
      "loss": 0.0002,
      "step": 173700
    },
    {
      "epoch": 8.348950074479843,
      "grad_norm": 0.10559958964586258,
      "learning_rate": 8.25548988515689e-06,
      "loss": 0.0001,
      "step": 173750
    },
    {
      "epoch": 8.351352650040845,
      "grad_norm": 0.06580857187509537,
      "learning_rate": 8.24347700735188e-06,
      "loss": 0.0001,
      "step": 173800
    },
    {
      "epoch": 8.353755225601844,
      "grad_norm": 0.1521066427230835,
      "learning_rate": 8.231464129546875e-06,
      "loss": 0.0001,
      "step": 173850
    },
    {
      "epoch": 8.356157801162846,
      "grad_norm": 0.1817818135023117,
      "learning_rate": 8.219451251741867e-06,
      "loss": 0.0001,
      "step": 173900
    },
    {
      "epoch": 8.358560376723847,
      "grad_norm": 0.20877747237682343,
      "learning_rate": 8.207438373936861e-06,
      "loss": 0.0001,
      "step": 173950
    },
    {
      "epoch": 8.360962952284849,
      "grad_norm": 0.14191241562366486,
      "learning_rate": 8.195425496131854e-06,
      "loss": 0.0001,
      "step": 174000
    },
    {
      "epoch": 8.36336552784585,
      "grad_norm": 0.19080990552902222,
      "learning_rate": 8.183412618326846e-06,
      "loss": 0.0001,
      "step": 174050
    },
    {
      "epoch": 8.365768103406852,
      "grad_norm": 0.04064314439892769,
      "learning_rate": 8.17139974052184e-06,
      "loss": 0.0001,
      "step": 174100
    },
    {
      "epoch": 8.368170678967854,
      "grad_norm": 0.12821517884731293,
      "learning_rate": 8.159386862716833e-06,
      "loss": 0.0001,
      "step": 174150
    },
    {
      "epoch": 8.370573254528855,
      "grad_norm": 0.0956466794013977,
      "learning_rate": 8.147373984911826e-06,
      "loss": 0.0001,
      "step": 174200
    },
    {
      "epoch": 8.372975830089857,
      "grad_norm": 0.24568849802017212,
      "learning_rate": 8.135361107106818e-06,
      "loss": 0.0001,
      "step": 174250
    },
    {
      "epoch": 8.375378405650858,
      "grad_norm": 0.15854991972446442,
      "learning_rate": 8.123348229301812e-06,
      "loss": 0.0001,
      "step": 174300
    },
    {
      "epoch": 8.37778098121186,
      "grad_norm": 0.13889017701148987,
      "learning_rate": 8.111335351496805e-06,
      "loss": 0.0001,
      "step": 174350
    },
    {
      "epoch": 8.380183556772861,
      "grad_norm": 0.2528730630874634,
      "learning_rate": 8.099322473691797e-06,
      "loss": 0.0001,
      "step": 174400
    },
    {
      "epoch": 8.382586132333861,
      "grad_norm": 0.2203582376241684,
      "learning_rate": 8.087309595886792e-06,
      "loss": 0.0004,
      "step": 174450
    },
    {
      "epoch": 8.384988707894863,
      "grad_norm": 0.39563390612602234,
      "learning_rate": 8.075296718081784e-06,
      "loss": 0.0001,
      "step": 174500
    },
    {
      "epoch": 8.387391283455864,
      "grad_norm": 0.33927053213119507,
      "learning_rate": 8.063283840276777e-06,
      "loss": 0.0001,
      "step": 174550
    },
    {
      "epoch": 8.389793859016866,
      "grad_norm": 0.16139785945415497,
      "learning_rate": 8.05127096247177e-06,
      "loss": 0.0003,
      "step": 174600
    },
    {
      "epoch": 8.392196434577867,
      "grad_norm": 0.2922568619251251,
      "learning_rate": 8.039258084666763e-06,
      "loss": 0.0001,
      "step": 174650
    },
    {
      "epoch": 8.394599010138869,
      "grad_norm": 0.145347461104393,
      "learning_rate": 8.027245206861758e-06,
      "loss": 0.0001,
      "step": 174700
    },
    {
      "epoch": 8.39700158569987,
      "grad_norm": 0.2509632110595703,
      "learning_rate": 8.015232329056748e-06,
      "loss": 0.0001,
      "step": 174750
    },
    {
      "epoch": 8.399404161260872,
      "grad_norm": 0.0913684293627739,
      "learning_rate": 8.003219451251743e-06,
      "loss": 0.0001,
      "step": 174800
    },
    {
      "epoch": 8.401806736821873,
      "grad_norm": 0.12723863124847412,
      "learning_rate": 7.991206573446735e-06,
      "loss": 0.0001,
      "step": 174850
    },
    {
      "epoch": 8.404209312382875,
      "grad_norm": 0.03323541209101677,
      "learning_rate": 7.979193695641728e-06,
      "loss": 0.0001,
      "step": 174900
    },
    {
      "epoch": 8.406611887943876,
      "grad_norm": 0.1977826952934265,
      "learning_rate": 7.96718081783672e-06,
      "loss": 0.0001,
      "step": 174950
    },
    {
      "epoch": 8.409014463504878,
      "grad_norm": 0.1809212565422058,
      "learning_rate": 7.955167940031714e-06,
      "loss": 0.0001,
      "step": 175000
    },
    {
      "epoch": 8.411417039065878,
      "grad_norm": 0.2729792892932892,
      "learning_rate": 7.943155062226709e-06,
      "loss": 0.0001,
      "step": 175050
    },
    {
      "epoch": 8.41381961462688,
      "grad_norm": 0.335735559463501,
      "learning_rate": 7.9311421844217e-06,
      "loss": 0.0001,
      "step": 175100
    },
    {
      "epoch": 8.41622219018788,
      "grad_norm": 0.290620356798172,
      "learning_rate": 7.919129306616694e-06,
      "loss": 0.0001,
      "step": 175150
    },
    {
      "epoch": 8.418624765748882,
      "grad_norm": 0.1353687345981598,
      "learning_rate": 7.907116428811686e-06,
      "loss": 0.0001,
      "step": 175200
    },
    {
      "epoch": 8.421027341309884,
      "grad_norm": NaN,
      "learning_rate": 7.89510355100668e-06,
      "loss": 0.0004,
      "step": 175250
    },
    {
      "epoch": 8.423429916870885,
      "grad_norm": 0.07478825002908707,
      "learning_rate": 7.883090673201673e-06,
      "loss": 0.0002,
      "step": 175300
    },
    {
      "epoch": 8.425832492431887,
      "grad_norm": 0.20594103634357452,
      "learning_rate": 7.871077795396665e-06,
      "loss": 0.0001,
      "step": 175350
    },
    {
      "epoch": 8.428235067992889,
      "grad_norm": 0.11914736777544022,
      "learning_rate": 7.85906491759166e-06,
      "loss": 0.0001,
      "step": 175400
    },
    {
      "epoch": 8.43063764355389,
      "grad_norm": 0.2742701768875122,
      "learning_rate": 7.847052039786652e-06,
      "loss": 0.0001,
      "step": 175450
    },
    {
      "epoch": 8.433040219114892,
      "grad_norm": 0.13519908487796783,
      "learning_rate": 7.835039161981645e-06,
      "loss": 0.0001,
      "step": 175500
    },
    {
      "epoch": 8.435442794675893,
      "grad_norm": 0.18979135155677795,
      "learning_rate": 7.823026284176637e-06,
      "loss": 0.0001,
      "step": 175550
    },
    {
      "epoch": 8.437845370236895,
      "grad_norm": 0.08306843042373657,
      "learning_rate": 7.811013406371631e-06,
      "loss": 0.0001,
      "step": 175600
    },
    {
      "epoch": 8.440247945797895,
      "grad_norm": 0.09500313550233841,
      "learning_rate": 7.799000528566624e-06,
      "loss": 0.0001,
      "step": 175650
    },
    {
      "epoch": 8.442650521358896,
      "grad_norm": 0.28438758850097656,
      "learning_rate": 7.786987650761616e-06,
      "loss": 0.0001,
      "step": 175700
    },
    {
      "epoch": 8.445053096919898,
      "grad_norm": 0.1275220662355423,
      "learning_rate": 7.77497477295661e-06,
      "loss": 0.0001,
      "step": 175750
    },
    {
      "epoch": 8.4474556724809,
      "grad_norm": 0.12654957175254822,
      "learning_rate": 7.762961895151603e-06,
      "loss": 0.0001,
      "step": 175800
    },
    {
      "epoch": 8.4498582480419,
      "grad_norm": 0.20040836930274963,
      "learning_rate": 7.750949017346596e-06,
      "loss": 0.0001,
      "step": 175850
    },
    {
      "epoch": 8.452260823602902,
      "grad_norm": 0.30869871377944946,
      "learning_rate": 7.738936139541588e-06,
      "loss": 0.0001,
      "step": 175900
    },
    {
      "epoch": 8.454663399163904,
      "grad_norm": 0.22882699966430664,
      "learning_rate": 7.726923261736582e-06,
      "loss": 0.0001,
      "step": 175950
    },
    {
      "epoch": 8.457065974724905,
      "grad_norm": 0.0723811537027359,
      "learning_rate": 7.714910383931575e-06,
      "loss": 0.0001,
      "step": 176000
    },
    {
      "epoch": 8.459468550285907,
      "grad_norm": 0.2133347988128662,
      "learning_rate": 7.702897506126568e-06,
      "loss": 0.0001,
      "step": 176050
    },
    {
      "epoch": 8.461871125846908,
      "grad_norm": 0.24187614023685455,
      "learning_rate": 7.690884628321562e-06,
      "loss": 0.0001,
      "step": 176100
    },
    {
      "epoch": 8.46427370140791,
      "grad_norm": 0.7728731632232666,
      "learning_rate": 7.678871750516554e-06,
      "loss": 0.0001,
      "step": 176150
    },
    {
      "epoch": 8.466676276968911,
      "grad_norm": 0.12859764695167542,
      "learning_rate": 7.666858872711547e-06,
      "loss": 0.0001,
      "step": 176200
    },
    {
      "epoch": 8.469078852529911,
      "grad_norm": 0.050961386412382126,
      "learning_rate": 7.65484599490654e-06,
      "loss": 0.0001,
      "step": 176250
    },
    {
      "epoch": 8.471481428090913,
      "grad_norm": 0.4069954454898834,
      "learning_rate": 7.642833117101533e-06,
      "loss": 0.0002,
      "step": 176300
    },
    {
      "epoch": 8.473884003651914,
      "grad_norm": 0.059455450624227524,
      "learning_rate": 7.630820239296526e-06,
      "loss": 0.0001,
      "step": 176350
    },
    {
      "epoch": 8.476286579212916,
      "grad_norm": 0.2066446840763092,
      "learning_rate": 7.6188073614915185e-06,
      "loss": 0.0001,
      "step": 176400
    },
    {
      "epoch": 8.478689154773917,
      "grad_norm": 0.12793658673763275,
      "learning_rate": 7.606794483686512e-06,
      "loss": 0.0001,
      "step": 176450
    },
    {
      "epoch": 8.481091730334919,
      "grad_norm": 0.19131341576576233,
      "learning_rate": 7.594781605881505e-06,
      "loss": 0.0001,
      "step": 176500
    },
    {
      "epoch": 8.48349430589592,
      "grad_norm": 0.22431248426437378,
      "learning_rate": 7.582768728076499e-06,
      "loss": 0.0001,
      "step": 176550
    },
    {
      "epoch": 8.485896881456922,
      "grad_norm": 0.22049060463905334,
      "learning_rate": 7.570755850271491e-06,
      "loss": 0.0001,
      "step": 176600
    },
    {
      "epoch": 8.488299457017924,
      "grad_norm": 0.12557055056095123,
      "learning_rate": 7.5587429724664845e-06,
      "loss": 0.0001,
      "step": 176650
    },
    {
      "epoch": 8.490702032578925,
      "grad_norm": 0.05220929905772209,
      "learning_rate": 7.546730094661478e-06,
      "loss": 0.0001,
      "step": 176700
    },
    {
      "epoch": 8.493104608139927,
      "grad_norm": 0.24378840625286102,
      "learning_rate": 7.534717216856471e-06,
      "loss": 0.0001,
      "step": 176750
    },
    {
      "epoch": 8.495507183700928,
      "grad_norm": 0.1398729681968689,
      "learning_rate": 7.522704339051463e-06,
      "loss": 0.0001,
      "step": 176800
    },
    {
      "epoch": 8.497909759261928,
      "grad_norm": 0.07317879796028137,
      "learning_rate": 7.510691461246456e-06,
      "loss": 0.0001,
      "step": 176850
    },
    {
      "epoch": 8.50031233482293,
      "grad_norm": 0.13573475182056427,
      "learning_rate": 7.49867858344145e-06,
      "loss": 0.0001,
      "step": 176900
    },
    {
      "epoch": 8.502714910383931,
      "grad_norm": 0.16308586299419403,
      "learning_rate": 7.486665705636442e-06,
      "loss": 0.0001,
      "step": 176950
    },
    {
      "epoch": 8.505117485944933,
      "grad_norm": 0.08832389861345291,
      "learning_rate": 7.4746528278314355e-06,
      "loss": 0.0001,
      "step": 177000
    },
    {
      "epoch": 8.507520061505934,
      "grad_norm": 0.1522403508424759,
      "learning_rate": 7.462639950026429e-06,
      "loss": 0.0001,
      "step": 177050
    },
    {
      "epoch": 8.509922637066936,
      "grad_norm": 0.06654874235391617,
      "learning_rate": 7.450627072221422e-06,
      "loss": 0.0001,
      "step": 177100
    },
    {
      "epoch": 8.512325212627937,
      "grad_norm": 0.11832891404628754,
      "learning_rate": 7.438614194416414e-06,
      "loss": 0.0001,
      "step": 177150
    },
    {
      "epoch": 8.514727788188939,
      "grad_norm": 0.161211758852005,
      "learning_rate": 7.426601316611407e-06,
      "loss": 0.0001,
      "step": 177200
    },
    {
      "epoch": 8.51713036374994,
      "grad_norm": 0.044030580669641495,
      "learning_rate": 7.414588438806401e-06,
      "loss": 0.0001,
      "step": 177250
    },
    {
      "epoch": 8.519532939310942,
      "grad_norm": 0.3700866997241974,
      "learning_rate": 7.402575561001394e-06,
      "loss": 0.0001,
      "step": 177300
    },
    {
      "epoch": 8.521935514871943,
      "grad_norm": 0.041962891817092896,
      "learning_rate": 7.3905626831963866e-06,
      "loss": 0.0001,
      "step": 177350
    },
    {
      "epoch": 8.524338090432945,
      "grad_norm": 0.11274025589227676,
      "learning_rate": 7.37854980539138e-06,
      "loss": 0.0001,
      "step": 177400
    },
    {
      "epoch": 8.526740665993945,
      "grad_norm": 0.21050642430782318,
      "learning_rate": 7.366536927586373e-06,
      "loss": 0.0001,
      "step": 177450
    },
    {
      "epoch": 8.529143241554946,
      "grad_norm": 0.021294590085744858,
      "learning_rate": 7.354524049781367e-06,
      "loss": 0.0001,
      "step": 177500
    },
    {
      "epoch": 8.531545817115948,
      "grad_norm": 0.10582355409860611,
      "learning_rate": 7.342511171976358e-06,
      "loss": 0.0001,
      "step": 177550
    },
    {
      "epoch": 8.53394839267695,
      "grad_norm": 0.14038443565368652,
      "learning_rate": 7.330498294171352e-06,
      "loss": 0.0001,
      "step": 177600
    },
    {
      "epoch": 8.53635096823795,
      "grad_norm": 0.13208407163619995,
      "learning_rate": 7.318485416366346e-06,
      "loss": 0.0001,
      "step": 177650
    },
    {
      "epoch": 8.538753543798952,
      "grad_norm": 0.08087858557701111,
      "learning_rate": 7.306472538561338e-06,
      "loss": 0.0001,
      "step": 177700
    },
    {
      "epoch": 8.541156119359954,
      "grad_norm": 0.21686314046382904,
      "learning_rate": 7.294459660756331e-06,
      "loss": 0.0001,
      "step": 177750
    },
    {
      "epoch": 8.543558694920955,
      "grad_norm": 0.030502216890454292,
      "learning_rate": 7.282446782951324e-06,
      "loss": 0.0001,
      "step": 177800
    },
    {
      "epoch": 8.545961270481957,
      "grad_norm": 0.4564531147480011,
      "learning_rate": 7.270433905146318e-06,
      "loss": 0.0003,
      "step": 177850
    },
    {
      "epoch": 8.548363846042959,
      "grad_norm": 0.03576160594820976,
      "learning_rate": 7.258421027341309e-06,
      "loss": 0.0001,
      "step": 177900
    },
    {
      "epoch": 8.55076642160396,
      "grad_norm": 0.27838876843452454,
      "learning_rate": 7.246408149536303e-06,
      "loss": 0.0005,
      "step": 177950
    },
    {
      "epoch": 8.553168997164962,
      "grad_norm": 0.46423107385635376,
      "learning_rate": 7.234395271731297e-06,
      "loss": 0.0001,
      "step": 178000
    },
    {
      "epoch": 8.555571572725963,
      "grad_norm": 0.2648114860057831,
      "learning_rate": 7.22238239392629e-06,
      "loss": 0.0004,
      "step": 178050
    },
    {
      "epoch": 8.557974148286963,
      "grad_norm": 0.07382781058549881,
      "learning_rate": 7.210369516121282e-06,
      "loss": 0.0001,
      "step": 178100
    },
    {
      "epoch": 8.560376723847964,
      "grad_norm": 0.07362116873264313,
      "learning_rate": 7.198356638316275e-06,
      "loss": 0.0001,
      "step": 178150
    },
    {
      "epoch": 8.562779299408966,
      "grad_norm": 0.23951169848442078,
      "learning_rate": 7.186343760511269e-06,
      "loss": 0.0001,
      "step": 178200
    },
    {
      "epoch": 8.565181874969968,
      "grad_norm": 0.07847698777914047,
      "learning_rate": 7.17433088270626e-06,
      "loss": 0.0001,
      "step": 178250
    },
    {
      "epoch": 8.567584450530969,
      "grad_norm": 0.1957663744688034,
      "learning_rate": 7.162318004901255e-06,
      "loss": 0.0001,
      "step": 178300
    },
    {
      "epoch": 8.56998702609197,
      "grad_norm": 0.4266328811645508,
      "learning_rate": 7.150305127096248e-06,
      "loss": 0.0001,
      "step": 178350
    },
    {
      "epoch": 8.572389601652972,
      "grad_norm": 0.20014172792434692,
      "learning_rate": 7.138292249291241e-06,
      "loss": 0.0005,
      "step": 178400
    },
    {
      "epoch": 8.574792177213974,
      "grad_norm": 0.1775711625814438,
      "learning_rate": 7.126279371486233e-06,
      "loss": 0.0001,
      "step": 178450
    },
    {
      "epoch": 8.577194752774975,
      "grad_norm": 0.05412432551383972,
      "learning_rate": 7.114266493681226e-06,
      "loss": 0.0001,
      "step": 178500
    },
    {
      "epoch": 8.579597328335977,
      "grad_norm": 0.1395546793937683,
      "learning_rate": 7.10225361587622e-06,
      "loss": 0.0001,
      "step": 178550
    },
    {
      "epoch": 8.581999903896978,
      "grad_norm": 0.45776811242103577,
      "learning_rate": 7.090240738071213e-06,
      "loss": 0.0001,
      "step": 178600
    },
    {
      "epoch": 8.584402479457978,
      "grad_norm": 0.1053890585899353,
      "learning_rate": 7.078227860266206e-06,
      "loss": 0.0005,
      "step": 178650
    },
    {
      "epoch": 8.58680505501898,
      "grad_norm": 0.24384267628192902,
      "learning_rate": 7.066214982461199e-06,
      "loss": 0.0001,
      "step": 178700
    },
    {
      "epoch": 8.589207630579981,
      "grad_norm": 0.3689224123954773,
      "learning_rate": 7.054202104656192e-06,
      "loss": 0.0002,
      "step": 178750
    },
    {
      "epoch": 8.591610206140983,
      "grad_norm": 0.21293653547763824,
      "learning_rate": 7.042189226851186e-06,
      "loss": 0.0001,
      "step": 178800
    },
    {
      "epoch": 8.594012781701984,
      "grad_norm": 0.19694019854068756,
      "learning_rate": 7.030176349046177e-06,
      "loss": 0.0001,
      "step": 178850
    },
    {
      "epoch": 8.596415357262986,
      "grad_norm": 0.04600217193365097,
      "learning_rate": 7.018163471241171e-06,
      "loss": 0.0001,
      "step": 178900
    },
    {
      "epoch": 8.598817932823987,
      "grad_norm": 0.21743831038475037,
      "learning_rate": 7.006150593436164e-06,
      "loss": 0.0001,
      "step": 178950
    },
    {
      "epoch": 8.601220508384989,
      "grad_norm": 0.18518346548080444,
      "learning_rate": 6.994137715631157e-06,
      "loss": 0.0001,
      "step": 179000
    },
    {
      "epoch": 8.60362308394599,
      "grad_norm": 0.6400299072265625,
      "learning_rate": 6.98212483782615e-06,
      "loss": 0.0001,
      "step": 179050
    },
    {
      "epoch": 8.606025659506992,
      "grad_norm": 0.0699419230222702,
      "learning_rate": 6.970111960021143e-06,
      "loss": 0.0001,
      "step": 179100
    },
    {
      "epoch": 8.608428235067993,
      "grad_norm": 0.1228557899594307,
      "learning_rate": 6.958099082216137e-06,
      "loss": 0.0001,
      "step": 179150
    },
    {
      "epoch": 8.610830810628995,
      "grad_norm": 0.2208644449710846,
      "learning_rate": 6.946086204411128e-06,
      "loss": 0.0001,
      "step": 179200
    },
    {
      "epoch": 8.613233386189997,
      "grad_norm": 0.19473116099834442,
      "learning_rate": 6.934073326606122e-06,
      "loss": 0.0001,
      "step": 179250
    },
    {
      "epoch": 8.615635961750996,
      "grad_norm": 0.059790465980768204,
      "learning_rate": 6.922060448801115e-06,
      "loss": 0.0001,
      "step": 179300
    },
    {
      "epoch": 8.618038537311998,
      "grad_norm": 0.07743598520755768,
      "learning_rate": 6.9100475709961085e-06,
      "loss": 0.0001,
      "step": 179350
    },
    {
      "epoch": 8.620441112873,
      "grad_norm": 0.11778665333986282,
      "learning_rate": 6.898034693191101e-06,
      "loss": 0.0001,
      "step": 179400
    },
    {
      "epoch": 8.622843688434001,
      "grad_norm": 0.07977701723575592,
      "learning_rate": 6.886021815386094e-06,
      "loss": 0.0001,
      "step": 179450
    },
    {
      "epoch": 8.625246263995002,
      "grad_norm": 0.12245318293571472,
      "learning_rate": 6.874008937581088e-06,
      "loss": 0.0001,
      "step": 179500
    },
    {
      "epoch": 8.627648839556004,
      "grad_norm": 0.3713853061199188,
      "learning_rate": 6.8619960597760794e-06,
      "loss": 0.0001,
      "step": 179550
    },
    {
      "epoch": 8.630051415117006,
      "grad_norm": 0.4363091289997101,
      "learning_rate": 6.849983181971073e-06,
      "loss": 0.0001,
      "step": 179600
    },
    {
      "epoch": 8.632453990678007,
      "grad_norm": 0.17532506585121155,
      "learning_rate": 6.837970304166066e-06,
      "loss": 0.0004,
      "step": 179650
    },
    {
      "epoch": 8.634856566239009,
      "grad_norm": 0.2705075442790985,
      "learning_rate": 6.8259574263610595e-06,
      "loss": 0.0001,
      "step": 179700
    },
    {
      "epoch": 8.63725914180001,
      "grad_norm": 0.15237022936344147,
      "learning_rate": 6.813944548556052e-06,
      "loss": 0.0001,
      "step": 179750
    },
    {
      "epoch": 8.639661717361012,
      "grad_norm": 0.04535505920648575,
      "learning_rate": 6.8019316707510454e-06,
      "loss": 0.0001,
      "step": 179800
    },
    {
      "epoch": 8.642064292922012,
      "grad_norm": 0.24748072028160095,
      "learning_rate": 6.789918792946039e-06,
      "loss": 0.0001,
      "step": 179850
    },
    {
      "epoch": 8.644466868483013,
      "grad_norm": 0.19101159274578094,
      "learning_rate": 6.777905915141032e-06,
      "loss": 0.0001,
      "step": 179900
    },
    {
      "epoch": 8.646869444044015,
      "grad_norm": 0.39318975806236267,
      "learning_rate": 6.765893037336024e-06,
      "loss": 0.0001,
      "step": 179950
    },
    {
      "epoch": 8.649272019605016,
      "grad_norm": 0.21858632564544678,
      "learning_rate": 6.753880159531017e-06,
      "loss": 0.0001,
      "step": 180000
    },
    {
      "epoch": 8.651674595166018,
      "grad_norm": 0.06975714862346649,
      "learning_rate": 6.7418672817260106e-06,
      "loss": 0.0001,
      "step": 180050
    },
    {
      "epoch": 8.65407717072702,
      "grad_norm": 0.25394076108932495,
      "learning_rate": 6.729854403921004e-06,
      "loss": 0.0001,
      "step": 180100
    },
    {
      "epoch": 8.65647974628802,
      "grad_norm": 0.3640238046646118,
      "learning_rate": 6.7178415261159964e-06,
      "loss": 0.0001,
      "step": 180150
    },
    {
      "epoch": 8.658882321849022,
      "grad_norm": 0.04326188936829567,
      "learning_rate": 6.70582864831099e-06,
      "loss": 0.0001,
      "step": 180200
    },
    {
      "epoch": 8.661284897410024,
      "grad_norm": 0.14853598177433014,
      "learning_rate": 6.693815770505983e-06,
      "loss": 0.0001,
      "step": 180250
    },
    {
      "epoch": 8.663687472971025,
      "grad_norm": 0.17313382029533386,
      "learning_rate": 6.681802892700975e-06,
      "loss": 0.0001,
      "step": 180300
    },
    {
      "epoch": 8.666090048532027,
      "grad_norm": 0.10545791685581207,
      "learning_rate": 6.669790014895968e-06,
      "loss": 0.0001,
      "step": 180350
    },
    {
      "epoch": 8.668492624093028,
      "grad_norm": 0.09565257281064987,
      "learning_rate": 6.657777137090962e-06,
      "loss": 0.0001,
      "step": 180400
    },
    {
      "epoch": 8.67089519965403,
      "grad_norm": 0.44630470871925354,
      "learning_rate": 6.645764259285955e-06,
      "loss": 0.0001,
      "step": 180450
    },
    {
      "epoch": 8.67329777521503,
      "grad_norm": 0.09577353298664093,
      "learning_rate": 6.6337513814809475e-06,
      "loss": 0.0001,
      "step": 180500
    },
    {
      "epoch": 8.675700350776031,
      "grad_norm": 0.06386171281337738,
      "learning_rate": 6.621738503675941e-06,
      "loss": 0.0001,
      "step": 180550
    },
    {
      "epoch": 8.678102926337033,
      "grad_norm": 0.40744295716285706,
      "learning_rate": 6.609725625870934e-06,
      "loss": 0.0001,
      "step": 180600
    },
    {
      "epoch": 8.680505501898034,
      "grad_norm": 0.31594914197921753,
      "learning_rate": 6.5977127480659276e-06,
      "loss": 0.0001,
      "step": 180650
    },
    {
      "epoch": 8.682908077459036,
      "grad_norm": 0.44814300537109375,
      "learning_rate": 6.585699870260919e-06,
      "loss": 0.0001,
      "step": 180700
    },
    {
      "epoch": 8.685310653020037,
      "grad_norm": 0.05255680903792381,
      "learning_rate": 6.573686992455913e-06,
      "loss": 0.0001,
      "step": 180750
    },
    {
      "epoch": 8.687713228581039,
      "grad_norm": 0.1796913594007492,
      "learning_rate": 6.561674114650907e-06,
      "loss": 0.0001,
      "step": 180800
    },
    {
      "epoch": 8.69011580414204,
      "grad_norm": 0.36201584339141846,
      "learning_rate": 6.5496612368458985e-06,
      "loss": 0.0001,
      "step": 180850
    },
    {
      "epoch": 8.692518379703042,
      "grad_norm": 0.34521570801734924,
      "learning_rate": 6.537648359040892e-06,
      "loss": 0.0001,
      "step": 180900
    },
    {
      "epoch": 8.694920955264044,
      "grad_norm": 0.06441730260848999,
      "learning_rate": 6.525635481235885e-06,
      "loss": 0.0001,
      "step": 180950
    },
    {
      "epoch": 8.697323530825045,
      "grad_norm": 0.27718281745910645,
      "learning_rate": 6.513622603430879e-06,
      "loss": 0.0001,
      "step": 181000
    },
    {
      "epoch": 8.699726106386045,
      "grad_norm": 0.14427562057971954,
      "learning_rate": 6.50160972562587e-06,
      "loss": 0.0001,
      "step": 181050
    },
    {
      "epoch": 8.702128681947046,
      "grad_norm": 0.21790315210819244,
      "learning_rate": 6.4895968478208645e-06,
      "loss": 0.0001,
      "step": 181100
    },
    {
      "epoch": 8.704531257508048,
      "grad_norm": 0.09779119491577148,
      "learning_rate": 6.477583970015858e-06,
      "loss": 0.0001,
      "step": 181150
    },
    {
      "epoch": 8.70693383306905,
      "grad_norm": 0.20437926054000854,
      "learning_rate": 6.465571092210851e-06,
      "loss": 0.0001,
      "step": 181200
    },
    {
      "epoch": 8.709336408630051,
      "grad_norm": 0.16119444370269775,
      "learning_rate": 6.453558214405843e-06,
      "loss": 0.0005,
      "step": 181250
    },
    {
      "epoch": 8.711738984191053,
      "grad_norm": 0.05447275936603546,
      "learning_rate": 6.441545336600836e-06,
      "loss": 0.0001,
      "step": 181300
    },
    {
      "epoch": 8.714141559752054,
      "grad_norm": 0.2157781720161438,
      "learning_rate": 6.42953245879583e-06,
      "loss": 0.0001,
      "step": 181350
    },
    {
      "epoch": 8.716544135313056,
      "grad_norm": 0.15033426880836487,
      "learning_rate": 6.417519580990823e-06,
      "loss": 0.0001,
      "step": 181400
    },
    {
      "epoch": 8.718946710874057,
      "grad_norm": 0.13676080107688904,
      "learning_rate": 6.4055067031858155e-06,
      "loss": 0.0001,
      "step": 181450
    },
    {
      "epoch": 8.721349286435059,
      "grad_norm": 0.1674777716398239,
      "learning_rate": 6.393493825380809e-06,
      "loss": 0.0001,
      "step": 181500
    },
    {
      "epoch": 8.72375186199606,
      "grad_norm": 0.38509321212768555,
      "learning_rate": 6.381480947575802e-06,
      "loss": 0.0001,
      "step": 181550
    },
    {
      "epoch": 8.726154437557062,
      "grad_norm": 0.13595305383205414,
      "learning_rate": 6.369468069770794e-06,
      "loss": 0.0001,
      "step": 181600
    },
    {
      "epoch": 8.728557013118063,
      "grad_norm": 0.16319099068641663,
      "learning_rate": 6.357455191965787e-06,
      "loss": 0.0001,
      "step": 181650
    },
    {
      "epoch": 8.730959588679063,
      "grad_norm": 0.1114540621638298,
      "learning_rate": 6.345442314160781e-06,
      "loss": 0.0001,
      "step": 181700
    },
    {
      "epoch": 8.733362164240065,
      "grad_norm": 0.08773455023765564,
      "learning_rate": 6.333429436355774e-06,
      "loss": 0.0001,
      "step": 181750
    },
    {
      "epoch": 8.735764739801066,
      "grad_norm": 0.05940870940685272,
      "learning_rate": 6.3214165585507665e-06,
      "loss": 0.0005,
      "step": 181800
    },
    {
      "epoch": 8.738167315362068,
      "grad_norm": 0.26680484414100647,
      "learning_rate": 6.30940368074576e-06,
      "loss": 0.0001,
      "step": 181850
    },
    {
      "epoch": 8.74056989092307,
      "grad_norm": 0.22600321471691132,
      "learning_rate": 6.297390802940753e-06,
      "loss": 0.0001,
      "step": 181900
    },
    {
      "epoch": 8.742972466484071,
      "grad_norm": 0.20256663858890533,
      "learning_rate": 6.285377925135747e-06,
      "loss": 0.0001,
      "step": 181950
    },
    {
      "epoch": 8.745375042045072,
      "grad_norm": 0.3034820854663849,
      "learning_rate": 6.273365047330738e-06,
      "loss": 0.0001,
      "step": 182000
    },
    {
      "epoch": 8.747777617606074,
      "grad_norm": 0.04060232639312744,
      "learning_rate": 6.261352169525732e-06,
      "loss": 0.0001,
      "step": 182050
    },
    {
      "epoch": 8.750180193167076,
      "grad_norm": 0.19621412456035614,
      "learning_rate": 6.249339291720725e-06,
      "loss": 0.0001,
      "step": 182100
    },
    {
      "epoch": 8.752582768728077,
      "grad_norm": 0.09701023250818253,
      "learning_rate": 6.2373264139157176e-06,
      "loss": 0.0001,
      "step": 182150
    },
    {
      "epoch": 8.754985344289079,
      "grad_norm": 0.17236676812171936,
      "learning_rate": 6.225313536110711e-06,
      "loss": 0.0003,
      "step": 182200
    },
    {
      "epoch": 8.757387919850078,
      "grad_norm": 0.0741477981209755,
      "learning_rate": 6.213300658305704e-06,
      "loss": 0.0001,
      "step": 182250
    },
    {
      "epoch": 8.75979049541108,
      "grad_norm": 0.07604993879795074,
      "learning_rate": 6.201287780500697e-06,
      "loss": 0.0001,
      "step": 182300
    },
    {
      "epoch": 8.762193070972081,
      "grad_norm": 0.2454039305448532,
      "learning_rate": 6.18927490269569e-06,
      "loss": 0.0001,
      "step": 182350
    },
    {
      "epoch": 8.764595646533083,
      "grad_norm": 0.1108599305152893,
      "learning_rate": 6.177262024890683e-06,
      "loss": 0.0001,
      "step": 182400
    },
    {
      "epoch": 8.766998222094085,
      "grad_norm": 0.07170606404542923,
      "learning_rate": 6.165249147085676e-06,
      "loss": 0.0001,
      "step": 182450
    },
    {
      "epoch": 8.769400797655086,
      "grad_norm": 0.15242649614810944,
      "learning_rate": 6.153236269280669e-06,
      "loss": 0.0001,
      "step": 182500
    },
    {
      "epoch": 8.771803373216088,
      "grad_norm": 0.09367859363555908,
      "learning_rate": 6.141223391475663e-06,
      "loss": 0.0001,
      "step": 182550
    },
    {
      "epoch": 8.77420594877709,
      "grad_norm": 0.2974680960178375,
      "learning_rate": 6.129210513670655e-06,
      "loss": 0.0001,
      "step": 182600
    },
    {
      "epoch": 8.77660852433809,
      "grad_norm": 0.15126480162143707,
      "learning_rate": 6.117197635865649e-06,
      "loss": 0.0001,
      "step": 182650
    },
    {
      "epoch": 8.779011099899092,
      "grad_norm": 0.2631084620952606,
      "learning_rate": 6.105184758060641e-06,
      "loss": 0.0001,
      "step": 182700
    },
    {
      "epoch": 8.781413675460094,
      "grad_norm": 0.0733097493648529,
      "learning_rate": 6.0931718802556346e-06,
      "loss": 0.0001,
      "step": 182750
    },
    {
      "epoch": 8.783816251021095,
      "grad_norm": 0.3806743025779724,
      "learning_rate": 6.081159002450627e-06,
      "loss": 0.0001,
      "step": 182800
    },
    {
      "epoch": 8.786218826582097,
      "grad_norm": 0.06545137614011765,
      "learning_rate": 6.0691461246456204e-06,
      "loss": 0.0001,
      "step": 182850
    },
    {
      "epoch": 8.788621402143097,
      "grad_norm": 0.16368120908737183,
      "learning_rate": 6.057133246840614e-06,
      "loss": 0.0001,
      "step": 182900
    },
    {
      "epoch": 8.791023977704098,
      "grad_norm": 0.12827125191688538,
      "learning_rate": 6.045120369035606e-06,
      "loss": 0.0001,
      "step": 182950
    },
    {
      "epoch": 8.7934265532651,
      "grad_norm": 0.3269493877887726,
      "learning_rate": 6.0331074912306e-06,
      "loss": 0.0001,
      "step": 183000
    },
    {
      "epoch": 8.795829128826101,
      "grad_norm": 0.19872485101222992,
      "learning_rate": 6.021094613425592e-06,
      "loss": 0.0001,
      "step": 183050
    },
    {
      "epoch": 8.798231704387103,
      "grad_norm": 0.11756984144449234,
      "learning_rate": 6.009081735620586e-06,
      "loss": 0.0001,
      "step": 183100
    },
    {
      "epoch": 8.800634279948104,
      "grad_norm": 0.10030604153871536,
      "learning_rate": 5.997068857815578e-06,
      "loss": 0.0001,
      "step": 183150
    },
    {
      "epoch": 8.803036855509106,
      "grad_norm": 0.047398246824741364,
      "learning_rate": 5.9850559800105715e-06,
      "loss": 0.0001,
      "step": 183200
    },
    {
      "epoch": 8.805439431070107,
      "grad_norm": 0.07989467680454254,
      "learning_rate": 5.973043102205565e-06,
      "loss": 0.0001,
      "step": 183250
    },
    {
      "epoch": 8.807842006631109,
      "grad_norm": 0.05491774156689644,
      "learning_rate": 5.961030224400558e-06,
      "loss": 0.0001,
      "step": 183300
    },
    {
      "epoch": 8.81024458219211,
      "grad_norm": 0.1300569772720337,
      "learning_rate": 5.949017346595551e-06,
      "loss": 0.0001,
      "step": 183350
    },
    {
      "epoch": 8.812647157753112,
      "grad_norm": 0.2890169322490692,
      "learning_rate": 5.937004468790544e-06,
      "loss": 0.0001,
      "step": 183400
    },
    {
      "epoch": 8.815049733314112,
      "grad_norm": 0.3250991404056549,
      "learning_rate": 5.924991590985537e-06,
      "loss": 0.0001,
      "step": 183450
    },
    {
      "epoch": 8.817452308875113,
      "grad_norm": 0.11853020638227463,
      "learning_rate": 5.912978713180529e-06,
      "loss": 0.0001,
      "step": 183500
    },
    {
      "epoch": 8.819854884436115,
      "grad_norm": 0.44801467657089233,
      "learning_rate": 5.9009658353755225e-06,
      "loss": 0.0001,
      "step": 183550
    },
    {
      "epoch": 8.822257459997116,
      "grad_norm": 0.08652722835540771,
      "learning_rate": 5.888952957570516e-06,
      "loss": 0.0001,
      "step": 183600
    },
    {
      "epoch": 8.824660035558118,
      "grad_norm": 0.15984950959682465,
      "learning_rate": 5.876940079765509e-06,
      "loss": 0.0001,
      "step": 183650
    },
    {
      "epoch": 8.82706261111912,
      "grad_norm": 0.4113810360431671,
      "learning_rate": 5.864927201960502e-06,
      "loss": 0.0001,
      "step": 183700
    },
    {
      "epoch": 8.829465186680121,
      "grad_norm": 0.1582217663526535,
      "learning_rate": 5.852914324155495e-06,
      "loss": 0.0004,
      "step": 183750
    },
    {
      "epoch": 8.831867762241123,
      "grad_norm": 0.26541605591773987,
      "learning_rate": 5.840901446350488e-06,
      "loss": 0.0004,
      "step": 183800
    },
    {
      "epoch": 8.834270337802124,
      "grad_norm": 0.14017502963542938,
      "learning_rate": 5.828888568545481e-06,
      "loss": 0.0001,
      "step": 183850
    },
    {
      "epoch": 8.836672913363126,
      "grad_norm": 0.2633333206176758,
      "learning_rate": 5.816875690740474e-06,
      "loss": 0.0001,
      "step": 183900
    },
    {
      "epoch": 8.839075488924127,
      "grad_norm": 0.03181261196732521,
      "learning_rate": 5.804862812935468e-06,
      "loss": 0.0001,
      "step": 183950
    },
    {
      "epoch": 8.841478064485129,
      "grad_norm": 0.10086911171674728,
      "learning_rate": 5.79284993513046e-06,
      "loss": 0.0001,
      "step": 184000
    },
    {
      "epoch": 8.84388064004613,
      "grad_norm": 0.22066174447536469,
      "learning_rate": 5.780837057325454e-06,
      "loss": 0.0001,
      "step": 184050
    },
    {
      "epoch": 8.84628321560713,
      "grad_norm": 0.12809230387210846,
      "learning_rate": 5.768824179520446e-06,
      "loss": 0.0001,
      "step": 184100
    },
    {
      "epoch": 8.848685791168132,
      "grad_norm": 0.23920686542987823,
      "learning_rate": 5.756811301715439e-06,
      "loss": 0.0005,
      "step": 184150
    },
    {
      "epoch": 8.851088366729133,
      "grad_norm": 0.35861966013908386,
      "learning_rate": 5.744798423910432e-06,
      "loss": 0.0001,
      "step": 184200
    },
    {
      "epoch": 8.853490942290135,
      "grad_norm": 0.16468892991542816,
      "learning_rate": 5.732785546105425e-06,
      "loss": 0.0001,
      "step": 184250
    },
    {
      "epoch": 8.855893517851136,
      "grad_norm": 0.5508169531822205,
      "learning_rate": 5.720772668300419e-06,
      "loss": 0.0001,
      "step": 184300
    },
    {
      "epoch": 8.858296093412138,
      "grad_norm": 0.06414467841386795,
      "learning_rate": 5.708759790495411e-06,
      "loss": 0.0001,
      "step": 184350
    },
    {
      "epoch": 8.86069866897314,
      "grad_norm": 0.08267659693956375,
      "learning_rate": 5.696746912690405e-06,
      "loss": 0.0001,
      "step": 184400
    },
    {
      "epoch": 8.86310124453414,
      "grad_norm": 0.21853555738925934,
      "learning_rate": 5.684734034885397e-06,
      "loss": 0.0001,
      "step": 184450
    },
    {
      "epoch": 8.865503820095142,
      "grad_norm": 0.19430772960186005,
      "learning_rate": 5.6727211570803905e-06,
      "loss": 0.0001,
      "step": 184500
    },
    {
      "epoch": 8.867906395656144,
      "grad_norm": 0.0932515412569046,
      "learning_rate": 5.660708279275383e-06,
      "loss": 0.0001,
      "step": 184550
    },
    {
      "epoch": 8.870308971217145,
      "grad_norm": 0.0687626376748085,
      "learning_rate": 5.648695401470376e-06,
      "loss": 0.0001,
      "step": 184600
    },
    {
      "epoch": 8.872711546778147,
      "grad_norm": 0.07502847164869308,
      "learning_rate": 5.63668252366537e-06,
      "loss": 0.0001,
      "step": 184650
    },
    {
      "epoch": 8.875114122339147,
      "grad_norm": 0.12507665157318115,
      "learning_rate": 5.624669645860363e-06,
      "loss": 0.0001,
      "step": 184700
    },
    {
      "epoch": 8.877516697900148,
      "grad_norm": 0.025879720225930214,
      "learning_rate": 5.612656768055356e-06,
      "loss": 0.0001,
      "step": 184750
    },
    {
      "epoch": 8.87991927346115,
      "grad_norm": 0.12310491502285004,
      "learning_rate": 5.600643890250348e-06,
      "loss": 0.0004,
      "step": 184800
    },
    {
      "epoch": 8.882321849022151,
      "grad_norm": 0.2593013048171997,
      "learning_rate": 5.5886310124453415e-06,
      "loss": 0.0004,
      "step": 184850
    },
    {
      "epoch": 8.884724424583153,
      "grad_norm": 0.23760521411895752,
      "learning_rate": 5.576618134640334e-06,
      "loss": 0.0001,
      "step": 184900
    },
    {
      "epoch": 8.887127000144154,
      "grad_norm": 0.31732994318008423,
      "learning_rate": 5.5646052568353274e-06,
      "loss": 0.0001,
      "step": 184950
    },
    {
      "epoch": 8.889529575705156,
      "grad_norm": 0.27946943044662476,
      "learning_rate": 5.552592379030321e-06,
      "loss": 0.0001,
      "step": 185000
    },
    {
      "epoch": 8.891932151266158,
      "grad_norm": 0.12942618131637573,
      "learning_rate": 5.540579501225314e-06,
      "loss": 0.0001,
      "step": 185050
    },
    {
      "epoch": 8.894334726827159,
      "grad_norm": 0.10585898905992508,
      "learning_rate": 5.528566623420307e-06,
      "loss": 0.0004,
      "step": 185100
    },
    {
      "epoch": 8.89673730238816,
      "grad_norm": 0.14035411179065704,
      "learning_rate": 5.5165537456153e-06,
      "loss": 0.0001,
      "step": 185150
    },
    {
      "epoch": 8.899139877949162,
      "grad_norm": 0.277955561876297,
      "learning_rate": 5.5045408678102926e-06,
      "loss": 0.0001,
      "step": 185200
    },
    {
      "epoch": 8.901542453510164,
      "grad_norm": 0.08918400853872299,
      "learning_rate": 5.492527990005286e-06,
      "loss": 0.0001,
      "step": 185250
    },
    {
      "epoch": 8.903945029071163,
      "grad_norm": 0.32507801055908203,
      "learning_rate": 5.480515112200279e-06,
      "loss": 0.0001,
      "step": 185300
    },
    {
      "epoch": 8.906347604632165,
      "grad_norm": 0.4907967150211334,
      "learning_rate": 5.468502234395273e-06,
      "loss": 0.0001,
      "step": 185350
    },
    {
      "epoch": 8.908750180193167,
      "grad_norm": 0.04767381027340889,
      "learning_rate": 5.456489356590265e-06,
      "loss": 0.0005,
      "step": 185400
    },
    {
      "epoch": 8.911152755754168,
      "grad_norm": 0.14619877934455872,
      "learning_rate": 5.444476478785258e-06,
      "loss": 0.0001,
      "step": 185450
    },
    {
      "epoch": 8.91355533131517,
      "grad_norm": 0.20021183788776398,
      "learning_rate": 5.432463600980251e-06,
      "loss": 0.0005,
      "step": 185500
    },
    {
      "epoch": 8.915957906876171,
      "grad_norm": 0.08943303674459457,
      "learning_rate": 5.420450723175244e-06,
      "loss": 0.0001,
      "step": 185550
    },
    {
      "epoch": 8.918360482437173,
      "grad_norm": 0.35368797183036804,
      "learning_rate": 5.408437845370237e-06,
      "loss": 0.0001,
      "step": 185600
    },
    {
      "epoch": 8.920763057998174,
      "grad_norm": 0.05761369317770004,
      "learning_rate": 5.39642496756523e-06,
      "loss": 0.0001,
      "step": 185650
    },
    {
      "epoch": 8.923165633559176,
      "grad_norm": 0.11815637350082397,
      "learning_rate": 5.384412089760224e-06,
      "loss": 0.0001,
      "step": 185700
    },
    {
      "epoch": 8.925568209120177,
      "grad_norm": 0.14508569240570068,
      "learning_rate": 5.372399211955216e-06,
      "loss": 0.0001,
      "step": 185750
    },
    {
      "epoch": 8.927970784681179,
      "grad_norm": 0.1607421189546585,
      "learning_rate": 5.36038633415021e-06,
      "loss": 0.0001,
      "step": 185800
    },
    {
      "epoch": 8.93037336024218,
      "grad_norm": 0.08943092077970505,
      "learning_rate": 5.348373456345202e-06,
      "loss": 0.0001,
      "step": 185850
    },
    {
      "epoch": 8.93277593580318,
      "grad_norm": 0.16255468130111694,
      "learning_rate": 5.3363605785401955e-06,
      "loss": 0.0001,
      "step": 185900
    },
    {
      "epoch": 8.935178511364182,
      "grad_norm": 0.15596598386764526,
      "learning_rate": 5.324347700735188e-06,
      "loss": 0.0001,
      "step": 185950
    },
    {
      "epoch": 8.937581086925183,
      "grad_norm": 0.3035276234149933,
      "learning_rate": 5.312334822930181e-06,
      "loss": 0.0001,
      "step": 186000
    },
    {
      "epoch": 8.939983662486185,
      "grad_norm": 0.4995808005332947,
      "learning_rate": 5.300321945125175e-06,
      "loss": 0.0001,
      "step": 186050
    },
    {
      "epoch": 8.942386238047186,
      "grad_norm": 0.33581334352493286,
      "learning_rate": 5.288309067320168e-06,
      "loss": 0.0001,
      "step": 186100
    },
    {
      "epoch": 8.944788813608188,
      "grad_norm": 0.08245959132909775,
      "learning_rate": 5.276296189515161e-06,
      "loss": 0.0001,
      "step": 186150
    },
    {
      "epoch": 8.94719138916919,
      "grad_norm": 0.19568459689617157,
      "learning_rate": 5.264283311710153e-06,
      "loss": 0.0001,
      "step": 186200
    },
    {
      "epoch": 8.949593964730191,
      "grad_norm": 0.07556045800447464,
      "learning_rate": 5.2522704339051465e-06,
      "loss": 0.0001,
      "step": 186250
    },
    {
      "epoch": 8.951996540291193,
      "grad_norm": 0.10043460875749588,
      "learning_rate": 5.240257556100139e-06,
      "loss": 0.0001,
      "step": 186300
    },
    {
      "epoch": 8.954399115852194,
      "grad_norm": 0.3586350679397583,
      "learning_rate": 5.228244678295132e-06,
      "loss": 0.0004,
      "step": 186350
    },
    {
      "epoch": 8.956801691413196,
      "grad_norm": 0.20655392110347748,
      "learning_rate": 5.216231800490126e-06,
      "loss": 0.0001,
      "step": 186400
    },
    {
      "epoch": 8.959204266974197,
      "grad_norm": 0.14172150194644928,
      "learning_rate": 5.204218922685119e-06,
      "loss": 0.0001,
      "step": 186450
    },
    {
      "epoch": 8.961606842535197,
      "grad_norm": 0.12655086815357208,
      "learning_rate": 5.192206044880112e-06,
      "loss": 0.0001,
      "step": 186500
    },
    {
      "epoch": 8.964009418096198,
      "grad_norm": 0.7109155654907227,
      "learning_rate": 5.180193167075105e-06,
      "loss": 0.0001,
      "step": 186550
    },
    {
      "epoch": 8.9664119936572,
      "grad_norm": 0.4449767768383026,
      "learning_rate": 5.1681802892700975e-06,
      "loss": 0.0001,
      "step": 186600
    },
    {
      "epoch": 8.968814569218202,
      "grad_norm": 0.09603416174650192,
      "learning_rate": 5.156167411465091e-06,
      "loss": 0.0001,
      "step": 186650
    },
    {
      "epoch": 8.971217144779203,
      "grad_norm": 0.19437645375728607,
      "learning_rate": 5.144154533660083e-06,
      "loss": 0.0001,
      "step": 186700
    },
    {
      "epoch": 8.973619720340205,
      "grad_norm": 0.1010374128818512,
      "learning_rate": 5.132141655855078e-06,
      "loss": 0.0001,
      "step": 186750
    },
    {
      "epoch": 8.976022295901206,
      "grad_norm": 0.2052483707666397,
      "learning_rate": 5.12012877805007e-06,
      "loss": 0.0001,
      "step": 186800
    },
    {
      "epoch": 8.978424871462208,
      "grad_norm": 0.13306953012943268,
      "learning_rate": 5.108115900245063e-06,
      "loss": 0.0001,
      "step": 186850
    },
    {
      "epoch": 8.98082744702321,
      "grad_norm": 0.10718543082475662,
      "learning_rate": 5.096103022440056e-06,
      "loss": 0.0001,
      "step": 186900
    },
    {
      "epoch": 8.98323002258421,
      "grad_norm": 0.2662094533443451,
      "learning_rate": 5.0840901446350485e-06,
      "loss": 0.0001,
      "step": 186950
    },
    {
      "epoch": 8.985632598145212,
      "grad_norm": 0.0698467269539833,
      "learning_rate": 5.072077266830042e-06,
      "loss": 0.0001,
      "step": 187000
    },
    {
      "epoch": 8.988035173706214,
      "grad_norm": 0.13896584510803223,
      "learning_rate": 5.060064389025035e-06,
      "loss": 0.0001,
      "step": 187050
    },
    {
      "epoch": 8.990437749267215,
      "grad_norm": 0.058952778577804565,
      "learning_rate": 5.048051511220029e-06,
      "loss": 0.0001,
      "step": 187100
    },
    {
      "epoch": 8.992840324828215,
      "grad_norm": 0.04471168667078018,
      "learning_rate": 5.036038633415021e-06,
      "loss": 0.0001,
      "step": 187150
    },
    {
      "epoch": 8.995242900389217,
      "grad_norm": 0.05782361328601837,
      "learning_rate": 5.0240257556100145e-06,
      "loss": 0.0001,
      "step": 187200
    },
    {
      "epoch": 8.997645475950218,
      "grad_norm": 0.2986907660961151,
      "learning_rate": 5.012012877805007e-06,
      "loss": 0.0001,
      "step": 187250
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.00014504413411486894,
      "eval_runtime": 17.3747,
      "eval_samples_per_second": 546.543,
      "eval_steps_per_second": 68.318,
      "step": 187299
    }
  ],
  "logging_steps": 50,
  "max_steps": 208110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.102724285734526e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
