{
  "best_global_step": 62433,
  "best_metric": 0.00017453967302571982,
  "best_model_checkpoint": "ckpt/neurips.pt/FFV/checkpoint-62433",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 104055,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0024025755610013935,
      "grad_norm": 1.3977797031402588,
      "learning_rate": 4.99882273797511e-05,
      "loss": 0.0476,
      "step": 50
    },
    {
      "epoch": 0.004805151122002787,
      "grad_norm": 5.024441719055176,
      "learning_rate": 4.997621450194609e-05,
      "loss": 0.0289,
      "step": 100
    },
    {
      "epoch": 0.00720772668300418,
      "grad_norm": 1.565306544303894,
      "learning_rate": 4.996420162414108e-05,
      "loss": 0.0387,
      "step": 150
    },
    {
      "epoch": 0.009610302244005574,
      "grad_norm": 1.6434930562973022,
      "learning_rate": 4.995218874633608e-05,
      "loss": 0.025,
      "step": 200
    },
    {
      "epoch": 0.012012877805006967,
      "grad_norm": 4.89108943939209,
      "learning_rate": 4.994017586853107e-05,
      "loss": 0.0238,
      "step": 250
    },
    {
      "epoch": 0.01441545336600836,
      "grad_norm": 1.0357552766799927,
      "learning_rate": 4.9928162990726066e-05,
      "loss": 0.0176,
      "step": 300
    },
    {
      "epoch": 0.016818028927009756,
      "grad_norm": 2.2466228008270264,
      "learning_rate": 4.991615011292106e-05,
      "loss": 0.0212,
      "step": 350
    },
    {
      "epoch": 0.019220604488011148,
      "grad_norm": 2.003396511077881,
      "learning_rate": 4.990413723511604e-05,
      "loss": 0.0216,
      "step": 400
    },
    {
      "epoch": 0.021623180049012543,
      "grad_norm": 0.7462701797485352,
      "learning_rate": 4.989212435731104e-05,
      "loss": 0.02,
      "step": 450
    },
    {
      "epoch": 0.024025755610013935,
      "grad_norm": 1.7794575691223145,
      "learning_rate": 4.988011147950603e-05,
      "loss": 0.0175,
      "step": 500
    },
    {
      "epoch": 0.02642833117101533,
      "grad_norm": 1.3216904401779175,
      "learning_rate": 4.986809860170103e-05,
      "loss": 0.0198,
      "step": 550
    },
    {
      "epoch": 0.02883090673201672,
      "grad_norm": 3.202026128768921,
      "learning_rate": 4.985608572389602e-05,
      "loss": 0.0166,
      "step": 600
    },
    {
      "epoch": 0.031233482293018117,
      "grad_norm": 1.434770941734314,
      "learning_rate": 4.984407284609101e-05,
      "loss": 0.0162,
      "step": 650
    },
    {
      "epoch": 0.03363605785401951,
      "grad_norm": 4.874935626983643,
      "learning_rate": 4.9832059968286006e-05,
      "loss": 0.0189,
      "step": 700
    },
    {
      "epoch": 0.0360386334150209,
      "grad_norm": 4.808428764343262,
      "learning_rate": 4.9820047090481e-05,
      "loss": 0.0168,
      "step": 750
    },
    {
      "epoch": 0.038441208976022295,
      "grad_norm": 2.936591148376465,
      "learning_rate": 4.980803421267599e-05,
      "loss": 0.0208,
      "step": 800
    },
    {
      "epoch": 0.04084378453702369,
      "grad_norm": 0.6572856903076172,
      "learning_rate": 4.9796021334870986e-05,
      "loss": 0.0156,
      "step": 850
    },
    {
      "epoch": 0.043246360098025086,
      "grad_norm": 2.383610963821411,
      "learning_rate": 4.9784008457065976e-05,
      "loss": 0.0171,
      "step": 900
    },
    {
      "epoch": 0.045648935659026474,
      "grad_norm": 1.7208203077316284,
      "learning_rate": 4.9771995579260974e-05,
      "loss": 0.0178,
      "step": 950
    },
    {
      "epoch": 0.04805151122002787,
      "grad_norm": 1.8242915868759155,
      "learning_rate": 4.9759982701455965e-05,
      "loss": 0.0186,
      "step": 1000
    },
    {
      "epoch": 0.050454086781029264,
      "grad_norm": 2.109001398086548,
      "learning_rate": 4.9747969823650956e-05,
      "loss": 0.0192,
      "step": 1050
    },
    {
      "epoch": 0.05285666234203066,
      "grad_norm": 1.2478501796722412,
      "learning_rate": 4.973595694584595e-05,
      "loss": 0.0166,
      "step": 1100
    },
    {
      "epoch": 0.05525923790303205,
      "grad_norm": 1.3806898593902588,
      "learning_rate": 4.972394406804094e-05,
      "loss": 0.0172,
      "step": 1150
    },
    {
      "epoch": 0.05766181346403344,
      "grad_norm": 1.7513642311096191,
      "learning_rate": 4.9711931190235935e-05,
      "loss": 0.0124,
      "step": 1200
    },
    {
      "epoch": 0.06006438902503484,
      "grad_norm": 3.117465019226074,
      "learning_rate": 4.9699918312430926e-05,
      "loss": 0.0145,
      "step": 1250
    },
    {
      "epoch": 0.06246696458603623,
      "grad_norm": 2.624201536178589,
      "learning_rate": 4.968790543462592e-05,
      "loss": 0.0163,
      "step": 1300
    },
    {
      "epoch": 0.06486954014703762,
      "grad_norm": 2.4585120677948,
      "learning_rate": 4.9675892556820914e-05,
      "loss": 0.0181,
      "step": 1350
    },
    {
      "epoch": 0.06727211570803902,
      "grad_norm": 1.311131238937378,
      "learning_rate": 4.9663879679015905e-05,
      "loss": 0.0121,
      "step": 1400
    },
    {
      "epoch": 0.06967469126904041,
      "grad_norm": 0.9783168435096741,
      "learning_rate": 4.96518668012109e-05,
      "loss": 0.0121,
      "step": 1450
    },
    {
      "epoch": 0.0720772668300418,
      "grad_norm": 0.9726380109786987,
      "learning_rate": 4.9639853923405893e-05,
      "loss": 0.0148,
      "step": 1500
    },
    {
      "epoch": 0.0744798423910432,
      "grad_norm": 2.8475356101989746,
      "learning_rate": 4.9627841045600884e-05,
      "loss": 0.01,
      "step": 1550
    },
    {
      "epoch": 0.07688241795204459,
      "grad_norm": 0.889223575592041,
      "learning_rate": 4.961582816779588e-05,
      "loss": 0.0104,
      "step": 1600
    },
    {
      "epoch": 0.07928499351304598,
      "grad_norm": 1.589859127998352,
      "learning_rate": 4.960381528999087e-05,
      "loss": 0.0103,
      "step": 1650
    },
    {
      "epoch": 0.08168756907404738,
      "grad_norm": 0.8792979121208191,
      "learning_rate": 4.959180241218587e-05,
      "loss": 0.0136,
      "step": 1700
    },
    {
      "epoch": 0.08409014463504877,
      "grad_norm": 1.183384895324707,
      "learning_rate": 4.957978953438086e-05,
      "loss": 0.0107,
      "step": 1750
    },
    {
      "epoch": 0.08649272019605017,
      "grad_norm": 4.050797462463379,
      "learning_rate": 4.956777665657585e-05,
      "loss": 0.0128,
      "step": 1800
    },
    {
      "epoch": 0.08889529575705156,
      "grad_norm": 2.58302903175354,
      "learning_rate": 4.955576377877085e-05,
      "loss": 0.0108,
      "step": 1850
    },
    {
      "epoch": 0.09129787131805295,
      "grad_norm": 1.6763356924057007,
      "learning_rate": 4.9543750900965834e-05,
      "loss": 0.0113,
      "step": 1900
    },
    {
      "epoch": 0.09370044687905435,
      "grad_norm": 3.229660987854004,
      "learning_rate": 4.953173802316083e-05,
      "loss": 0.0111,
      "step": 1950
    },
    {
      "epoch": 0.09610302244005574,
      "grad_norm": 1.7616082429885864,
      "learning_rate": 4.951972514535582e-05,
      "loss": 0.012,
      "step": 2000
    },
    {
      "epoch": 0.09850559800105713,
      "grad_norm": 1.5646854639053345,
      "learning_rate": 4.950771226755081e-05,
      "loss": 0.0101,
      "step": 2050
    },
    {
      "epoch": 0.10090817356205853,
      "grad_norm": 4.657251834869385,
      "learning_rate": 4.949569938974581e-05,
      "loss": 0.0094,
      "step": 2100
    },
    {
      "epoch": 0.10331074912305992,
      "grad_norm": 2.1267502307891846,
      "learning_rate": 4.94836865119408e-05,
      "loss": 0.014,
      "step": 2150
    },
    {
      "epoch": 0.10571332468406132,
      "grad_norm": 5.356624126434326,
      "learning_rate": 4.94716736341358e-05,
      "loss": 0.0124,
      "step": 2200
    },
    {
      "epoch": 0.10811590024506271,
      "grad_norm": 2.064894914627075,
      "learning_rate": 4.945966075633079e-05,
      "loss": 0.0094,
      "step": 2250
    },
    {
      "epoch": 0.1105184758060641,
      "grad_norm": 2.0159528255462646,
      "learning_rate": 4.944764787852578e-05,
      "loss": 0.0099,
      "step": 2300
    },
    {
      "epoch": 0.1129210513670655,
      "grad_norm": 3.8876395225524902,
      "learning_rate": 4.943563500072078e-05,
      "loss": 0.0096,
      "step": 2350
    },
    {
      "epoch": 0.11532362692806689,
      "grad_norm": 3.4123547077178955,
      "learning_rate": 4.942362212291577e-05,
      "loss": 0.011,
      "step": 2400
    },
    {
      "epoch": 0.11772620248906829,
      "grad_norm": 2.3515970706939697,
      "learning_rate": 4.941160924511076e-05,
      "loss": 0.0101,
      "step": 2450
    },
    {
      "epoch": 0.12012877805006968,
      "grad_norm": 4.216569423675537,
      "learning_rate": 4.939959636730576e-05,
      "loss": 0.0127,
      "step": 2500
    },
    {
      "epoch": 0.12253135361107106,
      "grad_norm": 1.6170148849487305,
      "learning_rate": 4.938758348950075e-05,
      "loss": 0.0111,
      "step": 2550
    },
    {
      "epoch": 0.12493392917207247,
      "grad_norm": 0.6739742159843445,
      "learning_rate": 4.9375570611695746e-05,
      "loss": 0.0086,
      "step": 2600
    },
    {
      "epoch": 0.12733650473307387,
      "grad_norm": 2.3992059230804443,
      "learning_rate": 4.936355773389073e-05,
      "loss": 0.0123,
      "step": 2650
    },
    {
      "epoch": 0.12973908029407524,
      "grad_norm": 2.6405045986175537,
      "learning_rate": 4.935154485608572e-05,
      "loss": 0.0114,
      "step": 2700
    },
    {
      "epoch": 0.13214165585507665,
      "grad_norm": 0.3864342272281647,
      "learning_rate": 4.933953197828072e-05,
      "loss": 0.0088,
      "step": 2750
    },
    {
      "epoch": 0.13454423141607805,
      "grad_norm": 1.4979263544082642,
      "learning_rate": 4.932751910047571e-05,
      "loss": 0.008,
      "step": 2800
    },
    {
      "epoch": 0.13694680697707942,
      "grad_norm": 4.138174057006836,
      "learning_rate": 4.931550622267071e-05,
      "loss": 0.0138,
      "step": 2850
    },
    {
      "epoch": 0.13934938253808082,
      "grad_norm": 0.8691509366035461,
      "learning_rate": 4.93034933448657e-05,
      "loss": 0.0089,
      "step": 2900
    },
    {
      "epoch": 0.14175195809908223,
      "grad_norm": 2.495490312576294,
      "learning_rate": 4.929148046706069e-05,
      "loss": 0.0072,
      "step": 2950
    },
    {
      "epoch": 0.1441545336600836,
      "grad_norm": 2.8286640644073486,
      "learning_rate": 4.9279467589255686e-05,
      "loss": 0.0104,
      "step": 3000
    },
    {
      "epoch": 0.146557109221085,
      "grad_norm": 2.058450698852539,
      "learning_rate": 4.926745471145068e-05,
      "loss": 0.0116,
      "step": 3050
    },
    {
      "epoch": 0.1489596847820864,
      "grad_norm": 1.6004475355148315,
      "learning_rate": 4.9255441833645674e-05,
      "loss": 0.0079,
      "step": 3100
    },
    {
      "epoch": 0.15136226034308778,
      "grad_norm": 3.1092495918273926,
      "learning_rate": 4.9243428955840665e-05,
      "loss": 0.0098,
      "step": 3150
    },
    {
      "epoch": 0.15376483590408918,
      "grad_norm": 1.8317694664001465,
      "learning_rate": 4.9231416078035656e-05,
      "loss": 0.0094,
      "step": 3200
    },
    {
      "epoch": 0.15616741146509058,
      "grad_norm": 1.5068285465240479,
      "learning_rate": 4.9219403200230654e-05,
      "loss": 0.0073,
      "step": 3250
    },
    {
      "epoch": 0.15856998702609196,
      "grad_norm": 1.204134225845337,
      "learning_rate": 4.9207390322425645e-05,
      "loss": 0.0082,
      "step": 3300
    },
    {
      "epoch": 0.16097256258709336,
      "grad_norm": 1.2216471433639526,
      "learning_rate": 4.9195377444620635e-05,
      "loss": 0.0084,
      "step": 3350
    },
    {
      "epoch": 0.16337513814809476,
      "grad_norm": 2.2922213077545166,
      "learning_rate": 4.9183364566815626e-05,
      "loss": 0.0058,
      "step": 3400
    },
    {
      "epoch": 0.16577771370909616,
      "grad_norm": 1.4693466424942017,
      "learning_rate": 4.917135168901062e-05,
      "loss": 0.0058,
      "step": 3450
    },
    {
      "epoch": 0.16818028927009754,
      "grad_norm": 1.3643933534622192,
      "learning_rate": 4.9159338811205615e-05,
      "loss": 0.0063,
      "step": 3500
    },
    {
      "epoch": 0.17058286483109894,
      "grad_norm": 1.0520546436309814,
      "learning_rate": 4.9147325933400605e-05,
      "loss": 0.0075,
      "step": 3550
    },
    {
      "epoch": 0.17298544039210034,
      "grad_norm": 1.178865909576416,
      "learning_rate": 4.91353130555956e-05,
      "loss": 0.0083,
      "step": 3600
    },
    {
      "epoch": 0.17538801595310172,
      "grad_norm": 0.8996872305870056,
      "learning_rate": 4.9123300177790594e-05,
      "loss": 0.0067,
      "step": 3650
    },
    {
      "epoch": 0.17779059151410312,
      "grad_norm": 2.0464773178100586,
      "learning_rate": 4.9111287299985585e-05,
      "loss": 0.0067,
      "step": 3700
    },
    {
      "epoch": 0.18019316707510452,
      "grad_norm": 1.003833293914795,
      "learning_rate": 4.909927442218058e-05,
      "loss": 0.0097,
      "step": 3750
    },
    {
      "epoch": 0.1825957426361059,
      "grad_norm": 0.8388890027999878,
      "learning_rate": 4.908726154437557e-05,
      "loss": 0.0074,
      "step": 3800
    },
    {
      "epoch": 0.1849983181971073,
      "grad_norm": 0.6696130633354187,
      "learning_rate": 4.9075248666570564e-05,
      "loss": 0.006,
      "step": 3850
    },
    {
      "epoch": 0.1874008937581087,
      "grad_norm": 0.2937922179698944,
      "learning_rate": 4.906323578876556e-05,
      "loss": 0.0061,
      "step": 3900
    },
    {
      "epoch": 0.18980346931911007,
      "grad_norm": 1.0247782468795776,
      "learning_rate": 4.905122291096055e-05,
      "loss": 0.0056,
      "step": 3950
    },
    {
      "epoch": 0.19220604488011148,
      "grad_norm": 0.5409323573112488,
      "learning_rate": 4.903921003315555e-05,
      "loss": 0.0046,
      "step": 4000
    },
    {
      "epoch": 0.19460862044111288,
      "grad_norm": 0.43130701780319214,
      "learning_rate": 4.902719715535054e-05,
      "loss": 0.0059,
      "step": 4050
    },
    {
      "epoch": 0.19701119600211425,
      "grad_norm": 1.1368478536605835,
      "learning_rate": 4.901518427754553e-05,
      "loss": 0.0047,
      "step": 4100
    },
    {
      "epoch": 0.19941377156311565,
      "grad_norm": 1.3211380243301392,
      "learning_rate": 4.900317139974052e-05,
      "loss": 0.0046,
      "step": 4150
    },
    {
      "epoch": 0.20181634712411706,
      "grad_norm": 2.1333322525024414,
      "learning_rate": 4.899115852193551e-05,
      "loss": 0.0057,
      "step": 4200
    },
    {
      "epoch": 0.20421892268511846,
      "grad_norm": 0.5230908989906311,
      "learning_rate": 4.897914564413051e-05,
      "loss": 0.006,
      "step": 4250
    },
    {
      "epoch": 0.20662149824611983,
      "grad_norm": 2.048586130142212,
      "learning_rate": 4.89671327663255e-05,
      "loss": 0.0052,
      "step": 4300
    },
    {
      "epoch": 0.20902407380712124,
      "grad_norm": 1.6597139835357666,
      "learning_rate": 4.895511988852049e-05,
      "loss": 0.0045,
      "step": 4350
    },
    {
      "epoch": 0.21142664936812264,
      "grad_norm": 0.47161102294921875,
      "learning_rate": 4.894310701071549e-05,
      "loss": 0.004,
      "step": 4400
    },
    {
      "epoch": 0.213829224929124,
      "grad_norm": 0.7128011584281921,
      "learning_rate": 4.893109413291048e-05,
      "loss": 0.0038,
      "step": 4450
    },
    {
      "epoch": 0.21623180049012541,
      "grad_norm": 0.39195820689201355,
      "learning_rate": 4.891908125510548e-05,
      "loss": 0.0041,
      "step": 4500
    },
    {
      "epoch": 0.21863437605112682,
      "grad_norm": 0.352633535861969,
      "learning_rate": 4.890706837730047e-05,
      "loss": 0.0039,
      "step": 4550
    },
    {
      "epoch": 0.2210369516121282,
      "grad_norm": 0.62523353099823,
      "learning_rate": 4.889505549949546e-05,
      "loss": 0.005,
      "step": 4600
    },
    {
      "epoch": 0.2234395271731296,
      "grad_norm": 2.3909573554992676,
      "learning_rate": 4.888304262169046e-05,
      "loss": 0.0043,
      "step": 4650
    },
    {
      "epoch": 0.225842102734131,
      "grad_norm": 0.7748146057128906,
      "learning_rate": 4.887102974388545e-05,
      "loss": 0.0033,
      "step": 4700
    },
    {
      "epoch": 0.22824467829513237,
      "grad_norm": 0.3099277913570404,
      "learning_rate": 4.885901686608044e-05,
      "loss": 0.004,
      "step": 4750
    },
    {
      "epoch": 0.23064725385613377,
      "grad_norm": 1.8322608470916748,
      "learning_rate": 4.884700398827544e-05,
      "loss": 0.0042,
      "step": 4800
    },
    {
      "epoch": 0.23304982941713517,
      "grad_norm": 1.8548411130905151,
      "learning_rate": 4.883499111047043e-05,
      "loss": 0.0047,
      "step": 4850
    },
    {
      "epoch": 0.23545240497813658,
      "grad_norm": 1.062731146812439,
      "learning_rate": 4.882297823266542e-05,
      "loss": 0.0048,
      "step": 4900
    },
    {
      "epoch": 0.23785498053913795,
      "grad_norm": 1.5180546045303345,
      "learning_rate": 4.881096535486041e-05,
      "loss": 0.0039,
      "step": 4950
    },
    {
      "epoch": 0.24025755610013935,
      "grad_norm": 1.1765363216400146,
      "learning_rate": 4.879895247705541e-05,
      "loss": 0.0039,
      "step": 5000
    },
    {
      "epoch": 0.24266013166114075,
      "grad_norm": 0.455443412065506,
      "learning_rate": 4.87869395992504e-05,
      "loss": 0.0035,
      "step": 5050
    },
    {
      "epoch": 0.24506270722214213,
      "grad_norm": 1.46443772315979,
      "learning_rate": 4.877492672144539e-05,
      "loss": 0.0038,
      "step": 5100
    },
    {
      "epoch": 0.24746528278314353,
      "grad_norm": 0.5781234502792358,
      "learning_rate": 4.8762913843640386e-05,
      "loss": 0.0048,
      "step": 5150
    },
    {
      "epoch": 0.24986785834414493,
      "grad_norm": 1.2511003017425537,
      "learning_rate": 4.875090096583538e-05,
      "loss": 0.0031,
      "step": 5200
    },
    {
      "epoch": 0.2522704339051463,
      "grad_norm": 2.3380489349365234,
      "learning_rate": 4.873888808803037e-05,
      "loss": 0.004,
      "step": 5250
    },
    {
      "epoch": 0.25467300946614774,
      "grad_norm": 0.3612140417098999,
      "learning_rate": 4.8726875210225366e-05,
      "loss": 0.0054,
      "step": 5300
    },
    {
      "epoch": 0.2570755850271491,
      "grad_norm": 0.4610612988471985,
      "learning_rate": 4.8714862332420356e-05,
      "loss": 0.0035,
      "step": 5350
    },
    {
      "epoch": 0.2594781605881505,
      "grad_norm": 0.7935386300086975,
      "learning_rate": 4.8702849454615354e-05,
      "loss": 0.0037,
      "step": 5400
    },
    {
      "epoch": 0.2618807361491519,
      "grad_norm": 1.397274136543274,
      "learning_rate": 4.8690836576810345e-05,
      "loss": 0.003,
      "step": 5450
    },
    {
      "epoch": 0.2642833117101533,
      "grad_norm": 1.3162274360656738,
      "learning_rate": 4.8678823699005336e-05,
      "loss": 0.004,
      "step": 5500
    },
    {
      "epoch": 0.26668588727115466,
      "grad_norm": 1.1938406229019165,
      "learning_rate": 4.866681082120033e-05,
      "loss": 0.0046,
      "step": 5550
    },
    {
      "epoch": 0.2690884628321561,
      "grad_norm": 0.4257481098175049,
      "learning_rate": 4.865479794339532e-05,
      "loss": 0.0026,
      "step": 5600
    },
    {
      "epoch": 0.27149103839315747,
      "grad_norm": 0.567571759223938,
      "learning_rate": 4.8642785065590315e-05,
      "loss": 0.0033,
      "step": 5650
    },
    {
      "epoch": 0.27389361395415884,
      "grad_norm": 1.661132574081421,
      "learning_rate": 4.8630772187785306e-05,
      "loss": 0.0033,
      "step": 5700
    },
    {
      "epoch": 0.2762961895151603,
      "grad_norm": 1.2566858530044556,
      "learning_rate": 4.8618759309980297e-05,
      "loss": 0.0033,
      "step": 5750
    },
    {
      "epoch": 0.27869876507616165,
      "grad_norm": 1.9318197965621948,
      "learning_rate": 4.8606746432175294e-05,
      "loss": 0.0037,
      "step": 5800
    },
    {
      "epoch": 0.281101340637163,
      "grad_norm": 1.4022386074066162,
      "learning_rate": 4.8594733554370285e-05,
      "loss": 0.0033,
      "step": 5850
    },
    {
      "epoch": 0.28350391619816445,
      "grad_norm": 1.4420922994613647,
      "learning_rate": 4.858272067656528e-05,
      "loss": 0.0038,
      "step": 5900
    },
    {
      "epoch": 0.2859064917591658,
      "grad_norm": 0.5299707651138306,
      "learning_rate": 4.8570707798760273e-05,
      "loss": 0.0026,
      "step": 5950
    },
    {
      "epoch": 0.2883090673201672,
      "grad_norm": 1.218781590461731,
      "learning_rate": 4.8558694920955264e-05,
      "loss": 0.0032,
      "step": 6000
    },
    {
      "epoch": 0.29071164288116863,
      "grad_norm": 0.8099576830863953,
      "learning_rate": 4.854668204315026e-05,
      "loss": 0.0026,
      "step": 6050
    },
    {
      "epoch": 0.29311421844217,
      "grad_norm": 0.839592456817627,
      "learning_rate": 4.853466916534525e-05,
      "loss": 0.0025,
      "step": 6100
    },
    {
      "epoch": 0.2955167940031714,
      "grad_norm": 0.5667944550514221,
      "learning_rate": 4.8522656287540244e-05,
      "loss": 0.0031,
      "step": 6150
    },
    {
      "epoch": 0.2979193695641728,
      "grad_norm": 1.277574062347412,
      "learning_rate": 4.851064340973524e-05,
      "loss": 0.0022,
      "step": 6200
    },
    {
      "epoch": 0.3003219451251742,
      "grad_norm": 0.7289004921913147,
      "learning_rate": 4.849863053193023e-05,
      "loss": 0.0029,
      "step": 6250
    },
    {
      "epoch": 0.30272452068617556,
      "grad_norm": 1.75052011013031,
      "learning_rate": 4.848661765412523e-05,
      "loss": 0.003,
      "step": 6300
    },
    {
      "epoch": 0.305127096247177,
      "grad_norm": 0.8101513981819153,
      "learning_rate": 4.8474604776320214e-05,
      "loss": 0.0036,
      "step": 6350
    },
    {
      "epoch": 0.30752967180817836,
      "grad_norm": 0.625751256942749,
      "learning_rate": 4.846259189851521e-05,
      "loss": 0.0026,
      "step": 6400
    },
    {
      "epoch": 0.30993224736917974,
      "grad_norm": 0.38452669978141785,
      "learning_rate": 4.84505790207102e-05,
      "loss": 0.0019,
      "step": 6450
    },
    {
      "epoch": 0.31233482293018117,
      "grad_norm": 0.4652124047279358,
      "learning_rate": 4.843856614290519e-05,
      "loss": 0.0025,
      "step": 6500
    },
    {
      "epoch": 0.31473739849118254,
      "grad_norm": 0.2544368803501129,
      "learning_rate": 4.842655326510019e-05,
      "loss": 0.003,
      "step": 6550
    },
    {
      "epoch": 0.3171399740521839,
      "grad_norm": 0.993867039680481,
      "learning_rate": 4.841454038729518e-05,
      "loss": 0.0031,
      "step": 6600
    },
    {
      "epoch": 0.31954254961318534,
      "grad_norm": 0.8605760931968689,
      "learning_rate": 4.840252750949017e-05,
      "loss": 0.0022,
      "step": 6650
    },
    {
      "epoch": 0.3219451251741867,
      "grad_norm": 1.1287469863891602,
      "learning_rate": 4.839051463168517e-05,
      "loss": 0.0028,
      "step": 6700
    },
    {
      "epoch": 0.32434770073518815,
      "grad_norm": 1.0360721349716187,
      "learning_rate": 4.837850175388016e-05,
      "loss": 0.0031,
      "step": 6750
    },
    {
      "epoch": 0.3267502762961895,
      "grad_norm": 0.3745308816432953,
      "learning_rate": 4.836648887607516e-05,
      "loss": 0.0016,
      "step": 6800
    },
    {
      "epoch": 0.3291528518571909,
      "grad_norm": 0.42093610763549805,
      "learning_rate": 4.835447599827015e-05,
      "loss": 0.0024,
      "step": 6850
    },
    {
      "epoch": 0.33155542741819233,
      "grad_norm": 0.4041617810726166,
      "learning_rate": 4.834246312046514e-05,
      "loss": 0.0024,
      "step": 6900
    },
    {
      "epoch": 0.3339580029791937,
      "grad_norm": 0.2239319235086441,
      "learning_rate": 4.833045024266014e-05,
      "loss": 0.0024,
      "step": 6950
    },
    {
      "epoch": 0.3363605785401951,
      "grad_norm": 0.5156970620155334,
      "learning_rate": 4.831843736485513e-05,
      "loss": 0.0025,
      "step": 7000
    },
    {
      "epoch": 0.3387631541011965,
      "grad_norm": 0.589368999004364,
      "learning_rate": 4.8306424487050126e-05,
      "loss": 0.0017,
      "step": 7050
    },
    {
      "epoch": 0.3411657296621979,
      "grad_norm": 0.9890074729919434,
      "learning_rate": 4.829441160924511e-05,
      "loss": 0.0022,
      "step": 7100
    },
    {
      "epoch": 0.34356830522319926,
      "grad_norm": 0.36482352018356323,
      "learning_rate": 4.82823987314401e-05,
      "loss": 0.0017,
      "step": 7150
    },
    {
      "epoch": 0.3459708807842007,
      "grad_norm": 0.3104461133480072,
      "learning_rate": 4.82703858536351e-05,
      "loss": 0.0016,
      "step": 7200
    },
    {
      "epoch": 0.34837345634520206,
      "grad_norm": 0.5063043832778931,
      "learning_rate": 4.825837297583009e-05,
      "loss": 0.0018,
      "step": 7250
    },
    {
      "epoch": 0.35077603190620343,
      "grad_norm": 1.35908842086792,
      "learning_rate": 4.824636009802509e-05,
      "loss": 0.0019,
      "step": 7300
    },
    {
      "epoch": 0.35317860746720486,
      "grad_norm": 0.4147496521472931,
      "learning_rate": 4.823434722022008e-05,
      "loss": 0.0028,
      "step": 7350
    },
    {
      "epoch": 0.35558118302820624,
      "grad_norm": 0.6044933795928955,
      "learning_rate": 4.822233434241507e-05,
      "loss": 0.0013,
      "step": 7400
    },
    {
      "epoch": 0.3579837585892076,
      "grad_norm": 0.7975555062294006,
      "learning_rate": 4.8210321464610066e-05,
      "loss": 0.0023,
      "step": 7450
    },
    {
      "epoch": 0.36038633415020904,
      "grad_norm": 0.8660078644752502,
      "learning_rate": 4.819830858680506e-05,
      "loss": 0.0018,
      "step": 7500
    },
    {
      "epoch": 0.3627889097112104,
      "grad_norm": 0.9014655947685242,
      "learning_rate": 4.8186295709000054e-05,
      "loss": 0.0024,
      "step": 7550
    },
    {
      "epoch": 0.3651914852722118,
      "grad_norm": 0.44202256202697754,
      "learning_rate": 4.8174282831195045e-05,
      "loss": 0.0018,
      "step": 7600
    },
    {
      "epoch": 0.3675940608332132,
      "grad_norm": 0.9656853675842285,
      "learning_rate": 4.8162269953390036e-05,
      "loss": 0.0028,
      "step": 7650
    },
    {
      "epoch": 0.3699966363942146,
      "grad_norm": 0.2906738519668579,
      "learning_rate": 4.8150257075585034e-05,
      "loss": 0.0015,
      "step": 7700
    },
    {
      "epoch": 0.37239921195521597,
      "grad_norm": 1.329195261001587,
      "learning_rate": 4.8138244197780024e-05,
      "loss": 0.0016,
      "step": 7750
    },
    {
      "epoch": 0.3748017875162174,
      "grad_norm": 0.5366710424423218,
      "learning_rate": 4.8126231319975015e-05,
      "loss": 0.0016,
      "step": 7800
    },
    {
      "epoch": 0.3772043630772188,
      "grad_norm": 0.38370034098625183,
      "learning_rate": 4.8114218442170006e-05,
      "loss": 0.0017,
      "step": 7850
    },
    {
      "epoch": 0.37960693863822015,
      "grad_norm": 0.3066962957382202,
      "learning_rate": 4.8102205564365e-05,
      "loss": 0.0018,
      "step": 7900
    },
    {
      "epoch": 0.3820095141992216,
      "grad_norm": 0.2574390769004822,
      "learning_rate": 4.8090192686559995e-05,
      "loss": 0.0017,
      "step": 7950
    },
    {
      "epoch": 0.38441208976022295,
      "grad_norm": 0.1367029994726181,
      "learning_rate": 4.8078179808754985e-05,
      "loss": 0.0044,
      "step": 8000
    },
    {
      "epoch": 0.3868146653212243,
      "grad_norm": 0.29495754837989807,
      "learning_rate": 4.8066166930949976e-05,
      "loss": 0.0015,
      "step": 8050
    },
    {
      "epoch": 0.38921724088222576,
      "grad_norm": 1.0089691877365112,
      "learning_rate": 4.8054154053144974e-05,
      "loss": 0.0014,
      "step": 8100
    },
    {
      "epoch": 0.39161981644322713,
      "grad_norm": 0.9552493691444397,
      "learning_rate": 4.8042141175339965e-05,
      "loss": 0.0015,
      "step": 8150
    },
    {
      "epoch": 0.3940223920042285,
      "grad_norm": 0.5448896884918213,
      "learning_rate": 4.803012829753496e-05,
      "loss": 0.0015,
      "step": 8200
    },
    {
      "epoch": 0.39642496756522994,
      "grad_norm": 0.7121440768241882,
      "learning_rate": 4.801811541972995e-05,
      "loss": 0.0015,
      "step": 8250
    },
    {
      "epoch": 0.3988275431262313,
      "grad_norm": 1.0201919078826904,
      "learning_rate": 4.8006102541924944e-05,
      "loss": 0.0025,
      "step": 8300
    },
    {
      "epoch": 0.40123011868723274,
      "grad_norm": 0.5103296637535095,
      "learning_rate": 4.799408966411994e-05,
      "loss": 0.0014,
      "step": 8350
    },
    {
      "epoch": 0.4036326942482341,
      "grad_norm": 1.3019262552261353,
      "learning_rate": 4.798207678631493e-05,
      "loss": 0.0016,
      "step": 8400
    },
    {
      "epoch": 0.4060352698092355,
      "grad_norm": 0.853866457939148,
      "learning_rate": 4.797006390850993e-05,
      "loss": 0.0014,
      "step": 8450
    },
    {
      "epoch": 0.4084378453702369,
      "grad_norm": 0.4468635618686676,
      "learning_rate": 4.795805103070492e-05,
      "loss": 0.0014,
      "step": 8500
    },
    {
      "epoch": 0.4108404209312383,
      "grad_norm": 0.5029453635215759,
      "learning_rate": 4.794603815289991e-05,
      "loss": 0.001,
      "step": 8550
    },
    {
      "epoch": 0.41324299649223967,
      "grad_norm": 0.6873670816421509,
      "learning_rate": 4.79340252750949e-05,
      "loss": 0.0013,
      "step": 8600
    },
    {
      "epoch": 0.4156455720532411,
      "grad_norm": 0.4353700876235962,
      "learning_rate": 4.792201239728989e-05,
      "loss": 0.0016,
      "step": 8650
    },
    {
      "epoch": 0.41804814761424247,
      "grad_norm": 0.27242541313171387,
      "learning_rate": 4.790999951948489e-05,
      "loss": 0.0018,
      "step": 8700
    },
    {
      "epoch": 0.42045072317524385,
      "grad_norm": 0.6060540080070496,
      "learning_rate": 4.789798664167988e-05,
      "loss": 0.0013,
      "step": 8750
    },
    {
      "epoch": 0.4228532987362453,
      "grad_norm": 0.42970892786979675,
      "learning_rate": 4.788597376387487e-05,
      "loss": 0.0011,
      "step": 8800
    },
    {
      "epoch": 0.42525587429724665,
      "grad_norm": 0.3042391240596771,
      "learning_rate": 4.787396088606987e-05,
      "loss": 0.0016,
      "step": 8850
    },
    {
      "epoch": 0.427658449858248,
      "grad_norm": 0.7691907286643982,
      "learning_rate": 4.786194800826486e-05,
      "loss": 0.0012,
      "step": 8900
    },
    {
      "epoch": 0.43006102541924945,
      "grad_norm": 0.4786968529224396,
      "learning_rate": 4.784993513045986e-05,
      "loss": 0.0011,
      "step": 8950
    },
    {
      "epoch": 0.43246360098025083,
      "grad_norm": 0.8461541533470154,
      "learning_rate": 4.783792225265485e-05,
      "loss": 0.0011,
      "step": 9000
    },
    {
      "epoch": 0.4348661765412522,
      "grad_norm": 0.33702102303504944,
      "learning_rate": 4.782590937484984e-05,
      "loss": 0.0015,
      "step": 9050
    },
    {
      "epoch": 0.43726875210225363,
      "grad_norm": 0.6144108176231384,
      "learning_rate": 4.781389649704484e-05,
      "loss": 0.0012,
      "step": 9100
    },
    {
      "epoch": 0.439671327663255,
      "grad_norm": 0.5265894532203674,
      "learning_rate": 4.780188361923983e-05,
      "loss": 0.0011,
      "step": 9150
    },
    {
      "epoch": 0.4420739032242564,
      "grad_norm": 0.6786264181137085,
      "learning_rate": 4.778987074143482e-05,
      "loss": 0.0016,
      "step": 9200
    },
    {
      "epoch": 0.4444764787852578,
      "grad_norm": 0.39735889434814453,
      "learning_rate": 4.777785786362982e-05,
      "loss": 0.0015,
      "step": 9250
    },
    {
      "epoch": 0.4468790543462592,
      "grad_norm": 0.30964046716690063,
      "learning_rate": 4.776584498582481e-05,
      "loss": 0.001,
      "step": 9300
    },
    {
      "epoch": 0.44928162990726056,
      "grad_norm": 0.3742053806781769,
      "learning_rate": 4.77538321080198e-05,
      "loss": 0.0013,
      "step": 9350
    },
    {
      "epoch": 0.451684205468262,
      "grad_norm": 0.16615520417690277,
      "learning_rate": 4.774181923021479e-05,
      "loss": 0.0022,
      "step": 9400
    },
    {
      "epoch": 0.45408678102926336,
      "grad_norm": 1.7019116878509521,
      "learning_rate": 4.772980635240979e-05,
      "loss": 0.0018,
      "step": 9450
    },
    {
      "epoch": 0.45648935659026474,
      "grad_norm": 0.36377424001693726,
      "learning_rate": 4.771779347460478e-05,
      "loss": 0.0025,
      "step": 9500
    },
    {
      "epoch": 0.45889193215126617,
      "grad_norm": 0.26808589696884155,
      "learning_rate": 4.770578059679977e-05,
      "loss": 0.0013,
      "step": 9550
    },
    {
      "epoch": 0.46129450771226754,
      "grad_norm": 1.0855271816253662,
      "learning_rate": 4.7693767718994766e-05,
      "loss": 0.0019,
      "step": 9600
    },
    {
      "epoch": 0.4636970832732689,
      "grad_norm": 0.8001090884208679,
      "learning_rate": 4.768175484118976e-05,
      "loss": 0.0013,
      "step": 9650
    },
    {
      "epoch": 0.46609965883427035,
      "grad_norm": 0.2877447009086609,
      "learning_rate": 4.766974196338475e-05,
      "loss": 0.0013,
      "step": 9700
    },
    {
      "epoch": 0.4685022343952717,
      "grad_norm": 0.15168769657611847,
      "learning_rate": 4.7657729085579746e-05,
      "loss": 0.001,
      "step": 9750
    },
    {
      "epoch": 0.47090480995627315,
      "grad_norm": 0.13548272848129272,
      "learning_rate": 4.7645716207774736e-05,
      "loss": 0.0014,
      "step": 9800
    },
    {
      "epoch": 0.4733073855172745,
      "grad_norm": 0.2586910128593445,
      "learning_rate": 4.7633703329969734e-05,
      "loss": 0.001,
      "step": 9850
    },
    {
      "epoch": 0.4757099610782759,
      "grad_norm": 0.19806697964668274,
      "learning_rate": 4.7621690452164725e-05,
      "loss": 0.001,
      "step": 9900
    },
    {
      "epoch": 0.47811253663927733,
      "grad_norm": 0.5505807399749756,
      "learning_rate": 4.7609677574359716e-05,
      "loss": 0.0017,
      "step": 9950
    },
    {
      "epoch": 0.4805151122002787,
      "grad_norm": 0.4760282039642334,
      "learning_rate": 4.759766469655471e-05,
      "loss": 0.0009,
      "step": 10000
    },
    {
      "epoch": 0.4829176877612801,
      "grad_norm": 1.452796459197998,
      "learning_rate": 4.7585651818749704e-05,
      "loss": 0.0013,
      "step": 10050
    },
    {
      "epoch": 0.4853202633222815,
      "grad_norm": 0.21217229962348938,
      "learning_rate": 4.7573638940944695e-05,
      "loss": 0.0016,
      "step": 10100
    },
    {
      "epoch": 0.4877228388832829,
      "grad_norm": 0.1599077433347702,
      "learning_rate": 4.7561626063139686e-05,
      "loss": 0.0008,
      "step": 10150
    },
    {
      "epoch": 0.49012541444428426,
      "grad_norm": 0.2584468424320221,
      "learning_rate": 4.7549613185334677e-05,
      "loss": 0.001,
      "step": 10200
    },
    {
      "epoch": 0.4925279900052857,
      "grad_norm": 0.32612329721450806,
      "learning_rate": 4.7537600307529674e-05,
      "loss": 0.0013,
      "step": 10250
    },
    {
      "epoch": 0.49493056556628706,
      "grad_norm": 0.24040719866752625,
      "learning_rate": 4.7525587429724665e-05,
      "loss": 0.0014,
      "step": 10300
    },
    {
      "epoch": 0.49733314112728844,
      "grad_norm": 0.418674111366272,
      "learning_rate": 4.751357455191966e-05,
      "loss": 0.0007,
      "step": 10350
    },
    {
      "epoch": 0.49973571668828987,
      "grad_norm": 0.4090425670146942,
      "learning_rate": 4.7501561674114653e-05,
      "loss": 0.0009,
      "step": 10400
    },
    {
      "epoch": 0.5021382922492912,
      "grad_norm": 0.1169799342751503,
      "learning_rate": 4.7489548796309644e-05,
      "loss": 0.0009,
      "step": 10450
    },
    {
      "epoch": 0.5045408678102926,
      "grad_norm": 0.3678429126739502,
      "learning_rate": 4.747753591850464e-05,
      "loss": 0.0008,
      "step": 10500
    },
    {
      "epoch": 0.506943443371294,
      "grad_norm": 0.24571798741817474,
      "learning_rate": 4.746552304069963e-05,
      "loss": 0.0012,
      "step": 10550
    },
    {
      "epoch": 0.5093460189322955,
      "grad_norm": 0.12910117208957672,
      "learning_rate": 4.7453510162894623e-05,
      "loss": 0.0007,
      "step": 10600
    },
    {
      "epoch": 0.5117485944932968,
      "grad_norm": 0.37375181913375854,
      "learning_rate": 4.744149728508962e-05,
      "loss": 0.0007,
      "step": 10650
    },
    {
      "epoch": 0.5141511700542982,
      "grad_norm": 0.21670688688755035,
      "learning_rate": 4.742948440728461e-05,
      "loss": 0.0009,
      "step": 10700
    },
    {
      "epoch": 0.5165537456152997,
      "grad_norm": 0.9681891202926636,
      "learning_rate": 4.741747152947961e-05,
      "loss": 0.0008,
      "step": 10750
    },
    {
      "epoch": 0.518956321176301,
      "grad_norm": 0.688563346862793,
      "learning_rate": 4.74054586516746e-05,
      "loss": 0.0008,
      "step": 10800
    },
    {
      "epoch": 0.5213588967373024,
      "grad_norm": 0.45723238587379456,
      "learning_rate": 4.739344577386959e-05,
      "loss": 0.0011,
      "step": 10850
    },
    {
      "epoch": 0.5237614722983038,
      "grad_norm": 0.3736203908920288,
      "learning_rate": 4.738143289606458e-05,
      "loss": 0.0009,
      "step": 10900
    },
    {
      "epoch": 0.5261640478593052,
      "grad_norm": 0.28052544593811035,
      "learning_rate": 4.736942001825957e-05,
      "loss": 0.0007,
      "step": 10950
    },
    {
      "epoch": 0.5285666234203066,
      "grad_norm": 0.12103938311338425,
      "learning_rate": 4.735740714045457e-05,
      "loss": 0.001,
      "step": 11000
    },
    {
      "epoch": 0.530969198981308,
      "grad_norm": 0.49166709184646606,
      "learning_rate": 4.734539426264956e-05,
      "loss": 0.0017,
      "step": 11050
    },
    {
      "epoch": 0.5333717745423093,
      "grad_norm": 0.49919912219047546,
      "learning_rate": 4.733338138484455e-05,
      "loss": 0.0007,
      "step": 11100
    },
    {
      "epoch": 0.5357743501033108,
      "grad_norm": 0.7029434442520142,
      "learning_rate": 4.732136850703955e-05,
      "loss": 0.0009,
      "step": 11150
    },
    {
      "epoch": 0.5381769256643122,
      "grad_norm": 0.25718995928764343,
      "learning_rate": 4.730935562923454e-05,
      "loss": 0.0006,
      "step": 11200
    },
    {
      "epoch": 0.5405795012253135,
      "grad_norm": 0.4542209506034851,
      "learning_rate": 4.729734275142954e-05,
      "loss": 0.0015,
      "step": 11250
    },
    {
      "epoch": 0.5429820767863149,
      "grad_norm": 0.22616103291511536,
      "learning_rate": 4.728532987362453e-05,
      "loss": 0.0006,
      "step": 11300
    },
    {
      "epoch": 0.5453846523473164,
      "grad_norm": 0.4343211352825165,
      "learning_rate": 4.727331699581952e-05,
      "loss": 0.0009,
      "step": 11350
    },
    {
      "epoch": 0.5477872279083177,
      "grad_norm": 0.3514123558998108,
      "learning_rate": 4.726130411801452e-05,
      "loss": 0.001,
      "step": 11400
    },
    {
      "epoch": 0.5501898034693191,
      "grad_norm": 0.10461115837097168,
      "learning_rate": 4.724929124020951e-05,
      "loss": 0.0007,
      "step": 11450
    },
    {
      "epoch": 0.5525923790303205,
      "grad_norm": 0.7199437022209167,
      "learning_rate": 4.72372783624045e-05,
      "loss": 0.0006,
      "step": 11500
    },
    {
      "epoch": 0.5549949545913219,
      "grad_norm": 0.32292890548706055,
      "learning_rate": 4.722526548459949e-05,
      "loss": 0.0009,
      "step": 11550
    },
    {
      "epoch": 0.5573975301523233,
      "grad_norm": 0.6617770195007324,
      "learning_rate": 4.721325260679448e-05,
      "loss": 0.0007,
      "step": 11600
    },
    {
      "epoch": 0.5598001057133247,
      "grad_norm": 0.06440966576337814,
      "learning_rate": 4.720123972898948e-05,
      "loss": 0.0006,
      "step": 11650
    },
    {
      "epoch": 0.562202681274326,
      "grad_norm": 0.3029870092868805,
      "learning_rate": 4.718922685118447e-05,
      "loss": 0.0017,
      "step": 11700
    },
    {
      "epoch": 0.5646052568353275,
      "grad_norm": 0.2416248321533203,
      "learning_rate": 4.717721397337947e-05,
      "loss": 0.0008,
      "step": 11750
    },
    {
      "epoch": 0.5670078323963289,
      "grad_norm": 0.20123884081840515,
      "learning_rate": 4.716520109557446e-05,
      "loss": 0.0006,
      "step": 11800
    },
    {
      "epoch": 0.5694104079573302,
      "grad_norm": 0.3825666308403015,
      "learning_rate": 4.715318821776945e-05,
      "loss": 0.0008,
      "step": 11850
    },
    {
      "epoch": 0.5718129835183317,
      "grad_norm": 0.35742446780204773,
      "learning_rate": 4.7141175339964446e-05,
      "loss": 0.0013,
      "step": 11900
    },
    {
      "epoch": 0.5742155590793331,
      "grad_norm": 0.21975021064281464,
      "learning_rate": 4.712916246215944e-05,
      "loss": 0.0007,
      "step": 11950
    },
    {
      "epoch": 0.5766181346403344,
      "grad_norm": 0.607764482498169,
      "learning_rate": 4.711714958435443e-05,
      "loss": 0.0006,
      "step": 12000
    },
    {
      "epoch": 0.5790207102013358,
      "grad_norm": 0.2979283034801483,
      "learning_rate": 4.7105136706549425e-05,
      "loss": 0.0009,
      "step": 12050
    },
    {
      "epoch": 0.5814232857623373,
      "grad_norm": 0.22214260697364807,
      "learning_rate": 4.7093123828744416e-05,
      "loss": 0.0006,
      "step": 12100
    },
    {
      "epoch": 0.5838258613233386,
      "grad_norm": 0.2760601341724396,
      "learning_rate": 4.7081110950939414e-05,
      "loss": 0.0007,
      "step": 12150
    },
    {
      "epoch": 0.58622843688434,
      "grad_norm": 0.5125977993011475,
      "learning_rate": 4.7069098073134404e-05,
      "loss": 0.0006,
      "step": 12200
    },
    {
      "epoch": 0.5886310124453414,
      "grad_norm": 0.39274945855140686,
      "learning_rate": 4.7057085195329395e-05,
      "loss": 0.0012,
      "step": 12250
    },
    {
      "epoch": 0.5910335880063428,
      "grad_norm": 0.12645234167575836,
      "learning_rate": 4.7045072317524386e-05,
      "loss": 0.0016,
      "step": 12300
    },
    {
      "epoch": 0.5934361635673442,
      "grad_norm": 0.5217161178588867,
      "learning_rate": 4.703305943971938e-05,
      "loss": 0.0007,
      "step": 12350
    },
    {
      "epoch": 0.5958387391283456,
      "grad_norm": 0.15700966119766235,
      "learning_rate": 4.7021046561914375e-05,
      "loss": 0.0006,
      "step": 12400
    },
    {
      "epoch": 0.5982413146893469,
      "grad_norm": 0.506783127784729,
      "learning_rate": 4.7009033684109365e-05,
      "loss": 0.0007,
      "step": 12450
    },
    {
      "epoch": 0.6006438902503484,
      "grad_norm": 0.7790651917457581,
      "learning_rate": 4.6997020806304356e-05,
      "loss": 0.0007,
      "step": 12500
    },
    {
      "epoch": 0.6030464658113498,
      "grad_norm": 0.4262654185295105,
      "learning_rate": 4.6985007928499354e-05,
      "loss": 0.0007,
      "step": 12550
    },
    {
      "epoch": 0.6054490413723511,
      "grad_norm": 0.16989585757255554,
      "learning_rate": 4.6972995050694345e-05,
      "loss": 0.0006,
      "step": 12600
    },
    {
      "epoch": 0.6078516169333525,
      "grad_norm": 0.3065897226333618,
      "learning_rate": 4.696098217288934e-05,
      "loss": 0.0005,
      "step": 12650
    },
    {
      "epoch": 0.610254192494354,
      "grad_norm": 0.4384155869483948,
      "learning_rate": 4.694896929508433e-05,
      "loss": 0.0005,
      "step": 12700
    },
    {
      "epoch": 0.6126567680553553,
      "grad_norm": 0.6204643845558167,
      "learning_rate": 4.6936956417279324e-05,
      "loss": 0.0006,
      "step": 12750
    },
    {
      "epoch": 0.6150593436163567,
      "grad_norm": 0.6278405785560608,
      "learning_rate": 4.692494353947432e-05,
      "loss": 0.0006,
      "step": 12800
    },
    {
      "epoch": 0.6174619191773582,
      "grad_norm": 0.1425287276506424,
      "learning_rate": 4.691293066166931e-05,
      "loss": 0.0007,
      "step": 12850
    },
    {
      "epoch": 0.6198644947383595,
      "grad_norm": 0.5710081458091736,
      "learning_rate": 4.690091778386431e-05,
      "loss": 0.0007,
      "step": 12900
    },
    {
      "epoch": 0.6222670702993609,
      "grad_norm": 0.49438947439193726,
      "learning_rate": 4.68889049060593e-05,
      "loss": 0.0007,
      "step": 12950
    },
    {
      "epoch": 0.6246696458603623,
      "grad_norm": 0.15969662368297577,
      "learning_rate": 4.687689202825429e-05,
      "loss": 0.0005,
      "step": 13000
    },
    {
      "epoch": 0.6270722214213637,
      "grad_norm": 0.2225857973098755,
      "learning_rate": 4.686487915044928e-05,
      "loss": 0.0005,
      "step": 13050
    },
    {
      "epoch": 0.6294747969823651,
      "grad_norm": 0.24664218723773956,
      "learning_rate": 4.685286627264427e-05,
      "loss": 0.0006,
      "step": 13100
    },
    {
      "epoch": 0.6318773725433665,
      "grad_norm": 0.11504471302032471,
      "learning_rate": 4.684085339483927e-05,
      "loss": 0.0005,
      "step": 13150
    },
    {
      "epoch": 0.6342799481043678,
      "grad_norm": 0.7715178728103638,
      "learning_rate": 4.682884051703426e-05,
      "loss": 0.0007,
      "step": 13200
    },
    {
      "epoch": 0.6366825236653693,
      "grad_norm": 0.20270946621894836,
      "learning_rate": 4.681682763922925e-05,
      "loss": 0.0006,
      "step": 13250
    },
    {
      "epoch": 0.6390850992263707,
      "grad_norm": 0.21342764794826508,
      "learning_rate": 4.680481476142425e-05,
      "loss": 0.0005,
      "step": 13300
    },
    {
      "epoch": 0.641487674787372,
      "grad_norm": 0.5223425030708313,
      "learning_rate": 4.679280188361924e-05,
      "loss": 0.0005,
      "step": 13350
    },
    {
      "epoch": 0.6438902503483734,
      "grad_norm": 0.12004567682743073,
      "learning_rate": 4.678078900581424e-05,
      "loss": 0.0006,
      "step": 13400
    },
    {
      "epoch": 0.6462928259093749,
      "grad_norm": 0.42098134756088257,
      "learning_rate": 4.676877612800923e-05,
      "loss": 0.0007,
      "step": 13450
    },
    {
      "epoch": 0.6486954014703763,
      "grad_norm": 0.2151358425617218,
      "learning_rate": 4.675676325020422e-05,
      "loss": 0.0005,
      "step": 13500
    },
    {
      "epoch": 0.6510979770313776,
      "grad_norm": 0.1564132422208786,
      "learning_rate": 4.674475037239922e-05,
      "loss": 0.0006,
      "step": 13550
    },
    {
      "epoch": 0.653500552592379,
      "grad_norm": 0.34378185868263245,
      "learning_rate": 4.673273749459421e-05,
      "loss": 0.0005,
      "step": 13600
    },
    {
      "epoch": 0.6559031281533805,
      "grad_norm": 0.5846260786056519,
      "learning_rate": 4.67207246167892e-05,
      "loss": 0.0005,
      "step": 13650
    },
    {
      "epoch": 0.6583057037143818,
      "grad_norm": 0.31590744853019714,
      "learning_rate": 4.67087117389842e-05,
      "loss": 0.0009,
      "step": 13700
    },
    {
      "epoch": 0.6607082792753832,
      "grad_norm": 0.12359816581010818,
      "learning_rate": 4.669669886117919e-05,
      "loss": 0.0006,
      "step": 13750
    },
    {
      "epoch": 0.6631108548363847,
      "grad_norm": 0.3400913178920746,
      "learning_rate": 4.668468598337418e-05,
      "loss": 0.0006,
      "step": 13800
    },
    {
      "epoch": 0.665513430397386,
      "grad_norm": 0.4283086061477661,
      "learning_rate": 4.667267310556917e-05,
      "loss": 0.0006,
      "step": 13850
    },
    {
      "epoch": 0.6679160059583874,
      "grad_norm": 0.7601321935653687,
      "learning_rate": 4.666066022776416e-05,
      "loss": 0.0006,
      "step": 13900
    },
    {
      "epoch": 0.6703185815193888,
      "grad_norm": 0.3197753131389618,
      "learning_rate": 4.664864734995916e-05,
      "loss": 0.0005,
      "step": 13950
    },
    {
      "epoch": 0.6727211570803902,
      "grad_norm": 0.6270705461502075,
      "learning_rate": 4.663663447215415e-05,
      "loss": 0.0013,
      "step": 14000
    },
    {
      "epoch": 0.6751237326413916,
      "grad_norm": 0.14623108506202698,
      "learning_rate": 4.6624621594349146e-05,
      "loss": 0.0004,
      "step": 14050
    },
    {
      "epoch": 0.677526308202393,
      "grad_norm": 0.1553351879119873,
      "learning_rate": 4.661260871654414e-05,
      "loss": 0.0004,
      "step": 14100
    },
    {
      "epoch": 0.6799288837633943,
      "grad_norm": 0.4013386368751526,
      "learning_rate": 4.660059583873913e-05,
      "loss": 0.0005,
      "step": 14150
    },
    {
      "epoch": 0.6823314593243958,
      "grad_norm": 0.22471214830875397,
      "learning_rate": 4.6588582960934126e-05,
      "loss": 0.0006,
      "step": 14200
    },
    {
      "epoch": 0.6847340348853972,
      "grad_norm": 0.3483694791793823,
      "learning_rate": 4.6576570083129116e-05,
      "loss": 0.0004,
      "step": 14250
    },
    {
      "epoch": 0.6871366104463985,
      "grad_norm": 0.2009802907705307,
      "learning_rate": 4.6564557205324114e-05,
      "loss": 0.0004,
      "step": 14300
    },
    {
      "epoch": 0.6895391860073999,
      "grad_norm": 0.48448190093040466,
      "learning_rate": 4.6552544327519105e-05,
      "loss": 0.0005,
      "step": 14350
    },
    {
      "epoch": 0.6919417615684014,
      "grad_norm": 0.5146467685699463,
      "learning_rate": 4.6540531449714096e-05,
      "loss": 0.0005,
      "step": 14400
    },
    {
      "epoch": 0.6943443371294027,
      "grad_norm": 0.3616337478160858,
      "learning_rate": 4.652851857190909e-05,
      "loss": 0.0005,
      "step": 14450
    },
    {
      "epoch": 0.6967469126904041,
      "grad_norm": 0.5003799200057983,
      "learning_rate": 4.6516505694104084e-05,
      "loss": 0.0006,
      "step": 14500
    },
    {
      "epoch": 0.6991494882514055,
      "grad_norm": 0.14854463934898376,
      "learning_rate": 4.6504492816299075e-05,
      "loss": 0.0012,
      "step": 14550
    },
    {
      "epoch": 0.7015520638124069,
      "grad_norm": 0.21859683096408844,
      "learning_rate": 4.6492479938494066e-05,
      "loss": 0.0013,
      "step": 14600
    },
    {
      "epoch": 0.7039546393734083,
      "grad_norm": 0.1741461604833603,
      "learning_rate": 4.6480467060689057e-05,
      "loss": 0.0004,
      "step": 14650
    },
    {
      "epoch": 0.7063572149344097,
      "grad_norm": 0.051883917301893234,
      "learning_rate": 4.6468454182884054e-05,
      "loss": 0.0004,
      "step": 14700
    },
    {
      "epoch": 0.708759790495411,
      "grad_norm": 0.5903456211090088,
      "learning_rate": 4.6456441305079045e-05,
      "loss": 0.0004,
      "step": 14750
    },
    {
      "epoch": 0.7111623660564125,
      "grad_norm": 0.22995281219482422,
      "learning_rate": 4.644442842727404e-05,
      "loss": 0.0004,
      "step": 14800
    },
    {
      "epoch": 0.7135649416174139,
      "grad_norm": 0.04761036857962608,
      "learning_rate": 4.643241554946903e-05,
      "loss": 0.0004,
      "step": 14850
    },
    {
      "epoch": 0.7159675171784152,
      "grad_norm": 0.5436388254165649,
      "learning_rate": 4.6420402671664024e-05,
      "loss": 0.0003,
      "step": 14900
    },
    {
      "epoch": 0.7183700927394167,
      "grad_norm": 0.15185348689556122,
      "learning_rate": 4.640838979385902e-05,
      "loss": 0.0018,
      "step": 14950
    },
    {
      "epoch": 0.7207726683004181,
      "grad_norm": 0.1837403029203415,
      "learning_rate": 4.639637691605401e-05,
      "loss": 0.0005,
      "step": 15000
    },
    {
      "epoch": 0.7231752438614194,
      "grad_norm": 0.23922692239284515,
      "learning_rate": 4.6384364038249003e-05,
      "loss": 0.0004,
      "step": 15050
    },
    {
      "epoch": 0.7255778194224208,
      "grad_norm": 0.15882593393325806,
      "learning_rate": 4.6372351160444e-05,
      "loss": 0.0003,
      "step": 15100
    },
    {
      "epoch": 0.7279803949834223,
      "grad_norm": 0.09423285722732544,
      "learning_rate": 4.636033828263899e-05,
      "loss": 0.0007,
      "step": 15150
    },
    {
      "epoch": 0.7303829705444236,
      "grad_norm": 0.260184645652771,
      "learning_rate": 4.634832540483399e-05,
      "loss": 0.0005,
      "step": 15200
    },
    {
      "epoch": 0.732785546105425,
      "grad_norm": 0.20817090570926666,
      "learning_rate": 4.633631252702898e-05,
      "loss": 0.0006,
      "step": 15250
    },
    {
      "epoch": 0.7351881216664264,
      "grad_norm": 0.17084501683712006,
      "learning_rate": 4.632429964922397e-05,
      "loss": 0.0004,
      "step": 15300
    },
    {
      "epoch": 0.7375906972274278,
      "grad_norm": 0.193682000041008,
      "learning_rate": 4.631228677141896e-05,
      "loss": 0.0004,
      "step": 15350
    },
    {
      "epoch": 0.7399932727884292,
      "grad_norm": 0.15719152987003326,
      "learning_rate": 4.630027389361395e-05,
      "loss": 0.0005,
      "step": 15400
    },
    {
      "epoch": 0.7423958483494306,
      "grad_norm": 0.1569463014602661,
      "learning_rate": 4.628826101580895e-05,
      "loss": 0.0005,
      "step": 15450
    },
    {
      "epoch": 0.7447984239104319,
      "grad_norm": 0.17209003865718842,
      "learning_rate": 4.627624813800394e-05,
      "loss": 0.0004,
      "step": 15500
    },
    {
      "epoch": 0.7472009994714334,
      "grad_norm": 0.1934378743171692,
      "learning_rate": 4.626423526019893e-05,
      "loss": 0.0004,
      "step": 15550
    },
    {
      "epoch": 0.7496035750324348,
      "grad_norm": 0.10144836455583572,
      "learning_rate": 4.625222238239393e-05,
      "loss": 0.0004,
      "step": 15600
    },
    {
      "epoch": 0.7520061505934361,
      "grad_norm": 0.5811201333999634,
      "learning_rate": 4.624020950458892e-05,
      "loss": 0.0004,
      "step": 15650
    },
    {
      "epoch": 0.7544087261544375,
      "grad_norm": 0.3101181089878082,
      "learning_rate": 4.622819662678392e-05,
      "loss": 0.0004,
      "step": 15700
    },
    {
      "epoch": 0.756811301715439,
      "grad_norm": 0.3473042845726013,
      "learning_rate": 4.621618374897891e-05,
      "loss": 0.0003,
      "step": 15750
    },
    {
      "epoch": 0.7592138772764403,
      "grad_norm": 0.8602665066719055,
      "learning_rate": 4.62041708711739e-05,
      "loss": 0.0005,
      "step": 15800
    },
    {
      "epoch": 0.7616164528374417,
      "grad_norm": 0.16456608474254608,
      "learning_rate": 4.61921579933689e-05,
      "loss": 0.0006,
      "step": 15850
    },
    {
      "epoch": 0.7640190283984432,
      "grad_norm": 0.17578771710395813,
      "learning_rate": 4.618014511556389e-05,
      "loss": 0.0004,
      "step": 15900
    },
    {
      "epoch": 0.7664216039594445,
      "grad_norm": 0.443629652261734,
      "learning_rate": 4.616813223775888e-05,
      "loss": 0.0005,
      "step": 15950
    },
    {
      "epoch": 0.7688241795204459,
      "grad_norm": 0.06637255847454071,
      "learning_rate": 4.6156119359953877e-05,
      "loss": 0.0012,
      "step": 16000
    },
    {
      "epoch": 0.7712267550814473,
      "grad_norm": 0.4256909489631653,
      "learning_rate": 4.614410648214886e-05,
      "loss": 0.0004,
      "step": 16050
    },
    {
      "epoch": 0.7736293306424487,
      "grad_norm": 0.17608195543289185,
      "learning_rate": 4.613209360434386e-05,
      "loss": 0.0004,
      "step": 16100
    },
    {
      "epoch": 0.7760319062034501,
      "grad_norm": 0.06355367600917816,
      "learning_rate": 4.612008072653885e-05,
      "loss": 0.0004,
      "step": 16150
    },
    {
      "epoch": 0.7784344817644515,
      "grad_norm": 0.21487824618816376,
      "learning_rate": 4.610806784873385e-05,
      "loss": 0.0004,
      "step": 16200
    },
    {
      "epoch": 0.7808370573254528,
      "grad_norm": 0.4879235327243805,
      "learning_rate": 4.609605497092884e-05,
      "loss": 0.0003,
      "step": 16250
    },
    {
      "epoch": 0.7832396328864543,
      "grad_norm": 0.47245651483535767,
      "learning_rate": 4.608404209312383e-05,
      "loss": 0.0004,
      "step": 16300
    },
    {
      "epoch": 0.7856422084474557,
      "grad_norm": 0.27663683891296387,
      "learning_rate": 4.6072029215318826e-05,
      "loss": 0.0004,
      "step": 16350
    },
    {
      "epoch": 0.788044784008457,
      "grad_norm": 0.10262192040681839,
      "learning_rate": 4.606001633751382e-05,
      "loss": 0.0005,
      "step": 16400
    },
    {
      "epoch": 0.7904473595694584,
      "grad_norm": 0.18882723152637482,
      "learning_rate": 4.604800345970881e-05,
      "loss": 0.0003,
      "step": 16450
    },
    {
      "epoch": 0.7928499351304599,
      "grad_norm": 0.3279273808002472,
      "learning_rate": 4.6035990581903805e-05,
      "loss": 0.0003,
      "step": 16500
    },
    {
      "epoch": 0.7952525106914613,
      "grad_norm": 0.23209944367408752,
      "learning_rate": 4.6023977704098796e-05,
      "loss": 0.0003,
      "step": 16550
    },
    {
      "epoch": 0.7976550862524626,
      "grad_norm": 0.29151651263237,
      "learning_rate": 4.6011964826293794e-05,
      "loss": 0.0004,
      "step": 16600
    },
    {
      "epoch": 0.800057661813464,
      "grad_norm": 0.23741181194782257,
      "learning_rate": 4.5999951948488784e-05,
      "loss": 0.0004,
      "step": 16650
    },
    {
      "epoch": 0.8024602373744655,
      "grad_norm": 0.1282050758600235,
      "learning_rate": 4.5987939070683775e-05,
      "loss": 0.0006,
      "step": 16700
    },
    {
      "epoch": 0.8048628129354668,
      "grad_norm": 0.5281004309654236,
      "learning_rate": 4.597592619287877e-05,
      "loss": 0.0003,
      "step": 16750
    },
    {
      "epoch": 0.8072653884964682,
      "grad_norm": 0.105466328561306,
      "learning_rate": 4.596391331507376e-05,
      "loss": 0.0006,
      "step": 16800
    },
    {
      "epoch": 0.8096679640574697,
      "grad_norm": 0.33728885650634766,
      "learning_rate": 4.5951900437268754e-05,
      "loss": 0.0003,
      "step": 16850
    },
    {
      "epoch": 0.812070539618471,
      "grad_norm": 0.3270459473133087,
      "learning_rate": 4.5939887559463745e-05,
      "loss": 0.0003,
      "step": 16900
    },
    {
      "epoch": 0.8144731151794724,
      "grad_norm": 0.39197736978530884,
      "learning_rate": 4.5927874681658736e-05,
      "loss": 0.0004,
      "step": 16950
    },
    {
      "epoch": 0.8168756907404738,
      "grad_norm": 0.2630337178707123,
      "learning_rate": 4.5915861803853734e-05,
      "loss": 0.0005,
      "step": 17000
    },
    {
      "epoch": 0.8192782663014752,
      "grad_norm": 0.12100967764854431,
      "learning_rate": 4.5903848926048725e-05,
      "loss": 0.0004,
      "step": 17050
    },
    {
      "epoch": 0.8216808418624766,
      "grad_norm": 0.30437594652175903,
      "learning_rate": 4.589183604824372e-05,
      "loss": 0.0004,
      "step": 17100
    },
    {
      "epoch": 0.824083417423478,
      "grad_norm": 0.23258104920387268,
      "learning_rate": 4.587982317043871e-05,
      "loss": 0.0004,
      "step": 17150
    },
    {
      "epoch": 0.8264859929844793,
      "grad_norm": 0.26034241914749146,
      "learning_rate": 4.5867810292633704e-05,
      "loss": 0.0004,
      "step": 17200
    },
    {
      "epoch": 0.8288885685454808,
      "grad_norm": 0.6104981303215027,
      "learning_rate": 4.58557974148287e-05,
      "loss": 0.0003,
      "step": 17250
    },
    {
      "epoch": 0.8312911441064822,
      "grad_norm": 0.1092868521809578,
      "learning_rate": 4.584378453702369e-05,
      "loss": 0.0003,
      "step": 17300
    },
    {
      "epoch": 0.8336937196674835,
      "grad_norm": 0.3565486669540405,
      "learning_rate": 4.583177165921868e-05,
      "loss": 0.0019,
      "step": 17350
    },
    {
      "epoch": 0.8360962952284849,
      "grad_norm": 0.039763398468494415,
      "learning_rate": 4.581975878141368e-05,
      "loss": 0.001,
      "step": 17400
    },
    {
      "epoch": 0.8384988707894864,
      "grad_norm": 0.22541488707065582,
      "learning_rate": 4.580774590360867e-05,
      "loss": 0.0004,
      "step": 17450
    },
    {
      "epoch": 0.8409014463504877,
      "grad_norm": 0.4568646550178528,
      "learning_rate": 4.579573302580366e-05,
      "loss": 0.0003,
      "step": 17500
    },
    {
      "epoch": 0.8433040219114891,
      "grad_norm": 0.210551917552948,
      "learning_rate": 4.578372014799865e-05,
      "loss": 0.0004,
      "step": 17550
    },
    {
      "epoch": 0.8457065974724906,
      "grad_norm": 0.09916633367538452,
      "learning_rate": 4.577170727019365e-05,
      "loss": 0.0003,
      "step": 17600
    },
    {
      "epoch": 0.8481091730334919,
      "grad_norm": 0.0883723720908165,
      "learning_rate": 4.575969439238864e-05,
      "loss": 0.0003,
      "step": 17650
    },
    {
      "epoch": 0.8505117485944933,
      "grad_norm": 0.2823579013347626,
      "learning_rate": 4.574768151458363e-05,
      "loss": 0.0003,
      "step": 17700
    },
    {
      "epoch": 0.8529143241554947,
      "grad_norm": 0.33642271161079407,
      "learning_rate": 4.573566863677863e-05,
      "loss": 0.0003,
      "step": 17750
    },
    {
      "epoch": 0.855316899716496,
      "grad_norm": 0.3782644271850586,
      "learning_rate": 4.572365575897362e-05,
      "loss": 0.0004,
      "step": 17800
    },
    {
      "epoch": 0.8577194752774975,
      "grad_norm": 0.1584354192018509,
      "learning_rate": 4.571164288116861e-05,
      "loss": 0.0004,
      "step": 17850
    },
    {
      "epoch": 0.8601220508384989,
      "grad_norm": 0.37643149495124817,
      "learning_rate": 4.569963000336361e-05,
      "loss": 0.0004,
      "step": 17900
    },
    {
      "epoch": 0.8625246263995002,
      "grad_norm": 0.32858750224113464,
      "learning_rate": 4.56876171255586e-05,
      "loss": 0.0003,
      "step": 17950
    },
    {
      "epoch": 0.8649272019605017,
      "grad_norm": 0.2948163151741028,
      "learning_rate": 4.56756042477536e-05,
      "loss": 0.0002,
      "step": 18000
    },
    {
      "epoch": 0.8673297775215031,
      "grad_norm": 0.344052255153656,
      "learning_rate": 4.566359136994859e-05,
      "loss": 0.0004,
      "step": 18050
    },
    {
      "epoch": 0.8697323530825044,
      "grad_norm": 0.12947531044483185,
      "learning_rate": 4.565157849214358e-05,
      "loss": 0.0004,
      "step": 18100
    },
    {
      "epoch": 0.8721349286435058,
      "grad_norm": 0.1878499984741211,
      "learning_rate": 4.563956561433858e-05,
      "loss": 0.0003,
      "step": 18150
    },
    {
      "epoch": 0.8745375042045073,
      "grad_norm": 0.13571342825889587,
      "learning_rate": 4.562755273653357e-05,
      "loss": 0.0004,
      "step": 18200
    },
    {
      "epoch": 0.8769400797655086,
      "grad_norm": 0.2651681900024414,
      "learning_rate": 4.561553985872856e-05,
      "loss": 0.0003,
      "step": 18250
    },
    {
      "epoch": 0.87934265532651,
      "grad_norm": 0.49337679147720337,
      "learning_rate": 4.560352698092355e-05,
      "loss": 0.0003,
      "step": 18300
    },
    {
      "epoch": 0.8817452308875114,
      "grad_norm": 0.17957456409931183,
      "learning_rate": 4.559151410311854e-05,
      "loss": 0.0003,
      "step": 18350
    },
    {
      "epoch": 0.8841478064485128,
      "grad_norm": 0.23218616843223572,
      "learning_rate": 4.557950122531354e-05,
      "loss": 0.0004,
      "step": 18400
    },
    {
      "epoch": 0.8865503820095142,
      "grad_norm": 0.3005669414997101,
      "learning_rate": 4.556748834750853e-05,
      "loss": 0.0004,
      "step": 18450
    },
    {
      "epoch": 0.8889529575705156,
      "grad_norm": 0.22637823224067688,
      "learning_rate": 4.5555475469703526e-05,
      "loss": 0.0004,
      "step": 18500
    },
    {
      "epoch": 0.8913555331315169,
      "grad_norm": 0.10558310896158218,
      "learning_rate": 4.554346259189852e-05,
      "loss": 0.0003,
      "step": 18550
    },
    {
      "epoch": 0.8937581086925184,
      "grad_norm": 0.22686965763568878,
      "learning_rate": 4.553144971409351e-05,
      "loss": 0.0003,
      "step": 18600
    },
    {
      "epoch": 0.8961606842535198,
      "grad_norm": 0.18179915845394135,
      "learning_rate": 4.5519436836288505e-05,
      "loss": 0.0003,
      "step": 18650
    },
    {
      "epoch": 0.8985632598145211,
      "grad_norm": 0.4425230026245117,
      "learning_rate": 4.5507423958483496e-05,
      "loss": 0.0004,
      "step": 18700
    },
    {
      "epoch": 0.9009658353755226,
      "grad_norm": 0.28177642822265625,
      "learning_rate": 4.5495411080678494e-05,
      "loss": 0.0004,
      "step": 18750
    },
    {
      "epoch": 0.903368410936524,
      "grad_norm": 0.22463539242744446,
      "learning_rate": 4.5483398202873485e-05,
      "loss": 0.0004,
      "step": 18800
    },
    {
      "epoch": 0.9057709864975253,
      "grad_norm": 0.07656191289424896,
      "learning_rate": 4.5471385325068476e-05,
      "loss": 0.0004,
      "step": 18850
    },
    {
      "epoch": 0.9081735620585267,
      "grad_norm": 0.5765153765678406,
      "learning_rate": 4.545937244726347e-05,
      "loss": 0.0003,
      "step": 18900
    },
    {
      "epoch": 0.9105761376195282,
      "grad_norm": 0.28534284234046936,
      "learning_rate": 4.5447359569458464e-05,
      "loss": 0.0003,
      "step": 18950
    },
    {
      "epoch": 0.9129787131805295,
      "grad_norm": 0.3234435021877289,
      "learning_rate": 4.5435346691653455e-05,
      "loss": 0.0003,
      "step": 19000
    },
    {
      "epoch": 0.9153812887415309,
      "grad_norm": 0.3263469934463501,
      "learning_rate": 4.5423333813848446e-05,
      "loss": 0.0003,
      "step": 19050
    },
    {
      "epoch": 0.9177838643025323,
      "grad_norm": 0.39933428168296814,
      "learning_rate": 4.5411320936043436e-05,
      "loss": 0.0003,
      "step": 19100
    },
    {
      "epoch": 0.9201864398635337,
      "grad_norm": 0.2768672704696655,
      "learning_rate": 4.5399308058238434e-05,
      "loss": 0.0004,
      "step": 19150
    },
    {
      "epoch": 0.9225890154245351,
      "grad_norm": 0.2994152307510376,
      "learning_rate": 4.5387295180433425e-05,
      "loss": 0.0003,
      "step": 19200
    },
    {
      "epoch": 0.9249915909855365,
      "grad_norm": 0.5419884920120239,
      "learning_rate": 4.5375282302628416e-05,
      "loss": 0.0003,
      "step": 19250
    },
    {
      "epoch": 0.9273941665465378,
      "grad_norm": 0.26611900329589844,
      "learning_rate": 4.536326942482341e-05,
      "loss": 0.0002,
      "step": 19300
    },
    {
      "epoch": 0.9297967421075393,
      "grad_norm": 0.26324787735939026,
      "learning_rate": 4.5351256547018404e-05,
      "loss": 0.0003,
      "step": 19350
    },
    {
      "epoch": 0.9321993176685407,
      "grad_norm": 0.18422597646713257,
      "learning_rate": 4.53392436692134e-05,
      "loss": 0.0003,
      "step": 19400
    },
    {
      "epoch": 0.9346018932295421,
      "grad_norm": 0.2393866926431656,
      "learning_rate": 4.532723079140839e-05,
      "loss": 0.0004,
      "step": 19450
    },
    {
      "epoch": 0.9370044687905434,
      "grad_norm": 0.11371919512748718,
      "learning_rate": 4.5315217913603383e-05,
      "loss": 0.0003,
      "step": 19500
    },
    {
      "epoch": 0.9394070443515449,
      "grad_norm": 0.1446971893310547,
      "learning_rate": 4.530320503579838e-05,
      "loss": 0.0003,
      "step": 19550
    },
    {
      "epoch": 0.9418096199125463,
      "grad_norm": 0.2577582895755768,
      "learning_rate": 4.529119215799337e-05,
      "loss": 0.0003,
      "step": 19600
    },
    {
      "epoch": 0.9442121954735476,
      "grad_norm": 0.33768004179000854,
      "learning_rate": 4.527917928018837e-05,
      "loss": 0.0005,
      "step": 19650
    },
    {
      "epoch": 0.946614771034549,
      "grad_norm": 0.4355790615081787,
      "learning_rate": 4.526716640238336e-05,
      "loss": 0.0003,
      "step": 19700
    },
    {
      "epoch": 0.9490173465955505,
      "grad_norm": 0.8038241267204285,
      "learning_rate": 4.5255153524578344e-05,
      "loss": 0.0004,
      "step": 19750
    },
    {
      "epoch": 0.9514199221565518,
      "grad_norm": 0.08516258746385574,
      "learning_rate": 4.524314064677334e-05,
      "loss": 0.0003,
      "step": 19800
    },
    {
      "epoch": 0.9538224977175532,
      "grad_norm": 0.6796096563339233,
      "learning_rate": 4.523112776896833e-05,
      "loss": 0.0003,
      "step": 19850
    },
    {
      "epoch": 0.9562250732785547,
      "grad_norm": 0.1397419571876526,
      "learning_rate": 4.521911489116333e-05,
      "loss": 0.0006,
      "step": 19900
    },
    {
      "epoch": 0.958627648839556,
      "grad_norm": 0.05650286376476288,
      "learning_rate": 4.520710201335832e-05,
      "loss": 0.0009,
      "step": 19950
    },
    {
      "epoch": 0.9610302244005574,
      "grad_norm": 0.1624632030725479,
      "learning_rate": 4.519508913555331e-05,
      "loss": 0.0004,
      "step": 20000
    },
    {
      "epoch": 0.9634327999615588,
      "grad_norm": 0.39822089672088623,
      "learning_rate": 4.518307625774831e-05,
      "loss": 0.0013,
      "step": 20050
    },
    {
      "epoch": 0.9658353755225602,
      "grad_norm": 0.09939216077327728,
      "learning_rate": 4.51710633799433e-05,
      "loss": 0.0006,
      "step": 20100
    },
    {
      "epoch": 0.9682379510835616,
      "grad_norm": 0.24893417954444885,
      "learning_rate": 4.51590505021383e-05,
      "loss": 0.001,
      "step": 20150
    },
    {
      "epoch": 0.970640526644563,
      "grad_norm": 0.49658769369125366,
      "learning_rate": 4.514703762433329e-05,
      "loss": 0.0003,
      "step": 20200
    },
    {
      "epoch": 0.9730431022055643,
      "grad_norm": 0.2812676727771759,
      "learning_rate": 4.513502474652828e-05,
      "loss": 0.0004,
      "step": 20250
    },
    {
      "epoch": 0.9754456777665658,
      "grad_norm": 0.09896504133939743,
      "learning_rate": 4.512301186872328e-05,
      "loss": 0.0002,
      "step": 20300
    },
    {
      "epoch": 0.9778482533275672,
      "grad_norm": 0.35569944977760315,
      "learning_rate": 4.511099899091827e-05,
      "loss": 0.0009,
      "step": 20350
    },
    {
      "epoch": 0.9802508288885685,
      "grad_norm": 0.3320241868495941,
      "learning_rate": 4.509898611311326e-05,
      "loss": 0.0002,
      "step": 20400
    },
    {
      "epoch": 0.98265340444957,
      "grad_norm": 0.14085736870765686,
      "learning_rate": 4.5086973235308257e-05,
      "loss": 0.0004,
      "step": 20450
    },
    {
      "epoch": 0.9850559800105714,
      "grad_norm": 0.39604371786117554,
      "learning_rate": 4.507496035750324e-05,
      "loss": 0.0003,
      "step": 20500
    },
    {
      "epoch": 0.9874585555715727,
      "grad_norm": 0.27979251742362976,
      "learning_rate": 4.506294747969824e-05,
      "loss": 0.0004,
      "step": 20550
    },
    {
      "epoch": 0.9898611311325741,
      "grad_norm": 0.5717251300811768,
      "learning_rate": 4.505093460189323e-05,
      "loss": 0.0004,
      "step": 20600
    },
    {
      "epoch": 0.9922637066935756,
      "grad_norm": 0.08681616932153702,
      "learning_rate": 4.5038921724088227e-05,
      "loss": 0.0003,
      "step": 20650
    },
    {
      "epoch": 0.9946662822545769,
      "grad_norm": 0.14518681168556213,
      "learning_rate": 4.502690884628322e-05,
      "loss": 0.0003,
      "step": 20700
    },
    {
      "epoch": 0.9970688578155783,
      "grad_norm": 0.20828211307525635,
      "learning_rate": 4.501489596847821e-05,
      "loss": 0.0003,
      "step": 20750
    },
    {
      "epoch": 0.9994714333765797,
      "grad_norm": 0.13671663403511047,
      "learning_rate": 4.5002883090673206e-05,
      "loss": 0.0008,
      "step": 20800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0003530265821609646,
      "eval_runtime": 17.3519,
      "eval_samples_per_second": 547.261,
      "eval_steps_per_second": 68.408,
      "step": 20811
    },
    {
      "epoch": 1.001874008937581,
      "grad_norm": 0.22540220618247986,
      "learning_rate": 4.49908702128682e-05,
      "loss": 0.0003,
      "step": 20850
    },
    {
      "epoch": 1.0042765844985824,
      "grad_norm": 0.17521248757839203,
      "learning_rate": 4.497885733506319e-05,
      "loss": 0.0002,
      "step": 20900
    },
    {
      "epoch": 1.006679160059584,
      "grad_norm": 0.34575599431991577,
      "learning_rate": 4.4966844457258185e-05,
      "loss": 0.0003,
      "step": 20950
    },
    {
      "epoch": 1.0090817356205852,
      "grad_norm": 0.4357072710990906,
      "learning_rate": 4.4954831579453176e-05,
      "loss": 0.0004,
      "step": 21000
    },
    {
      "epoch": 1.0114843111815868,
      "grad_norm": 0.3030729293823242,
      "learning_rate": 4.4942818701648174e-05,
      "loss": 0.0003,
      "step": 21050
    },
    {
      "epoch": 1.013886886742588,
      "grad_norm": 0.34333086013793945,
      "learning_rate": 4.4930805823843164e-05,
      "loss": 0.0003,
      "step": 21100
    },
    {
      "epoch": 1.0162894623035894,
      "grad_norm": 0.4592636227607727,
      "learning_rate": 4.4918792946038155e-05,
      "loss": 0.0004,
      "step": 21150
    },
    {
      "epoch": 1.018692037864591,
      "grad_norm": 0.19810563325881958,
      "learning_rate": 4.490678006823315e-05,
      "loss": 0.0003,
      "step": 21200
    },
    {
      "epoch": 1.0210946134255923,
      "grad_norm": 0.1706208437681198,
      "learning_rate": 4.489476719042814e-05,
      "loss": 0.0003,
      "step": 21250
    },
    {
      "epoch": 1.0234971889865936,
      "grad_norm": 0.3281797170639038,
      "learning_rate": 4.4882754312623134e-05,
      "loss": 0.0003,
      "step": 21300
    },
    {
      "epoch": 1.0258997645475951,
      "grad_norm": 0.15446533262729645,
      "learning_rate": 4.4870741434818125e-05,
      "loss": 0.0012,
      "step": 21350
    },
    {
      "epoch": 1.0283023401085964,
      "grad_norm": 0.10693914443254471,
      "learning_rate": 4.4858728557013116e-05,
      "loss": 0.0003,
      "step": 21400
    },
    {
      "epoch": 1.0307049156695978,
      "grad_norm": 0.5950049161911011,
      "learning_rate": 4.4846715679208114e-05,
      "loss": 0.0003,
      "step": 21450
    },
    {
      "epoch": 1.0331074912305993,
      "grad_norm": 0.4693148136138916,
      "learning_rate": 4.4834702801403105e-05,
      "loss": 0.0004,
      "step": 21500
    },
    {
      "epoch": 1.0355100667916006,
      "grad_norm": 0.09751024842262268,
      "learning_rate": 4.48226899235981e-05,
      "loss": 0.0003,
      "step": 21550
    },
    {
      "epoch": 1.037912642352602,
      "grad_norm": 0.11516804993152618,
      "learning_rate": 4.481067704579309e-05,
      "loss": 0.0002,
      "step": 21600
    },
    {
      "epoch": 1.0403152179136035,
      "grad_norm": 0.2428678423166275,
      "learning_rate": 4.4798664167988084e-05,
      "loss": 0.0002,
      "step": 21650
    },
    {
      "epoch": 1.0427177934746048,
      "grad_norm": 0.4114397466182709,
      "learning_rate": 4.478665129018308e-05,
      "loss": 0.001,
      "step": 21700
    },
    {
      "epoch": 1.0451203690356061,
      "grad_norm": 0.04575972259044647,
      "learning_rate": 4.477463841237807e-05,
      "loss": 0.0003,
      "step": 21750
    },
    {
      "epoch": 1.0475229445966077,
      "grad_norm": 0.08430736511945724,
      "learning_rate": 4.476262553457306e-05,
      "loss": 0.0003,
      "step": 21800
    },
    {
      "epoch": 1.049925520157609,
      "grad_norm": 0.5151498913764954,
      "learning_rate": 4.475061265676806e-05,
      "loss": 0.0003,
      "step": 21850
    },
    {
      "epoch": 1.0523280957186103,
      "grad_norm": 0.22281554341316223,
      "learning_rate": 4.473859977896305e-05,
      "loss": 0.0003,
      "step": 21900
    },
    {
      "epoch": 1.0547306712796118,
      "grad_norm": 0.1993546336889267,
      "learning_rate": 4.472658690115805e-05,
      "loss": 0.0005,
      "step": 21950
    },
    {
      "epoch": 1.0571332468406132,
      "grad_norm": 0.42535659670829773,
      "learning_rate": 4.471457402335303e-05,
      "loss": 0.0003,
      "step": 22000
    },
    {
      "epoch": 1.0595358224016145,
      "grad_norm": 0.20583006739616394,
      "learning_rate": 4.470256114554803e-05,
      "loss": 0.0003,
      "step": 22050
    },
    {
      "epoch": 1.061938397962616,
      "grad_norm": 0.2296852171421051,
      "learning_rate": 4.469054826774302e-05,
      "loss": 0.0004,
      "step": 22100
    },
    {
      "epoch": 1.0643409735236173,
      "grad_norm": 0.1629859358072281,
      "learning_rate": 4.467853538993801e-05,
      "loss": 0.0004,
      "step": 22150
    },
    {
      "epoch": 1.0667435490846187,
      "grad_norm": 0.19747678935527802,
      "learning_rate": 4.466652251213301e-05,
      "loss": 0.001,
      "step": 22200
    },
    {
      "epoch": 1.0691461246456202,
      "grad_norm": 0.1763625591993332,
      "learning_rate": 4.4654509634328e-05,
      "loss": 0.0004,
      "step": 22250
    },
    {
      "epoch": 1.0715487002066215,
      "grad_norm": 0.6522377133369446,
      "learning_rate": 4.464249675652299e-05,
      "loss": 0.0003,
      "step": 22300
    },
    {
      "epoch": 1.0739512757676228,
      "grad_norm": 0.1864190548658371,
      "learning_rate": 4.463048387871799e-05,
      "loss": 0.0003,
      "step": 22350
    },
    {
      "epoch": 1.0763538513286244,
      "grad_norm": 0.33472567796707153,
      "learning_rate": 4.461847100091298e-05,
      "loss": 0.0002,
      "step": 22400
    },
    {
      "epoch": 1.0787564268896257,
      "grad_norm": 0.17470186948776245,
      "learning_rate": 4.460645812310798e-05,
      "loss": 0.0003,
      "step": 22450
    },
    {
      "epoch": 1.081159002450627,
      "grad_norm": 0.4215323328971863,
      "learning_rate": 4.459444524530297e-05,
      "loss": 0.0002,
      "step": 22500
    },
    {
      "epoch": 1.0835615780116286,
      "grad_norm": 0.5166991353034973,
      "learning_rate": 4.458243236749796e-05,
      "loss": 0.0003,
      "step": 22550
    },
    {
      "epoch": 1.0859641535726299,
      "grad_norm": 0.11394623667001724,
      "learning_rate": 4.457041948969296e-05,
      "loss": 0.0003,
      "step": 22600
    },
    {
      "epoch": 1.0883667291336312,
      "grad_norm": 0.14962774515151978,
      "learning_rate": 4.455840661188795e-05,
      "loss": 0.0003,
      "step": 22650
    },
    {
      "epoch": 1.0907693046946327,
      "grad_norm": 0.3520509898662567,
      "learning_rate": 4.454639373408294e-05,
      "loss": 0.0003,
      "step": 22700
    },
    {
      "epoch": 1.093171880255634,
      "grad_norm": 0.5232177376747131,
      "learning_rate": 4.453438085627793e-05,
      "loss": 0.0002,
      "step": 22750
    },
    {
      "epoch": 1.0955744558166354,
      "grad_norm": 0.06873255223035812,
      "learning_rate": 4.452236797847292e-05,
      "loss": 0.0003,
      "step": 22800
    },
    {
      "epoch": 1.097977031377637,
      "grad_norm": 0.3874242901802063,
      "learning_rate": 4.451035510066792e-05,
      "loss": 0.0008,
      "step": 22850
    },
    {
      "epoch": 1.1003796069386382,
      "grad_norm": 0.4742075204849243,
      "learning_rate": 4.449834222286291e-05,
      "loss": 0.0008,
      "step": 22900
    },
    {
      "epoch": 1.1027821824996396,
      "grad_norm": 0.2640048861503601,
      "learning_rate": 4.4486329345057906e-05,
      "loss": 0.0003,
      "step": 22950
    },
    {
      "epoch": 1.105184758060641,
      "grad_norm": 0.1475822776556015,
      "learning_rate": 4.44743164672529e-05,
      "loss": 0.0004,
      "step": 23000
    },
    {
      "epoch": 1.1075873336216424,
      "grad_norm": 0.2007630616426468,
      "learning_rate": 4.446230358944789e-05,
      "loss": 0.0003,
      "step": 23050
    },
    {
      "epoch": 1.1099899091826437,
      "grad_norm": 0.15685276687145233,
      "learning_rate": 4.4450290711642885e-05,
      "loss": 0.0004,
      "step": 23100
    },
    {
      "epoch": 1.1123924847436453,
      "grad_norm": 0.14636199176311493,
      "learning_rate": 4.4438277833837876e-05,
      "loss": 0.0003,
      "step": 23150
    },
    {
      "epoch": 1.1147950603046466,
      "grad_norm": 0.06379241496324539,
      "learning_rate": 4.442626495603287e-05,
      "loss": 0.0003,
      "step": 23200
    },
    {
      "epoch": 1.117197635865648,
      "grad_norm": 0.2551630139350891,
      "learning_rate": 4.4414252078227865e-05,
      "loss": 0.0003,
      "step": 23250
    },
    {
      "epoch": 1.1196002114266494,
      "grad_norm": 0.28994572162628174,
      "learning_rate": 4.4402239200422856e-05,
      "loss": 0.0003,
      "step": 23300
    },
    {
      "epoch": 1.1220027869876508,
      "grad_norm": 0.19802938401699066,
      "learning_rate": 4.439022632261785e-05,
      "loss": 0.0003,
      "step": 23350
    },
    {
      "epoch": 1.124405362548652,
      "grad_norm": 0.39090368151664734,
      "learning_rate": 4.4378213444812844e-05,
      "loss": 0.0003,
      "step": 23400
    },
    {
      "epoch": 1.1268079381096536,
      "grad_norm": 0.49735113978385925,
      "learning_rate": 4.4366200567007835e-05,
      "loss": 0.0004,
      "step": 23450
    },
    {
      "epoch": 1.129210513670655,
      "grad_norm": 0.8266732692718506,
      "learning_rate": 4.4354187689202826e-05,
      "loss": 0.0003,
      "step": 23500
    },
    {
      "epoch": 1.1316130892316563,
      "grad_norm": 0.2538958489894867,
      "learning_rate": 4.4342174811397816e-05,
      "loss": 0.0003,
      "step": 23550
    },
    {
      "epoch": 1.1340156647926578,
      "grad_norm": 0.3303684592247009,
      "learning_rate": 4.4330161933592814e-05,
      "loss": 0.0003,
      "step": 23600
    },
    {
      "epoch": 1.1364182403536591,
      "grad_norm": 0.37454894185066223,
      "learning_rate": 4.4318149055787805e-05,
      "loss": 0.0002,
      "step": 23650
    },
    {
      "epoch": 1.1388208159146604,
      "grad_norm": 0.4981617331504822,
      "learning_rate": 4.4306136177982796e-05,
      "loss": 0.0003,
      "step": 23700
    },
    {
      "epoch": 1.141223391475662,
      "grad_norm": 0.2646760046482086,
      "learning_rate": 4.429412330017779e-05,
      "loss": 0.0004,
      "step": 23750
    },
    {
      "epoch": 1.1436259670366633,
      "grad_norm": 0.3911683261394501,
      "learning_rate": 4.4282110422372784e-05,
      "loss": 0.0002,
      "step": 23800
    },
    {
      "epoch": 1.1460285425976646,
      "grad_norm": 0.07793959975242615,
      "learning_rate": 4.427009754456778e-05,
      "loss": 0.0003,
      "step": 23850
    },
    {
      "epoch": 1.1484311181586662,
      "grad_norm": 0.1454523354768753,
      "learning_rate": 4.425808466676277e-05,
      "loss": 0.0003,
      "step": 23900
    },
    {
      "epoch": 1.1508336937196675,
      "grad_norm": 0.10990884155035019,
      "learning_rate": 4.424607178895776e-05,
      "loss": 0.0002,
      "step": 23950
    },
    {
      "epoch": 1.1532362692806688,
      "grad_norm": 0.41821932792663574,
      "learning_rate": 4.423405891115276e-05,
      "loss": 0.0003,
      "step": 24000
    },
    {
      "epoch": 1.1556388448416703,
      "grad_norm": 0.12840847671031952,
      "learning_rate": 4.422204603334775e-05,
      "loss": 0.0004,
      "step": 24050
    },
    {
      "epoch": 1.1580414204026717,
      "grad_norm": 0.35294532775878906,
      "learning_rate": 4.421003315554275e-05,
      "loss": 0.0004,
      "step": 24100
    },
    {
      "epoch": 1.160443995963673,
      "grad_norm": 0.06491407006978989,
      "learning_rate": 4.419802027773774e-05,
      "loss": 0.0003,
      "step": 24150
    },
    {
      "epoch": 1.1628465715246745,
      "grad_norm": 0.542722225189209,
      "learning_rate": 4.4186007399932724e-05,
      "loss": 0.0003,
      "step": 24200
    },
    {
      "epoch": 1.1652491470856758,
      "grad_norm": 0.11047433316707611,
      "learning_rate": 4.417399452212772e-05,
      "loss": 0.0005,
      "step": 24250
    },
    {
      "epoch": 1.1676517226466772,
      "grad_norm": 0.23749899864196777,
      "learning_rate": 4.416198164432271e-05,
      "loss": 0.0003,
      "step": 24300
    },
    {
      "epoch": 1.1700542982076787,
      "grad_norm": 0.12467671930789948,
      "learning_rate": 4.414996876651771e-05,
      "loss": 0.0003,
      "step": 24350
    },
    {
      "epoch": 1.17245687376868,
      "grad_norm": 0.38840043544769287,
      "learning_rate": 4.41379558887127e-05,
      "loss": 0.0004,
      "step": 24400
    },
    {
      "epoch": 1.1748594493296813,
      "grad_norm": 0.7796114087104797,
      "learning_rate": 4.412594301090769e-05,
      "loss": 0.0003,
      "step": 24450
    },
    {
      "epoch": 1.1772620248906829,
      "grad_norm": 0.09689223021268845,
      "learning_rate": 4.411393013310269e-05,
      "loss": 0.0003,
      "step": 24500
    },
    {
      "epoch": 1.1796646004516842,
      "grad_norm": 0.0818643569946289,
      "learning_rate": 4.410191725529768e-05,
      "loss": 0.0002,
      "step": 24550
    },
    {
      "epoch": 1.1820671760126855,
      "grad_norm": 0.22777143120765686,
      "learning_rate": 4.408990437749267e-05,
      "loss": 0.0003,
      "step": 24600
    },
    {
      "epoch": 1.184469751573687,
      "grad_norm": 0.0813300833106041,
      "learning_rate": 4.407789149968767e-05,
      "loss": 0.0002,
      "step": 24650
    },
    {
      "epoch": 1.1868723271346884,
      "grad_norm": 0.18326666951179504,
      "learning_rate": 4.406587862188266e-05,
      "loss": 0.0002,
      "step": 24700
    },
    {
      "epoch": 1.1892749026956897,
      "grad_norm": 0.24781355261802673,
      "learning_rate": 4.405386574407766e-05,
      "loss": 0.0003,
      "step": 24750
    },
    {
      "epoch": 1.1916774782566912,
      "grad_norm": 0.2731446623802185,
      "learning_rate": 4.404185286627265e-05,
      "loss": 0.0012,
      "step": 24800
    },
    {
      "epoch": 1.1940800538176926,
      "grad_norm": 0.43218833208084106,
      "learning_rate": 4.402983998846764e-05,
      "loss": 0.0003,
      "step": 24850
    },
    {
      "epoch": 1.1964826293786939,
      "grad_norm": 0.09094101190567017,
      "learning_rate": 4.4017827110662636e-05,
      "loss": 0.0002,
      "step": 24900
    },
    {
      "epoch": 1.1988852049396954,
      "grad_norm": 0.1054728552699089,
      "learning_rate": 4.400581423285762e-05,
      "loss": 0.0003,
      "step": 24950
    },
    {
      "epoch": 1.2012877805006967,
      "grad_norm": 0.12798510491847992,
      "learning_rate": 4.399380135505262e-05,
      "loss": 0.0003,
      "step": 25000
    },
    {
      "epoch": 1.203690356061698,
      "grad_norm": 0.2525150775909424,
      "learning_rate": 4.398178847724761e-05,
      "loss": 0.0002,
      "step": 25050
    },
    {
      "epoch": 1.2060929316226996,
      "grad_norm": 0.11612164974212646,
      "learning_rate": 4.39697755994426e-05,
      "loss": 0.0002,
      "step": 25100
    },
    {
      "epoch": 1.208495507183701,
      "grad_norm": 0.10086524486541748,
      "learning_rate": 4.39577627216376e-05,
      "loss": 0.0003,
      "step": 25150
    },
    {
      "epoch": 1.2108980827447022,
      "grad_norm": 0.3510166108608246,
      "learning_rate": 4.394574984383259e-05,
      "loss": 0.0003,
      "step": 25200
    },
    {
      "epoch": 1.2133006583057038,
      "grad_norm": 0.05989383906126022,
      "learning_rate": 4.3933736966027586e-05,
      "loss": 0.0003,
      "step": 25250
    },
    {
      "epoch": 1.215703233866705,
      "grad_norm": 0.7809902429580688,
      "learning_rate": 4.392172408822258e-05,
      "loss": 0.0003,
      "step": 25300
    },
    {
      "epoch": 1.2181058094277064,
      "grad_norm": 0.1777988225221634,
      "learning_rate": 4.390971121041757e-05,
      "loss": 0.0002,
      "step": 25350
    },
    {
      "epoch": 1.220508384988708,
      "grad_norm": 0.17214445769786835,
      "learning_rate": 4.3897698332612565e-05,
      "loss": 0.0003,
      "step": 25400
    },
    {
      "epoch": 1.2229109605497093,
      "grad_norm": 0.22019743919372559,
      "learning_rate": 4.3885685454807556e-05,
      "loss": 0.0003,
      "step": 25450
    },
    {
      "epoch": 1.2253135361107106,
      "grad_norm": 0.055477503687143326,
      "learning_rate": 4.3873672577002553e-05,
      "loss": 0.0003,
      "step": 25500
    },
    {
      "epoch": 1.2277161116717121,
      "grad_norm": 0.48270079493522644,
      "learning_rate": 4.3861659699197544e-05,
      "loss": 0.0004,
      "step": 25550
    },
    {
      "epoch": 1.2301186872327134,
      "grad_norm": 0.12254415452480316,
      "learning_rate": 4.3849646821392535e-05,
      "loss": 0.0002,
      "step": 25600
    },
    {
      "epoch": 1.2325212627937148,
      "grad_norm": 0.21984973549842834,
      "learning_rate": 4.383763394358753e-05,
      "loss": 0.0003,
      "step": 25650
    },
    {
      "epoch": 1.2349238383547163,
      "grad_norm": 0.36357057094573975,
      "learning_rate": 4.382562106578252e-05,
      "loss": 0.0003,
      "step": 25700
    },
    {
      "epoch": 1.2373264139157176,
      "grad_norm": 0.0739065408706665,
      "learning_rate": 4.3813608187977514e-05,
      "loss": 0.0003,
      "step": 25750
    },
    {
      "epoch": 1.2397289894767192,
      "grad_norm": 0.1947525143623352,
      "learning_rate": 4.3801595310172505e-05,
      "loss": 0.001,
      "step": 25800
    },
    {
      "epoch": 1.2421315650377205,
      "grad_norm": 0.7525554895401001,
      "learning_rate": 4.3789582432367496e-05,
      "loss": 0.0004,
      "step": 25850
    },
    {
      "epoch": 1.2445341405987218,
      "grad_norm": 0.16971996426582336,
      "learning_rate": 4.3777569554562494e-05,
      "loss": 0.0003,
      "step": 25900
    },
    {
      "epoch": 1.2469367161597233,
      "grad_norm": 0.1761680245399475,
      "learning_rate": 4.3765556676757484e-05,
      "loss": 0.0003,
      "step": 25950
    },
    {
      "epoch": 1.2493392917207247,
      "grad_norm": 0.19751451909542084,
      "learning_rate": 4.375354379895248e-05,
      "loss": 0.0003,
      "step": 26000
    },
    {
      "epoch": 1.251741867281726,
      "grad_norm": 0.09128549695014954,
      "learning_rate": 4.374153092114747e-05,
      "loss": 0.0004,
      "step": 26050
    },
    {
      "epoch": 1.2541444428427275,
      "grad_norm": 0.10404949635267258,
      "learning_rate": 4.3729518043342464e-05,
      "loss": 0.0003,
      "step": 26100
    },
    {
      "epoch": 1.2565470184037288,
      "grad_norm": 0.12468400597572327,
      "learning_rate": 4.371750516553746e-05,
      "loss": 0.0002,
      "step": 26150
    },
    {
      "epoch": 1.2589495939647302,
      "grad_norm": 0.4903065264225006,
      "learning_rate": 4.370549228773245e-05,
      "loss": 0.0002,
      "step": 26200
    },
    {
      "epoch": 1.2613521695257317,
      "grad_norm": 0.1683279275894165,
      "learning_rate": 4.369347940992744e-05,
      "loss": 0.0004,
      "step": 26250
    },
    {
      "epoch": 1.263754745086733,
      "grad_norm": 0.35741129517555237,
      "learning_rate": 4.368146653212244e-05,
      "loss": 0.0002,
      "step": 26300
    },
    {
      "epoch": 1.2661573206477343,
      "grad_norm": 0.14142781496047974,
      "learning_rate": 4.366945365431743e-05,
      "loss": 0.0003,
      "step": 26350
    },
    {
      "epoch": 1.2685598962087359,
      "grad_norm": 0.12414663285017014,
      "learning_rate": 4.365744077651243e-05,
      "loss": 0.0002,
      "step": 26400
    },
    {
      "epoch": 1.2709624717697372,
      "grad_norm": 0.32479989528656006,
      "learning_rate": 4.364542789870741e-05,
      "loss": 0.0009,
      "step": 26450
    },
    {
      "epoch": 1.2733650473307385,
      "grad_norm": 0.05397210642695427,
      "learning_rate": 4.363341502090241e-05,
      "loss": 0.0003,
      "step": 26500
    },
    {
      "epoch": 1.27576762289174,
      "grad_norm": 0.42768874764442444,
      "learning_rate": 4.36214021430974e-05,
      "loss": 0.0003,
      "step": 26550
    },
    {
      "epoch": 1.2781701984527414,
      "grad_norm": 0.3232393264770508,
      "learning_rate": 4.360938926529239e-05,
      "loss": 0.0011,
      "step": 26600
    },
    {
      "epoch": 1.2805727740137427,
      "grad_norm": 0.49348294734954834,
      "learning_rate": 4.359737638748739e-05,
      "loss": 0.0002,
      "step": 26650
    },
    {
      "epoch": 1.2829753495747442,
      "grad_norm": 0.23353737592697144,
      "learning_rate": 4.358536350968238e-05,
      "loss": 0.0003,
      "step": 26700
    },
    {
      "epoch": 1.2853779251357456,
      "grad_norm": 0.1937100887298584,
      "learning_rate": 4.357335063187737e-05,
      "loss": 0.0002,
      "step": 26750
    },
    {
      "epoch": 1.2877805006967469,
      "grad_norm": 0.3648567497730255,
      "learning_rate": 4.356133775407237e-05,
      "loss": 0.0003,
      "step": 26800
    },
    {
      "epoch": 1.2901830762577484,
      "grad_norm": 0.412325918674469,
      "learning_rate": 4.354932487626736e-05,
      "loss": 0.0003,
      "step": 26850
    },
    {
      "epoch": 1.2925856518187497,
      "grad_norm": 0.33980223536491394,
      "learning_rate": 4.353731199846236e-05,
      "loss": 0.0002,
      "step": 26900
    },
    {
      "epoch": 1.294988227379751,
      "grad_norm": 0.3690638840198517,
      "learning_rate": 4.352529912065735e-05,
      "loss": 0.0004,
      "step": 26950
    },
    {
      "epoch": 1.2973908029407526,
      "grad_norm": 0.3232174217700958,
      "learning_rate": 4.351328624285234e-05,
      "loss": 0.0003,
      "step": 27000
    },
    {
      "epoch": 1.299793378501754,
      "grad_norm": 0.21832674741744995,
      "learning_rate": 4.350127336504734e-05,
      "loss": 0.0002,
      "step": 27050
    },
    {
      "epoch": 1.3021959540627552,
      "grad_norm": 0.23820875585079193,
      "learning_rate": 4.348926048724233e-05,
      "loss": 0.0003,
      "step": 27100
    },
    {
      "epoch": 1.3045985296237568,
      "grad_norm": 0.11215326935052872,
      "learning_rate": 4.347724760943732e-05,
      "loss": 0.0003,
      "step": 27150
    },
    {
      "epoch": 1.307001105184758,
      "grad_norm": 0.328054815530777,
      "learning_rate": 4.346523473163231e-05,
      "loss": 0.0003,
      "step": 27200
    },
    {
      "epoch": 1.3094036807457594,
      "grad_norm": 0.2628526985645294,
      "learning_rate": 4.34532218538273e-05,
      "loss": 0.0009,
      "step": 27250
    },
    {
      "epoch": 1.311806256306761,
      "grad_norm": 0.13341212272644043,
      "learning_rate": 4.34412089760223e-05,
      "loss": 0.0003,
      "step": 27300
    },
    {
      "epoch": 1.3142088318677623,
      "grad_norm": 0.42439204454421997,
      "learning_rate": 4.342919609821729e-05,
      "loss": 0.0004,
      "step": 27350
    },
    {
      "epoch": 1.3166114074287636,
      "grad_norm": 0.36442503333091736,
      "learning_rate": 4.3417183220412286e-05,
      "loss": 0.0003,
      "step": 27400
    },
    {
      "epoch": 1.3190139829897651,
      "grad_norm": 0.08520469814538956,
      "learning_rate": 4.340517034260728e-05,
      "loss": 0.0002,
      "step": 27450
    },
    {
      "epoch": 1.3214165585507665,
      "grad_norm": 0.21118131279945374,
      "learning_rate": 4.339315746480227e-05,
      "loss": 0.0003,
      "step": 27500
    },
    {
      "epoch": 1.3238191341117678,
      "grad_norm": 0.2895908057689667,
      "learning_rate": 4.3381144586997265e-05,
      "loss": 0.0011,
      "step": 27550
    },
    {
      "epoch": 1.3262217096727693,
      "grad_norm": 0.3116430640220642,
      "learning_rate": 4.3369131709192256e-05,
      "loss": 0.0002,
      "step": 27600
    },
    {
      "epoch": 1.3286242852337706,
      "grad_norm": 0.3218556344509125,
      "learning_rate": 4.335711883138725e-05,
      "loss": 0.0002,
      "step": 27650
    },
    {
      "epoch": 1.331026860794772,
      "grad_norm": 0.34517741203308105,
      "learning_rate": 4.3345105953582245e-05,
      "loss": 0.0004,
      "step": 27700
    },
    {
      "epoch": 1.3334294363557735,
      "grad_norm": 0.11780449748039246,
      "learning_rate": 4.3333093075777235e-05,
      "loss": 0.0003,
      "step": 27750
    },
    {
      "epoch": 1.3358320119167748,
      "grad_norm": 0.2060290277004242,
      "learning_rate": 4.332108019797223e-05,
      "loss": 0.0003,
      "step": 27800
    },
    {
      "epoch": 1.3382345874777761,
      "grad_norm": 0.15089669823646545,
      "learning_rate": 4.3309067320167224e-05,
      "loss": 0.0003,
      "step": 27850
    },
    {
      "epoch": 1.3406371630387777,
      "grad_norm": 0.6104974150657654,
      "learning_rate": 4.3297054442362215e-05,
      "loss": 0.0002,
      "step": 27900
    },
    {
      "epoch": 1.343039738599779,
      "grad_norm": 0.16999709606170654,
      "learning_rate": 4.3285041564557206e-05,
      "loss": 0.0002,
      "step": 27950
    },
    {
      "epoch": 1.3454423141607803,
      "grad_norm": 0.6748199462890625,
      "learning_rate": 4.3273028686752196e-05,
      "loss": 0.0002,
      "step": 28000
    },
    {
      "epoch": 1.3478448897217818,
      "grad_norm": 0.31880801916122437,
      "learning_rate": 4.3261015808947194e-05,
      "loss": 0.0003,
      "step": 28050
    },
    {
      "epoch": 1.3502474652827832,
      "grad_norm": 0.3120270371437073,
      "learning_rate": 4.3249002931142185e-05,
      "loss": 0.0003,
      "step": 28100
    },
    {
      "epoch": 1.3526500408437845,
      "grad_norm": 0.8276293873786926,
      "learning_rate": 4.3236990053337176e-05,
      "loss": 0.0004,
      "step": 28150
    },
    {
      "epoch": 1.355052616404786,
      "grad_norm": 0.19405165314674377,
      "learning_rate": 4.322497717553217e-05,
      "loss": 0.0011,
      "step": 28200
    },
    {
      "epoch": 1.3574551919657873,
      "grad_norm": 0.1786317676305771,
      "learning_rate": 4.3212964297727164e-05,
      "loss": 0.0003,
      "step": 28250
    },
    {
      "epoch": 1.3598577675267887,
      "grad_norm": 0.27192577719688416,
      "learning_rate": 4.320095141992216e-05,
      "loss": 0.0003,
      "step": 28300
    },
    {
      "epoch": 1.3622603430877902,
      "grad_norm": 0.23895537853240967,
      "learning_rate": 4.318893854211715e-05,
      "loss": 0.0002,
      "step": 28350
    },
    {
      "epoch": 1.3646629186487915,
      "grad_norm": 0.2393680214881897,
      "learning_rate": 4.317692566431214e-05,
      "loss": 0.0003,
      "step": 28400
    },
    {
      "epoch": 1.3670654942097928,
      "grad_norm": 0.44740843772888184,
      "learning_rate": 4.316491278650714e-05,
      "loss": 0.0003,
      "step": 28450
    },
    {
      "epoch": 1.3694680697707944,
      "grad_norm": 0.29198649525642395,
      "learning_rate": 4.315289990870213e-05,
      "loss": 0.0011,
      "step": 28500
    },
    {
      "epoch": 1.3718706453317957,
      "grad_norm": 0.3590756952762604,
      "learning_rate": 4.314088703089712e-05,
      "loss": 0.0003,
      "step": 28550
    },
    {
      "epoch": 1.374273220892797,
      "grad_norm": 0.07434433698654175,
      "learning_rate": 4.312887415309212e-05,
      "loss": 0.0003,
      "step": 28600
    },
    {
      "epoch": 1.3766757964537986,
      "grad_norm": 0.4305468499660492,
      "learning_rate": 4.311686127528711e-05,
      "loss": 0.001,
      "step": 28650
    },
    {
      "epoch": 1.3790783720147999,
      "grad_norm": 0.21685373783111572,
      "learning_rate": 4.31048483974821e-05,
      "loss": 0.0003,
      "step": 28700
    },
    {
      "epoch": 1.3814809475758012,
      "grad_norm": 0.14424994587898254,
      "learning_rate": 4.309283551967709e-05,
      "loss": 0.0002,
      "step": 28750
    },
    {
      "epoch": 1.3838835231368027,
      "grad_norm": 0.19152240455150604,
      "learning_rate": 4.308082264187209e-05,
      "loss": 0.0003,
      "step": 28800
    },
    {
      "epoch": 1.386286098697804,
      "grad_norm": 0.22449995577335358,
      "learning_rate": 4.306880976406708e-05,
      "loss": 0.0002,
      "step": 28850
    },
    {
      "epoch": 1.3886886742588054,
      "grad_norm": 0.13369537889957428,
      "learning_rate": 4.305679688626207e-05,
      "loss": 0.0003,
      "step": 28900
    },
    {
      "epoch": 1.391091249819807,
      "grad_norm": 0.26843833923339844,
      "learning_rate": 4.304478400845707e-05,
      "loss": 0.0004,
      "step": 28950
    },
    {
      "epoch": 1.3934938253808082,
      "grad_norm": 0.15522386133670807,
      "learning_rate": 4.303277113065206e-05,
      "loss": 0.0002,
      "step": 29000
    },
    {
      "epoch": 1.3958964009418096,
      "grad_norm": 0.11702471226453781,
      "learning_rate": 4.302075825284705e-05,
      "loss": 0.0002,
      "step": 29050
    },
    {
      "epoch": 1.398298976502811,
      "grad_norm": 0.11432593315839767,
      "learning_rate": 4.300874537504205e-05,
      "loss": 0.0002,
      "step": 29100
    },
    {
      "epoch": 1.4007015520638124,
      "grad_norm": 0.11245197802782059,
      "learning_rate": 4.299673249723704e-05,
      "loss": 0.0005,
      "step": 29150
    },
    {
      "epoch": 1.4031041276248137,
      "grad_norm": 0.663247287273407,
      "learning_rate": 4.298471961943204e-05,
      "loss": 0.0003,
      "step": 29200
    },
    {
      "epoch": 1.4055067031858153,
      "grad_norm": 0.10814060270786285,
      "learning_rate": 4.297270674162703e-05,
      "loss": 0.001,
      "step": 29250
    },
    {
      "epoch": 1.4079092787468166,
      "grad_norm": 0.15442101657390594,
      "learning_rate": 4.296069386382202e-05,
      "loss": 0.0003,
      "step": 29300
    },
    {
      "epoch": 1.410311854307818,
      "grad_norm": 0.04019853472709656,
      "learning_rate": 4.2948680986017016e-05,
      "loss": 0.0003,
      "step": 29350
    },
    {
      "epoch": 1.4127144298688195,
      "grad_norm": 0.7454224228858948,
      "learning_rate": 4.2936668108212e-05,
      "loss": 0.0003,
      "step": 29400
    },
    {
      "epoch": 1.4151170054298208,
      "grad_norm": 0.2245170921087265,
      "learning_rate": 4.2924655230407e-05,
      "loss": 0.0011,
      "step": 29450
    },
    {
      "epoch": 1.417519580990822,
      "grad_norm": 0.2962872087955475,
      "learning_rate": 4.291264235260199e-05,
      "loss": 0.0002,
      "step": 29500
    },
    {
      "epoch": 1.4199221565518236,
      "grad_norm": 0.2970970869064331,
      "learning_rate": 4.290062947479698e-05,
      "loss": 0.0009,
      "step": 29550
    },
    {
      "epoch": 1.422324732112825,
      "grad_norm": 0.17883600294589996,
      "learning_rate": 4.288861659699198e-05,
      "loss": 0.0002,
      "step": 29600
    },
    {
      "epoch": 1.4247273076738263,
      "grad_norm": 0.25738051533699036,
      "learning_rate": 4.287660371918697e-05,
      "loss": 0.0002,
      "step": 29650
    },
    {
      "epoch": 1.4271298832348278,
      "grad_norm": 0.1192416399717331,
      "learning_rate": 4.2864590841381966e-05,
      "loss": 0.0003,
      "step": 29700
    },
    {
      "epoch": 1.4295324587958291,
      "grad_norm": 0.07386375218629837,
      "learning_rate": 4.2852577963576957e-05,
      "loss": 0.0002,
      "step": 29750
    },
    {
      "epoch": 1.4319350343568304,
      "grad_norm": 0.8805044889450073,
      "learning_rate": 4.284056508577195e-05,
      "loss": 0.0002,
      "step": 29800
    },
    {
      "epoch": 1.434337609917832,
      "grad_norm": 0.20008942484855652,
      "learning_rate": 4.2828552207966945e-05,
      "loss": 0.0003,
      "step": 29850
    },
    {
      "epoch": 1.4367401854788333,
      "grad_norm": 0.219995379447937,
      "learning_rate": 4.2816539330161936e-05,
      "loss": 0.0011,
      "step": 29900
    },
    {
      "epoch": 1.4391427610398346,
      "grad_norm": 0.372771292924881,
      "learning_rate": 4.280452645235693e-05,
      "loss": 0.0004,
      "step": 29950
    },
    {
      "epoch": 1.4415453366008362,
      "grad_norm": 0.15069404244422913,
      "learning_rate": 4.2792513574551924e-05,
      "loss": 0.0004,
      "step": 30000
    },
    {
      "epoch": 1.4439479121618375,
      "grad_norm": 0.28731629252433777,
      "learning_rate": 4.2780500696746915e-05,
      "loss": 0.0008,
      "step": 30050
    },
    {
      "epoch": 1.4463504877228388,
      "grad_norm": 0.12150480598211288,
      "learning_rate": 4.276848781894191e-05,
      "loss": 0.0002,
      "step": 30100
    },
    {
      "epoch": 1.4487530632838403,
      "grad_norm": 0.14776886999607086,
      "learning_rate": 4.27564749411369e-05,
      "loss": 0.0002,
      "step": 30150
    },
    {
      "epoch": 1.4511556388448417,
      "grad_norm": 0.13559316098690033,
      "learning_rate": 4.2744462063331894e-05,
      "loss": 0.0003,
      "step": 30200
    },
    {
      "epoch": 1.453558214405843,
      "grad_norm": 0.22673942148685455,
      "learning_rate": 4.2732449185526885e-05,
      "loss": 0.0002,
      "step": 30250
    },
    {
      "epoch": 1.4559607899668445,
      "grad_norm": 0.672328770160675,
      "learning_rate": 4.2720436307721876e-05,
      "loss": 0.0003,
      "step": 30300
    },
    {
      "epoch": 1.4583633655278458,
      "grad_norm": 0.2725568413734436,
      "learning_rate": 4.2708423429916874e-05,
      "loss": 0.0002,
      "step": 30350
    },
    {
      "epoch": 1.4607659410888472,
      "grad_norm": 0.2033998817205429,
      "learning_rate": 4.2696410552111864e-05,
      "loss": 0.0003,
      "step": 30400
    },
    {
      "epoch": 1.4631685166498487,
      "grad_norm": 0.17975066602230072,
      "learning_rate": 4.2684397674306855e-05,
      "loss": 0.0003,
      "step": 30450
    },
    {
      "epoch": 1.46557109221085,
      "grad_norm": 0.13251477479934692,
      "learning_rate": 4.267238479650185e-05,
      "loss": 0.0004,
      "step": 30500
    },
    {
      "epoch": 1.4679736677718513,
      "grad_norm": 0.5413303375244141,
      "learning_rate": 4.2660371918696844e-05,
      "loss": 0.0007,
      "step": 30550
    },
    {
      "epoch": 1.4703762433328529,
      "grad_norm": 0.18467338383197784,
      "learning_rate": 4.264835904089184e-05,
      "loss": 0.0002,
      "step": 30600
    },
    {
      "epoch": 1.4727788188938542,
      "grad_norm": 0.7437682151794434,
      "learning_rate": 4.263634616308683e-05,
      "loss": 0.0003,
      "step": 30650
    },
    {
      "epoch": 1.4751813944548555,
      "grad_norm": 0.42032256722450256,
      "learning_rate": 4.262433328528182e-05,
      "loss": 0.0002,
      "step": 30700
    },
    {
      "epoch": 1.477583970015857,
      "grad_norm": 0.11056716740131378,
      "learning_rate": 4.261232040747682e-05,
      "loss": 0.0003,
      "step": 30750
    },
    {
      "epoch": 1.4799865455768584,
      "grad_norm": 0.10462573915719986,
      "learning_rate": 4.260030752967181e-05,
      "loss": 0.0003,
      "step": 30800
    },
    {
      "epoch": 1.4823891211378597,
      "grad_norm": 0.38394370675086975,
      "learning_rate": 4.258829465186681e-05,
      "loss": 0.0003,
      "step": 30850
    },
    {
      "epoch": 1.4847916966988612,
      "grad_norm": 0.035092949867248535,
      "learning_rate": 4.257628177406179e-05,
      "loss": 0.0003,
      "step": 30900
    },
    {
      "epoch": 1.4871942722598626,
      "grad_norm": 0.19610510766506195,
      "learning_rate": 4.2564268896256784e-05,
      "loss": 0.0003,
      "step": 30950
    },
    {
      "epoch": 1.4895968478208639,
      "grad_norm": 0.8693848848342896,
      "learning_rate": 4.255225601845178e-05,
      "loss": 0.0003,
      "step": 31000
    },
    {
      "epoch": 1.4919994233818654,
      "grad_norm": 0.6300873756408691,
      "learning_rate": 4.254024314064677e-05,
      "loss": 0.0002,
      "step": 31050
    },
    {
      "epoch": 1.4944019989428667,
      "grad_norm": 0.36822792887687683,
      "learning_rate": 4.252823026284177e-05,
      "loss": 0.0002,
      "step": 31100
    },
    {
      "epoch": 1.496804574503868,
      "grad_norm": 0.043827272951602936,
      "learning_rate": 4.251621738503676e-05,
      "loss": 0.001,
      "step": 31150
    },
    {
      "epoch": 1.4992071500648696,
      "grad_norm": 0.14807382225990295,
      "learning_rate": 4.250420450723175e-05,
      "loss": 0.0002,
      "step": 31200
    },
    {
      "epoch": 1.501609725625871,
      "grad_norm": 0.0684456005692482,
      "learning_rate": 4.249219162942675e-05,
      "loss": 0.0002,
      "step": 31250
    },
    {
      "epoch": 1.5040123011868722,
      "grad_norm": 0.15899288654327393,
      "learning_rate": 4.248017875162174e-05,
      "loss": 0.0002,
      "step": 31300
    },
    {
      "epoch": 1.5064148767478738,
      "grad_norm": 0.20659296214580536,
      "learning_rate": 4.246816587381674e-05,
      "loss": 0.0002,
      "step": 31350
    },
    {
      "epoch": 1.508817452308875,
      "grad_norm": 0.09227947145700455,
      "learning_rate": 4.245615299601173e-05,
      "loss": 0.0002,
      "step": 31400
    },
    {
      "epoch": 1.5112200278698764,
      "grad_norm": 0.3237651288509369,
      "learning_rate": 4.244414011820672e-05,
      "loss": 0.0003,
      "step": 31450
    },
    {
      "epoch": 1.513622603430878,
      "grad_norm": 0.3557889461517334,
      "learning_rate": 4.243212724040172e-05,
      "loss": 0.0009,
      "step": 31500
    },
    {
      "epoch": 1.5160251789918793,
      "grad_norm": 0.4606798589229584,
      "learning_rate": 4.242011436259671e-05,
      "loss": 0.0002,
      "step": 31550
    },
    {
      "epoch": 1.5184277545528806,
      "grad_norm": 0.18892212212085724,
      "learning_rate": 4.24081014847917e-05,
      "loss": 0.0002,
      "step": 31600
    },
    {
      "epoch": 1.5208303301138821,
      "grad_norm": 0.12459063529968262,
      "learning_rate": 4.239608860698669e-05,
      "loss": 0.0003,
      "step": 31650
    },
    {
      "epoch": 1.5232329056748835,
      "grad_norm": 0.3235798478126526,
      "learning_rate": 4.238407572918168e-05,
      "loss": 0.0002,
      "step": 31700
    },
    {
      "epoch": 1.5256354812358848,
      "grad_norm": 0.1728474497795105,
      "learning_rate": 4.237206285137668e-05,
      "loss": 0.0002,
      "step": 31750
    },
    {
      "epoch": 1.5280380567968863,
      "grad_norm": 0.41164910793304443,
      "learning_rate": 4.236004997357167e-05,
      "loss": 0.0002,
      "step": 31800
    },
    {
      "epoch": 1.5304406323578876,
      "grad_norm": 0.24431683123111725,
      "learning_rate": 4.2348037095766666e-05,
      "loss": 0.0002,
      "step": 31850
    },
    {
      "epoch": 1.532843207918889,
      "grad_norm": 0.11089986562728882,
      "learning_rate": 4.233602421796166e-05,
      "loss": 0.0003,
      "step": 31900
    },
    {
      "epoch": 1.5352457834798905,
      "grad_norm": 0.4052330553531647,
      "learning_rate": 4.232401134015665e-05,
      "loss": 0.0002,
      "step": 31950
    },
    {
      "epoch": 1.5376483590408918,
      "grad_norm": 0.2550998628139496,
      "learning_rate": 4.2311998462351645e-05,
      "loss": 0.0002,
      "step": 32000
    },
    {
      "epoch": 1.5400509346018931,
      "grad_norm": 0.6465194821357727,
      "learning_rate": 4.2299985584546636e-05,
      "loss": 0.0003,
      "step": 32050
    },
    {
      "epoch": 1.5424535101628947,
      "grad_norm": 0.22474415600299835,
      "learning_rate": 4.228797270674163e-05,
      "loss": 0.0003,
      "step": 32100
    },
    {
      "epoch": 1.544856085723896,
      "grad_norm": 0.3989250957965851,
      "learning_rate": 4.2275959828936625e-05,
      "loss": 0.0003,
      "step": 32150
    },
    {
      "epoch": 1.5472586612848973,
      "grad_norm": 0.23539304733276367,
      "learning_rate": 4.2263946951131615e-05,
      "loss": 0.0003,
      "step": 32200
    },
    {
      "epoch": 1.5496612368458988,
      "grad_norm": 0.1350019872188568,
      "learning_rate": 4.225193407332661e-05,
      "loss": 0.0002,
      "step": 32250
    },
    {
      "epoch": 1.5520638124069002,
      "grad_norm": 0.4558686912059784,
      "learning_rate": 4.2239921195521604e-05,
      "loss": 0.0003,
      "step": 32300
    },
    {
      "epoch": 1.5544663879679015,
      "grad_norm": 0.33590906858444214,
      "learning_rate": 4.2227908317716595e-05,
      "loss": 0.0004,
      "step": 32350
    },
    {
      "epoch": 1.556868963528903,
      "grad_norm": 0.33438244462013245,
      "learning_rate": 4.2215895439911586e-05,
      "loss": 0.0003,
      "step": 32400
    },
    {
      "epoch": 1.5592715390899043,
      "grad_norm": 0.14033210277557373,
      "learning_rate": 4.2203882562106576e-05,
      "loss": 0.0003,
      "step": 32450
    },
    {
      "epoch": 1.5616741146509057,
      "grad_norm": 0.45333635807037354,
      "learning_rate": 4.2191869684301574e-05,
      "loss": 0.0003,
      "step": 32500
    },
    {
      "epoch": 1.5640766902119072,
      "grad_norm": 0.09055788069963455,
      "learning_rate": 4.2179856806496565e-05,
      "loss": 0.0003,
      "step": 32550
    },
    {
      "epoch": 1.5664792657729085,
      "grad_norm": 0.20395782589912415,
      "learning_rate": 4.2167843928691556e-05,
      "loss": 0.0002,
      "step": 32600
    },
    {
      "epoch": 1.5688818413339098,
      "grad_norm": 0.28211912512779236,
      "learning_rate": 4.215583105088655e-05,
      "loss": 0.0002,
      "step": 32650
    },
    {
      "epoch": 1.5712844168949114,
      "grad_norm": 0.13319727778434753,
      "learning_rate": 4.2143818173081544e-05,
      "loss": 0.0002,
      "step": 32700
    },
    {
      "epoch": 1.5736869924559127,
      "grad_norm": 0.17236214876174927,
      "learning_rate": 4.213180529527654e-05,
      "loss": 0.0003,
      "step": 32750
    },
    {
      "epoch": 1.576089568016914,
      "grad_norm": 0.1800520122051239,
      "learning_rate": 4.211979241747153e-05,
      "loss": 0.0003,
      "step": 32800
    },
    {
      "epoch": 1.5784921435779156,
      "grad_norm": 0.23782365024089813,
      "learning_rate": 4.210777953966652e-05,
      "loss": 0.0011,
      "step": 32850
    },
    {
      "epoch": 1.5808947191389169,
      "grad_norm": 0.12825006246566772,
      "learning_rate": 4.209576666186152e-05,
      "loss": 0.0003,
      "step": 32900
    },
    {
      "epoch": 1.5832972946999182,
      "grad_norm": 0.33154141902923584,
      "learning_rate": 4.208375378405651e-05,
      "loss": 0.0002,
      "step": 32950
    },
    {
      "epoch": 1.5856998702609197,
      "grad_norm": 0.5304999351501465,
      "learning_rate": 4.20717409062515e-05,
      "loss": 0.0003,
      "step": 33000
    },
    {
      "epoch": 1.588102445821921,
      "grad_norm": 0.07255654782056808,
      "learning_rate": 4.20597280284465e-05,
      "loss": 0.0002,
      "step": 33050
    },
    {
      "epoch": 1.5905050213829224,
      "grad_norm": 0.2847059667110443,
      "learning_rate": 4.204771515064149e-05,
      "loss": 0.0003,
      "step": 33100
    },
    {
      "epoch": 1.592907596943924,
      "grad_norm": 0.2079170048236847,
      "learning_rate": 4.203570227283648e-05,
      "loss": 0.0003,
      "step": 33150
    },
    {
      "epoch": 1.5953101725049252,
      "grad_norm": 0.27134114503860474,
      "learning_rate": 4.202368939503147e-05,
      "loss": 0.0003,
      "step": 33200
    },
    {
      "epoch": 1.5977127480659266,
      "grad_norm": 0.1582970917224884,
      "learning_rate": 4.201167651722647e-05,
      "loss": 0.0003,
      "step": 33250
    },
    {
      "epoch": 1.600115323626928,
      "grad_norm": 0.8561494946479797,
      "learning_rate": 4.199966363942146e-05,
      "loss": 0.0003,
      "step": 33300
    },
    {
      "epoch": 1.6025178991879294,
      "grad_norm": 0.463461697101593,
      "learning_rate": 4.198765076161645e-05,
      "loss": 0.0003,
      "step": 33350
    },
    {
      "epoch": 1.6049204747489307,
      "grad_norm": 0.266195148229599,
      "learning_rate": 4.197563788381145e-05,
      "loss": 0.0003,
      "step": 33400
    },
    {
      "epoch": 1.6073230503099323,
      "grad_norm": 0.09070646017789841,
      "learning_rate": 4.196362500600644e-05,
      "loss": 0.0004,
      "step": 33450
    },
    {
      "epoch": 1.6097256258709336,
      "grad_norm": 0.45898815989494324,
      "learning_rate": 4.195161212820143e-05,
      "loss": 0.0002,
      "step": 33500
    },
    {
      "epoch": 1.612128201431935,
      "grad_norm": 0.20257209241390228,
      "learning_rate": 4.193959925039643e-05,
      "loss": 0.0003,
      "step": 33550
    },
    {
      "epoch": 1.6145307769929365,
      "grad_norm": 0.47046637535095215,
      "learning_rate": 4.192758637259142e-05,
      "loss": 0.0003,
      "step": 33600
    },
    {
      "epoch": 1.6169333525539378,
      "grad_norm": 0.2542521059513092,
      "learning_rate": 4.191557349478642e-05,
      "loss": 0.0003,
      "step": 33650
    },
    {
      "epoch": 1.619335928114939,
      "grad_norm": 0.2721390724182129,
      "learning_rate": 4.190356061698141e-05,
      "loss": 0.0002,
      "step": 33700
    },
    {
      "epoch": 1.6217385036759406,
      "grad_norm": 0.37919747829437256,
      "learning_rate": 4.18915477391764e-05,
      "loss": 0.0003,
      "step": 33750
    },
    {
      "epoch": 1.624141079236942,
      "grad_norm": 0.12643925845623016,
      "learning_rate": 4.1879534861371396e-05,
      "loss": 0.0002,
      "step": 33800
    },
    {
      "epoch": 1.6265436547979433,
      "grad_norm": 0.0738300010561943,
      "learning_rate": 4.186752198356639e-05,
      "loss": 0.0002,
      "step": 33850
    },
    {
      "epoch": 1.6289462303589448,
      "grad_norm": 0.09816901385784149,
      "learning_rate": 4.185550910576138e-05,
      "loss": 0.0002,
      "step": 33900
    },
    {
      "epoch": 1.6313488059199461,
      "grad_norm": 0.24783416092395782,
      "learning_rate": 4.184349622795637e-05,
      "loss": 0.0002,
      "step": 33950
    },
    {
      "epoch": 1.6337513814809475,
      "grad_norm": 0.21759486198425293,
      "learning_rate": 4.183148335015136e-05,
      "loss": 0.0003,
      "step": 34000
    },
    {
      "epoch": 1.636153957041949,
      "grad_norm": 0.43999671936035156,
      "learning_rate": 4.181947047234636e-05,
      "loss": 0.0002,
      "step": 34050
    },
    {
      "epoch": 1.6385565326029503,
      "grad_norm": 0.3262476325035095,
      "learning_rate": 4.180745759454135e-05,
      "loss": 0.0003,
      "step": 34100
    },
    {
      "epoch": 1.6409591081639516,
      "grad_norm": 0.17994782328605652,
      "learning_rate": 4.1795444716736346e-05,
      "loss": 0.0002,
      "step": 34150
    },
    {
      "epoch": 1.6433616837249532,
      "grad_norm": 0.1471857726573944,
      "learning_rate": 4.1783431838931337e-05,
      "loss": 0.0002,
      "step": 34200
    },
    {
      "epoch": 1.6457642592859545,
      "grad_norm": 0.12955158948898315,
      "learning_rate": 4.177141896112633e-05,
      "loss": 0.0008,
      "step": 34250
    },
    {
      "epoch": 1.6481668348469558,
      "grad_norm": 0.3867940604686737,
      "learning_rate": 4.1759406083321325e-05,
      "loss": 0.0002,
      "step": 34300
    },
    {
      "epoch": 1.6505694104079573,
      "grad_norm": 0.16320562362670898,
      "learning_rate": 4.1747393205516316e-05,
      "loss": 0.0003,
      "step": 34350
    },
    {
      "epoch": 1.652971985968959,
      "grad_norm": 0.14085564017295837,
      "learning_rate": 4.173538032771131e-05,
      "loss": 0.0002,
      "step": 34400
    },
    {
      "epoch": 1.65537456152996,
      "grad_norm": 0.0970633402466774,
      "learning_rate": 4.1723367449906304e-05,
      "loss": 0.0002,
      "step": 34450
    },
    {
      "epoch": 1.6577771370909615,
      "grad_norm": 0.18491235375404358,
      "learning_rate": 4.1711354572101295e-05,
      "loss": 0.0003,
      "step": 34500
    },
    {
      "epoch": 1.660179712651963,
      "grad_norm": 0.7057790756225586,
      "learning_rate": 4.169934169429629e-05,
      "loss": 0.0002,
      "step": 34550
    },
    {
      "epoch": 1.6625822882129642,
      "grad_norm": 0.3401336073875427,
      "learning_rate": 4.1687328816491283e-05,
      "loss": 0.0002,
      "step": 34600
    },
    {
      "epoch": 1.6649848637739657,
      "grad_norm": 0.43774518370628357,
      "learning_rate": 4.1675315938686274e-05,
      "loss": 0.0008,
      "step": 34650
    },
    {
      "epoch": 1.6673874393349672,
      "grad_norm": 0.4826618731021881,
      "learning_rate": 4.1663303060881265e-05,
      "loss": 0.0003,
      "step": 34700
    },
    {
      "epoch": 1.6697900148959683,
      "grad_norm": 0.35428979992866516,
      "learning_rate": 4.1651290183076256e-05,
      "loss": 0.0002,
      "step": 34750
    },
    {
      "epoch": 1.6721925904569699,
      "grad_norm": 0.45400145649909973,
      "learning_rate": 4.1639277305271254e-05,
      "loss": 0.0004,
      "step": 34800
    },
    {
      "epoch": 1.6745951660179714,
      "grad_norm": 0.6183383464813232,
      "learning_rate": 4.1627264427466244e-05,
      "loss": 0.0002,
      "step": 34850
    },
    {
      "epoch": 1.6769977415789725,
      "grad_norm": 0.18359826505184174,
      "learning_rate": 4.1615251549661235e-05,
      "loss": 0.0002,
      "step": 34900
    },
    {
      "epoch": 1.679400317139974,
      "grad_norm": 0.5307702422142029,
      "learning_rate": 4.160323867185623e-05,
      "loss": 0.0003,
      "step": 34950
    },
    {
      "epoch": 1.6818028927009756,
      "grad_norm": 0.8450655341148376,
      "learning_rate": 4.1591225794051224e-05,
      "loss": 0.0002,
      "step": 35000
    },
    {
      "epoch": 1.6842054682619767,
      "grad_norm": 0.18549148738384247,
      "learning_rate": 4.157921291624622e-05,
      "loss": 0.0003,
      "step": 35050
    },
    {
      "epoch": 1.6866080438229782,
      "grad_norm": 0.15533490478992462,
      "learning_rate": 4.156720003844121e-05,
      "loss": 0.0002,
      "step": 35100
    },
    {
      "epoch": 1.6890106193839798,
      "grad_norm": 0.25791415572166443,
      "learning_rate": 4.15551871606362e-05,
      "loss": 0.0002,
      "step": 35150
    },
    {
      "epoch": 1.6914131949449809,
      "grad_norm": 0.4275081157684326,
      "learning_rate": 4.15431742828312e-05,
      "loss": 0.0002,
      "step": 35200
    },
    {
      "epoch": 1.6938157705059824,
      "grad_norm": 0.1651061475276947,
      "learning_rate": 4.153116140502619e-05,
      "loss": 0.0002,
      "step": 35250
    },
    {
      "epoch": 1.696218346066984,
      "grad_norm": 0.2553761601448059,
      "learning_rate": 4.151914852722118e-05,
      "loss": 0.0003,
      "step": 35300
    },
    {
      "epoch": 1.698620921627985,
      "grad_norm": 0.4721601903438568,
      "learning_rate": 4.150713564941617e-05,
      "loss": 0.0002,
      "step": 35350
    },
    {
      "epoch": 1.7010234971889866,
      "grad_norm": 0.14721561968326569,
      "learning_rate": 4.1495122771611164e-05,
      "loss": 0.0002,
      "step": 35400
    },
    {
      "epoch": 1.7034260727499881,
      "grad_norm": 0.21328556537628174,
      "learning_rate": 4.148310989380616e-05,
      "loss": 0.0002,
      "step": 35450
    },
    {
      "epoch": 1.7058286483109892,
      "grad_norm": 0.11222446709871292,
      "learning_rate": 4.147109701600115e-05,
      "loss": 0.001,
      "step": 35500
    },
    {
      "epoch": 1.7082312238719908,
      "grad_norm": 0.6405584216117859,
      "learning_rate": 4.145908413819615e-05,
      "loss": 0.0002,
      "step": 35550
    },
    {
      "epoch": 1.7106337994329923,
      "grad_norm": 0.24844861030578613,
      "learning_rate": 4.144707126039114e-05,
      "loss": 0.0003,
      "step": 35600
    },
    {
      "epoch": 1.7130363749939934,
      "grad_norm": 0.29185599088668823,
      "learning_rate": 4.143505838258613e-05,
      "loss": 0.0008,
      "step": 35650
    },
    {
      "epoch": 1.715438950554995,
      "grad_norm": 0.36590927839279175,
      "learning_rate": 4.142304550478113e-05,
      "loss": 0.0003,
      "step": 35700
    },
    {
      "epoch": 1.7178415261159965,
      "grad_norm": 0.09468801319599152,
      "learning_rate": 4.141103262697612e-05,
      "loss": 0.0002,
      "step": 35750
    },
    {
      "epoch": 1.7202441016769976,
      "grad_norm": 0.12199579924345016,
      "learning_rate": 4.139901974917111e-05,
      "loss": 0.0002,
      "step": 35800
    },
    {
      "epoch": 1.7226466772379991,
      "grad_norm": 0.06447631865739822,
      "learning_rate": 4.138700687136611e-05,
      "loss": 0.0002,
      "step": 35850
    },
    {
      "epoch": 1.7250492527990007,
      "grad_norm": 0.19833149015903473,
      "learning_rate": 4.13749939935611e-05,
      "loss": 0.0002,
      "step": 35900
    },
    {
      "epoch": 1.7274518283600018,
      "grad_norm": 0.4246577024459839,
      "learning_rate": 4.13629811157561e-05,
      "loss": 0.0002,
      "step": 35950
    },
    {
      "epoch": 1.7298544039210033,
      "grad_norm": 0.1874566525220871,
      "learning_rate": 4.135096823795109e-05,
      "loss": 0.0002,
      "step": 36000
    },
    {
      "epoch": 1.7322569794820049,
      "grad_norm": 0.26788824796676636,
      "learning_rate": 4.133895536014608e-05,
      "loss": 0.0002,
      "step": 36050
    },
    {
      "epoch": 1.734659555043006,
      "grad_norm": 0.6963486671447754,
      "learning_rate": 4.132694248234107e-05,
      "loss": 0.0003,
      "step": 36100
    },
    {
      "epoch": 1.7370621306040075,
      "grad_norm": 0.15076227486133575,
      "learning_rate": 4.131492960453606e-05,
      "loss": 0.0003,
      "step": 36150
    },
    {
      "epoch": 1.739464706165009,
      "grad_norm": 0.38748452067375183,
      "learning_rate": 4.130291672673106e-05,
      "loss": 0.0002,
      "step": 36200
    },
    {
      "epoch": 1.7418672817260101,
      "grad_norm": 0.13390500843524933,
      "learning_rate": 4.129090384892605e-05,
      "loss": 0.0002,
      "step": 36250
    },
    {
      "epoch": 1.7442698572870117,
      "grad_norm": 0.2015000879764557,
      "learning_rate": 4.127889097112104e-05,
      "loss": 0.0002,
      "step": 36300
    },
    {
      "epoch": 1.7466724328480132,
      "grad_norm": 0.09324540197849274,
      "learning_rate": 4.126687809331604e-05,
      "loss": 0.0002,
      "step": 36350
    },
    {
      "epoch": 1.7490750084090143,
      "grad_norm": 0.412992388010025,
      "learning_rate": 4.125486521551103e-05,
      "loss": 0.0002,
      "step": 36400
    },
    {
      "epoch": 1.7514775839700158,
      "grad_norm": 0.16915886104106903,
      "learning_rate": 4.1242852337706025e-05,
      "loss": 0.0003,
      "step": 36450
    },
    {
      "epoch": 1.7538801595310174,
      "grad_norm": 0.31476983428001404,
      "learning_rate": 4.1230839459901016e-05,
      "loss": 0.0003,
      "step": 36500
    },
    {
      "epoch": 1.7562827350920185,
      "grad_norm": 0.08235328644514084,
      "learning_rate": 4.121882658209601e-05,
      "loss": 0.0002,
      "step": 36550
    },
    {
      "epoch": 1.75868531065302,
      "grad_norm": 0.08773431926965714,
      "learning_rate": 4.1206813704291005e-05,
      "loss": 0.0003,
      "step": 36600
    },
    {
      "epoch": 1.7610878862140216,
      "grad_norm": 0.09232397377490997,
      "learning_rate": 4.1194800826485995e-05,
      "loss": 0.0002,
      "step": 36650
    },
    {
      "epoch": 1.7634904617750227,
      "grad_norm": 0.2044745832681656,
      "learning_rate": 4.118278794868099e-05,
      "loss": 0.0003,
      "step": 36700
    },
    {
      "epoch": 1.7658930373360242,
      "grad_norm": 0.08803584426641464,
      "learning_rate": 4.1170775070875984e-05,
      "loss": 0.0008,
      "step": 36750
    },
    {
      "epoch": 1.7682956128970257,
      "grad_norm": 0.114043228328228,
      "learning_rate": 4.1158762193070975e-05,
      "loss": 0.0003,
      "step": 36800
    },
    {
      "epoch": 1.7706981884580268,
      "grad_norm": 0.4338945150375366,
      "learning_rate": 4.1146749315265966e-05,
      "loss": 0.0003,
      "step": 36850
    },
    {
      "epoch": 1.7731007640190284,
      "grad_norm": 0.20248040556907654,
      "learning_rate": 4.1134736437460956e-05,
      "loss": 0.0003,
      "step": 36900
    },
    {
      "epoch": 1.77550333958003,
      "grad_norm": 0.06265722960233688,
      "learning_rate": 4.1122723559655954e-05,
      "loss": 0.0003,
      "step": 36950
    },
    {
      "epoch": 1.777905915141031,
      "grad_norm": 0.16323912143707275,
      "learning_rate": 4.1110710681850945e-05,
      "loss": 0.0003,
      "step": 37000
    },
    {
      "epoch": 1.7803084907020326,
      "grad_norm": 0.5365154147148132,
      "learning_rate": 4.1098697804045936e-05,
      "loss": 0.0002,
      "step": 37050
    },
    {
      "epoch": 1.782711066263034,
      "grad_norm": 0.7045608162879944,
      "learning_rate": 4.108668492624093e-05,
      "loss": 0.001,
      "step": 37100
    },
    {
      "epoch": 1.7851136418240352,
      "grad_norm": 0.8131425976753235,
      "learning_rate": 4.1074672048435924e-05,
      "loss": 0.0003,
      "step": 37150
    },
    {
      "epoch": 1.7875162173850367,
      "grad_norm": 0.24689048528671265,
      "learning_rate": 4.106265917063092e-05,
      "loss": 0.0003,
      "step": 37200
    },
    {
      "epoch": 1.7899187929460383,
      "grad_norm": 0.2619660496711731,
      "learning_rate": 4.105064629282591e-05,
      "loss": 0.0002,
      "step": 37250
    },
    {
      "epoch": 1.7923213685070394,
      "grad_norm": 0.40229669213294983,
      "learning_rate": 4.10386334150209e-05,
      "loss": 0.0007,
      "step": 37300
    },
    {
      "epoch": 1.794723944068041,
      "grad_norm": 0.11309698224067688,
      "learning_rate": 4.10266205372159e-05,
      "loss": 0.0011,
      "step": 37350
    },
    {
      "epoch": 1.7971265196290425,
      "grad_norm": 0.07678728550672531,
      "learning_rate": 4.101460765941089e-05,
      "loss": 0.0002,
      "step": 37400
    },
    {
      "epoch": 1.7995290951900438,
      "grad_norm": 0.21264715492725372,
      "learning_rate": 4.100259478160588e-05,
      "loss": 0.0002,
      "step": 37450
    },
    {
      "epoch": 1.801931670751045,
      "grad_norm": 0.31567075848579407,
      "learning_rate": 4.099058190380088e-05,
      "loss": 0.0003,
      "step": 37500
    },
    {
      "epoch": 1.8043342463120466,
      "grad_norm": 0.29525548219680786,
      "learning_rate": 4.097856902599587e-05,
      "loss": 0.0002,
      "step": 37550
    },
    {
      "epoch": 1.806736821873048,
      "grad_norm": 0.5452392101287842,
      "learning_rate": 4.096655614819086e-05,
      "loss": 0.0003,
      "step": 37600
    },
    {
      "epoch": 1.8091393974340493,
      "grad_norm": 0.16134491562843323,
      "learning_rate": 4.095454327038585e-05,
      "loss": 0.0003,
      "step": 37650
    },
    {
      "epoch": 1.8115419729950508,
      "grad_norm": 0.32096895575523376,
      "learning_rate": 4.0942530392580843e-05,
      "loss": 0.0003,
      "step": 37700
    },
    {
      "epoch": 1.8139445485560521,
      "grad_norm": 0.15027493238449097,
      "learning_rate": 4.093051751477584e-05,
      "loss": 0.0002,
      "step": 37750
    },
    {
      "epoch": 1.8163471241170535,
      "grad_norm": 0.3023838400840759,
      "learning_rate": 4.091850463697083e-05,
      "loss": 0.0003,
      "step": 37800
    },
    {
      "epoch": 1.818749699678055,
      "grad_norm": 0.41469046473503113,
      "learning_rate": 4.090649175916583e-05,
      "loss": 0.0002,
      "step": 37850
    },
    {
      "epoch": 1.8211522752390563,
      "grad_norm": 0.23867616057395935,
      "learning_rate": 4.089447888136082e-05,
      "loss": 0.0003,
      "step": 37900
    },
    {
      "epoch": 1.8235548508000576,
      "grad_norm": 0.07255494594573975,
      "learning_rate": 4.088246600355581e-05,
      "loss": 0.0002,
      "step": 37950
    },
    {
      "epoch": 1.8259574263610592,
      "grad_norm": 0.07782449573278427,
      "learning_rate": 4.087045312575081e-05,
      "loss": 0.0002,
      "step": 38000
    },
    {
      "epoch": 1.8283600019220605,
      "grad_norm": 0.1636013686656952,
      "learning_rate": 4.08584402479458e-05,
      "loss": 0.0003,
      "step": 38050
    },
    {
      "epoch": 1.8307625774830618,
      "grad_norm": 0.689122200012207,
      "learning_rate": 4.08464273701408e-05,
      "loss": 0.0002,
      "step": 38100
    },
    {
      "epoch": 1.8331651530440634,
      "grad_norm": 0.1736898422241211,
      "learning_rate": 4.083441449233579e-05,
      "loss": 0.0003,
      "step": 38150
    },
    {
      "epoch": 1.8355677286050647,
      "grad_norm": 0.18008658289909363,
      "learning_rate": 4.082240161453078e-05,
      "loss": 0.0003,
      "step": 38200
    },
    {
      "epoch": 1.837970304166066,
      "grad_norm": 0.1963019222021103,
      "learning_rate": 4.0810388736725776e-05,
      "loss": 0.0002,
      "step": 38250
    },
    {
      "epoch": 1.8403728797270675,
      "grad_norm": 0.5127596259117126,
      "learning_rate": 4.079837585892077e-05,
      "loss": 0.0002,
      "step": 38300
    },
    {
      "epoch": 1.8427754552880689,
      "grad_norm": 0.136821448802948,
      "learning_rate": 4.078636298111576e-05,
      "loss": 0.0008,
      "step": 38350
    },
    {
      "epoch": 1.8451780308490702,
      "grad_norm": 0.07697301357984543,
      "learning_rate": 4.077435010331075e-05,
      "loss": 0.0008,
      "step": 38400
    },
    {
      "epoch": 1.8475806064100717,
      "grad_norm": 0.10008389502763748,
      "learning_rate": 4.076233722550574e-05,
      "loss": 0.0008,
      "step": 38450
    },
    {
      "epoch": 1.849983181971073,
      "grad_norm": 0.14770640432834625,
      "learning_rate": 4.075032434770074e-05,
      "loss": 0.0002,
      "step": 38500
    },
    {
      "epoch": 1.8523857575320744,
      "grad_norm": 0.08176736533641815,
      "learning_rate": 4.073831146989573e-05,
      "loss": 0.0003,
      "step": 38550
    },
    {
      "epoch": 1.854788333093076,
      "grad_norm": 0.2156451940536499,
      "learning_rate": 4.0726298592090726e-05,
      "loss": 0.0002,
      "step": 38600
    },
    {
      "epoch": 1.8571909086540772,
      "grad_norm": 0.2562948167324066,
      "learning_rate": 4.0714285714285717e-05,
      "loss": 0.0003,
      "step": 38650
    },
    {
      "epoch": 1.8595934842150785,
      "grad_norm": 0.13238941133022308,
      "learning_rate": 4.070227283648071e-05,
      "loss": 0.0002,
      "step": 38700
    },
    {
      "epoch": 1.86199605977608,
      "grad_norm": 0.09398754686117172,
      "learning_rate": 4.0690259958675705e-05,
      "loss": 0.0007,
      "step": 38750
    },
    {
      "epoch": 1.8643986353370814,
      "grad_norm": 0.08275090157985687,
      "learning_rate": 4.0678247080870696e-05,
      "loss": 0.0002,
      "step": 38800
    },
    {
      "epoch": 1.8668012108980827,
      "grad_norm": 0.22755911946296692,
      "learning_rate": 4.0666234203065687e-05,
      "loss": 0.0002,
      "step": 38850
    },
    {
      "epoch": 1.8692037864590842,
      "grad_norm": 0.16153565049171448,
      "learning_rate": 4.0654221325260684e-05,
      "loss": 0.0002,
      "step": 38900
    },
    {
      "epoch": 1.8716063620200856,
      "grad_norm": 0.3047083020210266,
      "learning_rate": 4.0642208447455675e-05,
      "loss": 0.0002,
      "step": 38950
    },
    {
      "epoch": 1.8740089375810869,
      "grad_norm": 0.2566756308078766,
      "learning_rate": 4.063019556965067e-05,
      "loss": 0.0002,
      "step": 39000
    },
    {
      "epoch": 1.8764115131420884,
      "grad_norm": 0.4551422894001007,
      "learning_rate": 4.0618182691845663e-05,
      "loss": 0.0002,
      "step": 39050
    },
    {
      "epoch": 1.8788140887030897,
      "grad_norm": 0.1672452688217163,
      "learning_rate": 4.0606169814040654e-05,
      "loss": 0.0003,
      "step": 39100
    },
    {
      "epoch": 1.881216664264091,
      "grad_norm": 0.09239187091588974,
      "learning_rate": 4.0594156936235645e-05,
      "loss": 0.0002,
      "step": 39150
    },
    {
      "epoch": 1.8836192398250926,
      "grad_norm": 0.3127364218235016,
      "learning_rate": 4.0582144058430636e-05,
      "loss": 0.0002,
      "step": 39200
    },
    {
      "epoch": 1.886021815386094,
      "grad_norm": 0.5557047724723816,
      "learning_rate": 4.0570131180625634e-05,
      "loss": 0.0003,
      "step": 39250
    },
    {
      "epoch": 1.8884243909470952,
      "grad_norm": 0.7202554941177368,
      "learning_rate": 4.0558118302820624e-05,
      "loss": 0.0002,
      "step": 39300
    },
    {
      "epoch": 1.8908269665080968,
      "grad_norm": 0.4443577229976654,
      "learning_rate": 4.0546105425015615e-05,
      "loss": 0.0003,
      "step": 39350
    },
    {
      "epoch": 1.893229542069098,
      "grad_norm": 0.12409486621618271,
      "learning_rate": 4.053409254721061e-05,
      "loss": 0.0003,
      "step": 39400
    },
    {
      "epoch": 1.8956321176300994,
      "grad_norm": 0.15730981528759003,
      "learning_rate": 4.0522079669405604e-05,
      "loss": 0.0003,
      "step": 39450
    },
    {
      "epoch": 1.898034693191101,
      "grad_norm": 0.13762803375720978,
      "learning_rate": 4.05100667916006e-05,
      "loss": 0.0002,
      "step": 39500
    },
    {
      "epoch": 1.9004372687521023,
      "grad_norm": 0.06918915361166,
      "learning_rate": 4.049805391379559e-05,
      "loss": 0.0002,
      "step": 39550
    },
    {
      "epoch": 1.9028398443131036,
      "grad_norm": 0.095029816031456,
      "learning_rate": 4.048604103599058e-05,
      "loss": 0.0002,
      "step": 39600
    },
    {
      "epoch": 1.9052424198741051,
      "grad_norm": 0.8787901997566223,
      "learning_rate": 4.047402815818558e-05,
      "loss": 0.0003,
      "step": 39650
    },
    {
      "epoch": 1.9076449954351065,
      "grad_norm": 0.22174261510372162,
      "learning_rate": 4.046201528038057e-05,
      "loss": 0.0002,
      "step": 39700
    },
    {
      "epoch": 1.9100475709961078,
      "grad_norm": 0.9846295714378357,
      "learning_rate": 4.045000240257556e-05,
      "loss": 0.0004,
      "step": 39750
    },
    {
      "epoch": 1.9124501465571093,
      "grad_norm": 0.28958871960639954,
      "learning_rate": 4.043798952477056e-05,
      "loss": 0.0009,
      "step": 39800
    },
    {
      "epoch": 1.9148527221181106,
      "grad_norm": 0.25380077958106995,
      "learning_rate": 4.0425976646965544e-05,
      "loss": 0.0003,
      "step": 39850
    },
    {
      "epoch": 1.917255297679112,
      "grad_norm": 0.6349695920944214,
      "learning_rate": 4.041396376916054e-05,
      "loss": 0.0004,
      "step": 39900
    },
    {
      "epoch": 1.9196578732401135,
      "grad_norm": 0.5172313451766968,
      "learning_rate": 4.040195089135553e-05,
      "loss": 0.0003,
      "step": 39950
    },
    {
      "epoch": 1.9220604488011148,
      "grad_norm": 0.3594399392604828,
      "learning_rate": 4.038993801355053e-05,
      "loss": 0.0005,
      "step": 40000
    },
    {
      "epoch": 1.9244630243621161,
      "grad_norm": 0.3230490982532501,
      "learning_rate": 4.037792513574552e-05,
      "loss": 0.0006,
      "step": 40050
    },
    {
      "epoch": 1.9268655999231177,
      "grad_norm": 0.1389443278312683,
      "learning_rate": 4.036591225794051e-05,
      "loss": 0.0002,
      "step": 40100
    },
    {
      "epoch": 1.929268175484119,
      "grad_norm": 0.21225394308567047,
      "learning_rate": 4.035389938013551e-05,
      "loss": 0.0003,
      "step": 40150
    },
    {
      "epoch": 1.9316707510451203,
      "grad_norm": 0.13024713099002838,
      "learning_rate": 4.03418865023305e-05,
      "loss": 0.0002,
      "step": 40200
    },
    {
      "epoch": 1.9340733266061219,
      "grad_norm": 0.028152640908956528,
      "learning_rate": 4.032987362452549e-05,
      "loss": 0.0003,
      "step": 40250
    },
    {
      "epoch": 1.9364759021671232,
      "grad_norm": 0.21460124850273132,
      "learning_rate": 4.031786074672049e-05,
      "loss": 0.0002,
      "step": 40300
    },
    {
      "epoch": 1.9388784777281245,
      "grad_norm": 0.5409828424453735,
      "learning_rate": 4.030584786891548e-05,
      "loss": 0.0002,
      "step": 40350
    },
    {
      "epoch": 1.941281053289126,
      "grad_norm": 0.34937793016433716,
      "learning_rate": 4.029383499111048e-05,
      "loss": 0.0002,
      "step": 40400
    },
    {
      "epoch": 1.9436836288501274,
      "grad_norm": 0.400411456823349,
      "learning_rate": 4.028182211330547e-05,
      "loss": 0.0009,
      "step": 40450
    },
    {
      "epoch": 1.9460862044111287,
      "grad_norm": 0.45208704471588135,
      "learning_rate": 4.026980923550046e-05,
      "loss": 0.0003,
      "step": 40500
    },
    {
      "epoch": 1.9484887799721302,
      "grad_norm": 0.6281006932258606,
      "learning_rate": 4.0257796357695456e-05,
      "loss": 0.0008,
      "step": 40550
    },
    {
      "epoch": 1.9508913555331315,
      "grad_norm": 0.4969312846660614,
      "learning_rate": 4.024578347989044e-05,
      "loss": 0.0003,
      "step": 40600
    },
    {
      "epoch": 1.9532939310941329,
      "grad_norm": 0.697885274887085,
      "learning_rate": 4.023377060208544e-05,
      "loss": 0.0002,
      "step": 40650
    },
    {
      "epoch": 1.9556965066551344,
      "grad_norm": 0.22011986374855042,
      "learning_rate": 4.022175772428043e-05,
      "loss": 0.0003,
      "step": 40700
    },
    {
      "epoch": 1.9580990822161357,
      "grad_norm": 0.7306181192398071,
      "learning_rate": 4.020974484647542e-05,
      "loss": 0.0003,
      "step": 40750
    },
    {
      "epoch": 1.960501657777137,
      "grad_norm": 0.42067334055900574,
      "learning_rate": 4.019773196867042e-05,
      "loss": 0.0002,
      "step": 40800
    },
    {
      "epoch": 1.9629042333381386,
      "grad_norm": 0.18050532042980194,
      "learning_rate": 4.018571909086541e-05,
      "loss": 0.0002,
      "step": 40850
    },
    {
      "epoch": 1.96530680889914,
      "grad_norm": 0.17288242280483246,
      "learning_rate": 4.0173706213060405e-05,
      "loss": 0.0003,
      "step": 40900
    },
    {
      "epoch": 1.9677093844601412,
      "grad_norm": 0.0862312838435173,
      "learning_rate": 4.0161693335255396e-05,
      "loss": 0.0002,
      "step": 40950
    },
    {
      "epoch": 1.9701119600211427,
      "grad_norm": 0.07700788974761963,
      "learning_rate": 4.014968045745039e-05,
      "loss": 0.0002,
      "step": 41000
    },
    {
      "epoch": 1.972514535582144,
      "grad_norm": 0.14234140515327454,
      "learning_rate": 4.0137667579645385e-05,
      "loss": 0.0001,
      "step": 41050
    },
    {
      "epoch": 1.9749171111431454,
      "grad_norm": 0.2475491464138031,
      "learning_rate": 4.0125654701840375e-05,
      "loss": 0.0002,
      "step": 41100
    },
    {
      "epoch": 1.977319686704147,
      "grad_norm": 0.1126495823264122,
      "learning_rate": 4.0113641824035366e-05,
      "loss": 0.0002,
      "step": 41150
    },
    {
      "epoch": 1.9797222622651482,
      "grad_norm": 0.09397350251674652,
      "learning_rate": 4.0101628946230364e-05,
      "loss": 0.0002,
      "step": 41200
    },
    {
      "epoch": 1.9821248378261496,
      "grad_norm": 0.20789746940135956,
      "learning_rate": 4.0089616068425355e-05,
      "loss": 0.0002,
      "step": 41250
    },
    {
      "epoch": 1.984527413387151,
      "grad_norm": 0.10199245065450668,
      "learning_rate": 4.0077603190620345e-05,
      "loss": 0.0002,
      "step": 41300
    },
    {
      "epoch": 1.9869299889481524,
      "grad_norm": 0.14259858429431915,
      "learning_rate": 4.0065590312815336e-05,
      "loss": 0.0003,
      "step": 41350
    },
    {
      "epoch": 1.9893325645091537,
      "grad_norm": 0.6657786965370178,
      "learning_rate": 4.0053577435010334e-05,
      "loss": 0.0003,
      "step": 41400
    },
    {
      "epoch": 1.9917351400701553,
      "grad_norm": 0.2767373025417328,
      "learning_rate": 4.0041564557205325e-05,
      "loss": 0.0004,
      "step": 41450
    },
    {
      "epoch": 1.9941377156311566,
      "grad_norm": 0.08530121296644211,
      "learning_rate": 4.0029551679400316e-05,
      "loss": 0.0002,
      "step": 41500
    },
    {
      "epoch": 1.996540291192158,
      "grad_norm": 0.2888677716255188,
      "learning_rate": 4.001753880159531e-05,
      "loss": 0.0002,
      "step": 41550
    },
    {
      "epoch": 1.9989428667531595,
      "grad_norm": 0.19722571969032288,
      "learning_rate": 4.0005525923790304e-05,
      "loss": 0.0002,
      "step": 41600
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.00041477978811599314,
      "eval_runtime": 17.339,
      "eval_samples_per_second": 547.667,
      "eval_steps_per_second": 68.458,
      "step": 41622
    },
    {
      "epoch": 2.0013454423141606,
      "grad_norm": 0.4078594148159027,
      "learning_rate": 3.9993513045985295e-05,
      "loss": 0.0003,
      "step": 41650
    },
    {
      "epoch": 2.003748017875162,
      "grad_norm": 0.09417311102151871,
      "learning_rate": 3.998150016818029e-05,
      "loss": 0.0005,
      "step": 41700
    },
    {
      "epoch": 2.0061505934361636,
      "grad_norm": 0.1892285794019699,
      "learning_rate": 3.996948729037528e-05,
      "loss": 0.0002,
      "step": 41750
    },
    {
      "epoch": 2.0085531689971647,
      "grad_norm": 0.2531404495239258,
      "learning_rate": 3.995747441257028e-05,
      "loss": 0.0003,
      "step": 41800
    },
    {
      "epoch": 2.0109557445581663,
      "grad_norm": 0.37840038537979126,
      "learning_rate": 3.994546153476527e-05,
      "loss": 0.0002,
      "step": 41850
    },
    {
      "epoch": 2.013358320119168,
      "grad_norm": 0.4291863441467285,
      "learning_rate": 3.993344865696026e-05,
      "loss": 0.0002,
      "step": 41900
    },
    {
      "epoch": 2.0157608956801694,
      "grad_norm": 0.2395341694355011,
      "learning_rate": 3.992143577915526e-05,
      "loss": 0.0003,
      "step": 41950
    },
    {
      "epoch": 2.0181634712411705,
      "grad_norm": 0.10924787819385529,
      "learning_rate": 3.990942290135025e-05,
      "loss": 0.0003,
      "step": 42000
    },
    {
      "epoch": 2.020566046802172,
      "grad_norm": 0.4266636371612549,
      "learning_rate": 3.989741002354524e-05,
      "loss": 0.0002,
      "step": 42050
    },
    {
      "epoch": 2.0229686223631735,
      "grad_norm": 0.5219449996948242,
      "learning_rate": 3.988539714574023e-05,
      "loss": 0.0003,
      "step": 42100
    },
    {
      "epoch": 2.0253711979241746,
      "grad_norm": 0.07837063819169998,
      "learning_rate": 3.987338426793522e-05,
      "loss": 0.0007,
      "step": 42150
    },
    {
      "epoch": 2.027773773485176,
      "grad_norm": 0.35692065954208374,
      "learning_rate": 3.986137139013022e-05,
      "loss": 0.0002,
      "step": 42200
    },
    {
      "epoch": 2.0301763490461777,
      "grad_norm": 0.23009900748729706,
      "learning_rate": 3.984935851232521e-05,
      "loss": 0.0003,
      "step": 42250
    },
    {
      "epoch": 2.032578924607179,
      "grad_norm": 0.11324174702167511,
      "learning_rate": 3.983734563452021e-05,
      "loss": 0.0002,
      "step": 42300
    },
    {
      "epoch": 2.0349815001681804,
      "grad_norm": 0.23768924176692963,
      "learning_rate": 3.98253327567152e-05,
      "loss": 0.0002,
      "step": 42350
    },
    {
      "epoch": 2.037384075729182,
      "grad_norm": 0.09557679295539856,
      "learning_rate": 3.981331987891019e-05,
      "loss": 0.0008,
      "step": 42400
    },
    {
      "epoch": 2.039786651290183,
      "grad_norm": 0.22740799188613892,
      "learning_rate": 3.980130700110519e-05,
      "loss": 0.0002,
      "step": 42450
    },
    {
      "epoch": 2.0421892268511845,
      "grad_norm": 0.4276053309440613,
      "learning_rate": 3.978929412330018e-05,
      "loss": 0.0002,
      "step": 42500
    },
    {
      "epoch": 2.044591802412186,
      "grad_norm": 0.10858376324176788,
      "learning_rate": 3.977728124549518e-05,
      "loss": 0.0002,
      "step": 42550
    },
    {
      "epoch": 2.046994377973187,
      "grad_norm": 0.3802545368671417,
      "learning_rate": 3.976526836769017e-05,
      "loss": 0.0002,
      "step": 42600
    },
    {
      "epoch": 2.0493969535341887,
      "grad_norm": 0.21693751215934753,
      "learning_rate": 3.975325548988516e-05,
      "loss": 0.0002,
      "step": 42650
    },
    {
      "epoch": 2.0517995290951903,
      "grad_norm": 0.5908257365226746,
      "learning_rate": 3.9741242612080156e-05,
      "loss": 0.0002,
      "step": 42700
    },
    {
      "epoch": 2.0542021046561914,
      "grad_norm": 0.3555893003940582,
      "learning_rate": 3.972922973427515e-05,
      "loss": 0.0002,
      "step": 42750
    },
    {
      "epoch": 2.056604680217193,
      "grad_norm": 0.5087557435035706,
      "learning_rate": 3.971721685647014e-05,
      "loss": 0.0003,
      "step": 42800
    },
    {
      "epoch": 2.0590072557781944,
      "grad_norm": 0.29824212193489075,
      "learning_rate": 3.970520397866513e-05,
      "loss": 0.0002,
      "step": 42850
    },
    {
      "epoch": 2.0614098313391955,
      "grad_norm": 0.2062930017709732,
      "learning_rate": 3.969319110086012e-05,
      "loss": 0.0002,
      "step": 42900
    },
    {
      "epoch": 2.063812406900197,
      "grad_norm": 0.1900385171175003,
      "learning_rate": 3.968117822305512e-05,
      "loss": 0.0003,
      "step": 42950
    },
    {
      "epoch": 2.0662149824611986,
      "grad_norm": 0.14308713376522064,
      "learning_rate": 3.966916534525011e-05,
      "loss": 0.0002,
      "step": 43000
    },
    {
      "epoch": 2.0686175580221997,
      "grad_norm": 0.27370452880859375,
      "learning_rate": 3.96571524674451e-05,
      "loss": 0.0002,
      "step": 43050
    },
    {
      "epoch": 2.0710201335832013,
      "grad_norm": 0.07704731822013855,
      "learning_rate": 3.9645139589640096e-05,
      "loss": 0.0002,
      "step": 43100
    },
    {
      "epoch": 2.073422709144203,
      "grad_norm": 0.12204141914844513,
      "learning_rate": 3.963312671183509e-05,
      "loss": 0.0002,
      "step": 43150
    },
    {
      "epoch": 2.075825284705204,
      "grad_norm": 0.07381021231412888,
      "learning_rate": 3.9621113834030085e-05,
      "loss": 0.0002,
      "step": 43200
    },
    {
      "epoch": 2.0782278602662054,
      "grad_norm": 0.13078095018863678,
      "learning_rate": 3.9609100956225076e-05,
      "loss": 0.0003,
      "step": 43250
    },
    {
      "epoch": 2.080630435827207,
      "grad_norm": 0.1355329006910324,
      "learning_rate": 3.9597088078420067e-05,
      "loss": 0.0002,
      "step": 43300
    },
    {
      "epoch": 2.083033011388208,
      "grad_norm": 0.4654593765735626,
      "learning_rate": 3.9585075200615064e-05,
      "loss": 0.0003,
      "step": 43350
    },
    {
      "epoch": 2.0854355869492096,
      "grad_norm": 0.09904686361551285,
      "learning_rate": 3.9573062322810055e-05,
      "loss": 0.0002,
      "step": 43400
    },
    {
      "epoch": 2.087838162510211,
      "grad_norm": 0.3813920319080353,
      "learning_rate": 3.956104944500505e-05,
      "loss": 0.0003,
      "step": 43450
    },
    {
      "epoch": 2.0902407380712122,
      "grad_norm": 0.1884661465883255,
      "learning_rate": 3.9549036567200043e-05,
      "loss": 0.0004,
      "step": 43500
    },
    {
      "epoch": 2.092643313632214,
      "grad_norm": 0.8692275881767273,
      "learning_rate": 3.953702368939503e-05,
      "loss": 0.0002,
      "step": 43550
    },
    {
      "epoch": 2.0950458891932153,
      "grad_norm": 0.30245694518089294,
      "learning_rate": 3.9525010811590025e-05,
      "loss": 0.0002,
      "step": 43600
    },
    {
      "epoch": 2.0974484647542164,
      "grad_norm": 0.15237732231616974,
      "learning_rate": 3.9512997933785016e-05,
      "loss": 0.0002,
      "step": 43650
    },
    {
      "epoch": 2.099851040315218,
      "grad_norm": 0.11840136349201202,
      "learning_rate": 3.9500985055980013e-05,
      "loss": 0.0002,
      "step": 43700
    },
    {
      "epoch": 2.1022536158762195,
      "grad_norm": 0.5983670353889465,
      "learning_rate": 3.9488972178175004e-05,
      "loss": 0.0002,
      "step": 43750
    },
    {
      "epoch": 2.1046561914372206,
      "grad_norm": 0.10474897921085358,
      "learning_rate": 3.9476959300369995e-05,
      "loss": 0.0002,
      "step": 43800
    },
    {
      "epoch": 2.107058766998222,
      "grad_norm": 0.12732872366905212,
      "learning_rate": 3.946494642256499e-05,
      "loss": 0.0002,
      "step": 43850
    },
    {
      "epoch": 2.1094613425592237,
      "grad_norm": 0.25148463249206543,
      "learning_rate": 3.9452933544759984e-05,
      "loss": 0.0002,
      "step": 43900
    },
    {
      "epoch": 2.111863918120225,
      "grad_norm": 0.12611350417137146,
      "learning_rate": 3.944092066695498e-05,
      "loss": 0.0002,
      "step": 43950
    },
    {
      "epoch": 2.1142664936812263,
      "grad_norm": 0.6145294308662415,
      "learning_rate": 3.942890778914997e-05,
      "loss": 0.0009,
      "step": 44000
    },
    {
      "epoch": 2.116669069242228,
      "grad_norm": 0.11901931464672089,
      "learning_rate": 3.941689491134496e-05,
      "loss": 0.0003,
      "step": 44050
    },
    {
      "epoch": 2.119071644803229,
      "grad_norm": 0.3787572979927063,
      "learning_rate": 3.940488203353996e-05,
      "loss": 0.0002,
      "step": 44100
    },
    {
      "epoch": 2.1214742203642305,
      "grad_norm": 0.320324182510376,
      "learning_rate": 3.939286915573495e-05,
      "loss": 0.0002,
      "step": 44150
    },
    {
      "epoch": 2.123876795925232,
      "grad_norm": 0.06515423953533173,
      "learning_rate": 3.938085627792994e-05,
      "loss": 0.0003,
      "step": 44200
    },
    {
      "epoch": 2.126279371486233,
      "grad_norm": 0.4431802034378052,
      "learning_rate": 3.936884340012494e-05,
      "loss": 0.0003,
      "step": 44250
    },
    {
      "epoch": 2.1286819470472347,
      "grad_norm": 0.32982543110847473,
      "learning_rate": 3.9356830522319924e-05,
      "loss": 0.0002,
      "step": 44300
    },
    {
      "epoch": 2.131084522608236,
      "grad_norm": 0.16348347067832947,
      "learning_rate": 3.934481764451492e-05,
      "loss": 0.0003,
      "step": 44350
    },
    {
      "epoch": 2.1334870981692373,
      "grad_norm": 0.30105143785476685,
      "learning_rate": 3.933280476670991e-05,
      "loss": 0.0002,
      "step": 44400
    },
    {
      "epoch": 2.135889673730239,
      "grad_norm": 0.20925304293632507,
      "learning_rate": 3.932079188890491e-05,
      "loss": 0.0003,
      "step": 44450
    },
    {
      "epoch": 2.1382922492912404,
      "grad_norm": 0.1591317504644394,
      "learning_rate": 3.93087790110999e-05,
      "loss": 0.0002,
      "step": 44500
    },
    {
      "epoch": 2.1406948248522415,
      "grad_norm": 0.4116123914718628,
      "learning_rate": 3.929676613329489e-05,
      "loss": 0.0002,
      "step": 44550
    },
    {
      "epoch": 2.143097400413243,
      "grad_norm": 0.08643001317977905,
      "learning_rate": 3.928475325548989e-05,
      "loss": 0.0009,
      "step": 44600
    },
    {
      "epoch": 2.1454999759742446,
      "grad_norm": 0.5124751925468445,
      "learning_rate": 3.927274037768488e-05,
      "loss": 0.0003,
      "step": 44650
    },
    {
      "epoch": 2.1479025515352457,
      "grad_norm": 0.5514990091323853,
      "learning_rate": 3.926072749987987e-05,
      "loss": 0.0002,
      "step": 44700
    },
    {
      "epoch": 2.150305127096247,
      "grad_norm": 0.17131681740283966,
      "learning_rate": 3.924871462207487e-05,
      "loss": 0.0002,
      "step": 44750
    },
    {
      "epoch": 2.1527077026572488,
      "grad_norm": 0.05676263943314552,
      "learning_rate": 3.923670174426986e-05,
      "loss": 0.0002,
      "step": 44800
    },
    {
      "epoch": 2.15511027821825,
      "grad_norm": 0.3651449382305145,
      "learning_rate": 3.922468886646486e-05,
      "loss": 0.0002,
      "step": 44850
    },
    {
      "epoch": 2.1575128537792514,
      "grad_norm": 0.44127926230430603,
      "learning_rate": 3.921267598865985e-05,
      "loss": 0.0002,
      "step": 44900
    },
    {
      "epoch": 2.159915429340253,
      "grad_norm": 0.36059561371803284,
      "learning_rate": 3.920066311085484e-05,
      "loss": 0.0002,
      "step": 44950
    },
    {
      "epoch": 2.162318004901254,
      "grad_norm": 0.15205572545528412,
      "learning_rate": 3.9188650233049836e-05,
      "loss": 0.0003,
      "step": 45000
    },
    {
      "epoch": 2.1647205804622556,
      "grad_norm": 0.4725603759288788,
      "learning_rate": 3.917663735524482e-05,
      "loss": 0.0002,
      "step": 45050
    },
    {
      "epoch": 2.167123156023257,
      "grad_norm": 0.5876015424728394,
      "learning_rate": 3.916462447743982e-05,
      "loss": 0.0002,
      "step": 45100
    },
    {
      "epoch": 2.169525731584258,
      "grad_norm": 0.1580255627632141,
      "learning_rate": 3.915261159963481e-05,
      "loss": 0.0002,
      "step": 45150
    },
    {
      "epoch": 2.1719283071452598,
      "grad_norm": 0.09138262271881104,
      "learning_rate": 3.91405987218298e-05,
      "loss": 0.0002,
      "step": 45200
    },
    {
      "epoch": 2.1743308827062613,
      "grad_norm": 0.19796280562877655,
      "learning_rate": 3.91285858440248e-05,
      "loss": 0.0003,
      "step": 45250
    },
    {
      "epoch": 2.1767334582672624,
      "grad_norm": 0.5064794421195984,
      "learning_rate": 3.911657296621979e-05,
      "loss": 0.0002,
      "step": 45300
    },
    {
      "epoch": 2.179136033828264,
      "grad_norm": 0.2916278839111328,
      "learning_rate": 3.9104560088414785e-05,
      "loss": 0.0009,
      "step": 45350
    },
    {
      "epoch": 2.1815386093892655,
      "grad_norm": 0.10986433923244476,
      "learning_rate": 3.9092547210609776e-05,
      "loss": 0.0002,
      "step": 45400
    },
    {
      "epoch": 2.1839411849502666,
      "grad_norm": 0.5489683151245117,
      "learning_rate": 3.908053433280477e-05,
      "loss": 0.0002,
      "step": 45450
    },
    {
      "epoch": 2.186343760511268,
      "grad_norm": 0.5680423378944397,
      "learning_rate": 3.9068521454999765e-05,
      "loss": 0.0004,
      "step": 45500
    },
    {
      "epoch": 2.1887463360722696,
      "grad_norm": 0.07656465470790863,
      "learning_rate": 3.9056508577194755e-05,
      "loss": 0.0003,
      "step": 45550
    },
    {
      "epoch": 2.1911489116332707,
      "grad_norm": 0.3107885718345642,
      "learning_rate": 3.9044495699389746e-05,
      "loss": 0.0009,
      "step": 45600
    },
    {
      "epoch": 2.1935514871942723,
      "grad_norm": 0.23937538266181946,
      "learning_rate": 3.9032482821584744e-05,
      "loss": 0.0002,
      "step": 45650
    },
    {
      "epoch": 2.195954062755274,
      "grad_norm": 0.10356176644563675,
      "learning_rate": 3.9020469943779735e-05,
      "loss": 0.0008,
      "step": 45700
    },
    {
      "epoch": 2.198356638316275,
      "grad_norm": 0.1298723965883255,
      "learning_rate": 3.900845706597473e-05,
      "loss": 0.0002,
      "step": 45750
    },
    {
      "epoch": 2.2007592138772765,
      "grad_norm": 0.0958421528339386,
      "learning_rate": 3.8996444188169716e-05,
      "loss": 0.0002,
      "step": 45800
    },
    {
      "epoch": 2.203161789438278,
      "grad_norm": 0.19107003509998322,
      "learning_rate": 3.8984431310364714e-05,
      "loss": 0.0002,
      "step": 45850
    },
    {
      "epoch": 2.205564364999279,
      "grad_norm": 0.197743758559227,
      "learning_rate": 3.8972418432559705e-05,
      "loss": 0.0002,
      "step": 45900
    },
    {
      "epoch": 2.2079669405602806,
      "grad_norm": 0.24558481574058533,
      "learning_rate": 3.8960405554754696e-05,
      "loss": 0.0004,
      "step": 45950
    },
    {
      "epoch": 2.210369516121282,
      "grad_norm": 0.1751820594072342,
      "learning_rate": 3.894839267694969e-05,
      "loss": 0.0002,
      "step": 46000
    },
    {
      "epoch": 2.2127720916822833,
      "grad_norm": 0.11247367411851883,
      "learning_rate": 3.8936379799144684e-05,
      "loss": 0.0002,
      "step": 46050
    },
    {
      "epoch": 2.215174667243285,
      "grad_norm": 0.2853730022907257,
      "learning_rate": 3.8924366921339675e-05,
      "loss": 0.0002,
      "step": 46100
    },
    {
      "epoch": 2.2175772428042864,
      "grad_norm": 0.09567580372095108,
      "learning_rate": 3.891235404353467e-05,
      "loss": 0.0002,
      "step": 46150
    },
    {
      "epoch": 2.2199798183652875,
      "grad_norm": 0.39147040247917175,
      "learning_rate": 3.890034116572966e-05,
      "loss": 0.0002,
      "step": 46200
    },
    {
      "epoch": 2.222382393926289,
      "grad_norm": 0.4635055363178253,
      "learning_rate": 3.888832828792466e-05,
      "loss": 0.0002,
      "step": 46250
    },
    {
      "epoch": 2.2247849694872905,
      "grad_norm": 0.38999322056770325,
      "learning_rate": 3.887631541011965e-05,
      "loss": 0.0002,
      "step": 46300
    },
    {
      "epoch": 2.2271875450482916,
      "grad_norm": 0.12246672809123993,
      "learning_rate": 3.886430253231464e-05,
      "loss": 0.0002,
      "step": 46350
    },
    {
      "epoch": 2.229590120609293,
      "grad_norm": 0.17675887048244476,
      "learning_rate": 3.885228965450964e-05,
      "loss": 0.0002,
      "step": 46400
    },
    {
      "epoch": 2.2319926961702947,
      "grad_norm": 0.1821049302816391,
      "learning_rate": 3.884027677670463e-05,
      "loss": 0.0003,
      "step": 46450
    },
    {
      "epoch": 2.234395271731296,
      "grad_norm": 0.13072609901428223,
      "learning_rate": 3.882826389889962e-05,
      "loss": 0.0004,
      "step": 46500
    },
    {
      "epoch": 2.2367978472922974,
      "grad_norm": 0.09296075254678726,
      "learning_rate": 3.881625102109461e-05,
      "loss": 0.0002,
      "step": 46550
    },
    {
      "epoch": 2.239200422853299,
      "grad_norm": 0.4073535203933716,
      "learning_rate": 3.88042381432896e-05,
      "loss": 0.0002,
      "step": 46600
    },
    {
      "epoch": 2.2416029984143,
      "grad_norm": 0.09300295263528824,
      "learning_rate": 3.87922252654846e-05,
      "loss": 0.0002,
      "step": 46650
    },
    {
      "epoch": 2.2440055739753015,
      "grad_norm": 0.4531802833080292,
      "learning_rate": 3.878021238767959e-05,
      "loss": 0.0002,
      "step": 46700
    },
    {
      "epoch": 2.246408149536303,
      "grad_norm": 0.34606680274009705,
      "learning_rate": 3.876819950987459e-05,
      "loss": 0.0002,
      "step": 46750
    },
    {
      "epoch": 2.248810725097304,
      "grad_norm": 0.1436464935541153,
      "learning_rate": 3.875618663206958e-05,
      "loss": 0.0002,
      "step": 46800
    },
    {
      "epoch": 2.2512133006583057,
      "grad_norm": 0.40555405616760254,
      "learning_rate": 3.874417375426457e-05,
      "loss": 0.0002,
      "step": 46850
    },
    {
      "epoch": 2.2536158762193073,
      "grad_norm": 0.43795648217201233,
      "learning_rate": 3.873216087645957e-05,
      "loss": 0.0002,
      "step": 46900
    },
    {
      "epoch": 2.2560184517803084,
      "grad_norm": 0.1046232357621193,
      "learning_rate": 3.872014799865456e-05,
      "loss": 0.0002,
      "step": 46950
    },
    {
      "epoch": 2.25842102734131,
      "grad_norm": 0.24463315308094025,
      "learning_rate": 3.870813512084955e-05,
      "loss": 0.0002,
      "step": 47000
    },
    {
      "epoch": 2.2608236029023114,
      "grad_norm": 0.05556382238864899,
      "learning_rate": 3.869612224304455e-05,
      "loss": 0.0002,
      "step": 47050
    },
    {
      "epoch": 2.2632261784633125,
      "grad_norm": 0.227471262216568,
      "learning_rate": 3.868410936523954e-05,
      "loss": 0.0006,
      "step": 47100
    },
    {
      "epoch": 2.265628754024314,
      "grad_norm": 0.4110322892665863,
      "learning_rate": 3.8672096487434536e-05,
      "loss": 0.0002,
      "step": 47150
    },
    {
      "epoch": 2.2680313295853156,
      "grad_norm": 0.21994423866271973,
      "learning_rate": 3.866008360962953e-05,
      "loss": 0.0002,
      "step": 47200
    },
    {
      "epoch": 2.2704339051463167,
      "grad_norm": 0.09547950327396393,
      "learning_rate": 3.864807073182452e-05,
      "loss": 0.0002,
      "step": 47250
    },
    {
      "epoch": 2.2728364807073183,
      "grad_norm": 0.12142513692378998,
      "learning_rate": 3.863605785401951e-05,
      "loss": 0.0002,
      "step": 47300
    },
    {
      "epoch": 2.27523905626832,
      "grad_norm": 0.6295325756072998,
      "learning_rate": 3.86240449762145e-05,
      "loss": 0.0002,
      "step": 47350
    },
    {
      "epoch": 2.277641631829321,
      "grad_norm": 0.6719062328338623,
      "learning_rate": 3.86120320984095e-05,
      "loss": 0.0002,
      "step": 47400
    },
    {
      "epoch": 2.2800442073903224,
      "grad_norm": 0.12468872219324112,
      "learning_rate": 3.860001922060449e-05,
      "loss": 0.0007,
      "step": 47450
    },
    {
      "epoch": 2.282446782951324,
      "grad_norm": 0.11861356347799301,
      "learning_rate": 3.858800634279948e-05,
      "loss": 0.0002,
      "step": 47500
    },
    {
      "epoch": 2.284849358512325,
      "grad_norm": 0.2106127142906189,
      "learning_rate": 3.8575993464994476e-05,
      "loss": 0.0003,
      "step": 47550
    },
    {
      "epoch": 2.2872519340733266,
      "grad_norm": 0.4300028681755066,
      "learning_rate": 3.856398058718947e-05,
      "loss": 0.0002,
      "step": 47600
    },
    {
      "epoch": 2.289654509634328,
      "grad_norm": 0.10016258805990219,
      "learning_rate": 3.8551967709384465e-05,
      "loss": 0.0007,
      "step": 47650
    },
    {
      "epoch": 2.2920570851953292,
      "grad_norm": 0.48838913440704346,
      "learning_rate": 3.8539954831579456e-05,
      "loss": 0.0002,
      "step": 47700
    },
    {
      "epoch": 2.294459660756331,
      "grad_norm": 0.1635732352733612,
      "learning_rate": 3.8527941953774447e-05,
      "loss": 0.0003,
      "step": 47750
    },
    {
      "epoch": 2.2968622363173323,
      "grad_norm": 0.1319694072008133,
      "learning_rate": 3.8515929075969444e-05,
      "loss": 0.0004,
      "step": 47800
    },
    {
      "epoch": 2.2992648118783334,
      "grad_norm": 0.04599343240261078,
      "learning_rate": 3.8503916198164435e-05,
      "loss": 0.0003,
      "step": 47850
    },
    {
      "epoch": 2.301667387439335,
      "grad_norm": 0.09006187319755554,
      "learning_rate": 3.849190332035943e-05,
      "loss": 0.0002,
      "step": 47900
    },
    {
      "epoch": 2.3040699630003365,
      "grad_norm": 0.2344038337469101,
      "learning_rate": 3.847989044255442e-05,
      "loss": 0.0002,
      "step": 47950
    },
    {
      "epoch": 2.3064725385613376,
      "grad_norm": 0.38019007444381714,
      "learning_rate": 3.846787756474941e-05,
      "loss": 0.0005,
      "step": 48000
    },
    {
      "epoch": 2.308875114122339,
      "grad_norm": 0.3635117709636688,
      "learning_rate": 3.8455864686944405e-05,
      "loss": 0.0002,
      "step": 48050
    },
    {
      "epoch": 2.3112776896833407,
      "grad_norm": 0.07384950667619705,
      "learning_rate": 3.8443851809139396e-05,
      "loss": 0.0002,
      "step": 48100
    },
    {
      "epoch": 2.313680265244342,
      "grad_norm": 0.4024459719657898,
      "learning_rate": 3.8431838931334393e-05,
      "loss": 0.0002,
      "step": 48150
    },
    {
      "epoch": 2.3160828408053433,
      "grad_norm": 0.08477889001369476,
      "learning_rate": 3.8419826053529384e-05,
      "loss": 0.0008,
      "step": 48200
    },
    {
      "epoch": 2.318485416366345,
      "grad_norm": 0.1254250705242157,
      "learning_rate": 3.8407813175724375e-05,
      "loss": 0.0002,
      "step": 48250
    },
    {
      "epoch": 2.320887991927346,
      "grad_norm": 0.17924603819847107,
      "learning_rate": 3.839580029791937e-05,
      "loss": 0.0003,
      "step": 48300
    },
    {
      "epoch": 2.3232905674883475,
      "grad_norm": 0.2117638885974884,
      "learning_rate": 3.8383787420114364e-05,
      "loss": 0.0002,
      "step": 48350
    },
    {
      "epoch": 2.325693143049349,
      "grad_norm": 0.28624579310417175,
      "learning_rate": 3.837177454230936e-05,
      "loss": 0.0002,
      "step": 48400
    },
    {
      "epoch": 2.32809571861035,
      "grad_norm": 0.08892606198787689,
      "learning_rate": 3.835976166450435e-05,
      "loss": 0.0002,
      "step": 48450
    },
    {
      "epoch": 2.3304982941713517,
      "grad_norm": 0.0941028967499733,
      "learning_rate": 3.834774878669934e-05,
      "loss": 0.0002,
      "step": 48500
    },
    {
      "epoch": 2.332900869732353,
      "grad_norm": 0.18067900836467743,
      "learning_rate": 3.833573590889434e-05,
      "loss": 0.0002,
      "step": 48550
    },
    {
      "epoch": 2.3353034452933543,
      "grad_norm": 0.20226265490055084,
      "learning_rate": 3.832372303108933e-05,
      "loss": 0.0002,
      "step": 48600
    },
    {
      "epoch": 2.337706020854356,
      "grad_norm": 0.13538451492786407,
      "learning_rate": 3.831171015328432e-05,
      "loss": 0.0002,
      "step": 48650
    },
    {
      "epoch": 2.3401085964153574,
      "grad_norm": 0.08994276821613312,
      "learning_rate": 3.829969727547932e-05,
      "loss": 0.0002,
      "step": 48700
    },
    {
      "epoch": 2.3425111719763585,
      "grad_norm": 0.1354120373725891,
      "learning_rate": 3.8287684397674304e-05,
      "loss": 0.0002,
      "step": 48750
    },
    {
      "epoch": 2.34491374753736,
      "grad_norm": 0.24066859483718872,
      "learning_rate": 3.82756715198693e-05,
      "loss": 0.0002,
      "step": 48800
    },
    {
      "epoch": 2.3473163230983616,
      "grad_norm": 0.10691478848457336,
      "learning_rate": 3.826365864206429e-05,
      "loss": 0.0007,
      "step": 48850
    },
    {
      "epoch": 2.3497188986593627,
      "grad_norm": 0.0874600037932396,
      "learning_rate": 3.825164576425928e-05,
      "loss": 0.0002,
      "step": 48900
    },
    {
      "epoch": 2.352121474220364,
      "grad_norm": 0.31997138261795044,
      "learning_rate": 3.823963288645428e-05,
      "loss": 0.0002,
      "step": 48950
    },
    {
      "epoch": 2.3545240497813658,
      "grad_norm": 0.2814038395881653,
      "learning_rate": 3.822762000864927e-05,
      "loss": 0.0008,
      "step": 49000
    },
    {
      "epoch": 2.356926625342367,
      "grad_norm": 0.36560970544815063,
      "learning_rate": 3.821560713084427e-05,
      "loss": 0.0003,
      "step": 49050
    },
    {
      "epoch": 2.3593292009033684,
      "grad_norm": 0.25672438740730286,
      "learning_rate": 3.820359425303926e-05,
      "loss": 0.0002,
      "step": 49100
    },
    {
      "epoch": 2.36173177646437,
      "grad_norm": 0.23986707627773285,
      "learning_rate": 3.819158137523425e-05,
      "loss": 0.0002,
      "step": 49150
    },
    {
      "epoch": 2.364134352025371,
      "grad_norm": 0.3090210258960724,
      "learning_rate": 3.817956849742925e-05,
      "loss": 0.0002,
      "step": 49200
    },
    {
      "epoch": 2.3665369275863726,
      "grad_norm": 0.4023008346557617,
      "learning_rate": 3.816755561962424e-05,
      "loss": 0.0001,
      "step": 49250
    },
    {
      "epoch": 2.368939503147374,
      "grad_norm": 0.31471356749534607,
      "learning_rate": 3.815554274181924e-05,
      "loss": 0.0008,
      "step": 49300
    },
    {
      "epoch": 2.371342078708375,
      "grad_norm": 0.11113991588354111,
      "learning_rate": 3.814352986401423e-05,
      "loss": 0.0002,
      "step": 49350
    },
    {
      "epoch": 2.3737446542693768,
      "grad_norm": 0.05126139149069786,
      "learning_rate": 3.813151698620922e-05,
      "loss": 0.0002,
      "step": 49400
    },
    {
      "epoch": 2.3761472298303783,
      "grad_norm": 0.1446407288312912,
      "learning_rate": 3.8119504108404216e-05,
      "loss": 0.0003,
      "step": 49450
    },
    {
      "epoch": 2.3785498053913794,
      "grad_norm": 0.10285584628582001,
      "learning_rate": 3.81074912305992e-05,
      "loss": 0.0003,
      "step": 49500
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.043738093227148056,
      "learning_rate": 3.80954783527942e-05,
      "loss": 0.0002,
      "step": 49550
    },
    {
      "epoch": 2.3833549565133825,
      "grad_norm": 0.2358756959438324,
      "learning_rate": 3.808346547498919e-05,
      "loss": 0.0002,
      "step": 49600
    },
    {
      "epoch": 2.3857575320743836,
      "grad_norm": 0.3792881369590759,
      "learning_rate": 3.807145259718418e-05,
      "loss": 0.0002,
      "step": 49650
    },
    {
      "epoch": 2.388160107635385,
      "grad_norm": 0.08486293256282806,
      "learning_rate": 3.805943971937918e-05,
      "loss": 0.0002,
      "step": 49700
    },
    {
      "epoch": 2.3905626831963867,
      "grad_norm": 0.39307117462158203,
      "learning_rate": 3.804742684157417e-05,
      "loss": 0.0002,
      "step": 49750
    },
    {
      "epoch": 2.3929652587573877,
      "grad_norm": 0.1099986657500267,
      "learning_rate": 3.8035413963769165e-05,
      "loss": 0.0002,
      "step": 49800
    },
    {
      "epoch": 2.3953678343183893,
      "grad_norm": 0.7376587390899658,
      "learning_rate": 3.8023401085964156e-05,
      "loss": 0.0001,
      "step": 49850
    },
    {
      "epoch": 2.397770409879391,
      "grad_norm": 0.15547412633895874,
      "learning_rate": 3.801138820815915e-05,
      "loss": 0.0002,
      "step": 49900
    },
    {
      "epoch": 2.400172985440392,
      "grad_norm": 0.14255261421203613,
      "learning_rate": 3.7999375330354144e-05,
      "loss": 0.0002,
      "step": 49950
    },
    {
      "epoch": 2.4025755610013935,
      "grad_norm": 0.1653076559305191,
      "learning_rate": 3.7987362452549135e-05,
      "loss": 0.0002,
      "step": 50000
    },
    {
      "epoch": 2.404978136562395,
      "grad_norm": 0.12228445708751678,
      "learning_rate": 3.7975349574744126e-05,
      "loss": 0.0002,
      "step": 50050
    },
    {
      "epoch": 2.407380712123396,
      "grad_norm": 0.4376882314682007,
      "learning_rate": 3.7963336696939124e-05,
      "loss": 0.0007,
      "step": 50100
    },
    {
      "epoch": 2.4097832876843976,
      "grad_norm": 0.46222320199012756,
      "learning_rate": 3.7951323819134115e-05,
      "loss": 0.0008,
      "step": 50150
    },
    {
      "epoch": 2.412185863245399,
      "grad_norm": 0.10343153774738312,
      "learning_rate": 3.793931094132911e-05,
      "loss": 0.0003,
      "step": 50200
    },
    {
      "epoch": 2.4145884388064003,
      "grad_norm": 0.03602554649114609,
      "learning_rate": 3.7927298063524096e-05,
      "loss": 0.0002,
      "step": 50250
    },
    {
      "epoch": 2.416991014367402,
      "grad_norm": 0.10716433078050613,
      "learning_rate": 3.7915285185719094e-05,
      "loss": 0.0002,
      "step": 50300
    },
    {
      "epoch": 2.4193935899284034,
      "grad_norm": 0.19749261438846588,
      "learning_rate": 3.7903272307914085e-05,
      "loss": 0.0008,
      "step": 50350
    },
    {
      "epoch": 2.4217961654894045,
      "grad_norm": 0.1452750414609909,
      "learning_rate": 3.7891259430109075e-05,
      "loss": 0.0002,
      "step": 50400
    },
    {
      "epoch": 2.424198741050406,
      "grad_norm": 0.37786754965782166,
      "learning_rate": 3.787924655230407e-05,
      "loss": 0.0008,
      "step": 50450
    },
    {
      "epoch": 2.4266013166114075,
      "grad_norm": 0.2393411546945572,
      "learning_rate": 3.7867233674499064e-05,
      "loss": 0.0002,
      "step": 50500
    },
    {
      "epoch": 2.4290038921724086,
      "grad_norm": 0.29843002557754517,
      "learning_rate": 3.7855220796694055e-05,
      "loss": 0.0001,
      "step": 50550
    },
    {
      "epoch": 2.43140646773341,
      "grad_norm": 0.184634730219841,
      "learning_rate": 3.784320791888905e-05,
      "loss": 0.0002,
      "step": 50600
    },
    {
      "epoch": 2.4338090432944117,
      "grad_norm": 0.45991194248199463,
      "learning_rate": 3.783119504108404e-05,
      "loss": 0.0003,
      "step": 50650
    },
    {
      "epoch": 2.436211618855413,
      "grad_norm": 0.6050354242324829,
      "learning_rate": 3.781918216327904e-05,
      "loss": 0.0002,
      "step": 50700
    },
    {
      "epoch": 2.4386141944164144,
      "grad_norm": 0.09481147676706314,
      "learning_rate": 3.780716928547403e-05,
      "loss": 0.0002,
      "step": 50750
    },
    {
      "epoch": 2.441016769977416,
      "grad_norm": 0.3847770392894745,
      "learning_rate": 3.779515640766902e-05,
      "loss": 0.0002,
      "step": 50800
    },
    {
      "epoch": 2.443419345538417,
      "grad_norm": 0.10233603417873383,
      "learning_rate": 3.778314352986402e-05,
      "loss": 0.0009,
      "step": 50850
    },
    {
      "epoch": 2.4458219210994185,
      "grad_norm": 0.37040889263153076,
      "learning_rate": 3.777113065205901e-05,
      "loss": 0.0002,
      "step": 50900
    },
    {
      "epoch": 2.44822449666042,
      "grad_norm": 0.218481183052063,
      "learning_rate": 3.7759117774254e-05,
      "loss": 0.0008,
      "step": 50950
    },
    {
      "epoch": 2.450627072221421,
      "grad_norm": 0.5414186716079712,
      "learning_rate": 3.774710489644899e-05,
      "loss": 0.0002,
      "step": 51000
    },
    {
      "epoch": 2.4530296477824227,
      "grad_norm": 0.23799927532672882,
      "learning_rate": 3.773509201864398e-05,
      "loss": 0.0002,
      "step": 51050
    },
    {
      "epoch": 2.4554322233434243,
      "grad_norm": 0.25309744477272034,
      "learning_rate": 3.772307914083898e-05,
      "loss": 0.0002,
      "step": 51100
    },
    {
      "epoch": 2.4578347989044254,
      "grad_norm": 0.3381919264793396,
      "learning_rate": 3.771106626303397e-05,
      "loss": 0.0002,
      "step": 51150
    },
    {
      "epoch": 2.460237374465427,
      "grad_norm": 0.12927356362342834,
      "learning_rate": 3.769905338522897e-05,
      "loss": 0.0002,
      "step": 51200
    },
    {
      "epoch": 2.4626399500264284,
      "grad_norm": 0.2930889129638672,
      "learning_rate": 3.768704050742396e-05,
      "loss": 0.0007,
      "step": 51250
    },
    {
      "epoch": 2.4650425255874295,
      "grad_norm": 0.3558719754219055,
      "learning_rate": 3.767502762961895e-05,
      "loss": 0.0003,
      "step": 51300
    },
    {
      "epoch": 2.467445101148431,
      "grad_norm": 0.28757622838020325,
      "learning_rate": 3.766301475181395e-05,
      "loss": 0.0002,
      "step": 51350
    },
    {
      "epoch": 2.4698476767094326,
      "grad_norm": 0.11288436502218246,
      "learning_rate": 3.765100187400894e-05,
      "loss": 0.0002,
      "step": 51400
    },
    {
      "epoch": 2.4722502522704337,
      "grad_norm": 0.4627736210823059,
      "learning_rate": 3.763898899620393e-05,
      "loss": 0.0003,
      "step": 51450
    },
    {
      "epoch": 2.4746528278314353,
      "grad_norm": 0.5505245923995972,
      "learning_rate": 3.762697611839893e-05,
      "loss": 0.0002,
      "step": 51500
    },
    {
      "epoch": 2.477055403392437,
      "grad_norm": 0.3267301619052887,
      "learning_rate": 3.761496324059392e-05,
      "loss": 0.0002,
      "step": 51550
    },
    {
      "epoch": 2.4794579789534383,
      "grad_norm": 0.1997688263654709,
      "learning_rate": 3.7602950362788916e-05,
      "loss": 0.0002,
      "step": 51600
    },
    {
      "epoch": 2.4818605545144394,
      "grad_norm": 0.4149623513221741,
      "learning_rate": 3.759093748498391e-05,
      "loss": 0.0002,
      "step": 51650
    },
    {
      "epoch": 2.484263130075441,
      "grad_norm": 0.18498247861862183,
      "learning_rate": 3.75789246071789e-05,
      "loss": 0.0002,
      "step": 51700
    },
    {
      "epoch": 2.486665705636442,
      "grad_norm": 0.24773864448070526,
      "learning_rate": 3.756691172937389e-05,
      "loss": 0.0003,
      "step": 51750
    },
    {
      "epoch": 2.4890682811974436,
      "grad_norm": 0.7102482318878174,
      "learning_rate": 3.755489885156888e-05,
      "loss": 0.0002,
      "step": 51800
    },
    {
      "epoch": 2.491470856758445,
      "grad_norm": 0.10710954666137695,
      "learning_rate": 3.754288597376388e-05,
      "loss": 0.0002,
      "step": 51850
    },
    {
      "epoch": 2.4938734323194467,
      "grad_norm": 0.09799814224243164,
      "learning_rate": 3.753087309595887e-05,
      "loss": 0.0003,
      "step": 51900
    },
    {
      "epoch": 2.496276007880448,
      "grad_norm": 0.2386482059955597,
      "learning_rate": 3.751886021815386e-05,
      "loss": 0.0002,
      "step": 51950
    },
    {
      "epoch": 2.4986785834414493,
      "grad_norm": 0.3243923783302307,
      "learning_rate": 3.7506847340348856e-05,
      "loss": 0.0002,
      "step": 52000
    },
    {
      "epoch": 2.5010811590024504,
      "grad_norm": 0.07943504303693771,
      "learning_rate": 3.749483446254385e-05,
      "loss": 0.0001,
      "step": 52050
    },
    {
      "epoch": 2.503483734563452,
      "grad_norm": 0.30110156536102295,
      "learning_rate": 3.7482821584738845e-05,
      "loss": 0.0002,
      "step": 52100
    },
    {
      "epoch": 2.5058863101244535,
      "grad_norm": 0.1590431183576584,
      "learning_rate": 3.7470808706933836e-05,
      "loss": 0.0002,
      "step": 52150
    },
    {
      "epoch": 2.508288885685455,
      "grad_norm": 0.5003302693367004,
      "learning_rate": 3.7458795829128826e-05,
      "loss": 0.0002,
      "step": 52200
    },
    {
      "epoch": 2.510691461246456,
      "grad_norm": 0.5206578373908997,
      "learning_rate": 3.7446782951323824e-05,
      "loss": 0.0004,
      "step": 52250
    },
    {
      "epoch": 2.5130940368074577,
      "grad_norm": 0.06755098700523376,
      "learning_rate": 3.7434770073518815e-05,
      "loss": 0.0003,
      "step": 52300
    },
    {
      "epoch": 2.515496612368459,
      "grad_norm": 0.21326224505901337,
      "learning_rate": 3.7422757195713806e-05,
      "loss": 0.0002,
      "step": 52350
    },
    {
      "epoch": 2.5178991879294603,
      "grad_norm": 0.09875672310590744,
      "learning_rate": 3.74107443179088e-05,
      "loss": 0.0002,
      "step": 52400
    },
    {
      "epoch": 2.520301763490462,
      "grad_norm": 0.6611276865005493,
      "learning_rate": 3.7398731440103794e-05,
      "loss": 0.0003,
      "step": 52450
    },
    {
      "epoch": 2.5227043390514634,
      "grad_norm": 0.23391130566596985,
      "learning_rate": 3.7386718562298785e-05,
      "loss": 0.0002,
      "step": 52500
    },
    {
      "epoch": 2.5251069146124645,
      "grad_norm": 0.14441046118736267,
      "learning_rate": 3.7374705684493776e-05,
      "loss": 0.0003,
      "step": 52550
    },
    {
      "epoch": 2.527509490173466,
      "grad_norm": 0.563559889793396,
      "learning_rate": 3.7362692806688773e-05,
      "loss": 0.0002,
      "step": 52600
    },
    {
      "epoch": 2.529912065734467,
      "grad_norm": 0.23592722415924072,
      "learning_rate": 3.7350679928883764e-05,
      "loss": 0.0003,
      "step": 52650
    },
    {
      "epoch": 2.5323146412954687,
      "grad_norm": 0.07672334462404251,
      "learning_rate": 3.7338667051078755e-05,
      "loss": 0.0002,
      "step": 52700
    },
    {
      "epoch": 2.5347172168564702,
      "grad_norm": 0.0799083411693573,
      "learning_rate": 3.732665417327375e-05,
      "loss": 0.0002,
      "step": 52750
    },
    {
      "epoch": 2.5371197924174718,
      "grad_norm": 0.5809189081192017,
      "learning_rate": 3.7314641295468744e-05,
      "loss": 0.0002,
      "step": 52800
    },
    {
      "epoch": 2.539522367978473,
      "grad_norm": 0.08100728690624237,
      "learning_rate": 3.7302628417663734e-05,
      "loss": 0.0002,
      "step": 52850
    },
    {
      "epoch": 2.5419249435394744,
      "grad_norm": 0.09180594235658646,
      "learning_rate": 3.729061553985873e-05,
      "loss": 0.0002,
      "step": 52900
    },
    {
      "epoch": 2.5443275191004755,
      "grad_norm": 0.44057005643844604,
      "learning_rate": 3.727860266205372e-05,
      "loss": 0.0002,
      "step": 52950
    },
    {
      "epoch": 2.546730094661477,
      "grad_norm": 0.10486789047718048,
      "learning_rate": 3.726658978424872e-05,
      "loss": 0.0002,
      "step": 53000
    },
    {
      "epoch": 2.5491326702224786,
      "grad_norm": 0.14027944207191467,
      "learning_rate": 3.725457690644371e-05,
      "loss": 0.0002,
      "step": 53050
    },
    {
      "epoch": 2.55153524578348,
      "grad_norm": 0.278820276260376,
      "learning_rate": 3.72425640286387e-05,
      "loss": 0.0002,
      "step": 53100
    },
    {
      "epoch": 2.553937821344481,
      "grad_norm": 0.644394040107727,
      "learning_rate": 3.72305511508337e-05,
      "loss": 0.0002,
      "step": 53150
    },
    {
      "epoch": 2.5563403969054828,
      "grad_norm": 0.1784939020872116,
      "learning_rate": 3.7218538273028684e-05,
      "loss": 0.0002,
      "step": 53200
    },
    {
      "epoch": 2.558742972466484,
      "grad_norm": 0.10272198170423508,
      "learning_rate": 3.720652539522368e-05,
      "loss": 0.0008,
      "step": 53250
    },
    {
      "epoch": 2.5611455480274854,
      "grad_norm": 0.3645307421684265,
      "learning_rate": 3.719451251741867e-05,
      "loss": 0.0002,
      "step": 53300
    },
    {
      "epoch": 2.563548123588487,
      "grad_norm": 0.34352564811706543,
      "learning_rate": 3.718249963961366e-05,
      "loss": 0.0002,
      "step": 53350
    },
    {
      "epoch": 2.5659506991494885,
      "grad_norm": 0.5890789031982422,
      "learning_rate": 3.717048676180866e-05,
      "loss": 0.0003,
      "step": 53400
    },
    {
      "epoch": 2.5683532747104896,
      "grad_norm": 0.5944074988365173,
      "learning_rate": 3.715847388400365e-05,
      "loss": 0.0001,
      "step": 53450
    },
    {
      "epoch": 2.570755850271491,
      "grad_norm": 0.1127852126955986,
      "learning_rate": 3.714646100619865e-05,
      "loss": 0.0002,
      "step": 53500
    },
    {
      "epoch": 2.573158425832492,
      "grad_norm": 0.14454250037670135,
      "learning_rate": 3.713444812839364e-05,
      "loss": 0.0002,
      "step": 53550
    },
    {
      "epoch": 2.5755610013934938,
      "grad_norm": 0.32969504594802856,
      "learning_rate": 3.712243525058863e-05,
      "loss": 0.0002,
      "step": 53600
    },
    {
      "epoch": 2.5779635769544953,
      "grad_norm": 0.4719448387622833,
      "learning_rate": 3.711042237278363e-05,
      "loss": 0.0003,
      "step": 53650
    },
    {
      "epoch": 2.580366152515497,
      "grad_norm": 0.4764336943626404,
      "learning_rate": 3.709840949497862e-05,
      "loss": 0.0003,
      "step": 53700
    },
    {
      "epoch": 2.582768728076498,
      "grad_norm": 0.5071412324905396,
      "learning_rate": 3.708639661717362e-05,
      "loss": 0.0003,
      "step": 53750
    },
    {
      "epoch": 2.5851713036374995,
      "grad_norm": 0.1504550278186798,
      "learning_rate": 3.707438373936861e-05,
      "loss": 0.0002,
      "step": 53800
    },
    {
      "epoch": 2.5875738791985006,
      "grad_norm": 0.29794004559516907,
      "learning_rate": 3.70623708615636e-05,
      "loss": 0.0002,
      "step": 53850
    },
    {
      "epoch": 2.589976454759502,
      "grad_norm": 0.21987727284431458,
      "learning_rate": 3.7050357983758596e-05,
      "loss": 0.0002,
      "step": 53900
    },
    {
      "epoch": 2.5923790303205037,
      "grad_norm": 0.10939463973045349,
      "learning_rate": 3.703834510595358e-05,
      "loss": 0.0002,
      "step": 53950
    },
    {
      "epoch": 2.594781605881505,
      "grad_norm": 0.0334487222135067,
      "learning_rate": 3.702633222814858e-05,
      "loss": 0.0002,
      "step": 54000
    },
    {
      "epoch": 2.5971841814425063,
      "grad_norm": 0.3566013276576996,
      "learning_rate": 3.701431935034357e-05,
      "loss": 0.0002,
      "step": 54050
    },
    {
      "epoch": 2.599586757003508,
      "grad_norm": 0.09371530264616013,
      "learning_rate": 3.700230647253856e-05,
      "loss": 0.0002,
      "step": 54100
    },
    {
      "epoch": 2.601989332564509,
      "grad_norm": 0.18808642029762268,
      "learning_rate": 3.699029359473356e-05,
      "loss": 0.0002,
      "step": 54150
    },
    {
      "epoch": 2.6043919081255105,
      "grad_norm": 0.19455450773239136,
      "learning_rate": 3.697828071692855e-05,
      "loss": 0.0002,
      "step": 54200
    },
    {
      "epoch": 2.606794483686512,
      "grad_norm": 0.4825668931007385,
      "learning_rate": 3.696626783912354e-05,
      "loss": 0.0002,
      "step": 54250
    },
    {
      "epoch": 2.6091970592475136,
      "grad_norm": 0.13681963086128235,
      "learning_rate": 3.6954254961318536e-05,
      "loss": 0.0003,
      "step": 54300
    },
    {
      "epoch": 2.6115996348085146,
      "grad_norm": 0.21227465569972992,
      "learning_rate": 3.694224208351353e-05,
      "loss": 0.0007,
      "step": 54350
    },
    {
      "epoch": 2.614002210369516,
      "grad_norm": 0.18882183730602264,
      "learning_rate": 3.6930229205708524e-05,
      "loss": 0.0002,
      "step": 54400
    },
    {
      "epoch": 2.6164047859305173,
      "grad_norm": 0.18025356531143188,
      "learning_rate": 3.6918216327903515e-05,
      "loss": 0.0002,
      "step": 54450
    },
    {
      "epoch": 2.618807361491519,
      "grad_norm": 0.10352884232997894,
      "learning_rate": 3.6906203450098506e-05,
      "loss": 0.0002,
      "step": 54500
    },
    {
      "epoch": 2.6212099370525204,
      "grad_norm": 0.24329593777656555,
      "learning_rate": 3.6894190572293504e-05,
      "loss": 0.0003,
      "step": 54550
    },
    {
      "epoch": 2.623612512613522,
      "grad_norm": 0.5418544411659241,
      "learning_rate": 3.6882177694488495e-05,
      "loss": 0.0006,
      "step": 54600
    },
    {
      "epoch": 2.626015088174523,
      "grad_norm": 0.2904028296470642,
      "learning_rate": 3.687016481668349e-05,
      "loss": 0.0003,
      "step": 54650
    },
    {
      "epoch": 2.6284176637355245,
      "grad_norm": 0.09099164605140686,
      "learning_rate": 3.6858151938878476e-05,
      "loss": 0.0002,
      "step": 54700
    },
    {
      "epoch": 2.6308202392965256,
      "grad_norm": 0.4799121022224426,
      "learning_rate": 3.684613906107347e-05,
      "loss": 0.0002,
      "step": 54750
    },
    {
      "epoch": 2.633222814857527,
      "grad_norm": 0.10769116133451462,
      "learning_rate": 3.6834126183268465e-05,
      "loss": 0.0002,
      "step": 54800
    },
    {
      "epoch": 2.6356253904185287,
      "grad_norm": 0.1403190791606903,
      "learning_rate": 3.6822113305463455e-05,
      "loss": 0.0002,
      "step": 54850
    },
    {
      "epoch": 2.6380279659795303,
      "grad_norm": 0.3074534237384796,
      "learning_rate": 3.681010042765845e-05,
      "loss": 0.0007,
      "step": 54900
    },
    {
      "epoch": 2.6404305415405314,
      "grad_norm": 0.24213957786560059,
      "learning_rate": 3.6798087549853444e-05,
      "loss": 0.0002,
      "step": 54950
    },
    {
      "epoch": 2.642833117101533,
      "grad_norm": 0.43051019310951233,
      "learning_rate": 3.6786074672048435e-05,
      "loss": 0.0002,
      "step": 55000
    },
    {
      "epoch": 2.645235692662534,
      "grad_norm": 0.4454003870487213,
      "learning_rate": 3.677406179424343e-05,
      "loss": 0.0003,
      "step": 55050
    },
    {
      "epoch": 2.6476382682235355,
      "grad_norm": 0.5818271636962891,
      "learning_rate": 3.676204891643842e-05,
      "loss": 0.0002,
      "step": 55100
    },
    {
      "epoch": 2.650040843784537,
      "grad_norm": 0.05976928025484085,
      "learning_rate": 3.675003603863342e-05,
      "loss": 0.0002,
      "step": 55150
    },
    {
      "epoch": 2.6524434193455386,
      "grad_norm": 0.5529000163078308,
      "learning_rate": 3.673802316082841e-05,
      "loss": 0.0002,
      "step": 55200
    },
    {
      "epoch": 2.6548459949065397,
      "grad_norm": 0.0501321479678154,
      "learning_rate": 3.67260102830234e-05,
      "loss": 0.0002,
      "step": 55250
    },
    {
      "epoch": 2.6572485704675413,
      "grad_norm": 0.11596418917179108,
      "learning_rate": 3.67139974052184e-05,
      "loss": 0.0001,
      "step": 55300
    },
    {
      "epoch": 2.6596511460285424,
      "grad_norm": 0.045816678553819656,
      "learning_rate": 3.670198452741339e-05,
      "loss": 0.0001,
      "step": 55350
    },
    {
      "epoch": 2.662053721589544,
      "grad_norm": 0.23397061228752136,
      "learning_rate": 3.668997164960838e-05,
      "loss": 0.0002,
      "step": 55400
    },
    {
      "epoch": 2.6644562971505454,
      "grad_norm": 0.2910882830619812,
      "learning_rate": 3.667795877180337e-05,
      "loss": 0.0002,
      "step": 55450
    },
    {
      "epoch": 2.666858872711547,
      "grad_norm": 0.2043473720550537,
      "learning_rate": 3.666594589399836e-05,
      "loss": 0.0003,
      "step": 55500
    },
    {
      "epoch": 2.669261448272548,
      "grad_norm": 0.42666324973106384,
      "learning_rate": 3.665393301619336e-05,
      "loss": 0.0002,
      "step": 55550
    },
    {
      "epoch": 2.6716640238335496,
      "grad_norm": 0.31649118661880493,
      "learning_rate": 3.664192013838835e-05,
      "loss": 0.0002,
      "step": 55600
    },
    {
      "epoch": 2.6740665993945507,
      "grad_norm": 0.16380822658538818,
      "learning_rate": 3.662990726058335e-05,
      "loss": 0.0003,
      "step": 55650
    },
    {
      "epoch": 2.6764691749555523,
      "grad_norm": 0.5037558674812317,
      "learning_rate": 3.661789438277834e-05,
      "loss": 0.0002,
      "step": 55700
    },
    {
      "epoch": 2.678871750516554,
      "grad_norm": 0.21932528913021088,
      "learning_rate": 3.660588150497333e-05,
      "loss": 0.0002,
      "step": 55750
    },
    {
      "epoch": 2.6812743260775553,
      "grad_norm": 0.35026466846466064,
      "learning_rate": 3.659386862716833e-05,
      "loss": 0.0002,
      "step": 55800
    },
    {
      "epoch": 2.6836769016385564,
      "grad_norm": 0.1334972381591797,
      "learning_rate": 3.658185574936332e-05,
      "loss": 0.0001,
      "step": 55850
    },
    {
      "epoch": 2.686079477199558,
      "grad_norm": 0.3458475172519684,
      "learning_rate": 3.656984287155831e-05,
      "loss": 0.0003,
      "step": 55900
    },
    {
      "epoch": 2.688482052760559,
      "grad_norm": 0.20839186012744904,
      "learning_rate": 3.655782999375331e-05,
      "loss": 0.0002,
      "step": 55950
    },
    {
      "epoch": 2.6908846283215606,
      "grad_norm": 0.28267744183540344,
      "learning_rate": 3.65458171159483e-05,
      "loss": 0.0002,
      "step": 56000
    },
    {
      "epoch": 2.693287203882562,
      "grad_norm": 0.3657265603542328,
      "learning_rate": 3.6533804238143296e-05,
      "loss": 0.0002,
      "step": 56050
    },
    {
      "epoch": 2.6956897794435637,
      "grad_norm": 0.5480307340621948,
      "learning_rate": 3.652179136033829e-05,
      "loss": 0.0002,
      "step": 56100
    },
    {
      "epoch": 2.698092355004565,
      "grad_norm": 0.06647542864084244,
      "learning_rate": 3.650977848253328e-05,
      "loss": 0.0002,
      "step": 56150
    },
    {
      "epoch": 2.7004949305655663,
      "grad_norm": 0.2355244904756546,
      "learning_rate": 3.649776560472827e-05,
      "loss": 0.0002,
      "step": 56200
    },
    {
      "epoch": 2.7028975061265674,
      "grad_norm": 0.121815986931324,
      "learning_rate": 3.648575272692326e-05,
      "loss": 0.0005,
      "step": 56250
    },
    {
      "epoch": 2.705300081687569,
      "grad_norm": 0.333484411239624,
      "learning_rate": 3.647373984911826e-05,
      "loss": 0.0002,
      "step": 56300
    },
    {
      "epoch": 2.7077026572485705,
      "grad_norm": 0.5949151515960693,
      "learning_rate": 3.646172697131325e-05,
      "loss": 0.0002,
      "step": 56350
    },
    {
      "epoch": 2.710105232809572,
      "grad_norm": 0.30611780285835266,
      "learning_rate": 3.644971409350824e-05,
      "loss": 0.0002,
      "step": 56400
    },
    {
      "epoch": 2.712507808370573,
      "grad_norm": 0.3236773908138275,
      "learning_rate": 3.6437701215703236e-05,
      "loss": 0.0002,
      "step": 56450
    },
    {
      "epoch": 2.7149103839315747,
      "grad_norm": 0.08755000680685043,
      "learning_rate": 3.642568833789823e-05,
      "loss": 0.0002,
      "step": 56500
    },
    {
      "epoch": 2.717312959492576,
      "grad_norm": 0.054948482662439346,
      "learning_rate": 3.6413675460093225e-05,
      "loss": 0.0002,
      "step": 56550
    },
    {
      "epoch": 2.7197155350535773,
      "grad_norm": 0.3389332592487335,
      "learning_rate": 3.6401662582288216e-05,
      "loss": 0.0003,
      "step": 56600
    },
    {
      "epoch": 2.722118110614579,
      "grad_norm": 0.32162198424339294,
      "learning_rate": 3.6389649704483206e-05,
      "loss": 0.0002,
      "step": 56650
    },
    {
      "epoch": 2.7245206861755804,
      "grad_norm": 0.34189268946647644,
      "learning_rate": 3.6377636826678204e-05,
      "loss": 0.0003,
      "step": 56700
    },
    {
      "epoch": 2.7269232617365815,
      "grad_norm": 0.19701164960861206,
      "learning_rate": 3.6365623948873195e-05,
      "loss": 0.0002,
      "step": 56750
    },
    {
      "epoch": 2.729325837297583,
      "grad_norm": 0.1230122372508049,
      "learning_rate": 3.6353611071068186e-05,
      "loss": 0.0002,
      "step": 56800
    },
    {
      "epoch": 2.731728412858584,
      "grad_norm": 0.08125215768814087,
      "learning_rate": 3.634159819326318e-05,
      "loss": 0.0002,
      "step": 56850
    },
    {
      "epoch": 2.7341309884195857,
      "grad_norm": 0.20897063612937927,
      "learning_rate": 3.6329585315458174e-05,
      "loss": 0.0002,
      "step": 56900
    },
    {
      "epoch": 2.7365335639805872,
      "grad_norm": 0.1144193708896637,
      "learning_rate": 3.6317572437653165e-05,
      "loss": 0.0002,
      "step": 56950
    },
    {
      "epoch": 2.7389361395415888,
      "grad_norm": 0.7413998246192932,
      "learning_rate": 3.6305559559848156e-05,
      "loss": 0.0002,
      "step": 57000
    },
    {
      "epoch": 2.74133871510259,
      "grad_norm": 0.3722517192363739,
      "learning_rate": 3.6293546682043153e-05,
      "loss": 0.0002,
      "step": 57050
    },
    {
      "epoch": 2.7437412906635914,
      "grad_norm": 0.15225309133529663,
      "learning_rate": 3.6281533804238144e-05,
      "loss": 0.0002,
      "step": 57100
    },
    {
      "epoch": 2.7461438662245925,
      "grad_norm": 0.3325161337852478,
      "learning_rate": 3.6269520926433135e-05,
      "loss": 0.0008,
      "step": 57150
    },
    {
      "epoch": 2.748546441785594,
      "grad_norm": 0.10239283740520477,
      "learning_rate": 3.625750804862813e-05,
      "loss": 0.0002,
      "step": 57200
    },
    {
      "epoch": 2.7509490173465956,
      "grad_norm": 0.16658906638622284,
      "learning_rate": 3.6245495170823123e-05,
      "loss": 0.0003,
      "step": 57250
    },
    {
      "epoch": 2.753351592907597,
      "grad_norm": 0.12313847243785858,
      "learning_rate": 3.6233482293018114e-05,
      "loss": 0.0002,
      "step": 57300
    },
    {
      "epoch": 2.755754168468598,
      "grad_norm": 0.3002023696899414,
      "learning_rate": 3.622146941521311e-05,
      "loss": 0.0003,
      "step": 57350
    },
    {
      "epoch": 2.7581567440295998,
      "grad_norm": 0.37435582280158997,
      "learning_rate": 3.62094565374081e-05,
      "loss": 0.0003,
      "step": 57400
    },
    {
      "epoch": 2.760559319590601,
      "grad_norm": 0.17905960977077484,
      "learning_rate": 3.61974436596031e-05,
      "loss": 0.0002,
      "step": 57450
    },
    {
      "epoch": 2.7629618951516024,
      "grad_norm": 0.1008433848619461,
      "learning_rate": 3.618543078179809e-05,
      "loss": 0.0002,
      "step": 57500
    },
    {
      "epoch": 2.765364470712604,
      "grad_norm": 0.03774898871779442,
      "learning_rate": 3.617341790399308e-05,
      "loss": 0.0002,
      "step": 57550
    },
    {
      "epoch": 2.7677670462736055,
      "grad_norm": 0.3929581642150879,
      "learning_rate": 3.616140502618808e-05,
      "loss": 0.0008,
      "step": 57600
    },
    {
      "epoch": 2.7701696218346066,
      "grad_norm": 0.47515854239463806,
      "learning_rate": 3.614939214838307e-05,
      "loss": 0.0002,
      "step": 57650
    },
    {
      "epoch": 2.772572197395608,
      "grad_norm": 0.26311033964157104,
      "learning_rate": 3.613737927057806e-05,
      "loss": 0.0002,
      "step": 57700
    },
    {
      "epoch": 2.774974772956609,
      "grad_norm": 0.4156136214733124,
      "learning_rate": 3.612536639277305e-05,
      "loss": 0.0002,
      "step": 57750
    },
    {
      "epoch": 2.7773773485176108,
      "grad_norm": 0.11442884802818298,
      "learning_rate": 3.611335351496804e-05,
      "loss": 0.0002,
      "step": 57800
    },
    {
      "epoch": 2.7797799240786123,
      "grad_norm": 0.19366896152496338,
      "learning_rate": 3.610134063716304e-05,
      "loss": 0.0002,
      "step": 57850
    },
    {
      "epoch": 2.782182499639614,
      "grad_norm": 0.5582253336906433,
      "learning_rate": 3.608932775935803e-05,
      "loss": 0.0002,
      "step": 57900
    },
    {
      "epoch": 2.784585075200615,
      "grad_norm": 0.20676252245903015,
      "learning_rate": 3.607731488155303e-05,
      "loss": 0.0002,
      "step": 57950
    },
    {
      "epoch": 2.7869876507616165,
      "grad_norm": 0.11378257721662521,
      "learning_rate": 3.606530200374802e-05,
      "loss": 0.0002,
      "step": 58000
    },
    {
      "epoch": 2.7893902263226176,
      "grad_norm": 0.2739375829696655,
      "learning_rate": 3.605328912594301e-05,
      "loss": 0.0002,
      "step": 58050
    },
    {
      "epoch": 2.791792801883619,
      "grad_norm": 0.03912493586540222,
      "learning_rate": 3.604127624813801e-05,
      "loss": 0.0002,
      "step": 58100
    },
    {
      "epoch": 2.7941953774446207,
      "grad_norm": 0.07764041423797607,
      "learning_rate": 3.6029263370333e-05,
      "loss": 0.0001,
      "step": 58150
    },
    {
      "epoch": 2.796597953005622,
      "grad_norm": 0.19964757561683655,
      "learning_rate": 3.601725049252799e-05,
      "loss": 0.0002,
      "step": 58200
    },
    {
      "epoch": 2.7990005285666233,
      "grad_norm": 0.1482921838760376,
      "learning_rate": 3.600523761472299e-05,
      "loss": 0.0003,
      "step": 58250
    },
    {
      "epoch": 2.801403104127625,
      "grad_norm": 0.06824938952922821,
      "learning_rate": 3.599322473691798e-05,
      "loss": 0.0002,
      "step": 58300
    },
    {
      "epoch": 2.8038056796886264,
      "grad_norm": 0.6796367764472961,
      "learning_rate": 3.5981211859112976e-05,
      "loss": 0.0009,
      "step": 58350
    },
    {
      "epoch": 2.8062082552496275,
      "grad_norm": 0.13461710512638092,
      "learning_rate": 3.596919898130797e-05,
      "loss": 0.0001,
      "step": 58400
    },
    {
      "epoch": 2.808610830810629,
      "grad_norm": 0.11619693040847778,
      "learning_rate": 3.595718610350296e-05,
      "loss": 0.0002,
      "step": 58450
    },
    {
      "epoch": 2.8110134063716306,
      "grad_norm": 0.21817775070667267,
      "learning_rate": 3.594517322569795e-05,
      "loss": 0.0002,
      "step": 58500
    },
    {
      "epoch": 2.8134159819326316,
      "grad_norm": 0.02314259298145771,
      "learning_rate": 3.593316034789294e-05,
      "loss": 0.0001,
      "step": 58550
    },
    {
      "epoch": 2.815818557493633,
      "grad_norm": 0.1844898909330368,
      "learning_rate": 3.592114747008794e-05,
      "loss": 0.0002,
      "step": 58600
    },
    {
      "epoch": 2.8182211330546347,
      "grad_norm": 0.35868319869041443,
      "learning_rate": 3.590913459228293e-05,
      "loss": 0.0003,
      "step": 58650
    },
    {
      "epoch": 2.820623708615636,
      "grad_norm": 0.18236452341079712,
      "learning_rate": 3.589712171447792e-05,
      "loss": 0.0002,
      "step": 58700
    },
    {
      "epoch": 2.8230262841766374,
      "grad_norm": 0.18539007008075714,
      "learning_rate": 3.5885108836672916e-05,
      "loss": 0.0002,
      "step": 58750
    },
    {
      "epoch": 2.825428859737639,
      "grad_norm": 0.16778327524662018,
      "learning_rate": 3.587309595886791e-05,
      "loss": 0.0002,
      "step": 58800
    },
    {
      "epoch": 2.82783143529864,
      "grad_norm": 0.09882999956607819,
      "learning_rate": 3.5861083081062904e-05,
      "loss": 0.0003,
      "step": 58850
    },
    {
      "epoch": 2.8302340108596415,
      "grad_norm": 0.3526502251625061,
      "learning_rate": 3.5849070203257895e-05,
      "loss": 0.0002,
      "step": 58900
    },
    {
      "epoch": 2.832636586420643,
      "grad_norm": 0.5128737092018127,
      "learning_rate": 3.5837057325452886e-05,
      "loss": 0.0002,
      "step": 58950
    },
    {
      "epoch": 2.835039161981644,
      "grad_norm": 0.42156311869621277,
      "learning_rate": 3.5825044447647884e-05,
      "loss": 0.0002,
      "step": 59000
    },
    {
      "epoch": 2.8374417375426457,
      "grad_norm": 0.10498709231615067,
      "learning_rate": 3.5813031569842874e-05,
      "loss": 0.0002,
      "step": 59050
    },
    {
      "epoch": 2.8398443131036473,
      "grad_norm": 0.39232662320137024,
      "learning_rate": 3.580101869203787e-05,
      "loss": 0.0002,
      "step": 59100
    },
    {
      "epoch": 2.8422468886646484,
      "grad_norm": 0.2909398674964905,
      "learning_rate": 3.5789005814232856e-05,
      "loss": 0.0002,
      "step": 59150
    },
    {
      "epoch": 2.84464946422565,
      "grad_norm": 0.41267070174217224,
      "learning_rate": 3.577699293642785e-05,
      "loss": 0.0008,
      "step": 59200
    },
    {
      "epoch": 2.8470520397866514,
      "grad_norm": 0.19003894925117493,
      "learning_rate": 3.5764980058622845e-05,
      "loss": 0.0002,
      "step": 59250
    },
    {
      "epoch": 2.8494546153476525,
      "grad_norm": 0.1729961633682251,
      "learning_rate": 3.5752967180817835e-05,
      "loss": 0.0002,
      "step": 59300
    },
    {
      "epoch": 2.851857190908654,
      "grad_norm": 0.0991135910153389,
      "learning_rate": 3.574095430301283e-05,
      "loss": 0.0002,
      "step": 59350
    },
    {
      "epoch": 2.8542597664696556,
      "grad_norm": 0.2991063594818115,
      "learning_rate": 3.5728941425207824e-05,
      "loss": 0.0002,
      "step": 59400
    },
    {
      "epoch": 2.8566623420306567,
      "grad_norm": 0.27183738350868225,
      "learning_rate": 3.5716928547402815e-05,
      "loss": 0.0002,
      "step": 59450
    },
    {
      "epoch": 2.8590649175916583,
      "grad_norm": 0.10398653149604797,
      "learning_rate": 3.570491566959781e-05,
      "loss": 0.001,
      "step": 59500
    },
    {
      "epoch": 2.86146749315266,
      "grad_norm": 0.06490115076303482,
      "learning_rate": 3.56929027917928e-05,
      "loss": 0.0002,
      "step": 59550
    },
    {
      "epoch": 2.863870068713661,
      "grad_norm": 0.1650303602218628,
      "learning_rate": 3.5680889913987794e-05,
      "loss": 0.0002,
      "step": 59600
    },
    {
      "epoch": 2.8662726442746624,
      "grad_norm": 0.3314896821975708,
      "learning_rate": 3.566887703618279e-05,
      "loss": 0.0002,
      "step": 59650
    },
    {
      "epoch": 2.868675219835664,
      "grad_norm": 0.18532614409923553,
      "learning_rate": 3.565686415837778e-05,
      "loss": 0.0002,
      "step": 59700
    },
    {
      "epoch": 2.871077795396665,
      "grad_norm": 0.15212838351726532,
      "learning_rate": 3.564485128057278e-05,
      "loss": 0.0006,
      "step": 59750
    },
    {
      "epoch": 2.8734803709576666,
      "grad_norm": 0.05817463994026184,
      "learning_rate": 3.563283840276777e-05,
      "loss": 0.0002,
      "step": 59800
    },
    {
      "epoch": 2.875882946518668,
      "grad_norm": 0.34050053358078003,
      "learning_rate": 3.562082552496276e-05,
      "loss": 0.0002,
      "step": 59850
    },
    {
      "epoch": 2.8782855220796693,
      "grad_norm": 0.11819195747375488,
      "learning_rate": 3.560881264715775e-05,
      "loss": 0.0002,
      "step": 59900
    },
    {
      "epoch": 2.880688097640671,
      "grad_norm": 0.11120191961526871,
      "learning_rate": 3.559679976935274e-05,
      "loss": 0.0002,
      "step": 59950
    },
    {
      "epoch": 2.8830906732016723,
      "grad_norm": 0.04768827557563782,
      "learning_rate": 3.558478689154774e-05,
      "loss": 0.0002,
      "step": 60000
    },
    {
      "epoch": 2.8854932487626734,
      "grad_norm": 0.38898152112960815,
      "learning_rate": 3.557277401374273e-05,
      "loss": 0.0002,
      "step": 60050
    },
    {
      "epoch": 2.887895824323675,
      "grad_norm": 0.11094263195991516,
      "learning_rate": 3.556076113593772e-05,
      "loss": 0.0002,
      "step": 60100
    },
    {
      "epoch": 2.8902983998846765,
      "grad_norm": 0.1352359801530838,
      "learning_rate": 3.554874825813272e-05,
      "loss": 0.0002,
      "step": 60150
    },
    {
      "epoch": 2.8927009754456776,
      "grad_norm": 0.04517177492380142,
      "learning_rate": 3.553673538032771e-05,
      "loss": 0.0002,
      "step": 60200
    },
    {
      "epoch": 2.895103551006679,
      "grad_norm": 0.15952475368976593,
      "learning_rate": 3.552472250252271e-05,
      "loss": 0.0002,
      "step": 60250
    },
    {
      "epoch": 2.8975061265676807,
      "grad_norm": 0.07224258780479431,
      "learning_rate": 3.55127096247177e-05,
      "loss": 0.0007,
      "step": 60300
    },
    {
      "epoch": 2.899908702128682,
      "grad_norm": 0.19418704509735107,
      "learning_rate": 3.550069674691269e-05,
      "loss": 0.0001,
      "step": 60350
    },
    {
      "epoch": 2.9023112776896833,
      "grad_norm": 0.09567680209875107,
      "learning_rate": 3.548868386910769e-05,
      "loss": 0.0001,
      "step": 60400
    },
    {
      "epoch": 2.904713853250685,
      "grad_norm": 0.05984300747513771,
      "learning_rate": 3.547667099130268e-05,
      "loss": 0.0002,
      "step": 60450
    },
    {
      "epoch": 2.907116428811686,
      "grad_norm": 0.144274041056633,
      "learning_rate": 3.5464658113497676e-05,
      "loss": 0.0002,
      "step": 60500
    },
    {
      "epoch": 2.9095190043726875,
      "grad_norm": 0.3115510046482086,
      "learning_rate": 3.545264523569267e-05,
      "loss": 0.0002,
      "step": 60550
    },
    {
      "epoch": 2.911921579933689,
      "grad_norm": 0.4361084997653961,
      "learning_rate": 3.544063235788766e-05,
      "loss": 0.0002,
      "step": 60600
    },
    {
      "epoch": 2.91432415549469,
      "grad_norm": 0.28926002979278564,
      "learning_rate": 3.542861948008265e-05,
      "loss": 0.0002,
      "step": 60650
    },
    {
      "epoch": 2.9167267310556917,
      "grad_norm": 0.036608271300792694,
      "learning_rate": 3.541660660227764e-05,
      "loss": 0.0002,
      "step": 60700
    },
    {
      "epoch": 2.9191293066166932,
      "grad_norm": 0.10046043992042542,
      "learning_rate": 3.540459372447264e-05,
      "loss": 0.0002,
      "step": 60750
    },
    {
      "epoch": 2.9215318821776943,
      "grad_norm": 0.11741819977760315,
      "learning_rate": 3.539258084666763e-05,
      "loss": 0.0001,
      "step": 60800
    },
    {
      "epoch": 2.923934457738696,
      "grad_norm": 0.22390423715114594,
      "learning_rate": 3.538056796886262e-05,
      "loss": 0.0001,
      "step": 60850
    },
    {
      "epoch": 2.9263370332996974,
      "grad_norm": 0.2683485448360443,
      "learning_rate": 3.5368555091057616e-05,
      "loss": 0.0006,
      "step": 60900
    },
    {
      "epoch": 2.9287396088606985,
      "grad_norm": 0.47045350074768066,
      "learning_rate": 3.535654221325261e-05,
      "loss": 0.0002,
      "step": 60950
    },
    {
      "epoch": 2.9311421844217,
      "grad_norm": 0.3407745063304901,
      "learning_rate": 3.5344529335447605e-05,
      "loss": 0.0005,
      "step": 61000
    },
    {
      "epoch": 2.9335447599827016,
      "grad_norm": 0.32275888323783875,
      "learning_rate": 3.5332516457642596e-05,
      "loss": 0.0003,
      "step": 61050
    },
    {
      "epoch": 2.9359473355437027,
      "grad_norm": 0.10359703749418259,
      "learning_rate": 3.5320503579837586e-05,
      "loss": 0.0002,
      "step": 61100
    },
    {
      "epoch": 2.9383499111047042,
      "grad_norm": 0.49825775623321533,
      "learning_rate": 3.5308490702032584e-05,
      "loss": 0.0002,
      "step": 61150
    },
    {
      "epoch": 2.9407524866657058,
      "grad_norm": 0.22796961665153503,
      "learning_rate": 3.5296477824227575e-05,
      "loss": 0.0003,
      "step": 61200
    },
    {
      "epoch": 2.943155062226707,
      "grad_norm": 0.32840263843536377,
      "learning_rate": 3.5284464946422566e-05,
      "loss": 0.0002,
      "step": 61250
    },
    {
      "epoch": 2.9455576377877084,
      "grad_norm": 0.3766448497772217,
      "learning_rate": 3.527245206861756e-05,
      "loss": 0.0002,
      "step": 61300
    },
    {
      "epoch": 2.94796021334871,
      "grad_norm": 0.16223010420799255,
      "learning_rate": 3.5260439190812554e-05,
      "loss": 0.0002,
      "step": 61350
    },
    {
      "epoch": 2.950362788909711,
      "grad_norm": 0.07983006536960602,
      "learning_rate": 3.5248426313007545e-05,
      "loss": 0.0002,
      "step": 61400
    },
    {
      "epoch": 2.9527653644707126,
      "grad_norm": 0.14405551552772522,
      "learning_rate": 3.5236413435202536e-05,
      "loss": 0.0002,
      "step": 61450
    },
    {
      "epoch": 2.955167940031714,
      "grad_norm": 0.28594332933425903,
      "learning_rate": 3.522440055739753e-05,
      "loss": 0.0002,
      "step": 61500
    },
    {
      "epoch": 2.9575705155927157,
      "grad_norm": 0.24533632397651672,
      "learning_rate": 3.5212387679592524e-05,
      "loss": 0.0002,
      "step": 61550
    },
    {
      "epoch": 2.9599730911537168,
      "grad_norm": 0.2371990978717804,
      "learning_rate": 3.5200374801787515e-05,
      "loss": 0.0006,
      "step": 61600
    },
    {
      "epoch": 2.9623756667147183,
      "grad_norm": 0.19623209536075592,
      "learning_rate": 3.518836192398251e-05,
      "loss": 0.0002,
      "step": 61650
    },
    {
      "epoch": 2.9647782422757194,
      "grad_norm": 0.2915506660938263,
      "learning_rate": 3.5176349046177503e-05,
      "loss": 0.0002,
      "step": 61700
    },
    {
      "epoch": 2.967180817836721,
      "grad_norm": 0.15550512075424194,
      "learning_rate": 3.5164336168372494e-05,
      "loss": 0.0002,
      "step": 61750
    },
    {
      "epoch": 2.9695833933977225,
      "grad_norm": 0.4311997890472412,
      "learning_rate": 3.515232329056749e-05,
      "loss": 0.0002,
      "step": 61800
    },
    {
      "epoch": 2.971985968958724,
      "grad_norm": 0.3411620855331421,
      "learning_rate": 3.514031041276248e-05,
      "loss": 0.0002,
      "step": 61850
    },
    {
      "epoch": 2.974388544519725,
      "grad_norm": 0.6989138722419739,
      "learning_rate": 3.512829753495748e-05,
      "loss": 0.0002,
      "step": 61900
    },
    {
      "epoch": 2.9767911200807267,
      "grad_norm": 0.20192819833755493,
      "learning_rate": 3.511628465715247e-05,
      "loss": 0.0002,
      "step": 61950
    },
    {
      "epoch": 2.9791936956417278,
      "grad_norm": 0.34365227818489075,
      "learning_rate": 3.510427177934746e-05,
      "loss": 0.0002,
      "step": 62000
    },
    {
      "epoch": 2.9815962712027293,
      "grad_norm": 0.2635134160518646,
      "learning_rate": 3.509225890154246e-05,
      "loss": 0.0009,
      "step": 62050
    },
    {
      "epoch": 2.983998846763731,
      "grad_norm": 0.4244785010814667,
      "learning_rate": 3.508024602373745e-05,
      "loss": 0.0002,
      "step": 62100
    },
    {
      "epoch": 2.9864014223247324,
      "grad_norm": 0.12263031303882599,
      "learning_rate": 3.506823314593244e-05,
      "loss": 0.0001,
      "step": 62150
    },
    {
      "epoch": 2.9888039978857335,
      "grad_norm": 0.13430309295654297,
      "learning_rate": 3.505622026812743e-05,
      "loss": 0.0002,
      "step": 62200
    },
    {
      "epoch": 2.991206573446735,
      "grad_norm": 0.6797611117362976,
      "learning_rate": 3.504420739032242e-05,
      "loss": 0.0002,
      "step": 62250
    },
    {
      "epoch": 2.993609149007736,
      "grad_norm": 0.4418310225009918,
      "learning_rate": 3.503219451251742e-05,
      "loss": 0.0002,
      "step": 62300
    },
    {
      "epoch": 2.9960117245687377,
      "grad_norm": 0.28278228640556335,
      "learning_rate": 3.502018163471241e-05,
      "loss": 0.0002,
      "step": 62350
    },
    {
      "epoch": 2.998414300129739,
      "grad_norm": 0.2721526026725769,
      "learning_rate": 3.500816875690741e-05,
      "loss": 0.0007,
      "step": 62400
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.00017453967302571982,
      "eval_runtime": 17.3099,
      "eval_samples_per_second": 548.589,
      "eval_steps_per_second": 68.574,
      "step": 62433
    },
    {
      "epoch": 3.0008168756907403,
      "grad_norm": 0.06491848826408386,
      "learning_rate": 3.49961558791024e-05,
      "loss": 0.0002,
      "step": 62450
    },
    {
      "epoch": 3.003219451251742,
      "grad_norm": 0.46281132102012634,
      "learning_rate": 3.498414300129739e-05,
      "loss": 0.0007,
      "step": 62500
    },
    {
      "epoch": 3.0056220268127434,
      "grad_norm": 0.13758274912834167,
      "learning_rate": 3.497213012349239e-05,
      "loss": 0.0002,
      "step": 62550
    },
    {
      "epoch": 3.0080246023737445,
      "grad_norm": 0.06824903935194016,
      "learning_rate": 3.496011724568738e-05,
      "loss": 0.0002,
      "step": 62600
    },
    {
      "epoch": 3.010427177934746,
      "grad_norm": 0.24181972444057465,
      "learning_rate": 3.494810436788237e-05,
      "loss": 0.0002,
      "step": 62650
    },
    {
      "epoch": 3.0128297534957476,
      "grad_norm": 0.169401615858078,
      "learning_rate": 3.493609149007737e-05,
      "loss": 0.0002,
      "step": 62700
    },
    {
      "epoch": 3.0152323290567487,
      "grad_norm": 0.06204552948474884,
      "learning_rate": 3.492407861227236e-05,
      "loss": 0.0002,
      "step": 62750
    },
    {
      "epoch": 3.01763490461775,
      "grad_norm": 0.17999675869941711,
      "learning_rate": 3.4912065734467356e-05,
      "loss": 0.0002,
      "step": 62800
    },
    {
      "epoch": 3.0200374801787517,
      "grad_norm": 0.4347352981567383,
      "learning_rate": 3.490005285666235e-05,
      "loss": 0.0002,
      "step": 62850
    },
    {
      "epoch": 3.022440055739753,
      "grad_norm": 0.17434179782867432,
      "learning_rate": 3.488803997885734e-05,
      "loss": 0.0002,
      "step": 62900
    },
    {
      "epoch": 3.0248426313007544,
      "grad_norm": 0.16466906666755676,
      "learning_rate": 3.487602710105233e-05,
      "loss": 0.0002,
      "step": 62950
    },
    {
      "epoch": 3.027245206861756,
      "grad_norm": 0.22634322941303253,
      "learning_rate": 3.486401422324732e-05,
      "loss": 0.0006,
      "step": 63000
    },
    {
      "epoch": 3.029647782422757,
      "grad_norm": 0.4390002489089966,
      "learning_rate": 3.485200134544232e-05,
      "loss": 0.0002,
      "step": 63050
    },
    {
      "epoch": 3.0320503579837585,
      "grad_norm": 0.1663776934146881,
      "learning_rate": 3.483998846763731e-05,
      "loss": 0.0002,
      "step": 63100
    },
    {
      "epoch": 3.03445293354476,
      "grad_norm": 0.1317630410194397,
      "learning_rate": 3.48279755898323e-05,
      "loss": 0.0002,
      "step": 63150
    },
    {
      "epoch": 3.036855509105761,
      "grad_norm": 0.11925813555717468,
      "learning_rate": 3.4815962712027296e-05,
      "loss": 0.0002,
      "step": 63200
    },
    {
      "epoch": 3.0392580846667627,
      "grad_norm": 0.06537149101495743,
      "learning_rate": 3.480394983422229e-05,
      "loss": 0.0001,
      "step": 63250
    },
    {
      "epoch": 3.0416606602277643,
      "grad_norm": 0.46157675981521606,
      "learning_rate": 3.4791936956417284e-05,
      "loss": 0.0002,
      "step": 63300
    },
    {
      "epoch": 3.0440632357887654,
      "grad_norm": 0.1327807903289795,
      "learning_rate": 3.4779924078612275e-05,
      "loss": 0.0002,
      "step": 63350
    },
    {
      "epoch": 3.046465811349767,
      "grad_norm": 0.07342758774757385,
      "learning_rate": 3.4767911200807266e-05,
      "loss": 0.0003,
      "step": 63400
    },
    {
      "epoch": 3.0488683869107684,
      "grad_norm": 0.21080893278121948,
      "learning_rate": 3.4755898323002264e-05,
      "loss": 0.0002,
      "step": 63450
    },
    {
      "epoch": 3.0512709624717695,
      "grad_norm": 0.3370589017868042,
      "learning_rate": 3.4743885445197254e-05,
      "loss": 0.0002,
      "step": 63500
    },
    {
      "epoch": 3.053673538032771,
      "grad_norm": 0.1296158879995346,
      "learning_rate": 3.4731872567392245e-05,
      "loss": 0.0002,
      "step": 63550
    },
    {
      "epoch": 3.0560761135937726,
      "grad_norm": 0.07246848940849304,
      "learning_rate": 3.471985968958724e-05,
      "loss": 0.0002,
      "step": 63600
    },
    {
      "epoch": 3.0584786891547737,
      "grad_norm": 0.34222981333732605,
      "learning_rate": 3.470784681178223e-05,
      "loss": 0.0003,
      "step": 63650
    },
    {
      "epoch": 3.0608812647157753,
      "grad_norm": 0.24317722022533417,
      "learning_rate": 3.4695833933977225e-05,
      "loss": 0.0002,
      "step": 63700
    },
    {
      "epoch": 3.063283840276777,
      "grad_norm": 0.04395689442753792,
      "learning_rate": 3.4683821056172215e-05,
      "loss": 0.0002,
      "step": 63750
    },
    {
      "epoch": 3.065686415837778,
      "grad_norm": 0.5212293267250061,
      "learning_rate": 3.467180817836721e-05,
      "loss": 0.0002,
      "step": 63800
    },
    {
      "epoch": 3.0680889913987794,
      "grad_norm": 0.21834459900856018,
      "learning_rate": 3.4659795300562204e-05,
      "loss": 0.0005,
      "step": 63850
    },
    {
      "epoch": 3.070491566959781,
      "grad_norm": 0.18753397464752197,
      "learning_rate": 3.4647782422757195e-05,
      "loss": 0.0002,
      "step": 63900
    },
    {
      "epoch": 3.072894142520782,
      "grad_norm": 0.41821742057800293,
      "learning_rate": 3.463576954495219e-05,
      "loss": 0.0002,
      "step": 63950
    },
    {
      "epoch": 3.0752967180817836,
      "grad_norm": 0.2013486921787262,
      "learning_rate": 3.462375666714718e-05,
      "loss": 0.0002,
      "step": 64000
    },
    {
      "epoch": 3.077699293642785,
      "grad_norm": 0.290705144405365,
      "learning_rate": 3.4611743789342174e-05,
      "loss": 0.0008,
      "step": 64050
    },
    {
      "epoch": 3.0801018692037863,
      "grad_norm": 0.1010519340634346,
      "learning_rate": 3.459973091153717e-05,
      "loss": 0.0002,
      "step": 64100
    },
    {
      "epoch": 3.082504444764788,
      "grad_norm": 0.0787886530160904,
      "learning_rate": 3.458771803373216e-05,
      "loss": 0.0002,
      "step": 64150
    },
    {
      "epoch": 3.0849070203257893,
      "grad_norm": 0.1586272269487381,
      "learning_rate": 3.457570515592716e-05,
      "loss": 0.0002,
      "step": 64200
    },
    {
      "epoch": 3.0873095958867904,
      "grad_norm": 0.05704847723245621,
      "learning_rate": 3.456369227812215e-05,
      "loss": 0.0001,
      "step": 64250
    },
    {
      "epoch": 3.089712171447792,
      "grad_norm": 0.2704479694366455,
      "learning_rate": 3.455167940031714e-05,
      "loss": 0.0002,
      "step": 64300
    },
    {
      "epoch": 3.0921147470087935,
      "grad_norm": 0.06122113764286041,
      "learning_rate": 3.453966652251214e-05,
      "loss": 0.0002,
      "step": 64350
    },
    {
      "epoch": 3.0945173225697946,
      "grad_norm": 0.1419246643781662,
      "learning_rate": 3.452765364470712e-05,
      "loss": 0.0002,
      "step": 64400
    },
    {
      "epoch": 3.096919898130796,
      "grad_norm": 0.07184069603681564,
      "learning_rate": 3.451564076690212e-05,
      "loss": 0.0002,
      "step": 64450
    },
    {
      "epoch": 3.0993224736917977,
      "grad_norm": 0.21212930977344513,
      "learning_rate": 3.450362788909711e-05,
      "loss": 0.0002,
      "step": 64500
    },
    {
      "epoch": 3.101725049252799,
      "grad_norm": 0.05004538595676422,
      "learning_rate": 3.44916150112921e-05,
      "loss": 0.0001,
      "step": 64550
    },
    {
      "epoch": 3.1041276248138003,
      "grad_norm": 0.4055658280849457,
      "learning_rate": 3.44796021334871e-05,
      "loss": 0.0002,
      "step": 64600
    },
    {
      "epoch": 3.106530200374802,
      "grad_norm": 0.27724751830101013,
      "learning_rate": 3.446758925568209e-05,
      "loss": 0.0002,
      "step": 64650
    },
    {
      "epoch": 3.108932775935803,
      "grad_norm": 0.09166093170642853,
      "learning_rate": 3.445557637787709e-05,
      "loss": 0.0002,
      "step": 64700
    },
    {
      "epoch": 3.1113353514968045,
      "grad_norm": 0.19237104058265686,
      "learning_rate": 3.444356350007208e-05,
      "loss": 0.0002,
      "step": 64750
    },
    {
      "epoch": 3.113737927057806,
      "grad_norm": 0.1584720015525818,
      "learning_rate": 3.443155062226707e-05,
      "loss": 0.0003,
      "step": 64800
    },
    {
      "epoch": 3.116140502618807,
      "grad_norm": 0.05518842115998268,
      "learning_rate": 3.441953774446207e-05,
      "loss": 0.0002,
      "step": 64850
    },
    {
      "epoch": 3.1185430781798087,
      "grad_norm": 0.30557921528816223,
      "learning_rate": 3.440752486665706e-05,
      "loss": 0.0001,
      "step": 64900
    },
    {
      "epoch": 3.1209456537408102,
      "grad_norm": 0.4518270492553711,
      "learning_rate": 3.439551198885205e-05,
      "loss": 0.0005,
      "step": 64950
    },
    {
      "epoch": 3.1233482293018113,
      "grad_norm": 0.14566724002361298,
      "learning_rate": 3.438349911104705e-05,
      "loss": 0.0002,
      "step": 65000
    },
    {
      "epoch": 3.125750804862813,
      "grad_norm": 0.13425517082214355,
      "learning_rate": 3.437148623324204e-05,
      "loss": 0.0001,
      "step": 65050
    },
    {
      "epoch": 3.1281533804238144,
      "grad_norm": 0.0563071072101593,
      "learning_rate": 3.435947335543703e-05,
      "loss": 0.0002,
      "step": 65100
    },
    {
      "epoch": 3.130555955984816,
      "grad_norm": 0.502726137638092,
      "learning_rate": 3.434746047763202e-05,
      "loss": 0.0002,
      "step": 65150
    },
    {
      "epoch": 3.132958531545817,
      "grad_norm": 0.6143678426742554,
      "learning_rate": 3.433544759982702e-05,
      "loss": 0.0002,
      "step": 65200
    },
    {
      "epoch": 3.1353611071068186,
      "grad_norm": 0.49733781814575195,
      "learning_rate": 3.432343472202201e-05,
      "loss": 0.0002,
      "step": 65250
    },
    {
      "epoch": 3.1377636826678197,
      "grad_norm": 0.06730672717094421,
      "learning_rate": 3.4311421844217e-05,
      "loss": 0.0002,
      "step": 65300
    },
    {
      "epoch": 3.1401662582288212,
      "grad_norm": 0.08145463466644287,
      "learning_rate": 3.4299408966411996e-05,
      "loss": 0.0002,
      "step": 65350
    },
    {
      "epoch": 3.1425688337898228,
      "grad_norm": 0.19725161790847778,
      "learning_rate": 3.428739608860699e-05,
      "loss": 0.0002,
      "step": 65400
    },
    {
      "epoch": 3.1449714093508243,
      "grad_norm": 0.11469060182571411,
      "learning_rate": 3.427538321080198e-05,
      "loss": 0.0001,
      "step": 65450
    },
    {
      "epoch": 3.1473739849118254,
      "grad_norm": 0.2563490867614746,
      "learning_rate": 3.4263370332996976e-05,
      "loss": 0.0002,
      "step": 65500
    },
    {
      "epoch": 3.149776560472827,
      "grad_norm": 0.2512286603450775,
      "learning_rate": 3.4251357455191966e-05,
      "loss": 0.0002,
      "step": 65550
    },
    {
      "epoch": 3.152179136033828,
      "grad_norm": 0.23119254410266876,
      "learning_rate": 3.4239344577386964e-05,
      "loss": 0.0002,
      "step": 65600
    },
    {
      "epoch": 3.1545817115948296,
      "grad_norm": 0.4768507480621338,
      "learning_rate": 3.4227331699581955e-05,
      "loss": 0.0002,
      "step": 65650
    },
    {
      "epoch": 3.156984287155831,
      "grad_norm": 0.442290335893631,
      "learning_rate": 3.4215318821776946e-05,
      "loss": 0.0002,
      "step": 65700
    },
    {
      "epoch": 3.1593868627168327,
      "grad_norm": 0.17968830466270447,
      "learning_rate": 3.420330594397194e-05,
      "loss": 0.0002,
      "step": 65750
    },
    {
      "epoch": 3.1617894382778338,
      "grad_norm": 0.2797994911670685,
      "learning_rate": 3.4191293066166934e-05,
      "loss": 0.0002,
      "step": 65800
    },
    {
      "epoch": 3.1641920138388353,
      "grad_norm": 1.1091294288635254,
      "learning_rate": 3.4179280188361925e-05,
      "loss": 0.0002,
      "step": 65850
    },
    {
      "epoch": 3.1665945893998364,
      "grad_norm": 0.11936245113611221,
      "learning_rate": 3.4167267310556916e-05,
      "loss": 0.0002,
      "step": 65900
    },
    {
      "epoch": 3.168997164960838,
      "grad_norm": 0.028042104095220566,
      "learning_rate": 3.4155254432751907e-05,
      "loss": 0.0002,
      "step": 65950
    },
    {
      "epoch": 3.1713997405218395,
      "grad_norm": 0.3389580547809601,
      "learning_rate": 3.4143241554946904e-05,
      "loss": 0.0002,
      "step": 66000
    },
    {
      "epoch": 3.173802316082841,
      "grad_norm": 0.0814681425690651,
      "learning_rate": 3.4131228677141895e-05,
      "loss": 0.0001,
      "step": 66050
    },
    {
      "epoch": 3.176204891643842,
      "grad_norm": 0.15009963512420654,
      "learning_rate": 3.411921579933689e-05,
      "loss": 0.0002,
      "step": 66100
    },
    {
      "epoch": 3.1786074672048437,
      "grad_norm": 0.14899839460849762,
      "learning_rate": 3.4107202921531883e-05,
      "loss": 0.0003,
      "step": 66150
    },
    {
      "epoch": 3.1810100427658448,
      "grad_norm": 0.1669561117887497,
      "learning_rate": 3.4095190043726874e-05,
      "loss": 0.0009,
      "step": 66200
    },
    {
      "epoch": 3.1834126183268463,
      "grad_norm": 0.8096109628677368,
      "learning_rate": 3.408317716592187e-05,
      "loss": 0.0002,
      "step": 66250
    },
    {
      "epoch": 3.185815193887848,
      "grad_norm": 0.08795414119958878,
      "learning_rate": 3.407116428811686e-05,
      "loss": 0.0002,
      "step": 66300
    },
    {
      "epoch": 3.1882177694488494,
      "grad_norm": 0.19020406901836395,
      "learning_rate": 3.405915141031186e-05,
      "loss": 0.0005,
      "step": 66350
    },
    {
      "epoch": 3.1906203450098505,
      "grad_norm": 0.4260450005531311,
      "learning_rate": 3.404713853250685e-05,
      "loss": 0.0001,
      "step": 66400
    },
    {
      "epoch": 3.193022920570852,
      "grad_norm": 0.08053194731473923,
      "learning_rate": 3.403512565470184e-05,
      "loss": 0.0002,
      "step": 66450
    },
    {
      "epoch": 3.195425496131853,
      "grad_norm": 0.37124401330947876,
      "learning_rate": 3.402311277689684e-05,
      "loss": 0.0002,
      "step": 66500
    },
    {
      "epoch": 3.1978280716928547,
      "grad_norm": 0.4573039412498474,
      "learning_rate": 3.401109989909183e-05,
      "loss": 0.0003,
      "step": 66550
    },
    {
      "epoch": 3.200230647253856,
      "grad_norm": 0.1825886219739914,
      "learning_rate": 3.399908702128682e-05,
      "loss": 0.0002,
      "step": 66600
    },
    {
      "epoch": 3.2026332228148577,
      "grad_norm": 0.12668795883655548,
      "learning_rate": 3.398707414348181e-05,
      "loss": 0.0002,
      "step": 66650
    },
    {
      "epoch": 3.205035798375859,
      "grad_norm": 0.314399391412735,
      "learning_rate": 3.39750612656768e-05,
      "loss": 0.0002,
      "step": 66700
    },
    {
      "epoch": 3.2074383739368604,
      "grad_norm": 0.17749333381652832,
      "learning_rate": 3.39630483878718e-05,
      "loss": 0.0002,
      "step": 66750
    },
    {
      "epoch": 3.2098409494978615,
      "grad_norm": 0.1310223937034607,
      "learning_rate": 3.395103551006679e-05,
      "loss": 0.0002,
      "step": 66800
    },
    {
      "epoch": 3.212243525058863,
      "grad_norm": 0.13411767780780792,
      "learning_rate": 3.393902263226179e-05,
      "loss": 0.0002,
      "step": 66850
    },
    {
      "epoch": 3.2146461006198646,
      "grad_norm": 0.15699991583824158,
      "learning_rate": 3.392700975445678e-05,
      "loss": 0.0002,
      "step": 66900
    },
    {
      "epoch": 3.217048676180866,
      "grad_norm": 0.15975841879844666,
      "learning_rate": 3.391499687665177e-05,
      "loss": 0.0002,
      "step": 66950
    },
    {
      "epoch": 3.219451251741867,
      "grad_norm": 0.11322358250617981,
      "learning_rate": 3.390298399884677e-05,
      "loss": 0.0002,
      "step": 67000
    },
    {
      "epoch": 3.2218538273028687,
      "grad_norm": 0.04720986261963844,
      "learning_rate": 3.389097112104176e-05,
      "loss": 0.0003,
      "step": 67050
    },
    {
      "epoch": 3.2242564028638703,
      "grad_norm": 0.17473681271076202,
      "learning_rate": 3.387895824323675e-05,
      "loss": 0.0001,
      "step": 67100
    },
    {
      "epoch": 3.2266589784248714,
      "grad_norm": 0.25897884368896484,
      "learning_rate": 3.386694536543175e-05,
      "loss": 0.0003,
      "step": 67150
    },
    {
      "epoch": 3.229061553985873,
      "grad_norm": 0.3299517035484314,
      "learning_rate": 3.385493248762674e-05,
      "loss": 0.0002,
      "step": 67200
    },
    {
      "epoch": 3.2314641295468745,
      "grad_norm": 0.6621435880661011,
      "learning_rate": 3.3842919609821736e-05,
      "loss": 0.0002,
      "step": 67250
    },
    {
      "epoch": 3.2338667051078755,
      "grad_norm": 0.2728021740913391,
      "learning_rate": 3.3830906732016727e-05,
      "loss": 0.0002,
      "step": 67300
    },
    {
      "epoch": 3.236269280668877,
      "grad_norm": 0.1635582596063614,
      "learning_rate": 3.381889385421171e-05,
      "loss": 0.0001,
      "step": 67350
    },
    {
      "epoch": 3.2386718562298786,
      "grad_norm": 0.3967149257659912,
      "learning_rate": 3.380688097640671e-05,
      "loss": 0.0002,
      "step": 67400
    },
    {
      "epoch": 3.2410744317908797,
      "grad_norm": 0.18469026684761047,
      "learning_rate": 3.37948680986017e-05,
      "loss": 0.0002,
      "step": 67450
    },
    {
      "epoch": 3.2434770073518813,
      "grad_norm": 0.22766166925430298,
      "learning_rate": 3.37828552207967e-05,
      "loss": 0.0001,
      "step": 67500
    },
    {
      "epoch": 3.245879582912883,
      "grad_norm": 0.2552407681941986,
      "learning_rate": 3.377084234299169e-05,
      "loss": 0.0002,
      "step": 67550
    },
    {
      "epoch": 3.248282158473884,
      "grad_norm": 0.2201167196035385,
      "learning_rate": 3.375882946518668e-05,
      "loss": 0.0007,
      "step": 67600
    },
    {
      "epoch": 3.2506847340348854,
      "grad_norm": 0.14751388132572174,
      "learning_rate": 3.3746816587381676e-05,
      "loss": 0.0002,
      "step": 67650
    },
    {
      "epoch": 3.2530873095958865,
      "grad_norm": 0.339648962020874,
      "learning_rate": 3.373480370957667e-05,
      "loss": 0.0007,
      "step": 67700
    },
    {
      "epoch": 3.255489885156888,
      "grad_norm": 0.10077721625566483,
      "learning_rate": 3.3722790831771664e-05,
      "loss": 0.0002,
      "step": 67750
    },
    {
      "epoch": 3.2578924607178896,
      "grad_norm": 1.0284373760223389,
      "learning_rate": 3.3710777953966655e-05,
      "loss": 0.0003,
      "step": 67800
    },
    {
      "epoch": 3.260295036278891,
      "grad_norm": 0.21012897789478302,
      "learning_rate": 3.3698765076161646e-05,
      "loss": 0.0002,
      "step": 67850
    },
    {
      "epoch": 3.2626976118398923,
      "grad_norm": 0.3577187955379486,
      "learning_rate": 3.3686752198356644e-05,
      "loss": 0.0002,
      "step": 67900
    },
    {
      "epoch": 3.265100187400894,
      "grad_norm": 0.4803239107131958,
      "learning_rate": 3.3674739320551634e-05,
      "loss": 0.0002,
      "step": 67950
    },
    {
      "epoch": 3.267502762961895,
      "grad_norm": 0.3757248520851135,
      "learning_rate": 3.3662726442746625e-05,
      "loss": 0.0002,
      "step": 68000
    },
    {
      "epoch": 3.2699053385228964,
      "grad_norm": 0.1498873382806778,
      "learning_rate": 3.365071356494162e-05,
      "loss": 0.0001,
      "step": 68050
    },
    {
      "epoch": 3.272307914083898,
      "grad_norm": 0.44619020819664,
      "learning_rate": 3.363870068713661e-05,
      "loss": 0.0002,
      "step": 68100
    },
    {
      "epoch": 3.2747104896448995,
      "grad_norm": 0.08058679848909378,
      "learning_rate": 3.3626687809331604e-05,
      "loss": 0.0002,
      "step": 68150
    },
    {
      "epoch": 3.2771130652059006,
      "grad_norm": 0.12663978338241577,
      "learning_rate": 3.3614674931526595e-05,
      "loss": 0.0002,
      "step": 68200
    },
    {
      "epoch": 3.279515640766902,
      "grad_norm": 0.31245505809783936,
      "learning_rate": 3.360266205372159e-05,
      "loss": 0.0007,
      "step": 68250
    },
    {
      "epoch": 3.2819182163279037,
      "grad_norm": 0.4227440357208252,
      "learning_rate": 3.3590649175916584e-05,
      "loss": 0.0005,
      "step": 68300
    },
    {
      "epoch": 3.284320791888905,
      "grad_norm": 0.1628771722316742,
      "learning_rate": 3.3578636298111575e-05,
      "loss": 0.0002,
      "step": 68350
    },
    {
      "epoch": 3.2867233674499063,
      "grad_norm": 0.25305065512657166,
      "learning_rate": 3.356662342030657e-05,
      "loss": 0.0002,
      "step": 68400
    },
    {
      "epoch": 3.289125943010908,
      "grad_norm": 0.16953785717487335,
      "learning_rate": 3.355461054250156e-05,
      "loss": 0.0002,
      "step": 68450
    },
    {
      "epoch": 3.291528518571909,
      "grad_norm": 0.18287797272205353,
      "learning_rate": 3.3542597664696554e-05,
      "loss": 0.0002,
      "step": 68500
    },
    {
      "epoch": 3.2939310941329105,
      "grad_norm": 0.2660895884037018,
      "learning_rate": 3.353058478689155e-05,
      "loss": 0.0002,
      "step": 68550
    },
    {
      "epoch": 3.296333669693912,
      "grad_norm": 0.2993067502975464,
      "learning_rate": 3.351857190908654e-05,
      "loss": 0.0002,
      "step": 68600
    },
    {
      "epoch": 3.298736245254913,
      "grad_norm": 0.07732786238193512,
      "learning_rate": 3.350655903128154e-05,
      "loss": 0.0002,
      "step": 68650
    },
    {
      "epoch": 3.3011388208159147,
      "grad_norm": 0.09612637758255005,
      "learning_rate": 3.349454615347653e-05,
      "loss": 0.0002,
      "step": 68700
    },
    {
      "epoch": 3.3035413963769162,
      "grad_norm": 0.5432757139205933,
      "learning_rate": 3.348253327567152e-05,
      "loss": 0.0002,
      "step": 68750
    },
    {
      "epoch": 3.3059439719379173,
      "grad_norm": 0.29656949639320374,
      "learning_rate": 3.347052039786652e-05,
      "loss": 0.0002,
      "step": 68800
    },
    {
      "epoch": 3.308346547498919,
      "grad_norm": 0.16737717390060425,
      "learning_rate": 3.34585075200615e-05,
      "loss": 0.0002,
      "step": 68850
    },
    {
      "epoch": 3.3107491230599204,
      "grad_norm": 0.3102648854255676,
      "learning_rate": 3.34464946422565e-05,
      "loss": 0.0002,
      "step": 68900
    },
    {
      "epoch": 3.3131516986209215,
      "grad_norm": 0.4578503966331482,
      "learning_rate": 3.343448176445149e-05,
      "loss": 0.0002,
      "step": 68950
    },
    {
      "epoch": 3.315554274181923,
      "grad_norm": 0.22104907035827637,
      "learning_rate": 3.342246888664648e-05,
      "loss": 0.0002,
      "step": 69000
    },
    {
      "epoch": 3.3179568497429246,
      "grad_norm": 0.2577010691165924,
      "learning_rate": 3.341045600884148e-05,
      "loss": 0.0002,
      "step": 69050
    },
    {
      "epoch": 3.3203594253039257,
      "grad_norm": 0.15687404572963715,
      "learning_rate": 3.339844313103647e-05,
      "loss": 0.0003,
      "step": 69100
    },
    {
      "epoch": 3.3227620008649272,
      "grad_norm": 0.1026870384812355,
      "learning_rate": 3.338643025323147e-05,
      "loss": 0.0002,
      "step": 69150
    },
    {
      "epoch": 3.3251645764259288,
      "grad_norm": 0.433197945356369,
      "learning_rate": 3.337441737542646e-05,
      "loss": 0.0001,
      "step": 69200
    },
    {
      "epoch": 3.32756715198693,
      "grad_norm": 0.09309743344783783,
      "learning_rate": 3.336240449762145e-05,
      "loss": 0.0002,
      "step": 69250
    },
    {
      "epoch": 3.3299697275479314,
      "grad_norm": 0.08379426598548889,
      "learning_rate": 3.335039161981645e-05,
      "loss": 0.0002,
      "step": 69300
    },
    {
      "epoch": 3.332372303108933,
      "grad_norm": 0.09786798804998398,
      "learning_rate": 3.333837874201144e-05,
      "loss": 0.0002,
      "step": 69350
    },
    {
      "epoch": 3.334774878669934,
      "grad_norm": 0.14324936270713806,
      "learning_rate": 3.332636586420643e-05,
      "loss": 0.0001,
      "step": 69400
    },
    {
      "epoch": 3.3371774542309356,
      "grad_norm": 0.057430170476436615,
      "learning_rate": 3.331435298640143e-05,
      "loss": 0.0001,
      "step": 69450
    },
    {
      "epoch": 3.339580029791937,
      "grad_norm": 0.05376702919602394,
      "learning_rate": 3.330234010859642e-05,
      "loss": 0.0007,
      "step": 69500
    },
    {
      "epoch": 3.3419826053529382,
      "grad_norm": 0.44395074248313904,
      "learning_rate": 3.3290327230791415e-05,
      "loss": 0.0002,
      "step": 69550
    },
    {
      "epoch": 3.3443851809139398,
      "grad_norm": 0.09125493466854095,
      "learning_rate": 3.32783143529864e-05,
      "loss": 0.0002,
      "step": 69600
    },
    {
      "epoch": 3.3467877564749413,
      "grad_norm": 0.22300779819488525,
      "learning_rate": 3.32663014751814e-05,
      "loss": 0.0001,
      "step": 69650
    },
    {
      "epoch": 3.3491903320359424,
      "grad_norm": 0.4731821119785309,
      "learning_rate": 3.325428859737639e-05,
      "loss": 0.0002,
      "step": 69700
    },
    {
      "epoch": 3.351592907596944,
      "grad_norm": 0.27933934330940247,
      "learning_rate": 3.324227571957138e-05,
      "loss": 0.0002,
      "step": 69750
    },
    {
      "epoch": 3.3539954831579455,
      "grad_norm": 0.2130572646856308,
      "learning_rate": 3.3230262841766376e-05,
      "loss": 0.0002,
      "step": 69800
    },
    {
      "epoch": 3.3563980587189466,
      "grad_norm": 0.30337613821029663,
      "learning_rate": 3.321824996396137e-05,
      "loss": 0.0002,
      "step": 69850
    },
    {
      "epoch": 3.358800634279948,
      "grad_norm": 0.17154574394226074,
      "learning_rate": 3.320623708615636e-05,
      "loss": 0.0002,
      "step": 69900
    },
    {
      "epoch": 3.3612032098409497,
      "grad_norm": 0.1650492250919342,
      "learning_rate": 3.3194224208351356e-05,
      "loss": 0.0001,
      "step": 69950
    },
    {
      "epoch": 3.3636057854019508,
      "grad_norm": 0.3087403178215027,
      "learning_rate": 3.3182211330546346e-05,
      "loss": 0.0002,
      "step": 70000
    },
    {
      "epoch": 3.3660083609629523,
      "grad_norm": 0.37640246748924255,
      "learning_rate": 3.3170198452741344e-05,
      "loss": 0.0002,
      "step": 70050
    },
    {
      "epoch": 3.368410936523954,
      "grad_norm": 0.08470214903354645,
      "learning_rate": 3.3158185574936335e-05,
      "loss": 0.0002,
      "step": 70100
    },
    {
      "epoch": 3.370813512084955,
      "grad_norm": 0.3695523142814636,
      "learning_rate": 3.3146172697131326e-05,
      "loss": 0.0001,
      "step": 70150
    },
    {
      "epoch": 3.3732160876459565,
      "grad_norm": 0.6627557873725891,
      "learning_rate": 3.313415981932632e-05,
      "loss": 0.0002,
      "step": 70200
    },
    {
      "epoch": 3.375618663206958,
      "grad_norm": 0.3784753680229187,
      "learning_rate": 3.3122146941521314e-05,
      "loss": 0.0002,
      "step": 70250
    },
    {
      "epoch": 3.378021238767959,
      "grad_norm": 0.34358829259872437,
      "learning_rate": 3.3110134063716305e-05,
      "loss": 0.0002,
      "step": 70300
    },
    {
      "epoch": 3.3804238143289607,
      "grad_norm": 0.08524014800786972,
      "learning_rate": 3.3098121185911296e-05,
      "loss": 0.0002,
      "step": 70350
    },
    {
      "epoch": 3.382826389889962,
      "grad_norm": 0.08467262238264084,
      "learning_rate": 3.3086108308106287e-05,
      "loss": 0.0002,
      "step": 70400
    },
    {
      "epoch": 3.3852289654509633,
      "grad_norm": 0.09835749864578247,
      "learning_rate": 3.3074095430301284e-05,
      "loss": 0.0002,
      "step": 70450
    },
    {
      "epoch": 3.387631541011965,
      "grad_norm": 0.4160026013851166,
      "learning_rate": 3.3062082552496275e-05,
      "loss": 0.0003,
      "step": 70500
    },
    {
      "epoch": 3.3900341165729664,
      "grad_norm": 0.595295250415802,
      "learning_rate": 3.305006967469127e-05,
      "loss": 0.0002,
      "step": 70550
    },
    {
      "epoch": 3.3924366921339675,
      "grad_norm": 0.3439178466796875,
      "learning_rate": 3.303805679688626e-05,
      "loss": 0.0002,
      "step": 70600
    },
    {
      "epoch": 3.394839267694969,
      "grad_norm": 0.3001924753189087,
      "learning_rate": 3.3026043919081254e-05,
      "loss": 0.0001,
      "step": 70650
    },
    {
      "epoch": 3.3972418432559706,
      "grad_norm": 0.7437353134155273,
      "learning_rate": 3.301403104127625e-05,
      "loss": 0.0002,
      "step": 70700
    },
    {
      "epoch": 3.3996444188169717,
      "grad_norm": 0.11831498891115189,
      "learning_rate": 3.300201816347124e-05,
      "loss": 0.0002,
      "step": 70750
    },
    {
      "epoch": 3.402046994377973,
      "grad_norm": 0.4914740025997162,
      "learning_rate": 3.2990005285666233e-05,
      "loss": 0.0002,
      "step": 70800
    },
    {
      "epoch": 3.4044495699389747,
      "grad_norm": 0.2668454945087433,
      "learning_rate": 3.297799240786123e-05,
      "loss": 0.0001,
      "step": 70850
    },
    {
      "epoch": 3.406852145499976,
      "grad_norm": 0.07351874560117722,
      "learning_rate": 3.296597953005622e-05,
      "loss": 0.0002,
      "step": 70900
    },
    {
      "epoch": 3.4092547210609774,
      "grad_norm": 0.24933433532714844,
      "learning_rate": 3.295396665225122e-05,
      "loss": 0.0002,
      "step": 70950
    },
    {
      "epoch": 3.411657296621979,
      "grad_norm": 0.46037110686302185,
      "learning_rate": 3.294195377444621e-05,
      "loss": 0.0001,
      "step": 71000
    },
    {
      "epoch": 3.41405987218298,
      "grad_norm": 0.3696063160896301,
      "learning_rate": 3.29299408966412e-05,
      "loss": 0.0002,
      "step": 71050
    },
    {
      "epoch": 3.4164624477439816,
      "grad_norm": 0.20859283208847046,
      "learning_rate": 3.291792801883619e-05,
      "loss": 0.0001,
      "step": 71100
    },
    {
      "epoch": 3.418865023304983,
      "grad_norm": 0.03228707239031792,
      "learning_rate": 3.290591514103118e-05,
      "loss": 0.0001,
      "step": 71150
    },
    {
      "epoch": 3.421267598865984,
      "grad_norm": 0.19753430783748627,
      "learning_rate": 3.289390226322618e-05,
      "loss": 0.0001,
      "step": 71200
    },
    {
      "epoch": 3.4236701744269857,
      "grad_norm": 0.06091200187802315,
      "learning_rate": 3.288188938542117e-05,
      "loss": 0.0002,
      "step": 71250
    },
    {
      "epoch": 3.4260727499879873,
      "grad_norm": 0.15594732761383057,
      "learning_rate": 3.286987650761616e-05,
      "loss": 0.0002,
      "step": 71300
    },
    {
      "epoch": 3.4284753255489884,
      "grad_norm": 0.07690523564815521,
      "learning_rate": 3.285786362981116e-05,
      "loss": 0.0002,
      "step": 71350
    },
    {
      "epoch": 3.43087790110999,
      "grad_norm": 0.7736082077026367,
      "learning_rate": 3.284585075200615e-05,
      "loss": 0.0002,
      "step": 71400
    },
    {
      "epoch": 3.4332804766709915,
      "grad_norm": 0.18872514367103577,
      "learning_rate": 3.283383787420115e-05,
      "loss": 0.0002,
      "step": 71450
    },
    {
      "epoch": 3.4356830522319926,
      "grad_norm": 0.046653833240270615,
      "learning_rate": 3.282182499639614e-05,
      "loss": 0.0002,
      "step": 71500
    },
    {
      "epoch": 3.438085627792994,
      "grad_norm": 0.03265026584267616,
      "learning_rate": 3.280981211859113e-05,
      "loss": 0.0004,
      "step": 71550
    },
    {
      "epoch": 3.4404882033539956,
      "grad_norm": 0.04139034077525139,
      "learning_rate": 3.279779924078613e-05,
      "loss": 0.0002,
      "step": 71600
    },
    {
      "epoch": 3.4428907789149967,
      "grad_norm": 0.14558741450309753,
      "learning_rate": 3.278578636298112e-05,
      "loss": 0.0002,
      "step": 71650
    },
    {
      "epoch": 3.4452933544759983,
      "grad_norm": 0.39394307136535645,
      "learning_rate": 3.2773773485176116e-05,
      "loss": 0.0002,
      "step": 71700
    },
    {
      "epoch": 3.447695930037,
      "grad_norm": 0.04379952326416969,
      "learning_rate": 3.2761760607371107e-05,
      "loss": 0.0001,
      "step": 71750
    },
    {
      "epoch": 3.450098505598001,
      "grad_norm": 0.2895483374595642,
      "learning_rate": 3.274974772956609e-05,
      "loss": 0.0002,
      "step": 71800
    },
    {
      "epoch": 3.4525010811590024,
      "grad_norm": 0.2016172856092453,
      "learning_rate": 3.273773485176109e-05,
      "loss": 0.0006,
      "step": 71850
    },
    {
      "epoch": 3.454903656720004,
      "grad_norm": 0.42583999037742615,
      "learning_rate": 3.272572197395608e-05,
      "loss": 0.0004,
      "step": 71900
    },
    {
      "epoch": 3.457306232281005,
      "grad_norm": 0.3178243637084961,
      "learning_rate": 3.271370909615108e-05,
      "loss": 0.0002,
      "step": 71950
    },
    {
      "epoch": 3.4597088078420066,
      "grad_norm": 0.17888794839382172,
      "learning_rate": 3.270169621834607e-05,
      "loss": 0.0002,
      "step": 72000
    },
    {
      "epoch": 3.462111383403008,
      "grad_norm": 0.06312506645917892,
      "learning_rate": 3.268968334054106e-05,
      "loss": 0.0007,
      "step": 72050
    },
    {
      "epoch": 3.4645139589640093,
      "grad_norm": 0.364362508058548,
      "learning_rate": 3.2677670462736056e-05,
      "loss": 0.0002,
      "step": 72100
    },
    {
      "epoch": 3.466916534525011,
      "grad_norm": 0.2910706400871277,
      "learning_rate": 3.266565758493105e-05,
      "loss": 0.0002,
      "step": 72150
    },
    {
      "epoch": 3.4693191100860123,
      "grad_norm": 3.3207247257232666,
      "learning_rate": 3.2653644707126044e-05,
      "loss": 0.0007,
      "step": 72200
    },
    {
      "epoch": 3.4717216856470134,
      "grad_norm": 0.2887285351753235,
      "learning_rate": 3.2641631829321035e-05,
      "loss": 0.0002,
      "step": 72250
    },
    {
      "epoch": 3.474124261208015,
      "grad_norm": 0.10710692405700684,
      "learning_rate": 3.2629618951516026e-05,
      "loss": 0.0002,
      "step": 72300
    },
    {
      "epoch": 3.4765268367690165,
      "grad_norm": 0.23147080838680267,
      "learning_rate": 3.2617606073711024e-05,
      "loss": 0.0002,
      "step": 72350
    },
    {
      "epoch": 3.4789294123300176,
      "grad_norm": 0.25660640001296997,
      "learning_rate": 3.2605593195906014e-05,
      "loss": 0.0002,
      "step": 72400
    },
    {
      "epoch": 3.481331987891019,
      "grad_norm": 0.15419241786003113,
      "learning_rate": 3.2593580318101005e-05,
      "loss": 0.0006,
      "step": 72450
    },
    {
      "epoch": 3.4837345634520207,
      "grad_norm": 0.20663243532180786,
      "learning_rate": 3.2581567440296e-05,
      "loss": 0.0007,
      "step": 72500
    },
    {
      "epoch": 3.486137139013022,
      "grad_norm": 0.5882246494293213,
      "learning_rate": 3.256955456249099e-05,
      "loss": 0.0002,
      "step": 72550
    },
    {
      "epoch": 3.4885397145740233,
      "grad_norm": 0.22220686078071594,
      "learning_rate": 3.2557541684685984e-05,
      "loss": 0.0002,
      "step": 72600
    },
    {
      "epoch": 3.490942290135025,
      "grad_norm": 0.1889142245054245,
      "learning_rate": 3.2545528806880975e-05,
      "loss": 0.0006,
      "step": 72650
    },
    {
      "epoch": 3.493344865696026,
      "grad_norm": 0.14787885546684265,
      "learning_rate": 3.2533515929075966e-05,
      "loss": 0.0005,
      "step": 72700
    },
    {
      "epoch": 3.4957474412570275,
      "grad_norm": 0.149240180850029,
      "learning_rate": 3.2521503051270964e-05,
      "loss": 0.0002,
      "step": 72750
    },
    {
      "epoch": 3.498150016818029,
      "grad_norm": 0.1987706422805786,
      "learning_rate": 3.2509490173465955e-05,
      "loss": 0.0001,
      "step": 72800
    },
    {
      "epoch": 3.50055259237903,
      "grad_norm": 0.30301129817962646,
      "learning_rate": 3.249747729566095e-05,
      "loss": 0.0002,
      "step": 72850
    },
    {
      "epoch": 3.5029551679400317,
      "grad_norm": 0.3435349762439728,
      "learning_rate": 3.248546441785594e-05,
      "loss": 0.0002,
      "step": 72900
    },
    {
      "epoch": 3.5053577435010332,
      "grad_norm": 0.09302351623773575,
      "learning_rate": 3.2473451540050934e-05,
      "loss": 0.0002,
      "step": 72950
    },
    {
      "epoch": 3.5077603190620343,
      "grad_norm": 0.23138950765132904,
      "learning_rate": 3.246143866224593e-05,
      "loss": 0.0002,
      "step": 73000
    },
    {
      "epoch": 3.510162894623036,
      "grad_norm": 0.15394645929336548,
      "learning_rate": 3.244942578444092e-05,
      "loss": 0.0002,
      "step": 73050
    },
    {
      "epoch": 3.5125654701840374,
      "grad_norm": 0.1030823141336441,
      "learning_rate": 3.243741290663592e-05,
      "loss": 0.0002,
      "step": 73100
    },
    {
      "epoch": 3.5149680457450385,
      "grad_norm": 0.24164772033691406,
      "learning_rate": 3.242540002883091e-05,
      "loss": 0.0002,
      "step": 73150
    },
    {
      "epoch": 3.51737062130604,
      "grad_norm": 0.7859123349189758,
      "learning_rate": 3.24133871510259e-05,
      "loss": 0.0002,
      "step": 73200
    },
    {
      "epoch": 3.5197731968670416,
      "grad_norm": 0.08779928088188171,
      "learning_rate": 3.24013742732209e-05,
      "loss": 0.0003,
      "step": 73250
    },
    {
      "epoch": 3.522175772428043,
      "grad_norm": 0.40360143780708313,
      "learning_rate": 3.238936139541588e-05,
      "loss": 0.0002,
      "step": 73300
    },
    {
      "epoch": 3.5245783479890442,
      "grad_norm": 0.5017815828323364,
      "learning_rate": 3.237734851761088e-05,
      "loss": 0.0002,
      "step": 73350
    },
    {
      "epoch": 3.5269809235500458,
      "grad_norm": 0.19295041263103485,
      "learning_rate": 3.236533563980587e-05,
      "loss": 0.0002,
      "step": 73400
    },
    {
      "epoch": 3.529383499111047,
      "grad_norm": 0.7491960525512695,
      "learning_rate": 3.235332276200086e-05,
      "loss": 0.0002,
      "step": 73450
    },
    {
      "epoch": 3.5317860746720484,
      "grad_norm": 0.3435690999031067,
      "learning_rate": 3.234130988419586e-05,
      "loss": 0.0002,
      "step": 73500
    },
    {
      "epoch": 3.53418865023305,
      "grad_norm": 0.14199447631835938,
      "learning_rate": 3.232929700639085e-05,
      "loss": 0.0002,
      "step": 73550
    },
    {
      "epoch": 3.5365912257940515,
      "grad_norm": 0.08401190489530563,
      "learning_rate": 3.231728412858585e-05,
      "loss": 0.0002,
      "step": 73600
    },
    {
      "epoch": 3.5389938013550526,
      "grad_norm": 0.1604876071214676,
      "learning_rate": 3.230527125078084e-05,
      "loss": 0.0002,
      "step": 73650
    },
    {
      "epoch": 3.541396376916054,
      "grad_norm": 0.1569739580154419,
      "learning_rate": 3.229325837297583e-05,
      "loss": 0.0001,
      "step": 73700
    },
    {
      "epoch": 3.5437989524770552,
      "grad_norm": 0.2036343663930893,
      "learning_rate": 3.228124549517083e-05,
      "loss": 0.0007,
      "step": 73750
    },
    {
      "epoch": 3.5462015280380568,
      "grad_norm": 0.0782814547419548,
      "learning_rate": 3.226923261736582e-05,
      "loss": 0.0002,
      "step": 73800
    },
    {
      "epoch": 3.5486041035990583,
      "grad_norm": 0.08741925656795502,
      "learning_rate": 3.225721973956081e-05,
      "loss": 0.0001,
      "step": 73850
    },
    {
      "epoch": 3.55100667916006,
      "grad_norm": 0.2855905592441559,
      "learning_rate": 3.224520686175581e-05,
      "loss": 0.0002,
      "step": 73900
    },
    {
      "epoch": 3.553409254721061,
      "grad_norm": 0.11606625467538834,
      "learning_rate": 3.22331939839508e-05,
      "loss": 0.0002,
      "step": 73950
    },
    {
      "epoch": 3.5558118302820625,
      "grad_norm": 0.27909693121910095,
      "learning_rate": 3.2221181106145795e-05,
      "loss": 0.0002,
      "step": 74000
    },
    {
      "epoch": 3.5582144058430636,
      "grad_norm": 0.30660882592201233,
      "learning_rate": 3.220916822834078e-05,
      "loss": 0.0009,
      "step": 74050
    },
    {
      "epoch": 3.560616981404065,
      "grad_norm": 3.068132162094116,
      "learning_rate": 3.219715535053578e-05,
      "loss": 0.0009,
      "step": 74100
    },
    {
      "epoch": 3.5630195569650667,
      "grad_norm": 0.1009819284081459,
      "learning_rate": 3.218514247273077e-05,
      "loss": 0.0001,
      "step": 74150
    },
    {
      "epoch": 3.565422132526068,
      "grad_norm": 0.278326153755188,
      "learning_rate": 3.217312959492576e-05,
      "loss": 0.0002,
      "step": 74200
    },
    {
      "epoch": 3.5678247080870693,
      "grad_norm": 0.32494619488716125,
      "learning_rate": 3.2161116717120756e-05,
      "loss": 0.0002,
      "step": 74250
    },
    {
      "epoch": 3.570227283648071,
      "grad_norm": 0.12981072068214417,
      "learning_rate": 3.214910383931575e-05,
      "loss": 0.0002,
      "step": 74300
    },
    {
      "epoch": 3.572629859209072,
      "grad_norm": 0.15755026042461395,
      "learning_rate": 3.213709096151074e-05,
      "loss": 0.0002,
      "step": 74350
    },
    {
      "epoch": 3.5750324347700735,
      "grad_norm": 0.2463792860507965,
      "learning_rate": 3.2125078083705735e-05,
      "loss": 0.0002,
      "step": 74400
    },
    {
      "epoch": 3.577435010331075,
      "grad_norm": 0.2615203857421875,
      "learning_rate": 3.2113065205900726e-05,
      "loss": 0.0002,
      "step": 74450
    },
    {
      "epoch": 3.5798375858920766,
      "grad_norm": 0.3625991642475128,
      "learning_rate": 3.2101052328095724e-05,
      "loss": 0.0002,
      "step": 74500
    },
    {
      "epoch": 3.5822401614530777,
      "grad_norm": 0.15623629093170166,
      "learning_rate": 3.2089039450290715e-05,
      "loss": 0.0002,
      "step": 74550
    },
    {
      "epoch": 3.584642737014079,
      "grad_norm": 0.06307926028966904,
      "learning_rate": 3.2077026572485706e-05,
      "loss": 0.0001,
      "step": 74600
    },
    {
      "epoch": 3.5870453125750803,
      "grad_norm": 0.4586760103702545,
      "learning_rate": 3.20650136946807e-05,
      "loss": 0.0002,
      "step": 74650
    },
    {
      "epoch": 3.589447888136082,
      "grad_norm": 0.4590044319629669,
      "learning_rate": 3.2053000816875694e-05,
      "loss": 0.0003,
      "step": 74700
    },
    {
      "epoch": 3.5918504636970834,
      "grad_norm": 0.4520845413208008,
      "learning_rate": 3.2040987939070685e-05,
      "loss": 0.0002,
      "step": 74750
    },
    {
      "epoch": 3.594253039258085,
      "grad_norm": 0.2714383006095886,
      "learning_rate": 3.2028975061265676e-05,
      "loss": 0.0002,
      "step": 74800
    },
    {
      "epoch": 3.596655614819086,
      "grad_norm": 0.2625667452812195,
      "learning_rate": 3.2016962183460666e-05,
      "loss": 0.0003,
      "step": 74850
    },
    {
      "epoch": 3.5990581903800876,
      "grad_norm": 0.035701021552085876,
      "learning_rate": 3.2004949305655664e-05,
      "loss": 0.0001,
      "step": 74900
    },
    {
      "epoch": 3.6014607659410887,
      "grad_norm": 0.15654639899730682,
      "learning_rate": 3.1992936427850655e-05,
      "loss": 0.0002,
      "step": 74950
    },
    {
      "epoch": 3.60386334150209,
      "grad_norm": 0.3211846947669983,
      "learning_rate": 3.198092355004565e-05,
      "loss": 0.0003,
      "step": 75000
    },
    {
      "epoch": 3.6062659170630917,
      "grad_norm": 0.2026738077402115,
      "learning_rate": 3.196891067224064e-05,
      "loss": 0.0002,
      "step": 75050
    },
    {
      "epoch": 3.6086684926240933,
      "grad_norm": 0.08439372479915619,
      "learning_rate": 3.1956897794435634e-05,
      "loss": 0.0002,
      "step": 75100
    },
    {
      "epoch": 3.6110710681850944,
      "grad_norm": 0.16762444376945496,
      "learning_rate": 3.194488491663063e-05,
      "loss": 0.0002,
      "step": 75150
    },
    {
      "epoch": 3.613473643746096,
      "grad_norm": 0.43259888887405396,
      "learning_rate": 3.193287203882562e-05,
      "loss": 0.0008,
      "step": 75200
    },
    {
      "epoch": 3.615876219307097,
      "grad_norm": 0.10588306188583374,
      "learning_rate": 3.1920859161020613e-05,
      "loss": 0.0007,
      "step": 75250
    },
    {
      "epoch": 3.6182787948680986,
      "grad_norm": 0.50229412317276,
      "learning_rate": 3.190884628321561e-05,
      "loss": 0.0002,
      "step": 75300
    },
    {
      "epoch": 3.6206813704291,
      "grad_norm": 0.41635170578956604,
      "learning_rate": 3.18968334054106e-05,
      "loss": 0.0002,
      "step": 75350
    },
    {
      "epoch": 3.6230839459901016,
      "grad_norm": 0.17470744252204895,
      "learning_rate": 3.18848205276056e-05,
      "loss": 0.0002,
      "step": 75400
    },
    {
      "epoch": 3.6254865215511027,
      "grad_norm": 0.16007095575332642,
      "learning_rate": 3.187280764980059e-05,
      "loss": 0.0002,
      "step": 75450
    },
    {
      "epoch": 3.6278890971121043,
      "grad_norm": 0.22050248086452484,
      "learning_rate": 3.186079477199558e-05,
      "loss": 0.0002,
      "step": 75500
    },
    {
      "epoch": 3.6302916726731054,
      "grad_norm": 0.2381695955991745,
      "learning_rate": 3.184878189419057e-05,
      "loss": 0.0002,
      "step": 75550
    },
    {
      "epoch": 3.632694248234107,
      "grad_norm": 0.02791392244398594,
      "learning_rate": 3.183676901638556e-05,
      "loss": 0.0001,
      "step": 75600
    },
    {
      "epoch": 3.6350968237951085,
      "grad_norm": 0.14196310937404633,
      "learning_rate": 3.182475613858056e-05,
      "loss": 0.0002,
      "step": 75650
    },
    {
      "epoch": 3.63749939935611,
      "grad_norm": 0.28753671050071716,
      "learning_rate": 3.181274326077555e-05,
      "loss": 0.0002,
      "step": 75700
    },
    {
      "epoch": 3.639901974917111,
      "grad_norm": 0.18115408718585968,
      "learning_rate": 3.180073038297054e-05,
      "loss": 0.0002,
      "step": 75750
    },
    {
      "epoch": 3.6423045504781126,
      "grad_norm": 0.7748475074768066,
      "learning_rate": 3.178871750516554e-05,
      "loss": 0.0002,
      "step": 75800
    },
    {
      "epoch": 3.6447071260391137,
      "grad_norm": 0.482639342546463,
      "learning_rate": 3.177670462736053e-05,
      "loss": 0.0009,
      "step": 75850
    },
    {
      "epoch": 3.6471097016001153,
      "grad_norm": 0.11089599877595901,
      "learning_rate": 3.176469174955553e-05,
      "loss": 0.0002,
      "step": 75900
    },
    {
      "epoch": 3.649512277161117,
      "grad_norm": 0.18054838478565216,
      "learning_rate": 3.175267887175052e-05,
      "loss": 0.0001,
      "step": 75950
    },
    {
      "epoch": 3.6519148527221184,
      "grad_norm": 0.11106154322624207,
      "learning_rate": 3.174066599394551e-05,
      "loss": 0.0002,
      "step": 76000
    },
    {
      "epoch": 3.6543174282831195,
      "grad_norm": 0.21584169566631317,
      "learning_rate": 3.172865311614051e-05,
      "loss": 0.0002,
      "step": 76050
    },
    {
      "epoch": 3.656720003844121,
      "grad_norm": 0.45378193259239197,
      "learning_rate": 3.17166402383355e-05,
      "loss": 0.0002,
      "step": 76100
    },
    {
      "epoch": 3.659122579405122,
      "grad_norm": 0.39584100246429443,
      "learning_rate": 3.170462736053049e-05,
      "loss": 0.0002,
      "step": 76150
    },
    {
      "epoch": 3.6615251549661236,
      "grad_norm": 0.4010365605354309,
      "learning_rate": 3.1692614482725487e-05,
      "loss": 0.0002,
      "step": 76200
    },
    {
      "epoch": 3.663927730527125,
      "grad_norm": 0.12543487548828125,
      "learning_rate": 3.168060160492048e-05,
      "loss": 0.0003,
      "step": 76250
    },
    {
      "epoch": 3.6663303060881267,
      "grad_norm": 0.2535839080810547,
      "learning_rate": 3.166858872711547e-05,
      "loss": 0.0002,
      "step": 76300
    },
    {
      "epoch": 3.668732881649128,
      "grad_norm": 0.07512427121400833,
      "learning_rate": 3.165657584931046e-05,
      "loss": 0.0001,
      "step": 76350
    },
    {
      "epoch": 3.6711354572101293,
      "grad_norm": 0.49496927857398987,
      "learning_rate": 3.1644562971505457e-05,
      "loss": 0.0002,
      "step": 76400
    },
    {
      "epoch": 3.6735380327711304,
      "grad_norm": 0.18301662802696228,
      "learning_rate": 3.163255009370045e-05,
      "loss": 0.0001,
      "step": 76450
    },
    {
      "epoch": 3.675940608332132,
      "grad_norm": 0.12612895667552948,
      "learning_rate": 3.162053721589544e-05,
      "loss": 0.0001,
      "step": 76500
    },
    {
      "epoch": 3.6783431838931335,
      "grad_norm": 0.43882259726524353,
      "learning_rate": 3.1608524338090436e-05,
      "loss": 0.0002,
      "step": 76550
    },
    {
      "epoch": 3.680745759454135,
      "grad_norm": 0.37095415592193604,
      "learning_rate": 3.159651146028543e-05,
      "loss": 0.0002,
      "step": 76600
    },
    {
      "epoch": 3.683148335015136,
      "grad_norm": 0.20553730428218842,
      "learning_rate": 3.158449858248042e-05,
      "loss": 0.0001,
      "step": 76650
    },
    {
      "epoch": 3.6855509105761377,
      "grad_norm": 0.07191397994756699,
      "learning_rate": 3.1572485704675415e-05,
      "loss": 0.0002,
      "step": 76700
    },
    {
      "epoch": 3.687953486137139,
      "grad_norm": 0.17505499720573425,
      "learning_rate": 3.1560472826870406e-05,
      "loss": 0.0002,
      "step": 76750
    },
    {
      "epoch": 3.6903560616981403,
      "grad_norm": 0.1000356376171112,
      "learning_rate": 3.1548459949065404e-05,
      "loss": 0.0005,
      "step": 76800
    },
    {
      "epoch": 3.692758637259142,
      "grad_norm": 0.4412029981613159,
      "learning_rate": 3.1536447071260394e-05,
      "loss": 0.0002,
      "step": 76850
    },
    {
      "epoch": 3.6951612128201434,
      "grad_norm": 0.11771904677152634,
      "learning_rate": 3.1524434193455385e-05,
      "loss": 0.0002,
      "step": 76900
    },
    {
      "epoch": 3.6975637883811445,
      "grad_norm": 0.1352493017911911,
      "learning_rate": 3.151242131565038e-05,
      "loss": 0.0002,
      "step": 76950
    },
    {
      "epoch": 3.699966363942146,
      "grad_norm": 0.19053539633750916,
      "learning_rate": 3.150040843784537e-05,
      "loss": 0.0002,
      "step": 77000
    },
    {
      "epoch": 3.702368939503147,
      "grad_norm": 1.1074323654174805,
      "learning_rate": 3.1488395560040364e-05,
      "loss": 0.0002,
      "step": 77050
    },
    {
      "epoch": 3.7047715150641487,
      "grad_norm": 0.18403373658657074,
      "learning_rate": 3.1476382682235355e-05,
      "loss": 0.0002,
      "step": 77100
    },
    {
      "epoch": 3.7071740906251502,
      "grad_norm": 0.16481897234916687,
      "learning_rate": 3.1464369804430346e-05,
      "loss": 0.0001,
      "step": 77150
    },
    {
      "epoch": 3.709576666186152,
      "grad_norm": 0.38640329241752625,
      "learning_rate": 3.1452356926625344e-05,
      "loss": 0.0002,
      "step": 77200
    },
    {
      "epoch": 3.711979241747153,
      "grad_norm": 0.1885826587677002,
      "learning_rate": 3.1440344048820334e-05,
      "loss": 0.0002,
      "step": 77250
    },
    {
      "epoch": 3.7143818173081544,
      "grad_norm": 0.19129754602909088,
      "learning_rate": 3.142833117101533e-05,
      "loss": 0.0001,
      "step": 77300
    },
    {
      "epoch": 3.7167843928691555,
      "grad_norm": 0.5564923286437988,
      "learning_rate": 3.141631829321032e-05,
      "loss": 0.0002,
      "step": 77350
    },
    {
      "epoch": 3.719186968430157,
      "grad_norm": 0.2672562897205353,
      "learning_rate": 3.1404305415405314e-05,
      "loss": 0.0001,
      "step": 77400
    },
    {
      "epoch": 3.7215895439911586,
      "grad_norm": 0.13592521846294403,
      "learning_rate": 3.139229253760031e-05,
      "loss": 0.0002,
      "step": 77450
    },
    {
      "epoch": 3.72399211955216,
      "grad_norm": 0.14433974027633667,
      "learning_rate": 3.13802796597953e-05,
      "loss": 0.0001,
      "step": 77500
    },
    {
      "epoch": 3.7263946951131612,
      "grad_norm": 0.36864137649536133,
      "learning_rate": 3.13682667819903e-05,
      "loss": 0.0002,
      "step": 77550
    },
    {
      "epoch": 3.728797270674163,
      "grad_norm": 0.0496491976082325,
      "learning_rate": 3.135625390418529e-05,
      "loss": 0.0002,
      "step": 77600
    },
    {
      "epoch": 3.731199846235164,
      "grad_norm": 0.1446056067943573,
      "learning_rate": 3.134424102638028e-05,
      "loss": 0.0002,
      "step": 77650
    },
    {
      "epoch": 3.7336024217961654,
      "grad_norm": 0.7142602801322937,
      "learning_rate": 3.133222814857528e-05,
      "loss": 0.0008,
      "step": 77700
    },
    {
      "epoch": 3.736004997357167,
      "grad_norm": 0.033669885247945786,
      "learning_rate": 3.132021527077026e-05,
      "loss": 0.0001,
      "step": 77750
    },
    {
      "epoch": 3.7384075729181685,
      "grad_norm": 0.04365728422999382,
      "learning_rate": 3.130820239296526e-05,
      "loss": 0.0002,
      "step": 77800
    },
    {
      "epoch": 3.7408101484791696,
      "grad_norm": 0.11711496114730835,
      "learning_rate": 3.129618951516025e-05,
      "loss": 0.0002,
      "step": 77850
    },
    {
      "epoch": 3.743212724040171,
      "grad_norm": 0.2657650113105774,
      "learning_rate": 3.128417663735524e-05,
      "loss": 0.0002,
      "step": 77900
    },
    {
      "epoch": 3.7456152996011722,
      "grad_norm": 0.085614413022995,
      "learning_rate": 3.127216375955024e-05,
      "loss": 0.0002,
      "step": 77950
    },
    {
      "epoch": 3.7480178751621738,
      "grad_norm": 0.38866081833839417,
      "learning_rate": 3.126015088174523e-05,
      "loss": 0.0002,
      "step": 78000
    },
    {
      "epoch": 3.7504204507231753,
      "grad_norm": 0.292568176984787,
      "learning_rate": 3.124813800394022e-05,
      "loss": 0.0002,
      "step": 78050
    },
    {
      "epoch": 3.752823026284177,
      "grad_norm": 0.19539318978786469,
      "learning_rate": 3.123612512613522e-05,
      "loss": 0.0002,
      "step": 78100
    },
    {
      "epoch": 3.755225601845178,
      "grad_norm": 0.36081090569496155,
      "learning_rate": 3.122411224833021e-05,
      "loss": 0.0002,
      "step": 78150
    },
    {
      "epoch": 3.7576281774061795,
      "grad_norm": 0.3661843538284302,
      "learning_rate": 3.121209937052521e-05,
      "loss": 0.0002,
      "step": 78200
    },
    {
      "epoch": 3.7600307529671806,
      "grad_norm": 0.2747529447078705,
      "learning_rate": 3.12000864927202e-05,
      "loss": 0.0001,
      "step": 78250
    },
    {
      "epoch": 3.762433328528182,
      "grad_norm": 0.13261985778808594,
      "learning_rate": 3.118807361491519e-05,
      "loss": 0.0001,
      "step": 78300
    },
    {
      "epoch": 3.7648359040891837,
      "grad_norm": 0.09310121089220047,
      "learning_rate": 3.117606073711019e-05,
      "loss": 0.0002,
      "step": 78350
    },
    {
      "epoch": 3.767238479650185,
      "grad_norm": 0.3121853172779083,
      "learning_rate": 3.116404785930518e-05,
      "loss": 0.0002,
      "step": 78400
    },
    {
      "epoch": 3.7696410552111863,
      "grad_norm": 0.12378670275211334,
      "learning_rate": 3.1152034981500175e-05,
      "loss": 0.0002,
      "step": 78450
    },
    {
      "epoch": 3.772043630772188,
      "grad_norm": 0.4559420347213745,
      "learning_rate": 3.114002210369516e-05,
      "loss": 0.0002,
      "step": 78500
    },
    {
      "epoch": 3.774446206333189,
      "grad_norm": 0.17533621191978455,
      "learning_rate": 3.112800922589015e-05,
      "loss": 0.0008,
      "step": 78550
    },
    {
      "epoch": 3.7768487818941905,
      "grad_norm": 0.17173348367214203,
      "learning_rate": 3.111599634808515e-05,
      "loss": 0.0002,
      "step": 78600
    },
    {
      "epoch": 3.779251357455192,
      "grad_norm": 0.3230178654193878,
      "learning_rate": 3.110398347028014e-05,
      "loss": 0.0002,
      "step": 78650
    },
    {
      "epoch": 3.7816539330161936,
      "grad_norm": 0.27220436930656433,
      "learning_rate": 3.1091970592475136e-05,
      "loss": 0.0002,
      "step": 78700
    },
    {
      "epoch": 3.7840565085771947,
      "grad_norm": 0.14830656349658966,
      "learning_rate": 3.107995771467013e-05,
      "loss": 0.0002,
      "step": 78750
    },
    {
      "epoch": 3.786459084138196,
      "grad_norm": 0.21160031855106354,
      "learning_rate": 3.106794483686512e-05,
      "loss": 0.0001,
      "step": 78800
    },
    {
      "epoch": 3.7888616596991973,
      "grad_norm": 0.7786298394203186,
      "learning_rate": 3.1055931959060115e-05,
      "loss": 0.0002,
      "step": 78850
    },
    {
      "epoch": 3.791264235260199,
      "grad_norm": 0.6406038999557495,
      "learning_rate": 3.1043919081255106e-05,
      "loss": 0.0002,
      "step": 78900
    },
    {
      "epoch": 3.7936668108212004,
      "grad_norm": 0.2642221450805664,
      "learning_rate": 3.1031906203450104e-05,
      "loss": 0.0002,
      "step": 78950
    },
    {
      "epoch": 3.796069386382202,
      "grad_norm": 0.26160386204719543,
      "learning_rate": 3.1019893325645095e-05,
      "loss": 0.0002,
      "step": 79000
    },
    {
      "epoch": 3.798471961943203,
      "grad_norm": 0.11860401928424835,
      "learning_rate": 3.1007880447840086e-05,
      "loss": 0.0002,
      "step": 79050
    },
    {
      "epoch": 3.8008745375042046,
      "grad_norm": 0.3682788610458374,
      "learning_rate": 3.099586757003508e-05,
      "loss": 0.0002,
      "step": 79100
    },
    {
      "epoch": 3.8032771130652057,
      "grad_norm": 0.3386991620063782,
      "learning_rate": 3.0983854692230074e-05,
      "loss": 0.0002,
      "step": 79150
    },
    {
      "epoch": 3.805679688626207,
      "grad_norm": 0.26450997591018677,
      "learning_rate": 3.0971841814425065e-05,
      "loss": 0.0002,
      "step": 79200
    },
    {
      "epoch": 3.8080822641872087,
      "grad_norm": 0.33574533462524414,
      "learning_rate": 3.0959828936620056e-05,
      "loss": 0.0002,
      "step": 79250
    },
    {
      "epoch": 3.8104848397482103,
      "grad_norm": 0.4349077343940735,
      "learning_rate": 3.0947816058815046e-05,
      "loss": 0.0002,
      "step": 79300
    },
    {
      "epoch": 3.8128874153092114,
      "grad_norm": 0.32917359471321106,
      "learning_rate": 3.0935803181010044e-05,
      "loss": 0.0002,
      "step": 79350
    },
    {
      "epoch": 3.815289990870213,
      "grad_norm": 0.11898333579301834,
      "learning_rate": 3.0923790303205035e-05,
      "loss": 0.0002,
      "step": 79400
    },
    {
      "epoch": 3.817692566431214,
      "grad_norm": 0.48972246050834656,
      "learning_rate": 3.091177742540003e-05,
      "loss": 0.0002,
      "step": 79450
    },
    {
      "epoch": 3.8200951419922156,
      "grad_norm": 0.5081180930137634,
      "learning_rate": 3.089976454759502e-05,
      "loss": 0.0002,
      "step": 79500
    },
    {
      "epoch": 3.822497717553217,
      "grad_norm": 0.05482008680701256,
      "learning_rate": 3.0887751669790014e-05,
      "loss": 0.0001,
      "step": 79550
    },
    {
      "epoch": 3.8249002931142186,
      "grad_norm": 0.4731256067752838,
      "learning_rate": 3.087573879198501e-05,
      "loss": 0.0002,
      "step": 79600
    },
    {
      "epoch": 3.8273028686752197,
      "grad_norm": 0.0452442541718483,
      "learning_rate": 3.086372591418e-05,
      "loss": 0.0002,
      "step": 79650
    },
    {
      "epoch": 3.8297054442362213,
      "grad_norm": 0.10767330229282379,
      "learning_rate": 3.085171303637499e-05,
      "loss": 0.0001,
      "step": 79700
    },
    {
      "epoch": 3.8321080197972224,
      "grad_norm": 0.3118317425251007,
      "learning_rate": 3.083970015856999e-05,
      "loss": 0.0001,
      "step": 79750
    },
    {
      "epoch": 3.834510595358224,
      "grad_norm": 0.3993496894836426,
      "learning_rate": 3.082768728076498e-05,
      "loss": 0.0002,
      "step": 79800
    },
    {
      "epoch": 3.8369131709192255,
      "grad_norm": 0.15728195011615753,
      "learning_rate": 3.081567440295998e-05,
      "loss": 0.0003,
      "step": 79850
    },
    {
      "epoch": 3.839315746480227,
      "grad_norm": 0.4235905110836029,
      "learning_rate": 3.080366152515497e-05,
      "loss": 0.0002,
      "step": 79900
    },
    {
      "epoch": 3.841718322041228,
      "grad_norm": 0.06544771790504456,
      "learning_rate": 3.079164864734996e-05,
      "loss": 0.0002,
      "step": 79950
    },
    {
      "epoch": 3.8441208976022296,
      "grad_norm": 0.1111074909567833,
      "learning_rate": 3.077963576954495e-05,
      "loss": 0.0002,
      "step": 80000
    },
    {
      "epoch": 3.8465234731632307,
      "grad_norm": 0.08906080573797226,
      "learning_rate": 3.076762289173994e-05,
      "loss": 0.0002,
      "step": 80050
    },
    {
      "epoch": 3.8489260487242323,
      "grad_norm": 0.20184612274169922,
      "learning_rate": 3.075561001393494e-05,
      "loss": 0.0002,
      "step": 80100
    },
    {
      "epoch": 3.851328624285234,
      "grad_norm": 0.12918409705162048,
      "learning_rate": 3.074359713612993e-05,
      "loss": 0.0002,
      "step": 80150
    },
    {
      "epoch": 3.8537311998462354,
      "grad_norm": 0.14545723795890808,
      "learning_rate": 3.073158425832492e-05,
      "loss": 0.0002,
      "step": 80200
    },
    {
      "epoch": 3.8561337754072365,
      "grad_norm": 0.17527101933956146,
      "learning_rate": 3.071957138051992e-05,
      "loss": 0.0006,
      "step": 80250
    },
    {
      "epoch": 3.858536350968238,
      "grad_norm": 0.130097433924675,
      "learning_rate": 3.070755850271491e-05,
      "loss": 0.0002,
      "step": 80300
    },
    {
      "epoch": 3.860938926529239,
      "grad_norm": 0.28602713346481323,
      "learning_rate": 3.069554562490991e-05,
      "loss": 0.0003,
      "step": 80350
    },
    {
      "epoch": 3.8633415020902406,
      "grad_norm": 0.1454574316740036,
      "learning_rate": 3.06835327471049e-05,
      "loss": 0.0002,
      "step": 80400
    },
    {
      "epoch": 3.865744077651242,
      "grad_norm": 0.2586877942085266,
      "learning_rate": 3.067151986929989e-05,
      "loss": 0.0003,
      "step": 80450
    },
    {
      "epoch": 3.8681466532122437,
      "grad_norm": 0.05348461866378784,
      "learning_rate": 3.065950699149489e-05,
      "loss": 0.0002,
      "step": 80500
    },
    {
      "epoch": 3.870549228773245,
      "grad_norm": 0.3518734276294708,
      "learning_rate": 3.064749411368988e-05,
      "loss": 0.0005,
      "step": 80550
    },
    {
      "epoch": 3.8729518043342464,
      "grad_norm": 0.0648970678448677,
      "learning_rate": 3.063548123588487e-05,
      "loss": 0.0002,
      "step": 80600
    },
    {
      "epoch": 3.8753543798952474,
      "grad_norm": 0.48439255356788635,
      "learning_rate": 3.0623468358079866e-05,
      "loss": 0.0002,
      "step": 80650
    },
    {
      "epoch": 3.877756955456249,
      "grad_norm": 0.1282159686088562,
      "learning_rate": 3.061145548027486e-05,
      "loss": 0.0002,
      "step": 80700
    },
    {
      "epoch": 3.8801595310172505,
      "grad_norm": 0.3749086260795593,
      "learning_rate": 3.059944260246985e-05,
      "loss": 0.0002,
      "step": 80750
    },
    {
      "epoch": 3.882562106578252,
      "grad_norm": 0.18150292336940765,
      "learning_rate": 3.058742972466484e-05,
      "loss": 0.0002,
      "step": 80800
    },
    {
      "epoch": 3.884964682139253,
      "grad_norm": 0.3644871711730957,
      "learning_rate": 3.0575416846859837e-05,
      "loss": 0.0002,
      "step": 80850
    },
    {
      "epoch": 3.8873672577002547,
      "grad_norm": 0.10438840091228485,
      "learning_rate": 3.056340396905483e-05,
      "loss": 0.0002,
      "step": 80900
    },
    {
      "epoch": 3.889769833261256,
      "grad_norm": 0.3753250539302826,
      "learning_rate": 3.055139109124982e-05,
      "loss": 0.0002,
      "step": 80950
    },
    {
      "epoch": 3.8921724088222573,
      "grad_norm": 0.14005982875823975,
      "learning_rate": 3.0539378213444816e-05,
      "loss": 0.0001,
      "step": 81000
    },
    {
      "epoch": 3.894574984383259,
      "grad_norm": 0.04975813627243042,
      "learning_rate": 3.052736533563981e-05,
      "loss": 0.0004,
      "step": 81050
    },
    {
      "epoch": 3.8969775599442604,
      "grad_norm": 0.10879084467887878,
      "learning_rate": 3.05153524578348e-05,
      "loss": 0.0002,
      "step": 81100
    },
    {
      "epoch": 3.8993801355052615,
      "grad_norm": 0.08963266760110855,
      "learning_rate": 3.0503339580029795e-05,
      "loss": 0.0006,
      "step": 81150
    },
    {
      "epoch": 3.901782711066263,
      "grad_norm": 0.21587565541267395,
      "learning_rate": 3.0491326702224786e-05,
      "loss": 0.0001,
      "step": 81200
    },
    {
      "epoch": 3.904185286627264,
      "grad_norm": 0.2930109202861786,
      "learning_rate": 3.047931382441978e-05,
      "loss": 0.0002,
      "step": 81250
    },
    {
      "epoch": 3.9065878621882657,
      "grad_norm": 0.15858425199985504,
      "learning_rate": 3.0467300946614774e-05,
      "loss": 0.0002,
      "step": 81300
    },
    {
      "epoch": 3.9089904377492672,
      "grad_norm": 0.6334596872329712,
      "learning_rate": 3.045528806880977e-05,
      "loss": 0.0002,
      "step": 81350
    },
    {
      "epoch": 3.911393013310269,
      "grad_norm": 0.1724850982427597,
      "learning_rate": 3.044327519100476e-05,
      "loss": 0.0002,
      "step": 81400
    },
    {
      "epoch": 3.91379558887127,
      "grad_norm": 0.20226404070854187,
      "learning_rate": 3.0431262313199754e-05,
      "loss": 0.0001,
      "step": 81450
    },
    {
      "epoch": 3.9161981644322714,
      "grad_norm": 0.1810489445924759,
      "learning_rate": 3.041924943539474e-05,
      "loss": 0.0002,
      "step": 81500
    },
    {
      "epoch": 3.9186007399932725,
      "grad_norm": 0.13783705234527588,
      "learning_rate": 3.0407236557589735e-05,
      "loss": 0.0001,
      "step": 81550
    },
    {
      "epoch": 3.921003315554274,
      "grad_norm": 0.44798171520233154,
      "learning_rate": 3.039522367978473e-05,
      "loss": 0.0002,
      "step": 81600
    },
    {
      "epoch": 3.9234058911152756,
      "grad_norm": 0.28032609820365906,
      "learning_rate": 3.0383210801979724e-05,
      "loss": 0.0002,
      "step": 81650
    },
    {
      "epoch": 3.925808466676277,
      "grad_norm": 0.18758751451969147,
      "learning_rate": 3.0371197924174714e-05,
      "loss": 0.0002,
      "step": 81700
    },
    {
      "epoch": 3.9282110422372782,
      "grad_norm": 0.13169057667255402,
      "learning_rate": 3.035918504636971e-05,
      "loss": 0.0006,
      "step": 81750
    },
    {
      "epoch": 3.93061361779828,
      "grad_norm": 0.7192466259002686,
      "learning_rate": 3.0347172168564703e-05,
      "loss": 0.0002,
      "step": 81800
    },
    {
      "epoch": 3.933016193359281,
      "grad_norm": 0.08067288249731064,
      "learning_rate": 3.0335159290759697e-05,
      "loss": 0.0001,
      "step": 81850
    },
    {
      "epoch": 3.9354187689202824,
      "grad_norm": 0.24931436777114868,
      "learning_rate": 3.0323146412954688e-05,
      "loss": 0.0002,
      "step": 81900
    },
    {
      "epoch": 3.937821344481284,
      "grad_norm": 1.4896000623703003,
      "learning_rate": 3.0311133535149682e-05,
      "loss": 0.0004,
      "step": 81950
    },
    {
      "epoch": 3.9402239200422855,
      "grad_norm": 0.14612142741680145,
      "learning_rate": 3.0299120657344676e-05,
      "loss": 0.0007,
      "step": 82000
    },
    {
      "epoch": 3.9426264956032866,
      "grad_norm": 0.21497473120689392,
      "learning_rate": 3.028710777953967e-05,
      "loss": 0.0002,
      "step": 82050
    },
    {
      "epoch": 3.945029071164288,
      "grad_norm": 0.1679157167673111,
      "learning_rate": 3.027509490173466e-05,
      "loss": 0.0002,
      "step": 82100
    },
    {
      "epoch": 3.9474316467252892,
      "grad_norm": 0.11699357628822327,
      "learning_rate": 3.0263082023929656e-05,
      "loss": 0.0002,
      "step": 82150
    },
    {
      "epoch": 3.9498342222862908,
      "grad_norm": 0.310435026884079,
      "learning_rate": 3.025106914612465e-05,
      "loss": 0.0001,
      "step": 82200
    },
    {
      "epoch": 3.9522367978472923,
      "grad_norm": 0.21534225344657898,
      "learning_rate": 3.0239056268319637e-05,
      "loss": 0.0001,
      "step": 82250
    },
    {
      "epoch": 3.954639373408294,
      "grad_norm": 0.30908459424972534,
      "learning_rate": 3.022704339051463e-05,
      "loss": 0.0002,
      "step": 82300
    },
    {
      "epoch": 3.957041948969295,
      "grad_norm": 0.13784997165203094,
      "learning_rate": 3.0215030512709626e-05,
      "loss": 0.0002,
      "step": 82350
    },
    {
      "epoch": 3.9594445245302965,
      "grad_norm": 0.10874322056770325,
      "learning_rate": 3.0203017634904617e-05,
      "loss": 0.0001,
      "step": 82400
    },
    {
      "epoch": 3.961847100091298,
      "grad_norm": 0.038267236202955246,
      "learning_rate": 3.019100475709961e-05,
      "loss": 0.0001,
      "step": 82450
    },
    {
      "epoch": 3.964249675652299,
      "grad_norm": 0.04342981427907944,
      "learning_rate": 3.0178991879294605e-05,
      "loss": 0.0002,
      "step": 82500
    },
    {
      "epoch": 3.9666522512133007,
      "grad_norm": 0.231430783867836,
      "learning_rate": 3.01669790014896e-05,
      "loss": 0.0002,
      "step": 82550
    },
    {
      "epoch": 3.969054826774302,
      "grad_norm": 0.18617425858974457,
      "learning_rate": 3.015496612368459e-05,
      "loss": 0.0001,
      "step": 82600
    },
    {
      "epoch": 3.9714574023353033,
      "grad_norm": 0.5510238409042358,
      "learning_rate": 3.0142953245879584e-05,
      "loss": 0.0002,
      "step": 82650
    },
    {
      "epoch": 3.973859977896305,
      "grad_norm": 0.3754850924015045,
      "learning_rate": 3.013094036807458e-05,
      "loss": 0.0002,
      "step": 82700
    },
    {
      "epoch": 3.9762625534573064,
      "grad_norm": 0.3473513126373291,
      "learning_rate": 3.0118927490269573e-05,
      "loss": 0.0002,
      "step": 82750
    },
    {
      "epoch": 3.9786651290183075,
      "grad_norm": 0.08106013387441635,
      "learning_rate": 3.0106914612464563e-05,
      "loss": 0.0002,
      "step": 82800
    },
    {
      "epoch": 3.981067704579309,
      "grad_norm": 0.5467520356178284,
      "learning_rate": 3.0094901734659558e-05,
      "loss": 0.0001,
      "step": 82850
    },
    {
      "epoch": 3.9834702801403106,
      "grad_norm": 0.09695583581924438,
      "learning_rate": 3.0082888856854552e-05,
      "loss": 0.0002,
      "step": 82900
    },
    {
      "epoch": 3.9858728557013117,
      "grad_norm": 0.23225028812885284,
      "learning_rate": 3.007087597904954e-05,
      "loss": 0.0002,
      "step": 82950
    },
    {
      "epoch": 3.988275431262313,
      "grad_norm": 0.07634393125772476,
      "learning_rate": 3.0058863101244534e-05,
      "loss": 0.0002,
      "step": 83000
    },
    {
      "epoch": 3.9906780068233147,
      "grad_norm": 0.5238537192344666,
      "learning_rate": 3.0046850223439528e-05,
      "loss": 0.0002,
      "step": 83050
    },
    {
      "epoch": 3.993080582384316,
      "grad_norm": 0.3900948166847229,
      "learning_rate": 3.003483734563452e-05,
      "loss": 0.0004,
      "step": 83100
    },
    {
      "epoch": 3.9954831579453174,
      "grad_norm": 0.23093578219413757,
      "learning_rate": 3.0022824467829513e-05,
      "loss": 0.0003,
      "step": 83150
    },
    {
      "epoch": 3.997885733506319,
      "grad_norm": 0.18859489262104034,
      "learning_rate": 3.0010811590024507e-05,
      "loss": 0.0002,
      "step": 83200
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.0002698591270018369,
      "eval_runtime": 17.4575,
      "eval_samples_per_second": 543.95,
      "eval_steps_per_second": 67.994,
      "step": 83244
    },
    {
      "epoch": 4.0002883090673205,
      "grad_norm": 0.24462437629699707,
      "learning_rate": 2.99987987122195e-05,
      "loss": 0.0001,
      "step": 83250
    },
    {
      "epoch": 4.002690884628321,
      "grad_norm": 0.10822813957929611,
      "learning_rate": 2.9986785834414492e-05,
      "loss": 0.0001,
      "step": 83300
    },
    {
      "epoch": 4.005093460189323,
      "grad_norm": 0.20560665428638458,
      "learning_rate": 2.9974772956609486e-05,
      "loss": 0.0002,
      "step": 83350
    },
    {
      "epoch": 4.007496035750324,
      "grad_norm": 0.24122494459152222,
      "learning_rate": 2.996276007880448e-05,
      "loss": 0.0002,
      "step": 83400
    },
    {
      "epoch": 4.009898611311326,
      "grad_norm": 0.2860192656517029,
      "learning_rate": 2.9950747200999475e-05,
      "loss": 0.0001,
      "step": 83450
    },
    {
      "epoch": 4.012301186872327,
      "grad_norm": 0.20529483258724213,
      "learning_rate": 2.993873432319447e-05,
      "loss": 0.0002,
      "step": 83500
    },
    {
      "epoch": 4.014703762433329,
      "grad_norm": 0.3782166540622711,
      "learning_rate": 2.992672144538946e-05,
      "loss": 0.0001,
      "step": 83550
    },
    {
      "epoch": 4.0171063379943295,
      "grad_norm": 0.07325983792543411,
      "learning_rate": 2.9914708567584454e-05,
      "loss": 0.0002,
      "step": 83600
    },
    {
      "epoch": 4.019508913555331,
      "grad_norm": 0.38287046551704407,
      "learning_rate": 2.9902695689779448e-05,
      "loss": 0.0001,
      "step": 83650
    },
    {
      "epoch": 4.021911489116333,
      "grad_norm": 0.06151533126831055,
      "learning_rate": 2.9890682811974436e-05,
      "loss": 0.0001,
      "step": 83700
    },
    {
      "epoch": 4.024314064677334,
      "grad_norm": 0.22360438108444214,
      "learning_rate": 2.987866993416943e-05,
      "loss": 0.0006,
      "step": 83750
    },
    {
      "epoch": 4.026716640238336,
      "grad_norm": 0.11377852410078049,
      "learning_rate": 2.986665705636442e-05,
      "loss": 0.0002,
      "step": 83800
    },
    {
      "epoch": 4.029119215799337,
      "grad_norm": 0.05447192117571831,
      "learning_rate": 2.9854644178559415e-05,
      "loss": 0.0001,
      "step": 83850
    },
    {
      "epoch": 4.031521791360339,
      "grad_norm": 0.07768411189317703,
      "learning_rate": 2.984263130075441e-05,
      "loss": 0.0002,
      "step": 83900
    },
    {
      "epoch": 4.033924366921339,
      "grad_norm": 0.2731972932815552,
      "learning_rate": 2.9830618422949403e-05,
      "loss": 0.0001,
      "step": 83950
    },
    {
      "epoch": 4.036326942482341,
      "grad_norm": 0.15640346705913544,
      "learning_rate": 2.9818605545144394e-05,
      "loss": 0.0001,
      "step": 84000
    },
    {
      "epoch": 4.0387295180433425,
      "grad_norm": 0.4840817153453827,
      "learning_rate": 2.9806592667339388e-05,
      "loss": 0.0002,
      "step": 84050
    },
    {
      "epoch": 4.041132093604344,
      "grad_norm": 0.11350031942129135,
      "learning_rate": 2.9794579789534382e-05,
      "loss": 0.0002,
      "step": 84100
    },
    {
      "epoch": 4.0435346691653455,
      "grad_norm": 0.5616456270217896,
      "learning_rate": 2.9782566911729377e-05,
      "loss": 0.0001,
      "step": 84150
    },
    {
      "epoch": 4.045937244726347,
      "grad_norm": 0.026613209396600723,
      "learning_rate": 2.977055403392437e-05,
      "loss": 0.0006,
      "step": 84200
    },
    {
      "epoch": 4.048339820287348,
      "grad_norm": 0.06306201219558716,
      "learning_rate": 2.9758541156119362e-05,
      "loss": 0.0007,
      "step": 84250
    },
    {
      "epoch": 4.050742395848349,
      "grad_norm": 0.12282104790210724,
      "learning_rate": 2.9746528278314356e-05,
      "loss": 0.0001,
      "step": 84300
    },
    {
      "epoch": 4.053144971409351,
      "grad_norm": 0.15737669169902802,
      "learning_rate": 2.973451540050935e-05,
      "loss": 0.0002,
      "step": 84350
    },
    {
      "epoch": 4.055547546970352,
      "grad_norm": 0.12209869921207428,
      "learning_rate": 2.9722502522704344e-05,
      "loss": 0.0002,
      "step": 84400
    },
    {
      "epoch": 4.057950122531354,
      "grad_norm": 0.2682911157608032,
      "learning_rate": 2.9710489644899332e-05,
      "loss": 0.0001,
      "step": 84450
    },
    {
      "epoch": 4.060352698092355,
      "grad_norm": 0.15711353719234467,
      "learning_rate": 2.9698476767094323e-05,
      "loss": 0.0002,
      "step": 84500
    },
    {
      "epoch": 4.062755273653356,
      "grad_norm": 0.2886054813861847,
      "learning_rate": 2.9686463889289317e-05,
      "loss": 0.0007,
      "step": 84550
    },
    {
      "epoch": 4.065157849214358,
      "grad_norm": 0.08198980242013931,
      "learning_rate": 2.967445101148431e-05,
      "loss": 0.0001,
      "step": 84600
    },
    {
      "epoch": 4.067560424775359,
      "grad_norm": 0.05287696048617363,
      "learning_rate": 2.9662438133679305e-05,
      "loss": 0.0001,
      "step": 84650
    },
    {
      "epoch": 4.069963000336361,
      "grad_norm": 0.16365809738636017,
      "learning_rate": 2.96504252558743e-05,
      "loss": 0.0002,
      "step": 84700
    },
    {
      "epoch": 4.072365575897362,
      "grad_norm": 0.10955481231212616,
      "learning_rate": 2.963841237806929e-05,
      "loss": 0.0002,
      "step": 84750
    },
    {
      "epoch": 4.074768151458364,
      "grad_norm": 0.29809391498565674,
      "learning_rate": 2.9626399500264285e-05,
      "loss": 0.0001,
      "step": 84800
    },
    {
      "epoch": 4.0771707270193644,
      "grad_norm": 0.27409133315086365,
      "learning_rate": 2.961438662245928e-05,
      "loss": 0.0002,
      "step": 84850
    },
    {
      "epoch": 4.079573302580366,
      "grad_norm": 1.1085338592529297,
      "learning_rate": 2.9602373744654273e-05,
      "loss": 0.0002,
      "step": 84900
    },
    {
      "epoch": 4.0819758781413675,
      "grad_norm": 0.10720890760421753,
      "learning_rate": 2.9590360866849264e-05,
      "loss": 0.0001,
      "step": 84950
    },
    {
      "epoch": 4.084378453702369,
      "grad_norm": 0.1598939746618271,
      "learning_rate": 2.9578347989044258e-05,
      "loss": 0.0002,
      "step": 85000
    },
    {
      "epoch": 4.086781029263371,
      "grad_norm": 0.293055921792984,
      "learning_rate": 2.9566335111239252e-05,
      "loss": 0.0002,
      "step": 85050
    },
    {
      "epoch": 4.089183604824372,
      "grad_norm": 0.14189790189266205,
      "learning_rate": 2.9554322233434246e-05,
      "loss": 0.0001,
      "step": 85100
    },
    {
      "epoch": 4.091586180385373,
      "grad_norm": 0.10407551378011703,
      "learning_rate": 2.9542309355629237e-05,
      "loss": 0.0002,
      "step": 85150
    },
    {
      "epoch": 4.093988755946374,
      "grad_norm": 0.11086276918649673,
      "learning_rate": 2.9530296477824225e-05,
      "loss": 0.0002,
      "step": 85200
    },
    {
      "epoch": 4.096391331507376,
      "grad_norm": 0.09109370410442352,
      "learning_rate": 2.951828360001922e-05,
      "loss": 0.0002,
      "step": 85250
    },
    {
      "epoch": 4.098793907068377,
      "grad_norm": 0.031297650188207626,
      "learning_rate": 2.9506270722214213e-05,
      "loss": 0.0001,
      "step": 85300
    },
    {
      "epoch": 4.101196482629379,
      "grad_norm": 0.037121448665857315,
      "learning_rate": 2.9494257844409207e-05,
      "loss": 0.0001,
      "step": 85350
    },
    {
      "epoch": 4.1035990581903805,
      "grad_norm": 0.08750511705875397,
      "learning_rate": 2.94822449666042e-05,
      "loss": 0.0002,
      "step": 85400
    },
    {
      "epoch": 4.106001633751381,
      "grad_norm": 0.4275701642036438,
      "learning_rate": 2.9470232088799192e-05,
      "loss": 0.0001,
      "step": 85450
    },
    {
      "epoch": 4.108404209312383,
      "grad_norm": 0.23710176348686218,
      "learning_rate": 2.9458219210994187e-05,
      "loss": 0.0002,
      "step": 85500
    },
    {
      "epoch": 4.110806784873384,
      "grad_norm": 0.1755530685186386,
      "learning_rate": 2.944620633318918e-05,
      "loss": 0.0002,
      "step": 85550
    },
    {
      "epoch": 4.113209360434386,
      "grad_norm": 0.06831319630146027,
      "learning_rate": 2.9434193455384175e-05,
      "loss": 0.0002,
      "step": 85600
    },
    {
      "epoch": 4.115611935995387,
      "grad_norm": 0.5377312898635864,
      "learning_rate": 2.9422180577579166e-05,
      "loss": 0.0001,
      "step": 85650
    },
    {
      "epoch": 4.118014511556389,
      "grad_norm": 0.20808495581150055,
      "learning_rate": 2.941016769977416e-05,
      "loss": 0.0001,
      "step": 85700
    },
    {
      "epoch": 4.1204170871173895,
      "grad_norm": 0.25321492552757263,
      "learning_rate": 2.9398154821969154e-05,
      "loss": 0.0002,
      "step": 85750
    },
    {
      "epoch": 4.122819662678391,
      "grad_norm": 0.05200646445155144,
      "learning_rate": 2.938614194416415e-05,
      "loss": 0.0007,
      "step": 85800
    },
    {
      "epoch": 4.125222238239393,
      "grad_norm": 0.35529160499572754,
      "learning_rate": 2.937412906635914e-05,
      "loss": 0.0002,
      "step": 85850
    },
    {
      "epoch": 4.127624813800394,
      "grad_norm": 0.20950579643249512,
      "learning_rate": 2.9362116188554134e-05,
      "loss": 0.0002,
      "step": 85900
    },
    {
      "epoch": 4.130027389361396,
      "grad_norm": 0.08498073369264603,
      "learning_rate": 2.935010331074912e-05,
      "loss": 0.0001,
      "step": 85950
    },
    {
      "epoch": 4.132429964922397,
      "grad_norm": 0.43953385949134827,
      "learning_rate": 2.9338090432944115e-05,
      "loss": 0.0002,
      "step": 86000
    },
    {
      "epoch": 4.134832540483398,
      "grad_norm": 0.15172095596790314,
      "learning_rate": 2.932607755513911e-05,
      "loss": 0.0002,
      "step": 86050
    },
    {
      "epoch": 4.137235116044399,
      "grad_norm": 0.55302494764328,
      "learning_rate": 2.9314064677334104e-05,
      "loss": 0.0001,
      "step": 86100
    },
    {
      "epoch": 4.139637691605401,
      "grad_norm": 0.8597496151924133,
      "learning_rate": 2.9302051799529094e-05,
      "loss": 0.0002,
      "step": 86150
    },
    {
      "epoch": 4.1420402671664025,
      "grad_norm": 0.4910442531108856,
      "learning_rate": 2.929003892172409e-05,
      "loss": 0.0007,
      "step": 86200
    },
    {
      "epoch": 4.144442842727404,
      "grad_norm": 0.10523008555173874,
      "learning_rate": 2.9278026043919083e-05,
      "loss": 0.0001,
      "step": 86250
    },
    {
      "epoch": 4.146845418288406,
      "grad_norm": 0.3201342821121216,
      "learning_rate": 2.9266013166114077e-05,
      "loss": 0.0001,
      "step": 86300
    },
    {
      "epoch": 4.149247993849406,
      "grad_norm": 0.4084037244319916,
      "learning_rate": 2.9254000288309068e-05,
      "loss": 0.0001,
      "step": 86350
    },
    {
      "epoch": 4.151650569410408,
      "grad_norm": 0.16223162412643433,
      "learning_rate": 2.9241987410504062e-05,
      "loss": 0.0001,
      "step": 86400
    },
    {
      "epoch": 4.154053144971409,
      "grad_norm": 0.11982551962137222,
      "learning_rate": 2.9229974532699056e-05,
      "loss": 0.0002,
      "step": 86450
    },
    {
      "epoch": 4.156455720532411,
      "grad_norm": 0.15650910139083862,
      "learning_rate": 2.921796165489405e-05,
      "loss": 0.0002,
      "step": 86500
    },
    {
      "epoch": 4.158858296093412,
      "grad_norm": 0.4121367931365967,
      "learning_rate": 2.920594877708904e-05,
      "loss": 0.0002,
      "step": 86550
    },
    {
      "epoch": 4.161260871654414,
      "grad_norm": 0.37686780095100403,
      "learning_rate": 2.9193935899284036e-05,
      "loss": 0.0002,
      "step": 86600
    },
    {
      "epoch": 4.163663447215415,
      "grad_norm": 0.08408993482589722,
      "learning_rate": 2.918192302147903e-05,
      "loss": 0.0002,
      "step": 86650
    },
    {
      "epoch": 4.166066022776416,
      "grad_norm": 0.5000547766685486,
      "learning_rate": 2.9169910143674017e-05,
      "loss": 0.0002,
      "step": 86700
    },
    {
      "epoch": 4.168468598337418,
      "grad_norm": 0.06330830603837967,
      "learning_rate": 2.915789726586901e-05,
      "loss": 0.0002,
      "step": 86750
    },
    {
      "epoch": 4.170871173898419,
      "grad_norm": 0.24765552580356598,
      "learning_rate": 2.9145884388064006e-05,
      "loss": 0.0002,
      "step": 86800
    },
    {
      "epoch": 4.173273749459421,
      "grad_norm": 0.4998845160007477,
      "learning_rate": 2.9133871510258996e-05,
      "loss": 0.0002,
      "step": 86850
    },
    {
      "epoch": 4.175676325020422,
      "grad_norm": 0.31969696283340454,
      "learning_rate": 2.912185863245399e-05,
      "loss": 0.0001,
      "step": 86900
    },
    {
      "epoch": 4.178078900581423,
      "grad_norm": 0.11800722777843475,
      "learning_rate": 2.9109845754648985e-05,
      "loss": 0.0001,
      "step": 86950
    },
    {
      "epoch": 4.1804814761424245,
      "grad_norm": 0.565385639667511,
      "learning_rate": 2.909783287684398e-05,
      "loss": 0.0002,
      "step": 87000
    },
    {
      "epoch": 4.182884051703426,
      "grad_norm": 0.3696303367614746,
      "learning_rate": 2.908581999903897e-05,
      "loss": 0.0002,
      "step": 87050
    },
    {
      "epoch": 4.185286627264428,
      "grad_norm": 0.27354487776756287,
      "learning_rate": 2.9073807121233964e-05,
      "loss": 0.0001,
      "step": 87100
    },
    {
      "epoch": 4.187689202825429,
      "grad_norm": 0.09885375946760178,
      "learning_rate": 2.906179424342896e-05,
      "loss": 0.0001,
      "step": 87150
    },
    {
      "epoch": 4.190091778386431,
      "grad_norm": 0.12212192267179489,
      "learning_rate": 2.9049781365623953e-05,
      "loss": 0.0002,
      "step": 87200
    },
    {
      "epoch": 4.192494353947431,
      "grad_norm": 0.04874740540981293,
      "learning_rate": 2.9037768487818943e-05,
      "loss": 0.0002,
      "step": 87250
    },
    {
      "epoch": 4.194896929508433,
      "grad_norm": 0.16344696283340454,
      "learning_rate": 2.9025755610013938e-05,
      "loss": 0.0002,
      "step": 87300
    },
    {
      "epoch": 4.197299505069434,
      "grad_norm": 0.5481197834014893,
      "learning_rate": 2.9013742732208932e-05,
      "loss": 0.0005,
      "step": 87350
    },
    {
      "epoch": 4.199702080630436,
      "grad_norm": 0.1864313781261444,
      "learning_rate": 2.9001729854403926e-05,
      "loss": 0.0002,
      "step": 87400
    },
    {
      "epoch": 4.2021046561914375,
      "grad_norm": 0.3812873065471649,
      "learning_rate": 2.8989716976598913e-05,
      "loss": 0.0002,
      "step": 87450
    },
    {
      "epoch": 4.204507231752439,
      "grad_norm": 0.11353940516710281,
      "learning_rate": 2.8977704098793908e-05,
      "loss": 0.0002,
      "step": 87500
    },
    {
      "epoch": 4.20690980731344,
      "grad_norm": 0.26206961274147034,
      "learning_rate": 2.89656912209889e-05,
      "loss": 0.0002,
      "step": 87550
    },
    {
      "epoch": 4.209312382874441,
      "grad_norm": 0.20138485729694366,
      "learning_rate": 2.8953678343183893e-05,
      "loss": 0.0001,
      "step": 87600
    },
    {
      "epoch": 4.211714958435443,
      "grad_norm": 0.17552991211414337,
      "learning_rate": 2.8941665465378887e-05,
      "loss": 0.0001,
      "step": 87650
    },
    {
      "epoch": 4.214117533996444,
      "grad_norm": 0.10925048589706421,
      "learning_rate": 2.892965258757388e-05,
      "loss": 0.0002,
      "step": 87700
    },
    {
      "epoch": 4.216520109557446,
      "grad_norm": 0.5162054300308228,
      "learning_rate": 2.8917639709768872e-05,
      "loss": 0.0001,
      "step": 87750
    },
    {
      "epoch": 4.218922685118447,
      "grad_norm": 0.4319375455379486,
      "learning_rate": 2.8905626831963866e-05,
      "loss": 0.0002,
      "step": 87800
    },
    {
      "epoch": 4.221325260679448,
      "grad_norm": 0.4937220513820648,
      "learning_rate": 2.889361395415886e-05,
      "loss": 0.0002,
      "step": 87850
    },
    {
      "epoch": 4.22372783624045,
      "grad_norm": 0.15755873918533325,
      "learning_rate": 2.8881601076353855e-05,
      "loss": 0.0001,
      "step": 87900
    },
    {
      "epoch": 4.226130411801451,
      "grad_norm": 0.1387951374053955,
      "learning_rate": 2.8869588198548845e-05,
      "loss": 0.0002,
      "step": 87950
    },
    {
      "epoch": 4.228532987362453,
      "grad_norm": 0.3023932874202728,
      "learning_rate": 2.885757532074384e-05,
      "loss": 0.0001,
      "step": 88000
    },
    {
      "epoch": 4.230935562923454,
      "grad_norm": 0.0672299936413765,
      "learning_rate": 2.8845562442938834e-05,
      "loss": 0.0002,
      "step": 88050
    },
    {
      "epoch": 4.233338138484456,
      "grad_norm": 0.43378931283950806,
      "learning_rate": 2.8833549565133828e-05,
      "loss": 0.0001,
      "step": 88100
    },
    {
      "epoch": 4.235740714045456,
      "grad_norm": 0.30736804008483887,
      "learning_rate": 2.8821536687328822e-05,
      "loss": 0.0001,
      "step": 88150
    },
    {
      "epoch": 4.238143289606458,
      "grad_norm": 0.539579451084137,
      "learning_rate": 2.880952380952381e-05,
      "loss": 0.0001,
      "step": 88200
    },
    {
      "epoch": 4.2405458651674595,
      "grad_norm": 0.3539048433303833,
      "learning_rate": 2.87975109317188e-05,
      "loss": 0.0002,
      "step": 88250
    },
    {
      "epoch": 4.242948440728461,
      "grad_norm": 0.3071090579032898,
      "learning_rate": 2.8785498053913795e-05,
      "loss": 0.0002,
      "step": 88300
    },
    {
      "epoch": 4.2453510162894625,
      "grad_norm": 0.41646698117256165,
      "learning_rate": 2.877348517610879e-05,
      "loss": 0.0002,
      "step": 88350
    },
    {
      "epoch": 4.247753591850464,
      "grad_norm": 0.08655024319887161,
      "learning_rate": 2.8761472298303783e-05,
      "loss": 0.0002,
      "step": 88400
    },
    {
      "epoch": 4.250156167411465,
      "grad_norm": 0.17327088117599487,
      "learning_rate": 2.8749459420498774e-05,
      "loss": 0.0002,
      "step": 88450
    },
    {
      "epoch": 4.252558742972466,
      "grad_norm": 0.43638700246810913,
      "learning_rate": 2.8737446542693768e-05,
      "loss": 0.0002,
      "step": 88500
    },
    {
      "epoch": 4.254961318533468,
      "grad_norm": 0.16428107023239136,
      "learning_rate": 2.8725433664888762e-05,
      "loss": 0.0002,
      "step": 88550
    },
    {
      "epoch": 4.257363894094469,
      "grad_norm": 0.27968570590019226,
      "learning_rate": 2.8713420787083757e-05,
      "loss": 0.0001,
      "step": 88600
    },
    {
      "epoch": 4.259766469655471,
      "grad_norm": 0.08084851503372192,
      "learning_rate": 2.8701407909278747e-05,
      "loss": 0.0002,
      "step": 88650
    },
    {
      "epoch": 4.262169045216472,
      "grad_norm": 0.09156720340251923,
      "learning_rate": 2.8689395031473742e-05,
      "loss": 0.0002,
      "step": 88700
    },
    {
      "epoch": 4.264571620777473,
      "grad_norm": 0.20591098070144653,
      "learning_rate": 2.8677382153668736e-05,
      "loss": 0.0003,
      "step": 88750
    },
    {
      "epoch": 4.266974196338475,
      "grad_norm": 0.1523539274930954,
      "learning_rate": 2.866536927586373e-05,
      "loss": 0.0001,
      "step": 88800
    },
    {
      "epoch": 4.269376771899476,
      "grad_norm": 0.1214279979467392,
      "learning_rate": 2.8653356398058724e-05,
      "loss": 0.0002,
      "step": 88850
    },
    {
      "epoch": 4.271779347460478,
      "grad_norm": 0.07206010818481445,
      "learning_rate": 2.8641343520253712e-05,
      "loss": 0.0002,
      "step": 88900
    },
    {
      "epoch": 4.274181923021479,
      "grad_norm": 0.1338295340538025,
      "learning_rate": 2.8629330642448703e-05,
      "loss": 0.0002,
      "step": 88950
    },
    {
      "epoch": 4.276584498582481,
      "grad_norm": 0.06369799375534058,
      "learning_rate": 2.8617317764643697e-05,
      "loss": 0.0001,
      "step": 89000
    },
    {
      "epoch": 4.2789870741434815,
      "grad_norm": 0.21291320025920868,
      "learning_rate": 2.860530488683869e-05,
      "loss": 0.0001,
      "step": 89050
    },
    {
      "epoch": 4.281389649704483,
      "grad_norm": 0.19410350918769836,
      "learning_rate": 2.8593292009033685e-05,
      "loss": 0.0001,
      "step": 89100
    },
    {
      "epoch": 4.2837922252654845,
      "grad_norm": 0.6696135997772217,
      "learning_rate": 2.8581279131228676e-05,
      "loss": 0.0001,
      "step": 89150
    },
    {
      "epoch": 4.286194800826486,
      "grad_norm": 0.02528129518032074,
      "learning_rate": 2.856926625342367e-05,
      "loss": 0.0001,
      "step": 89200
    },
    {
      "epoch": 4.288597376387488,
      "grad_norm": 0.3604874312877655,
      "learning_rate": 2.8557253375618665e-05,
      "loss": 0.0002,
      "step": 89250
    },
    {
      "epoch": 4.290999951948489,
      "grad_norm": 0.2934742569923401,
      "learning_rate": 2.854524049781366e-05,
      "loss": 0.0002,
      "step": 89300
    },
    {
      "epoch": 4.29340252750949,
      "grad_norm": 0.08677024394273758,
      "learning_rate": 2.853322762000865e-05,
      "loss": 0.0002,
      "step": 89350
    },
    {
      "epoch": 4.295805103070491,
      "grad_norm": 0.20167523622512817,
      "learning_rate": 2.8521214742203644e-05,
      "loss": 0.0001,
      "step": 89400
    },
    {
      "epoch": 4.298207678631493,
      "grad_norm": 0.10881399363279343,
      "learning_rate": 2.8509201864398638e-05,
      "loss": 0.0001,
      "step": 89450
    },
    {
      "epoch": 4.300610254192494,
      "grad_norm": 0.12476662546396255,
      "learning_rate": 2.8497188986593632e-05,
      "loss": 0.0002,
      "step": 89500
    },
    {
      "epoch": 4.303012829753496,
      "grad_norm": 0.09384302794933319,
      "learning_rate": 2.8485176108788626e-05,
      "loss": 0.0001,
      "step": 89550
    },
    {
      "epoch": 4.3054154053144975,
      "grad_norm": 0.11319854110479355,
      "learning_rate": 2.8473163230983617e-05,
      "loss": 0.0004,
      "step": 89600
    },
    {
      "epoch": 4.307817980875498,
      "grad_norm": 0.1379767805337906,
      "learning_rate": 2.8461150353178605e-05,
      "loss": 0.0002,
      "step": 89650
    },
    {
      "epoch": 4.3102205564365,
      "grad_norm": 0.09639465808868408,
      "learning_rate": 2.84491374753736e-05,
      "loss": 0.0001,
      "step": 89700
    },
    {
      "epoch": 4.312623131997501,
      "grad_norm": 2.128624200820923,
      "learning_rate": 2.8437124597568593e-05,
      "loss": 0.0003,
      "step": 89750
    },
    {
      "epoch": 4.315025707558503,
      "grad_norm": 0.14121048152446747,
      "learning_rate": 2.8425111719763587e-05,
      "loss": 0.0002,
      "step": 89800
    },
    {
      "epoch": 4.317428283119504,
      "grad_norm": 0.08032708615064621,
      "learning_rate": 2.8413098841958578e-05,
      "loss": 0.0005,
      "step": 89850
    },
    {
      "epoch": 4.319830858680506,
      "grad_norm": 0.15091045200824738,
      "learning_rate": 2.8401085964153572e-05,
      "loss": 0.0002,
      "step": 89900
    },
    {
      "epoch": 4.3222334342415065,
      "grad_norm": 0.08571457862854004,
      "learning_rate": 2.8389073086348567e-05,
      "loss": 0.0006,
      "step": 89950
    },
    {
      "epoch": 4.324636009802508,
      "grad_norm": 0.285115122795105,
      "learning_rate": 2.837706020854356e-05,
      "loss": 0.0002,
      "step": 90000
    },
    {
      "epoch": 4.32703858536351,
      "grad_norm": 0.11262152343988419,
      "learning_rate": 2.8365047330738555e-05,
      "loss": 0.0002,
      "step": 90050
    },
    {
      "epoch": 4.329441160924511,
      "grad_norm": 0.2808871567249298,
      "learning_rate": 2.8353034452933546e-05,
      "loss": 0.0002,
      "step": 90100
    },
    {
      "epoch": 4.331843736485513,
      "grad_norm": 0.035584207624197006,
      "learning_rate": 2.834102157512854e-05,
      "loss": 0.0001,
      "step": 90150
    },
    {
      "epoch": 4.334246312046514,
      "grad_norm": 0.13908688724040985,
      "learning_rate": 2.8329008697323534e-05,
      "loss": 0.0002,
      "step": 90200
    },
    {
      "epoch": 4.336648887607515,
      "grad_norm": 0.18929660320281982,
      "learning_rate": 2.831699581951853e-05,
      "loss": 0.0001,
      "step": 90250
    },
    {
      "epoch": 4.339051463168516,
      "grad_norm": 0.1993795931339264,
      "learning_rate": 2.830498294171352e-05,
      "loss": 0.0001,
      "step": 90300
    },
    {
      "epoch": 4.341454038729518,
      "grad_norm": 0.4154404401779175,
      "learning_rate": 2.8292970063908513e-05,
      "loss": 0.0001,
      "step": 90350
    },
    {
      "epoch": 4.3438566142905195,
      "grad_norm": 0.34857234358787537,
      "learning_rate": 2.82809571861035e-05,
      "loss": 0.0002,
      "step": 90400
    },
    {
      "epoch": 4.346259189851521,
      "grad_norm": 0.3313547670841217,
      "learning_rate": 2.8268944308298495e-05,
      "loss": 0.0002,
      "step": 90450
    },
    {
      "epoch": 4.348661765412523,
      "grad_norm": 0.5436823964118958,
      "learning_rate": 2.825693143049349e-05,
      "loss": 0.0001,
      "step": 90500
    },
    {
      "epoch": 4.351064340973523,
      "grad_norm": 0.18734583258628845,
      "learning_rate": 2.824491855268848e-05,
      "loss": 0.0002,
      "step": 90550
    },
    {
      "epoch": 4.353466916534525,
      "grad_norm": 0.05502608045935631,
      "learning_rate": 2.8232905674883474e-05,
      "loss": 0.0001,
      "step": 90600
    },
    {
      "epoch": 4.355869492095526,
      "grad_norm": 0.5852232575416565,
      "learning_rate": 2.822089279707847e-05,
      "loss": 0.0002,
      "step": 90650
    },
    {
      "epoch": 4.358272067656528,
      "grad_norm": 0.14823555946350098,
      "learning_rate": 2.8208879919273463e-05,
      "loss": 0.0002,
      "step": 90700
    },
    {
      "epoch": 4.360674643217529,
      "grad_norm": 0.07439280301332474,
      "learning_rate": 2.8196867041468457e-05,
      "loss": 0.0002,
      "step": 90750
    },
    {
      "epoch": 4.363077218778531,
      "grad_norm": 0.26352056860923767,
      "learning_rate": 2.8184854163663448e-05,
      "loss": 0.0002,
      "step": 90800
    },
    {
      "epoch": 4.365479794339532,
      "grad_norm": 0.20560631155967712,
      "learning_rate": 2.8172841285858442e-05,
      "loss": 0.0002,
      "step": 90850
    },
    {
      "epoch": 4.367882369900533,
      "grad_norm": 0.514532208442688,
      "learning_rate": 2.8160828408053436e-05,
      "loss": 0.0002,
      "step": 90900
    },
    {
      "epoch": 4.370284945461535,
      "grad_norm": 0.5358392596244812,
      "learning_rate": 2.814881553024843e-05,
      "loss": 0.0001,
      "step": 90950
    },
    {
      "epoch": 4.372687521022536,
      "grad_norm": 0.42645567655563354,
      "learning_rate": 2.813680265244342e-05,
      "loss": 0.0007,
      "step": 91000
    },
    {
      "epoch": 4.375090096583538,
      "grad_norm": 0.19399873912334442,
      "learning_rate": 2.8124789774638416e-05,
      "loss": 0.0002,
      "step": 91050
    },
    {
      "epoch": 4.377492672144539,
      "grad_norm": 0.3380182981491089,
      "learning_rate": 2.811277689683341e-05,
      "loss": 0.0005,
      "step": 91100
    },
    {
      "epoch": 4.37989524770554,
      "grad_norm": 0.1581009477376938,
      "learning_rate": 2.8100764019028397e-05,
      "loss": 0.0002,
      "step": 91150
    },
    {
      "epoch": 4.3822978232665415,
      "grad_norm": 0.15510232746601105,
      "learning_rate": 2.808875114122339e-05,
      "loss": 0.0002,
      "step": 91200
    },
    {
      "epoch": 4.384700398827543,
      "grad_norm": 0.09647157043218613,
      "learning_rate": 2.8076738263418386e-05,
      "loss": 0.0003,
      "step": 91250
    },
    {
      "epoch": 4.387102974388545,
      "grad_norm": 0.7483084201812744,
      "learning_rate": 2.8064725385613376e-05,
      "loss": 0.0002,
      "step": 91300
    },
    {
      "epoch": 4.389505549949546,
      "grad_norm": 0.1204557791352272,
      "learning_rate": 2.805271250780837e-05,
      "loss": 0.0001,
      "step": 91350
    },
    {
      "epoch": 4.391908125510548,
      "grad_norm": 0.16675351560115814,
      "learning_rate": 2.8040699630003365e-05,
      "loss": 0.0005,
      "step": 91400
    },
    {
      "epoch": 4.394310701071548,
      "grad_norm": 0.0528835654258728,
      "learning_rate": 2.802868675219836e-05,
      "loss": 0.0001,
      "step": 91450
    },
    {
      "epoch": 4.39671327663255,
      "grad_norm": 0.2995442748069763,
      "learning_rate": 2.801667387439335e-05,
      "loss": 0.0001,
      "step": 91500
    },
    {
      "epoch": 4.399115852193551,
      "grad_norm": 0.2681902348995209,
      "learning_rate": 2.8004660996588344e-05,
      "loss": 0.0002,
      "step": 91550
    },
    {
      "epoch": 4.401518427754553,
      "grad_norm": 0.25704771280288696,
      "learning_rate": 2.799264811878334e-05,
      "loss": 0.0001,
      "step": 91600
    },
    {
      "epoch": 4.4039210033155545,
      "grad_norm": 0.14853259921073914,
      "learning_rate": 2.7980635240978333e-05,
      "loss": 0.0002,
      "step": 91650
    },
    {
      "epoch": 4.406323578876556,
      "grad_norm": 0.12285353243350983,
      "learning_rate": 2.7968622363173323e-05,
      "loss": 0.0002,
      "step": 91700
    },
    {
      "epoch": 4.408726154437557,
      "grad_norm": 0.3746154010295868,
      "learning_rate": 2.7956609485368318e-05,
      "loss": 0.0001,
      "step": 91750
    },
    {
      "epoch": 4.411128729998558,
      "grad_norm": 0.05256718024611473,
      "learning_rate": 2.7944596607563312e-05,
      "loss": 0.0001,
      "step": 91800
    },
    {
      "epoch": 4.41353130555956,
      "grad_norm": 0.07397633790969849,
      "learning_rate": 2.7932583729758306e-05,
      "loss": 0.0002,
      "step": 91850
    },
    {
      "epoch": 4.415933881120561,
      "grad_norm": 0.2729288637638092,
      "learning_rate": 2.7920570851953293e-05,
      "loss": 0.0001,
      "step": 91900
    },
    {
      "epoch": 4.418336456681563,
      "grad_norm": 0.12612022459506989,
      "learning_rate": 2.7908557974148288e-05,
      "loss": 0.0001,
      "step": 91950
    },
    {
      "epoch": 4.420739032242564,
      "grad_norm": 0.5643237829208374,
      "learning_rate": 2.789654509634328e-05,
      "loss": 0.0002,
      "step": 92000
    },
    {
      "epoch": 4.423141607803565,
      "grad_norm": 0.15294839441776276,
      "learning_rate": 2.7884532218538273e-05,
      "loss": 0.0001,
      "step": 92050
    },
    {
      "epoch": 4.425544183364567,
      "grad_norm": 0.12884379923343658,
      "learning_rate": 2.7872519340733267e-05,
      "loss": 0.0001,
      "step": 92100
    },
    {
      "epoch": 4.427946758925568,
      "grad_norm": 0.44171786308288574,
      "learning_rate": 2.786050646292826e-05,
      "loss": 0.0002,
      "step": 92150
    },
    {
      "epoch": 4.43034933448657,
      "grad_norm": 0.08416484296321869,
      "learning_rate": 2.7848493585123252e-05,
      "loss": 0.0002,
      "step": 92200
    },
    {
      "epoch": 4.432751910047571,
      "grad_norm": 0.057732101529836655,
      "learning_rate": 2.7836480707318246e-05,
      "loss": 0.0002,
      "step": 92250
    },
    {
      "epoch": 4.435154485608573,
      "grad_norm": 0.13971497118473053,
      "learning_rate": 2.782446782951324e-05,
      "loss": 0.0002,
      "step": 92300
    },
    {
      "epoch": 4.437557061169573,
      "grad_norm": 0.20878762006759644,
      "learning_rate": 2.7812454951708235e-05,
      "loss": 0.0001,
      "step": 92350
    },
    {
      "epoch": 4.439959636730575,
      "grad_norm": 0.08791198581457138,
      "learning_rate": 2.7800442073903225e-05,
      "loss": 0.0001,
      "step": 92400
    },
    {
      "epoch": 4.4423622122915765,
      "grad_norm": 0.17138369381427765,
      "learning_rate": 2.778842919609822e-05,
      "loss": 0.0001,
      "step": 92450
    },
    {
      "epoch": 4.444764787852578,
      "grad_norm": 0.15259277820587158,
      "learning_rate": 2.7776416318293214e-05,
      "loss": 0.0002,
      "step": 92500
    },
    {
      "epoch": 4.4471673634135795,
      "grad_norm": 0.36425772309303284,
      "learning_rate": 2.7764403440488208e-05,
      "loss": 0.0001,
      "step": 92550
    },
    {
      "epoch": 4.449569938974581,
      "grad_norm": 0.39168494939804077,
      "learning_rate": 2.77523905626832e-05,
      "loss": 0.0002,
      "step": 92600
    },
    {
      "epoch": 4.451972514535582,
      "grad_norm": 0.0863533765077591,
      "learning_rate": 2.774037768487819e-05,
      "loss": 0.0002,
      "step": 92650
    },
    {
      "epoch": 4.454375090096583,
      "grad_norm": 0.16291466355323792,
      "learning_rate": 2.772836480707318e-05,
      "loss": 0.0001,
      "step": 92700
    },
    {
      "epoch": 4.456777665657585,
      "grad_norm": 0.31215038895606995,
      "learning_rate": 2.7716351929268175e-05,
      "loss": 0.0002,
      "step": 92750
    },
    {
      "epoch": 4.459180241218586,
      "grad_norm": 0.22841010987758636,
      "learning_rate": 2.770433905146317e-05,
      "loss": 0.0002,
      "step": 92800
    },
    {
      "epoch": 4.461582816779588,
      "grad_norm": 0.2961271405220032,
      "learning_rate": 2.7692326173658163e-05,
      "loss": 0.0001,
      "step": 92850
    },
    {
      "epoch": 4.463985392340589,
      "grad_norm": 0.07312802970409393,
      "learning_rate": 2.7680313295853154e-05,
      "loss": 0.0001,
      "step": 92900
    },
    {
      "epoch": 4.46638796790159,
      "grad_norm": 0.2782658040523529,
      "learning_rate": 2.7668300418048148e-05,
      "loss": 0.0001,
      "step": 92950
    },
    {
      "epoch": 4.468790543462592,
      "grad_norm": 0.1671229898929596,
      "learning_rate": 2.7656287540243142e-05,
      "loss": 0.0002,
      "step": 93000
    },
    {
      "epoch": 4.471193119023593,
      "grad_norm": 0.1303287297487259,
      "learning_rate": 2.7644274662438137e-05,
      "loss": 0.0002,
      "step": 93050
    },
    {
      "epoch": 4.473595694584595,
      "grad_norm": 0.09533251076936722,
      "learning_rate": 2.7632261784633127e-05,
      "loss": 0.0004,
      "step": 93100
    },
    {
      "epoch": 4.475998270145596,
      "grad_norm": 0.15208664536476135,
      "learning_rate": 2.762024890682812e-05,
      "loss": 0.0001,
      "step": 93150
    },
    {
      "epoch": 4.478400845706598,
      "grad_norm": 0.15504565834999084,
      "learning_rate": 2.7608236029023116e-05,
      "loss": 0.0002,
      "step": 93200
    },
    {
      "epoch": 4.4808034212675985,
      "grad_norm": 0.15589608252048492,
      "learning_rate": 2.759622315121811e-05,
      "loss": 0.0002,
      "step": 93250
    },
    {
      "epoch": 4.4832059968286,
      "grad_norm": 0.3418484926223755,
      "learning_rate": 2.75842102734131e-05,
      "loss": 0.0002,
      "step": 93300
    },
    {
      "epoch": 4.4856085723896015,
      "grad_norm": 0.058177847415208817,
      "learning_rate": 2.7572197395608095e-05,
      "loss": 0.0001,
      "step": 93350
    },
    {
      "epoch": 4.488011147950603,
      "grad_norm": 0.09723088890314102,
      "learning_rate": 2.7560184517803083e-05,
      "loss": 0.0001,
      "step": 93400
    },
    {
      "epoch": 4.490413723511605,
      "grad_norm": 0.15551558136940002,
      "learning_rate": 2.7548171639998077e-05,
      "loss": 0.0006,
      "step": 93450
    },
    {
      "epoch": 4.492816299072606,
      "grad_norm": 0.27897801995277405,
      "learning_rate": 2.753615876219307e-05,
      "loss": 0.0001,
      "step": 93500
    },
    {
      "epoch": 4.495218874633608,
      "grad_norm": 0.06288723647594452,
      "learning_rate": 2.7524145884388065e-05,
      "loss": 0.0001,
      "step": 93550
    },
    {
      "epoch": 4.497621450194608,
      "grad_norm": 0.4949672520160675,
      "learning_rate": 2.7512133006583056e-05,
      "loss": 0.0006,
      "step": 93600
    },
    {
      "epoch": 4.50002402575561,
      "grad_norm": 0.509626567363739,
      "learning_rate": 2.750012012877805e-05,
      "loss": 0.0001,
      "step": 93650
    },
    {
      "epoch": 4.502426601316611,
      "grad_norm": 0.061420973390340805,
      "learning_rate": 2.7488107250973044e-05,
      "loss": 0.0003,
      "step": 93700
    },
    {
      "epoch": 4.504829176877613,
      "grad_norm": 0.08853016048669815,
      "learning_rate": 2.747609437316804e-05,
      "loss": 0.0002,
      "step": 93750
    },
    {
      "epoch": 4.5072317524386145,
      "grad_norm": 0.07689852267503738,
      "learning_rate": 2.746408149536303e-05,
      "loss": 0.0005,
      "step": 93800
    },
    {
      "epoch": 4.509634327999615,
      "grad_norm": 0.29338765144348145,
      "learning_rate": 2.7452068617558024e-05,
      "loss": 0.0003,
      "step": 93850
    },
    {
      "epoch": 4.512036903560617,
      "grad_norm": 0.15137621760368347,
      "learning_rate": 2.7440055739753018e-05,
      "loss": 0.0002,
      "step": 93900
    },
    {
      "epoch": 4.514439479121618,
      "grad_norm": 0.0760248526930809,
      "learning_rate": 2.7428042861948012e-05,
      "loss": 0.0001,
      "step": 93950
    },
    {
      "epoch": 4.51684205468262,
      "grad_norm": 0.04713341221213341,
      "learning_rate": 2.7416029984143003e-05,
      "loss": 0.0001,
      "step": 94000
    },
    {
      "epoch": 4.519244630243621,
      "grad_norm": 0.24031920731067657,
      "learning_rate": 2.7404017106337997e-05,
      "loss": 0.0001,
      "step": 94050
    },
    {
      "epoch": 4.521647205804623,
      "grad_norm": 0.39388906955718994,
      "learning_rate": 2.739200422853299e-05,
      "loss": 0.0001,
      "step": 94100
    },
    {
      "epoch": 4.524049781365624,
      "grad_norm": 0.4030891954898834,
      "learning_rate": 2.737999135072798e-05,
      "loss": 0.0002,
      "step": 94150
    },
    {
      "epoch": 4.526452356926625,
      "grad_norm": 0.2768166959285736,
      "learning_rate": 2.7367978472922973e-05,
      "loss": 0.0002,
      "step": 94200
    },
    {
      "epoch": 4.528854932487627,
      "grad_norm": 0.12244699150323868,
      "learning_rate": 2.7355965595117967e-05,
      "loss": 0.0006,
      "step": 94250
    },
    {
      "epoch": 4.531257508048628,
      "grad_norm": 0.1687222421169281,
      "learning_rate": 2.7343952717312958e-05,
      "loss": 0.0001,
      "step": 94300
    },
    {
      "epoch": 4.53366008360963,
      "grad_norm": 0.13635380566120148,
      "learning_rate": 2.7331939839507952e-05,
      "loss": 0.0002,
      "step": 94350
    },
    {
      "epoch": 4.536062659170631,
      "grad_norm": 0.0960160344839096,
      "learning_rate": 2.7319926961702947e-05,
      "loss": 0.0002,
      "step": 94400
    },
    {
      "epoch": 4.538465234731632,
      "grad_norm": 0.17262397706508636,
      "learning_rate": 2.730791408389794e-05,
      "loss": 0.0002,
      "step": 94450
    },
    {
      "epoch": 4.540867810292633,
      "grad_norm": 0.12561212480068207,
      "learning_rate": 2.729590120609293e-05,
      "loss": 0.0002,
      "step": 94500
    },
    {
      "epoch": 4.543270385853635,
      "grad_norm": 0.2730378806591034,
      "learning_rate": 2.7283888328287926e-05,
      "loss": 0.0002,
      "step": 94550
    },
    {
      "epoch": 4.5456729614146365,
      "grad_norm": 0.3800565302371979,
      "learning_rate": 2.727187545048292e-05,
      "loss": 0.0001,
      "step": 94600
    },
    {
      "epoch": 4.548075536975638,
      "grad_norm": 0.48225367069244385,
      "learning_rate": 2.7259862572677914e-05,
      "loss": 0.0002,
      "step": 94650
    },
    {
      "epoch": 4.55047811253664,
      "grad_norm": 0.23237018287181854,
      "learning_rate": 2.724784969487291e-05,
      "loss": 0.0006,
      "step": 94700
    },
    {
      "epoch": 4.552880688097641,
      "grad_norm": 0.157226100564003,
      "learning_rate": 2.72358368170679e-05,
      "loss": 0.0001,
      "step": 94750
    },
    {
      "epoch": 4.555283263658642,
      "grad_norm": 0.1384107619524002,
      "learning_rate": 2.7223823939262893e-05,
      "loss": 0.0001,
      "step": 94800
    },
    {
      "epoch": 4.557685839219643,
      "grad_norm": 0.028711942955851555,
      "learning_rate": 2.721181106145788e-05,
      "loss": 0.0004,
      "step": 94850
    },
    {
      "epoch": 4.560088414780645,
      "grad_norm": 0.5759389996528625,
      "learning_rate": 2.7199798183652875e-05,
      "loss": 0.0002,
      "step": 94900
    },
    {
      "epoch": 4.562490990341646,
      "grad_norm": 0.22728249430656433,
      "learning_rate": 2.718778530584787e-05,
      "loss": 0.0001,
      "step": 94950
    },
    {
      "epoch": 4.564893565902648,
      "grad_norm": 0.17023031413555145,
      "learning_rate": 2.717577242804286e-05,
      "loss": 0.0002,
      "step": 95000
    },
    {
      "epoch": 4.567296141463649,
      "grad_norm": 0.128903329372406,
      "learning_rate": 2.7163759550237854e-05,
      "loss": 0.0002,
      "step": 95050
    },
    {
      "epoch": 4.56969871702465,
      "grad_norm": 0.4234676659107208,
      "learning_rate": 2.715174667243285e-05,
      "loss": 0.0002,
      "step": 95100
    },
    {
      "epoch": 4.572101292585652,
      "grad_norm": 0.37773287296295166,
      "learning_rate": 2.7139733794627843e-05,
      "loss": 0.0002,
      "step": 95150
    },
    {
      "epoch": 4.574503868146653,
      "grad_norm": 0.2057482749223709,
      "learning_rate": 2.7127720916822834e-05,
      "loss": 0.0001,
      "step": 95200
    },
    {
      "epoch": 4.576906443707655,
      "grad_norm": 0.1060146912932396,
      "learning_rate": 2.7115708039017828e-05,
      "loss": 0.0002,
      "step": 95250
    },
    {
      "epoch": 4.579309019268656,
      "grad_norm": 0.29197657108306885,
      "learning_rate": 2.7103695161212822e-05,
      "loss": 0.0002,
      "step": 95300
    },
    {
      "epoch": 4.581711594829658,
      "grad_norm": 0.11681514978408813,
      "learning_rate": 2.7091682283407816e-05,
      "loss": 0.0001,
      "step": 95350
    },
    {
      "epoch": 4.5841141703906585,
      "grad_norm": 0.1268407106399536,
      "learning_rate": 2.707966940560281e-05,
      "loss": 0.0002,
      "step": 95400
    },
    {
      "epoch": 4.58651674595166,
      "grad_norm": 0.07851920276880264,
      "learning_rate": 2.70676565277978e-05,
      "loss": 0.0002,
      "step": 95450
    },
    {
      "epoch": 4.588919321512662,
      "grad_norm": 0.3830793499946594,
      "learning_rate": 2.7055643649992795e-05,
      "loss": 0.0007,
      "step": 95500
    },
    {
      "epoch": 4.591321897073663,
      "grad_norm": 0.17739588022232056,
      "learning_rate": 2.704363077218779e-05,
      "loss": 0.0001,
      "step": 95550
    },
    {
      "epoch": 4.593724472634665,
      "grad_norm": 0.2490898221731186,
      "learning_rate": 2.7031617894382777e-05,
      "loss": 0.0001,
      "step": 95600
    },
    {
      "epoch": 4.596127048195665,
      "grad_norm": 0.0865994542837143,
      "learning_rate": 2.701960501657777e-05,
      "loss": 0.0002,
      "step": 95650
    },
    {
      "epoch": 4.598529623756667,
      "grad_norm": 0.12687598168849945,
      "learning_rate": 2.7007592138772762e-05,
      "loss": 0.0001,
      "step": 95700
    },
    {
      "epoch": 4.600932199317668,
      "grad_norm": 0.10630437731742859,
      "learning_rate": 2.6995579260967756e-05,
      "loss": 0.0001,
      "step": 95750
    },
    {
      "epoch": 4.60333477487867,
      "grad_norm": 0.04030520096421242,
      "learning_rate": 2.698356638316275e-05,
      "loss": 0.0002,
      "step": 95800
    },
    {
      "epoch": 4.6057373504396715,
      "grad_norm": 0.39718949794769287,
      "learning_rate": 2.6971553505357745e-05,
      "loss": 0.0001,
      "step": 95850
    },
    {
      "epoch": 4.608139926000673,
      "grad_norm": 0.03569252789020538,
      "learning_rate": 2.695954062755274e-05,
      "loss": 0.0002,
      "step": 95900
    },
    {
      "epoch": 4.6105425015616746,
      "grad_norm": 0.35469675064086914,
      "learning_rate": 2.694752774974773e-05,
      "loss": 0.0002,
      "step": 95950
    },
    {
      "epoch": 4.612945077122675,
      "grad_norm": 0.6232880353927612,
      "learning_rate": 2.6935514871942724e-05,
      "loss": 0.0001,
      "step": 96000
    },
    {
      "epoch": 4.615347652683677,
      "grad_norm": 0.28434860706329346,
      "learning_rate": 2.6923501994137718e-05,
      "loss": 0.0002,
      "step": 96050
    },
    {
      "epoch": 4.617750228244678,
      "grad_norm": 0.3270486295223236,
      "learning_rate": 2.6911489116332713e-05,
      "loss": 0.0002,
      "step": 96100
    },
    {
      "epoch": 4.62015280380568,
      "grad_norm": 0.4831544756889343,
      "learning_rate": 2.6899476238527703e-05,
      "loss": 0.0002,
      "step": 96150
    },
    {
      "epoch": 4.622555379366681,
      "grad_norm": 0.27138739824295044,
      "learning_rate": 2.6887463360722698e-05,
      "loss": 0.0002,
      "step": 96200
    },
    {
      "epoch": 4.624957954927682,
      "grad_norm": 0.130731999874115,
      "learning_rate": 2.6875450482917692e-05,
      "loss": 0.0001,
      "step": 96250
    },
    {
      "epoch": 4.627360530488684,
      "grad_norm": 0.19281823933124542,
      "learning_rate": 2.6863437605112686e-05,
      "loss": 0.0001,
      "step": 96300
    },
    {
      "epoch": 4.629763106049685,
      "grad_norm": 0.42464566230773926,
      "learning_rate": 2.6851424727307673e-05,
      "loss": 0.0002,
      "step": 96350
    },
    {
      "epoch": 4.632165681610687,
      "grad_norm": 0.33452939987182617,
      "learning_rate": 2.6839411849502664e-05,
      "loss": 0.0001,
      "step": 96400
    },
    {
      "epoch": 4.634568257171688,
      "grad_norm": 0.28616511821746826,
      "learning_rate": 2.682739897169766e-05,
      "loss": 0.0002,
      "step": 96450
    },
    {
      "epoch": 4.63697083273269,
      "grad_norm": 0.1716437041759491,
      "learning_rate": 2.6815386093892653e-05,
      "loss": 0.0002,
      "step": 96500
    },
    {
      "epoch": 4.639373408293691,
      "grad_norm": 0.20920047163963318,
      "learning_rate": 2.6803373216087647e-05,
      "loss": 0.0002,
      "step": 96550
    },
    {
      "epoch": 4.641775983854692,
      "grad_norm": 0.5980604887008667,
      "learning_rate": 2.679136033828264e-05,
      "loss": 0.0001,
      "step": 96600
    },
    {
      "epoch": 4.6441785594156935,
      "grad_norm": 0.1993168741464615,
      "learning_rate": 2.6779347460477632e-05,
      "loss": 0.0002,
      "step": 96650
    },
    {
      "epoch": 4.646581134976695,
      "grad_norm": 0.1018553301692009,
      "learning_rate": 2.6767334582672626e-05,
      "loss": 0.0001,
      "step": 96700
    },
    {
      "epoch": 4.6489837105376965,
      "grad_norm": 0.1873713731765747,
      "learning_rate": 2.675532170486762e-05,
      "loss": 0.0002,
      "step": 96750
    },
    {
      "epoch": 4.651386286098698,
      "grad_norm": 0.6136474609375,
      "learning_rate": 2.6743308827062615e-05,
      "loss": 0.0007,
      "step": 96800
    },
    {
      "epoch": 4.653788861659699,
      "grad_norm": 0.5858991146087646,
      "learning_rate": 2.6731295949257605e-05,
      "loss": 0.0002,
      "step": 96850
    },
    {
      "epoch": 4.6561914372207,
      "grad_norm": 0.5207239389419556,
      "learning_rate": 2.67192830714526e-05,
      "loss": 0.0002,
      "step": 96900
    },
    {
      "epoch": 4.658594012781702,
      "grad_norm": 0.4357849657535553,
      "learning_rate": 2.6707270193647594e-05,
      "loss": 0.0002,
      "step": 96950
    },
    {
      "epoch": 4.660996588342703,
      "grad_norm": 0.06831037998199463,
      "learning_rate": 2.6695257315842588e-05,
      "loss": 0.0002,
      "step": 97000
    },
    {
      "epoch": 4.663399163903705,
      "grad_norm": 0.35508087277412415,
      "learning_rate": 2.668324443803758e-05,
      "loss": 0.0002,
      "step": 97050
    },
    {
      "epoch": 4.665801739464706,
      "grad_norm": 0.09742119908332825,
      "learning_rate": 2.6671231560232566e-05,
      "loss": 0.0001,
      "step": 97100
    },
    {
      "epoch": 4.668204315025708,
      "grad_norm": 0.17715570330619812,
      "learning_rate": 2.665921868242756e-05,
      "loss": 0.0002,
      "step": 97150
    },
    {
      "epoch": 4.670606890586709,
      "grad_norm": 0.42100781202316284,
      "learning_rate": 2.6647205804622555e-05,
      "loss": 0.0001,
      "step": 97200
    },
    {
      "epoch": 4.67300946614771,
      "grad_norm": 0.13701675832271576,
      "learning_rate": 2.663519292681755e-05,
      "loss": 0.0005,
      "step": 97250
    },
    {
      "epoch": 4.675412041708712,
      "grad_norm": 0.2955794930458069,
      "learning_rate": 2.6623180049012543e-05,
      "loss": 0.0002,
      "step": 97300
    },
    {
      "epoch": 4.677814617269713,
      "grad_norm": 0.07724727690219879,
      "learning_rate": 2.6611167171207534e-05,
      "loss": 0.0002,
      "step": 97350
    },
    {
      "epoch": 4.680217192830715,
      "grad_norm": 0.15346302092075348,
      "learning_rate": 2.6599154293402528e-05,
      "loss": 0.0005,
      "step": 97400
    },
    {
      "epoch": 4.6826197683917155,
      "grad_norm": 0.24908225238323212,
      "learning_rate": 2.6587141415597522e-05,
      "loss": 0.0007,
      "step": 97450
    },
    {
      "epoch": 4.685022343952717,
      "grad_norm": 0.11161484569311142,
      "learning_rate": 2.6575128537792517e-05,
      "loss": 0.0004,
      "step": 97500
    },
    {
      "epoch": 4.6874249195137185,
      "grad_norm": 0.2564070522785187,
      "learning_rate": 2.6563115659987507e-05,
      "loss": 0.0002,
      "step": 97550
    },
    {
      "epoch": 4.68982749507472,
      "grad_norm": 0.190179705619812,
      "learning_rate": 2.65511027821825e-05,
      "loss": 0.0002,
      "step": 97600
    },
    {
      "epoch": 4.692230070635722,
      "grad_norm": 0.4007790684700012,
      "learning_rate": 2.6539089904377496e-05,
      "loss": 0.0002,
      "step": 97650
    },
    {
      "epoch": 4.694632646196723,
      "grad_norm": 0.670459508895874,
      "learning_rate": 2.652707702657249e-05,
      "loss": 0.0003,
      "step": 97700
    },
    {
      "epoch": 4.697035221757725,
      "grad_norm": 0.266694039106369,
      "learning_rate": 2.651506414876748e-05,
      "loss": 0.0002,
      "step": 97750
    },
    {
      "epoch": 4.699437797318725,
      "grad_norm": 0.3779016137123108,
      "learning_rate": 2.6503051270962475e-05,
      "loss": 0.0002,
      "step": 97800
    },
    {
      "epoch": 4.701840372879727,
      "grad_norm": 0.16639916598796844,
      "learning_rate": 2.6491038393157463e-05,
      "loss": 0.0001,
      "step": 97850
    },
    {
      "epoch": 4.704242948440728,
      "grad_norm": 0.3640699088573456,
      "learning_rate": 2.6479025515352457e-05,
      "loss": 0.0002,
      "step": 97900
    },
    {
      "epoch": 4.70664552400173,
      "grad_norm": 0.22109448909759521,
      "learning_rate": 2.646701263754745e-05,
      "loss": 0.0002,
      "step": 97950
    },
    {
      "epoch": 4.7090480995627315,
      "grad_norm": 0.2024262249469757,
      "learning_rate": 2.6454999759742445e-05,
      "loss": 0.0001,
      "step": 98000
    },
    {
      "epoch": 4.711450675123732,
      "grad_norm": 0.11490857601165771,
      "learning_rate": 2.6442986881937436e-05,
      "loss": 0.0002,
      "step": 98050
    },
    {
      "epoch": 4.713853250684734,
      "grad_norm": 0.4554162323474884,
      "learning_rate": 2.643097400413243e-05,
      "loss": 0.0001,
      "step": 98100
    },
    {
      "epoch": 4.716255826245735,
      "grad_norm": 0.6306235194206238,
      "learning_rate": 2.6418961126327424e-05,
      "loss": 0.0001,
      "step": 98150
    },
    {
      "epoch": 4.718658401806737,
      "grad_norm": 0.5409515500068665,
      "learning_rate": 2.640694824852242e-05,
      "loss": 0.0002,
      "step": 98200
    },
    {
      "epoch": 4.721060977367738,
      "grad_norm": 0.2705872654914856,
      "learning_rate": 2.639493537071741e-05,
      "loss": 0.0002,
      "step": 98250
    },
    {
      "epoch": 4.72346355292874,
      "grad_norm": 0.36223965883255005,
      "learning_rate": 2.6382922492912404e-05,
      "loss": 0.0002,
      "step": 98300
    },
    {
      "epoch": 4.725866128489741,
      "grad_norm": 0.08443950861692429,
      "learning_rate": 2.6370909615107398e-05,
      "loss": 0.0002,
      "step": 98350
    },
    {
      "epoch": 4.728268704050742,
      "grad_norm": 0.10989166051149368,
      "learning_rate": 2.6358896737302392e-05,
      "loss": 0.0001,
      "step": 98400
    },
    {
      "epoch": 4.730671279611744,
      "grad_norm": 0.06801678985357285,
      "learning_rate": 2.6346883859497383e-05,
      "loss": 0.0002,
      "step": 98450
    },
    {
      "epoch": 4.733073855172745,
      "grad_norm": 0.2935808598995209,
      "learning_rate": 2.6334870981692377e-05,
      "loss": 0.0006,
      "step": 98500
    },
    {
      "epoch": 4.735476430733747,
      "grad_norm": 0.1417005956172943,
      "learning_rate": 2.632285810388737e-05,
      "loss": 0.0002,
      "step": 98550
    },
    {
      "epoch": 4.737879006294748,
      "grad_norm": 0.08852237462997437,
      "learning_rate": 2.631084522608236e-05,
      "loss": 0.0002,
      "step": 98600
    },
    {
      "epoch": 4.740281581855749,
      "grad_norm": 0.7296410799026489,
      "learning_rate": 2.6298832348277353e-05,
      "loss": 0.0002,
      "step": 98650
    },
    {
      "epoch": 4.74268415741675,
      "grad_norm": 0.2521659731864929,
      "learning_rate": 2.6286819470472347e-05,
      "loss": 0.0001,
      "step": 98700
    },
    {
      "epoch": 4.745086732977752,
      "grad_norm": 0.2562705874443054,
      "learning_rate": 2.6274806592667338e-05,
      "loss": 0.0001,
      "step": 98750
    },
    {
      "epoch": 4.7474893085387535,
      "grad_norm": 0.22706706821918488,
      "learning_rate": 2.6262793714862332e-05,
      "loss": 0.0002,
      "step": 98800
    },
    {
      "epoch": 4.749891884099755,
      "grad_norm": 0.14966212213039398,
      "learning_rate": 2.6250780837057326e-05,
      "loss": 0.0002,
      "step": 98850
    },
    {
      "epoch": 4.752294459660757,
      "grad_norm": 0.34182000160217285,
      "learning_rate": 2.623876795925232e-05,
      "loss": 0.0002,
      "step": 98900
    },
    {
      "epoch": 4.754697035221758,
      "grad_norm": 0.10273869335651398,
      "learning_rate": 2.622675508144731e-05,
      "loss": 0.0001,
      "step": 98950
    },
    {
      "epoch": 4.757099610782759,
      "grad_norm": 0.2598378658294678,
      "learning_rate": 2.6214742203642306e-05,
      "loss": 0.0001,
      "step": 99000
    },
    {
      "epoch": 4.75950218634376,
      "grad_norm": 0.2006642371416092,
      "learning_rate": 2.62027293258373e-05,
      "loss": 0.0002,
      "step": 99050
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.4222167730331421,
      "learning_rate": 2.6190716448032294e-05,
      "loss": 0.0006,
      "step": 99100
    },
    {
      "epoch": 4.764307337465763,
      "grad_norm": 0.35972437262535095,
      "learning_rate": 2.6178703570227285e-05,
      "loss": 0.0002,
      "step": 99150
    },
    {
      "epoch": 4.766709913026765,
      "grad_norm": 0.3917098939418793,
      "learning_rate": 2.616669069242228e-05,
      "loss": 0.0001,
      "step": 99200
    },
    {
      "epoch": 4.769112488587766,
      "grad_norm": 0.32606884837150574,
      "learning_rate": 2.6154677814617273e-05,
      "loss": 0.0001,
      "step": 99250
    },
    {
      "epoch": 4.771515064148767,
      "grad_norm": 0.1834295690059662,
      "learning_rate": 2.6142664936812268e-05,
      "loss": 0.0007,
      "step": 99300
    },
    {
      "epoch": 4.773917639709769,
      "grad_norm": 0.06215766817331314,
      "learning_rate": 2.6130652059007255e-05,
      "loss": 0.0001,
      "step": 99350
    },
    {
      "epoch": 4.77632021527077,
      "grad_norm": 0.27387022972106934,
      "learning_rate": 2.611863918120225e-05,
      "loss": 0.0002,
      "step": 99400
    },
    {
      "epoch": 4.778722790831772,
      "grad_norm": 0.05106961354613304,
      "learning_rate": 2.610662630339724e-05,
      "loss": 0.0001,
      "step": 99450
    },
    {
      "epoch": 4.781125366392773,
      "grad_norm": 0.24735325574874878,
      "learning_rate": 2.6094613425592234e-05,
      "loss": 0.0002,
      "step": 99500
    },
    {
      "epoch": 4.783527941953775,
      "grad_norm": 0.30961570143699646,
      "learning_rate": 2.608260054778723e-05,
      "loss": 0.0002,
      "step": 99550
    },
    {
      "epoch": 4.7859305175147755,
      "grad_norm": 0.039107631891965866,
      "learning_rate": 2.6070587669982223e-05,
      "loss": 0.0001,
      "step": 99600
    },
    {
      "epoch": 4.788333093075777,
      "grad_norm": 0.06197920814156532,
      "learning_rate": 2.6058574792177214e-05,
      "loss": 0.0001,
      "step": 99650
    },
    {
      "epoch": 4.790735668636779,
      "grad_norm": 0.12733140587806702,
      "learning_rate": 2.6046561914372208e-05,
      "loss": 0.0001,
      "step": 99700
    },
    {
      "epoch": 4.79313824419778,
      "grad_norm": 0.10198760777711868,
      "learning_rate": 2.6034549036567202e-05,
      "loss": 0.0002,
      "step": 99750
    },
    {
      "epoch": 4.795540819758782,
      "grad_norm": 0.3494758605957031,
      "learning_rate": 2.6022536158762196e-05,
      "loss": 0.0002,
      "step": 99800
    },
    {
      "epoch": 4.797943395319782,
      "grad_norm": 0.6770256161689758,
      "learning_rate": 2.6010523280957187e-05,
      "loss": 0.0002,
      "step": 99850
    },
    {
      "epoch": 4.800345970880784,
      "grad_norm": 0.07465110719203949,
      "learning_rate": 2.599851040315218e-05,
      "loss": 0.0002,
      "step": 99900
    },
    {
      "epoch": 4.802748546441785,
      "grad_norm": 0.38116222620010376,
      "learning_rate": 2.5986497525347175e-05,
      "loss": 0.0001,
      "step": 99950
    },
    {
      "epoch": 4.805151122002787,
      "grad_norm": 0.1727258861064911,
      "learning_rate": 2.597448464754217e-05,
      "loss": 0.0001,
      "step": 100000
    },
    {
      "epoch": 4.8075536975637885,
      "grad_norm": 0.4639686346054077,
      "learning_rate": 2.5962471769737164e-05,
      "loss": 0.0001,
      "step": 100050
    },
    {
      "epoch": 4.80995627312479,
      "grad_norm": 0.22399470210075378,
      "learning_rate": 2.595045889193215e-05,
      "loss": 0.0001,
      "step": 100100
    },
    {
      "epoch": 4.812358848685792,
      "grad_norm": 0.29593321681022644,
      "learning_rate": 2.5938446014127142e-05,
      "loss": 0.0002,
      "step": 100150
    },
    {
      "epoch": 4.814761424246792,
      "grad_norm": 0.1438376009464264,
      "learning_rate": 2.5926433136322136e-05,
      "loss": 0.0001,
      "step": 100200
    },
    {
      "epoch": 4.817163999807794,
      "grad_norm": 0.2586512565612793,
      "learning_rate": 2.591442025851713e-05,
      "loss": 0.0001,
      "step": 100250
    },
    {
      "epoch": 4.819566575368795,
      "grad_norm": 0.3528510630130768,
      "learning_rate": 2.5902407380712125e-05,
      "loss": 0.0004,
      "step": 100300
    },
    {
      "epoch": 4.821969150929797,
      "grad_norm": 0.1123109683394432,
      "learning_rate": 2.5890394502907116e-05,
      "loss": 0.0002,
      "step": 100350
    },
    {
      "epoch": 4.824371726490798,
      "grad_norm": 0.49199676513671875,
      "learning_rate": 2.587838162510211e-05,
      "loss": 0.0001,
      "step": 100400
    },
    {
      "epoch": 4.8267743020518,
      "grad_norm": 0.1567099690437317,
      "learning_rate": 2.5866368747297104e-05,
      "loss": 0.0002,
      "step": 100450
    },
    {
      "epoch": 4.829176877612801,
      "grad_norm": 0.09943988919258118,
      "learning_rate": 2.5854355869492098e-05,
      "loss": 0.0002,
      "step": 100500
    },
    {
      "epoch": 4.831579453173802,
      "grad_norm": 0.08939649164676666,
      "learning_rate": 2.584234299168709e-05,
      "loss": 0.0002,
      "step": 100550
    },
    {
      "epoch": 4.833982028734804,
      "grad_norm": 0.10822742432355881,
      "learning_rate": 2.5830330113882083e-05,
      "loss": 0.0002,
      "step": 100600
    },
    {
      "epoch": 4.836384604295805,
      "grad_norm": 0.22373272478580475,
      "learning_rate": 2.5818317236077078e-05,
      "loss": 0.0002,
      "step": 100650
    },
    {
      "epoch": 4.838787179856807,
      "grad_norm": 0.10397680103778839,
      "learning_rate": 2.5806304358272072e-05,
      "loss": 0.0001,
      "step": 100700
    },
    {
      "epoch": 4.841189755417808,
      "grad_norm": 0.4610563814640045,
      "learning_rate": 2.5794291480467066e-05,
      "loss": 0.0002,
      "step": 100750
    },
    {
      "epoch": 4.843592330978809,
      "grad_norm": 0.07744736969470978,
      "learning_rate": 2.5782278602662053e-05,
      "loss": 0.0002,
      "step": 100800
    },
    {
      "epoch": 4.8459949065398105,
      "grad_norm": 0.07365776598453522,
      "learning_rate": 2.5770265724857044e-05,
      "loss": 0.0002,
      "step": 100850
    },
    {
      "epoch": 4.848397482100812,
      "grad_norm": 0.2206147462129593,
      "learning_rate": 2.575825284705204e-05,
      "loss": 0.0001,
      "step": 100900
    },
    {
      "epoch": 4.8508000576618135,
      "grad_norm": 0.2062215507030487,
      "learning_rate": 2.5746239969247033e-05,
      "loss": 0.0001,
      "step": 100950
    },
    {
      "epoch": 4.853202633222815,
      "grad_norm": 0.2653205096721649,
      "learning_rate": 2.5734227091442027e-05,
      "loss": 0.0002,
      "step": 101000
    },
    {
      "epoch": 4.855605208783817,
      "grad_norm": 0.14751167595386505,
      "learning_rate": 2.5722214213637018e-05,
      "loss": 0.0001,
      "step": 101050
    },
    {
      "epoch": 4.858007784344817,
      "grad_norm": 0.1986599564552307,
      "learning_rate": 2.5710201335832012e-05,
      "loss": 0.0002,
      "step": 101100
    },
    {
      "epoch": 4.860410359905819,
      "grad_norm": 0.1341658979654312,
      "learning_rate": 2.5698188458027006e-05,
      "loss": 0.0002,
      "step": 101150
    },
    {
      "epoch": 4.86281293546682,
      "grad_norm": 0.3666752278804779,
      "learning_rate": 2.5686175580222e-05,
      "loss": 0.0002,
      "step": 101200
    },
    {
      "epoch": 4.865215511027822,
      "grad_norm": 0.08579719811677933,
      "learning_rate": 2.5674162702416995e-05,
      "loss": 0.0001,
      "step": 101250
    },
    {
      "epoch": 4.8676180865888234,
      "grad_norm": 0.2970106303691864,
      "learning_rate": 2.5662149824611985e-05,
      "loss": 0.0002,
      "step": 101300
    },
    {
      "epoch": 4.870020662149825,
      "grad_norm": 0.11762651056051254,
      "learning_rate": 2.565013694680698e-05,
      "loss": 0.0002,
      "step": 101350
    },
    {
      "epoch": 4.872423237710826,
      "grad_norm": 0.2367561012506485,
      "learning_rate": 2.5638124069001974e-05,
      "loss": 0.0001,
      "step": 101400
    },
    {
      "epoch": 4.874825813271827,
      "grad_norm": 0.10241471976041794,
      "learning_rate": 2.5626111191196968e-05,
      "loss": 0.0005,
      "step": 101450
    },
    {
      "epoch": 4.877228388832829,
      "grad_norm": 0.1496822088956833,
      "learning_rate": 2.561409831339196e-05,
      "loss": 0.0002,
      "step": 101500
    },
    {
      "epoch": 4.87963096439383,
      "grad_norm": 0.4830785095691681,
      "learning_rate": 2.5602085435586946e-05,
      "loss": 0.0002,
      "step": 101550
    },
    {
      "epoch": 4.882033539954832,
      "grad_norm": 0.461180716753006,
      "learning_rate": 2.559007255778194e-05,
      "loss": 0.0002,
      "step": 101600
    },
    {
      "epoch": 4.884436115515833,
      "grad_norm": 0.3629402220249176,
      "learning_rate": 2.5578059679976935e-05,
      "loss": 0.0002,
      "step": 101650
    },
    {
      "epoch": 4.886838691076834,
      "grad_norm": 0.3105309009552002,
      "learning_rate": 2.556604680217193e-05,
      "loss": 0.0002,
      "step": 101700
    },
    {
      "epoch": 4.8892412666378355,
      "grad_norm": 0.2387259304523468,
      "learning_rate": 2.555403392436692e-05,
      "loss": 0.0001,
      "step": 101750
    },
    {
      "epoch": 4.891643842198837,
      "grad_norm": 0.05813279375433922,
      "learning_rate": 2.5542021046561914e-05,
      "loss": 0.0002,
      "step": 101800
    },
    {
      "epoch": 4.894046417759839,
      "grad_norm": 0.08882922679185867,
      "learning_rate": 2.5530008168756908e-05,
      "loss": 0.0002,
      "step": 101850
    },
    {
      "epoch": 4.89644899332084,
      "grad_norm": 0.1618719846010208,
      "learning_rate": 2.5517995290951902e-05,
      "loss": 0.0001,
      "step": 101900
    },
    {
      "epoch": 4.898851568881842,
      "grad_norm": 0.17799431085586548,
      "learning_rate": 2.5505982413146897e-05,
      "loss": 0.0002,
      "step": 101950
    },
    {
      "epoch": 4.901254144442842,
      "grad_norm": 0.1734786331653595,
      "learning_rate": 2.5493969535341887e-05,
      "loss": 0.0001,
      "step": 102000
    },
    {
      "epoch": 4.903656720003844,
      "grad_norm": 0.1201716735959053,
      "learning_rate": 2.548195665753688e-05,
      "loss": 0.0002,
      "step": 102050
    },
    {
      "epoch": 4.906059295564845,
      "grad_norm": 0.23345470428466797,
      "learning_rate": 2.5469943779731876e-05,
      "loss": 0.0001,
      "step": 102100
    },
    {
      "epoch": 4.908461871125847,
      "grad_norm": 0.19425861537456512,
      "learning_rate": 2.545793090192687e-05,
      "loss": 0.0002,
      "step": 102150
    },
    {
      "epoch": 4.9108644466868485,
      "grad_norm": 0.23775312304496765,
      "learning_rate": 2.544591802412186e-05,
      "loss": 0.0002,
      "step": 102200
    },
    {
      "epoch": 4.91326702224785,
      "grad_norm": 0.21526935696601868,
      "learning_rate": 2.5433905146316855e-05,
      "loss": 0.0002,
      "step": 102250
    },
    {
      "epoch": 4.915669597808851,
      "grad_norm": 0.32188472151756287,
      "learning_rate": 2.5421892268511843e-05,
      "loss": 0.0002,
      "step": 102300
    },
    {
      "epoch": 4.918072173369852,
      "grad_norm": 0.07041790336370468,
      "learning_rate": 2.5409879390706837e-05,
      "loss": 0.0001,
      "step": 102350
    },
    {
      "epoch": 4.920474748930854,
      "grad_norm": 0.33482152223587036,
      "learning_rate": 2.539786651290183e-05,
      "loss": 0.0002,
      "step": 102400
    },
    {
      "epoch": 4.922877324491855,
      "grad_norm": 0.21195490658283234,
      "learning_rate": 2.5385853635096825e-05,
      "loss": 0.0002,
      "step": 102450
    },
    {
      "epoch": 4.925279900052857,
      "grad_norm": 0.17989987134933472,
      "learning_rate": 2.5373840757291816e-05,
      "loss": 0.0001,
      "step": 102500
    },
    {
      "epoch": 4.927682475613858,
      "grad_norm": 0.2442331612110138,
      "learning_rate": 2.536182787948681e-05,
      "loss": 0.0006,
      "step": 102550
    },
    {
      "epoch": 4.930085051174859,
      "grad_norm": 0.26696473360061646,
      "learning_rate": 2.5349815001681804e-05,
      "loss": 0.0002,
      "step": 102600
    },
    {
      "epoch": 4.932487626735861,
      "grad_norm": 0.17359866201877594,
      "learning_rate": 2.53378021238768e-05,
      "loss": 0.0002,
      "step": 102650
    },
    {
      "epoch": 4.934890202296862,
      "grad_norm": 0.06719549000263214,
      "learning_rate": 2.532578924607179e-05,
      "loss": 0.0002,
      "step": 102700
    },
    {
      "epoch": 4.937292777857864,
      "grad_norm": 0.08723089098930359,
      "learning_rate": 2.5313776368266784e-05,
      "loss": 0.0002,
      "step": 102750
    },
    {
      "epoch": 4.939695353418865,
      "grad_norm": 0.28024107217788696,
      "learning_rate": 2.5301763490461778e-05,
      "loss": 0.0001,
      "step": 102800
    },
    {
      "epoch": 4.942097928979867,
      "grad_norm": 0.11786975711584091,
      "learning_rate": 2.5289750612656772e-05,
      "loss": 0.0006,
      "step": 102850
    },
    {
      "epoch": 4.944500504540867,
      "grad_norm": 0.14721225202083588,
      "learning_rate": 2.5277737734851763e-05,
      "loss": 0.0002,
      "step": 102900
    },
    {
      "epoch": 4.946903080101869,
      "grad_norm": 0.11084990948438644,
      "learning_rate": 2.5265724857046757e-05,
      "loss": 0.0002,
      "step": 102950
    },
    {
      "epoch": 4.9493056556628705,
      "grad_norm": 0.3855995535850525,
      "learning_rate": 2.525371197924175e-05,
      "loss": 0.0001,
      "step": 103000
    },
    {
      "epoch": 4.951708231223872,
      "grad_norm": 0.1154947355389595,
      "learning_rate": 2.524169910143674e-05,
      "loss": 0.0003,
      "step": 103050
    },
    {
      "epoch": 4.954110806784874,
      "grad_norm": 0.3369259238243103,
      "learning_rate": 2.5229686223631733e-05,
      "loss": 0.0001,
      "step": 103100
    },
    {
      "epoch": 4.956513382345875,
      "grad_norm": 0.23878690600395203,
      "learning_rate": 2.5217673345826727e-05,
      "loss": 0.0005,
      "step": 103150
    },
    {
      "epoch": 4.958915957906877,
      "grad_norm": 0.27592024207115173,
      "learning_rate": 2.5205660468021718e-05,
      "loss": 0.0001,
      "step": 103200
    },
    {
      "epoch": 4.961318533467877,
      "grad_norm": 0.16127018630504608,
      "learning_rate": 2.5193647590216712e-05,
      "loss": 0.0002,
      "step": 103250
    },
    {
      "epoch": 4.963721109028879,
      "grad_norm": 0.18352633714675903,
      "learning_rate": 2.5181634712411706e-05,
      "loss": 0.0002,
      "step": 103300
    },
    {
      "epoch": 4.96612368458988,
      "grad_norm": 0.17024913430213928,
      "learning_rate": 2.51696218346067e-05,
      "loss": 0.0002,
      "step": 103350
    },
    {
      "epoch": 4.968526260150882,
      "grad_norm": 0.23441201448440552,
      "learning_rate": 2.515760895680169e-05,
      "loss": 0.0001,
      "step": 103400
    },
    {
      "epoch": 4.9709288357118835,
      "grad_norm": 0.08485985547304153,
      "learning_rate": 2.5145596078996686e-05,
      "loss": 0.0001,
      "step": 103450
    },
    {
      "epoch": 4.973331411272884,
      "grad_norm": 0.1016777753829956,
      "learning_rate": 2.513358320119168e-05,
      "loss": 0.0004,
      "step": 103500
    },
    {
      "epoch": 4.975733986833886,
      "grad_norm": 0.2991280257701874,
      "learning_rate": 2.5121570323386674e-05,
      "loss": 0.0002,
      "step": 103550
    },
    {
      "epoch": 4.978136562394887,
      "grad_norm": 0.10517899692058563,
      "learning_rate": 2.5109557445581665e-05,
      "loss": 0.0001,
      "step": 103600
    },
    {
      "epoch": 4.980539137955889,
      "grad_norm": 0.10045110434293747,
      "learning_rate": 2.509754456777666e-05,
      "loss": 0.0001,
      "step": 103650
    },
    {
      "epoch": 4.98294171351689,
      "grad_norm": 0.19392286241054535,
      "learning_rate": 2.5085531689971653e-05,
      "loss": 0.0001,
      "step": 103700
    },
    {
      "epoch": 4.985344289077892,
      "grad_norm": 0.04575445130467415,
      "learning_rate": 2.5073518812166648e-05,
      "loss": 0.0002,
      "step": 103750
    },
    {
      "epoch": 4.987746864638893,
      "grad_norm": 0.17365942895412445,
      "learning_rate": 2.5061505934361635e-05,
      "loss": 0.0001,
      "step": 103800
    },
    {
      "epoch": 4.990149440199894,
      "grad_norm": 0.34422019124031067,
      "learning_rate": 2.504949305655663e-05,
      "loss": 0.0001,
      "step": 103850
    },
    {
      "epoch": 4.992552015760896,
      "grad_norm": 0.025656292214989662,
      "learning_rate": 2.503748017875162e-05,
      "loss": 0.0002,
      "step": 103900
    },
    {
      "epoch": 4.994954591321897,
      "grad_norm": 0.23950909078121185,
      "learning_rate": 2.5025467300946614e-05,
      "loss": 0.0002,
      "step": 103950
    },
    {
      "epoch": 4.997357166882899,
      "grad_norm": 0.18903034925460815,
      "learning_rate": 2.501345442314161e-05,
      "loss": 0.0001,
      "step": 104000
    },
    {
      "epoch": 4.9997597424439,
      "grad_norm": 0.1297219693660736,
      "learning_rate": 2.5001441545336603e-05,
      "loss": 0.0001,
      "step": 104050
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.0004043725202791393,
      "eval_runtime": 17.3129,
      "eval_samples_per_second": 548.493,
      "eval_steps_per_second": 68.562,
      "step": 104055
    }
  ],
  "logging_steps": 50,
  "max_steps": 208110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.501513492074738e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
