{
  "best_global_step": 20811,
  "best_metric": 0.0002766257675830275,
  "best_model_checkpoint": "ckpt/neurips.pt/FFV/checkpoint-20811",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 20811,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0024025755610013935,
      "grad_norm": 3.752441644668579,
      "learning_rate": 4.99882273797511e-05,
      "loss": 0.0415,
      "step": 50
    },
    {
      "epoch": 0.004805151122002787,
      "grad_norm": 1.228306770324707,
      "learning_rate": 4.997621450194609e-05,
      "loss": 0.0324,
      "step": 100
    },
    {
      "epoch": 0.00720772668300418,
      "grad_norm": 4.905325889587402,
      "learning_rate": 4.996420162414108e-05,
      "loss": 0.0344,
      "step": 150
    },
    {
      "epoch": 0.009610302244005574,
      "grad_norm": 2.193751811981201,
      "learning_rate": 4.995218874633608e-05,
      "loss": 0.0221,
      "step": 200
    },
    {
      "epoch": 0.012012877805006967,
      "grad_norm": 1.6830034255981445,
      "learning_rate": 4.994017586853107e-05,
      "loss": 0.024,
      "step": 250
    },
    {
      "epoch": 0.01441545336600836,
      "grad_norm": 3.750678062438965,
      "learning_rate": 4.9928162990726066e-05,
      "loss": 0.0215,
      "step": 300
    },
    {
      "epoch": 0.016818028927009756,
      "grad_norm": 2.535874605178833,
      "learning_rate": 4.991615011292106e-05,
      "loss": 0.0186,
      "step": 350
    },
    {
      "epoch": 0.019220604488011148,
      "grad_norm": 0.7154179811477661,
      "learning_rate": 4.990413723511604e-05,
      "loss": 0.0212,
      "step": 400
    },
    {
      "epoch": 0.021623180049012543,
      "grad_norm": 1.7365463972091675,
      "learning_rate": 4.989212435731104e-05,
      "loss": 0.0177,
      "step": 450
    },
    {
      "epoch": 0.024025755610013935,
      "grad_norm": 1.3618357181549072,
      "learning_rate": 4.988011147950603e-05,
      "loss": 0.0281,
      "step": 500
    },
    {
      "epoch": 0.02642833117101533,
      "grad_norm": 2.555677652359009,
      "learning_rate": 4.986809860170103e-05,
      "loss": 0.0164,
      "step": 550
    },
    {
      "epoch": 0.02883090673201672,
      "grad_norm": 1.0062837600708008,
      "learning_rate": 4.985608572389602e-05,
      "loss": 0.0227,
      "step": 600
    },
    {
      "epoch": 0.031233482293018117,
      "grad_norm": 5.012147903442383,
      "learning_rate": 4.984407284609101e-05,
      "loss": 0.0191,
      "step": 650
    },
    {
      "epoch": 0.03363605785401951,
      "grad_norm": 2.7845020294189453,
      "learning_rate": 4.9832059968286006e-05,
      "loss": 0.0197,
      "step": 700
    },
    {
      "epoch": 0.0360386334150209,
      "grad_norm": 1.021740436553955,
      "learning_rate": 4.9820047090481e-05,
      "loss": 0.0174,
      "step": 750
    },
    {
      "epoch": 0.038441208976022295,
      "grad_norm": 2.853013038635254,
      "learning_rate": 4.980803421267599e-05,
      "loss": 0.0123,
      "step": 800
    },
    {
      "epoch": 0.04084378453702369,
      "grad_norm": 2.1503548622131348,
      "learning_rate": 4.9796021334870986e-05,
      "loss": 0.0167,
      "step": 850
    },
    {
      "epoch": 0.043246360098025086,
      "grad_norm": 1.6684565544128418,
      "learning_rate": 4.9784008457065976e-05,
      "loss": 0.0174,
      "step": 900
    },
    {
      "epoch": 0.045648935659026474,
      "grad_norm": 1.0092157125473022,
      "learning_rate": 4.9771995579260974e-05,
      "loss": 0.016,
      "step": 950
    },
    {
      "epoch": 0.04805151122002787,
      "grad_norm": 1.232095718383789,
      "learning_rate": 4.9759982701455965e-05,
      "loss": 0.0197,
      "step": 1000
    },
    {
      "epoch": 0.050454086781029264,
      "grad_norm": 1.941278100013733,
      "learning_rate": 4.9747969823650956e-05,
      "loss": 0.0168,
      "step": 1050
    },
    {
      "epoch": 0.05285666234203066,
      "grad_norm": 3.874238967895508,
      "learning_rate": 4.973595694584595e-05,
      "loss": 0.016,
      "step": 1100
    },
    {
      "epoch": 0.05525923790303205,
      "grad_norm": 2.4047505855560303,
      "learning_rate": 4.972394406804094e-05,
      "loss": 0.0174,
      "step": 1150
    },
    {
      "epoch": 0.05766181346403344,
      "grad_norm": 4.466421127319336,
      "learning_rate": 4.9711931190235935e-05,
      "loss": 0.0176,
      "step": 1200
    },
    {
      "epoch": 0.06006438902503484,
      "grad_norm": 2.1069514751434326,
      "learning_rate": 4.9699918312430926e-05,
      "loss": 0.0136,
      "step": 1250
    },
    {
      "epoch": 0.06246696458603623,
      "grad_norm": 1.1002517938613892,
      "learning_rate": 4.968790543462592e-05,
      "loss": 0.0124,
      "step": 1300
    },
    {
      "epoch": 0.06486954014703762,
      "grad_norm": 4.937185287475586,
      "learning_rate": 4.9675892556820914e-05,
      "loss": 0.0135,
      "step": 1350
    },
    {
      "epoch": 0.06727211570803902,
      "grad_norm": 1.193574070930481,
      "learning_rate": 4.9663879679015905e-05,
      "loss": 0.0127,
      "step": 1400
    },
    {
      "epoch": 0.06967469126904041,
      "grad_norm": 1.655759334564209,
      "learning_rate": 4.96518668012109e-05,
      "loss": 0.0156,
      "step": 1450
    },
    {
      "epoch": 0.0720772668300418,
      "grad_norm": 4.090753555297852,
      "learning_rate": 4.9639853923405893e-05,
      "loss": 0.01,
      "step": 1500
    },
    {
      "epoch": 0.0744798423910432,
      "grad_norm": 1.3033610582351685,
      "learning_rate": 4.9627841045600884e-05,
      "loss": 0.0174,
      "step": 1550
    },
    {
      "epoch": 0.07688241795204459,
      "grad_norm": 2.275681495666504,
      "learning_rate": 4.961582816779588e-05,
      "loss": 0.0133,
      "step": 1600
    },
    {
      "epoch": 0.07928499351304598,
      "grad_norm": 3.1619656085968018,
      "learning_rate": 4.960381528999087e-05,
      "loss": 0.0133,
      "step": 1650
    },
    {
      "epoch": 0.08168756907404738,
      "grad_norm": 1.3176674842834473,
      "learning_rate": 4.959180241218587e-05,
      "loss": 0.0113,
      "step": 1700
    },
    {
      "epoch": 0.08409014463504877,
      "grad_norm": 3.292354106903076,
      "learning_rate": 4.957978953438086e-05,
      "loss": 0.0123,
      "step": 1750
    },
    {
      "epoch": 0.08649272019605017,
      "grad_norm": 2.5628626346588135,
      "learning_rate": 4.956777665657585e-05,
      "loss": 0.0145,
      "step": 1800
    },
    {
      "epoch": 0.08889529575705156,
      "grad_norm": 2.2514307498931885,
      "learning_rate": 4.955576377877085e-05,
      "loss": 0.0115,
      "step": 1850
    },
    {
      "epoch": 0.09129787131805295,
      "grad_norm": 2.384793758392334,
      "learning_rate": 4.9543750900965834e-05,
      "loss": 0.0108,
      "step": 1900
    },
    {
      "epoch": 0.09370044687905435,
      "grad_norm": 1.7269525527954102,
      "learning_rate": 4.953173802316083e-05,
      "loss": 0.0082,
      "step": 1950
    },
    {
      "epoch": 0.09610302244005574,
      "grad_norm": 0.5155779719352722,
      "learning_rate": 4.951972514535582e-05,
      "loss": 0.0109,
      "step": 2000
    },
    {
      "epoch": 0.09850559800105713,
      "grad_norm": 2.3599705696105957,
      "learning_rate": 4.950771226755081e-05,
      "loss": 0.0108,
      "step": 2050
    },
    {
      "epoch": 0.10090817356205853,
      "grad_norm": 0.725629448890686,
      "learning_rate": 4.949569938974581e-05,
      "loss": 0.0098,
      "step": 2100
    },
    {
      "epoch": 0.10331074912305992,
      "grad_norm": 2.286933422088623,
      "learning_rate": 4.94836865119408e-05,
      "loss": 0.0117,
      "step": 2150
    },
    {
      "epoch": 0.10571332468406132,
      "grad_norm": 0.7589529156684875,
      "learning_rate": 4.94716736341358e-05,
      "loss": 0.0094,
      "step": 2200
    },
    {
      "epoch": 0.10811590024506271,
      "grad_norm": 2.178612232208252,
      "learning_rate": 4.945966075633079e-05,
      "loss": 0.0104,
      "step": 2250
    },
    {
      "epoch": 0.1105184758060641,
      "grad_norm": 1.7792679071426392,
      "learning_rate": 4.944764787852578e-05,
      "loss": 0.0092,
      "step": 2300
    },
    {
      "epoch": 0.1129210513670655,
      "grad_norm": 1.0822863578796387,
      "learning_rate": 4.943563500072078e-05,
      "loss": 0.0125,
      "step": 2350
    },
    {
      "epoch": 0.11532362692806689,
      "grad_norm": 1.3987854719161987,
      "learning_rate": 4.942362212291577e-05,
      "loss": 0.0095,
      "step": 2400
    },
    {
      "epoch": 0.11772620248906829,
      "grad_norm": 3.6113998889923096,
      "learning_rate": 4.941160924511076e-05,
      "loss": 0.0084,
      "step": 2450
    },
    {
      "epoch": 0.12012877805006968,
      "grad_norm": 0.7678483724594116,
      "learning_rate": 4.939959636730576e-05,
      "loss": 0.0118,
      "step": 2500
    },
    {
      "epoch": 0.12253135361107106,
      "grad_norm": 2.528989315032959,
      "learning_rate": 4.938758348950075e-05,
      "loss": 0.0082,
      "step": 2550
    },
    {
      "epoch": 0.12493392917207247,
      "grad_norm": 1.3806185722351074,
      "learning_rate": 4.9375570611695746e-05,
      "loss": 0.0085,
      "step": 2600
    },
    {
      "epoch": 0.12733650473307387,
      "grad_norm": 0.7406447529792786,
      "learning_rate": 4.936355773389073e-05,
      "loss": 0.008,
      "step": 2650
    },
    {
      "epoch": 0.12973908029407524,
      "grad_norm": 0.3724974989891052,
      "learning_rate": 4.935154485608572e-05,
      "loss": 0.0093,
      "step": 2700
    },
    {
      "epoch": 0.13214165585507665,
      "grad_norm": 0.6449531316757202,
      "learning_rate": 4.933953197828072e-05,
      "loss": 0.0104,
      "step": 2750
    },
    {
      "epoch": 0.13454423141607805,
      "grad_norm": 1.2498270273208618,
      "learning_rate": 4.932751910047571e-05,
      "loss": 0.0071,
      "step": 2800
    },
    {
      "epoch": 0.13694680697707942,
      "grad_norm": 3.0012714862823486,
      "learning_rate": 4.931550622267071e-05,
      "loss": 0.0092,
      "step": 2850
    },
    {
      "epoch": 0.13934938253808082,
      "grad_norm": 2.205944776535034,
      "learning_rate": 4.93034933448657e-05,
      "loss": 0.008,
      "step": 2900
    },
    {
      "epoch": 0.14175195809908223,
      "grad_norm": 3.701625347137451,
      "learning_rate": 4.929148046706069e-05,
      "loss": 0.008,
      "step": 2950
    },
    {
      "epoch": 0.1441545336600836,
      "grad_norm": 1.0817807912826538,
      "learning_rate": 4.9279467589255686e-05,
      "loss": 0.0069,
      "step": 3000
    },
    {
      "epoch": 0.146557109221085,
      "grad_norm": 0.6617302894592285,
      "learning_rate": 4.926745471145068e-05,
      "loss": 0.0087,
      "step": 3050
    },
    {
      "epoch": 0.1489596847820864,
      "grad_norm": 2.8477492332458496,
      "learning_rate": 4.9255441833645674e-05,
      "loss": 0.0083,
      "step": 3100
    },
    {
      "epoch": 0.15136226034308778,
      "grad_norm": 2.812577962875366,
      "learning_rate": 4.9243428955840665e-05,
      "loss": 0.006,
      "step": 3150
    },
    {
      "epoch": 0.15376483590408918,
      "grad_norm": 2.5595853328704834,
      "learning_rate": 4.9231416078035656e-05,
      "loss": 0.0069,
      "step": 3200
    },
    {
      "epoch": 0.15616741146509058,
      "grad_norm": 3.8520405292510986,
      "learning_rate": 4.9219403200230654e-05,
      "loss": 0.008,
      "step": 3250
    },
    {
      "epoch": 0.15856998702609196,
      "grad_norm": 4.4749345779418945,
      "learning_rate": 4.9207390322425645e-05,
      "loss": 0.0078,
      "step": 3300
    },
    {
      "epoch": 0.16097256258709336,
      "grad_norm": 0.622660756111145,
      "learning_rate": 4.9195377444620635e-05,
      "loss": 0.0084,
      "step": 3350
    },
    {
      "epoch": 0.16337513814809476,
      "grad_norm": 1.48850417137146,
      "learning_rate": 4.9183364566815626e-05,
      "loss": 0.0089,
      "step": 3400
    },
    {
      "epoch": 0.16577771370909616,
      "grad_norm": 3.1630680561065674,
      "learning_rate": 4.917135168901062e-05,
      "loss": 0.0061,
      "step": 3450
    },
    {
      "epoch": 0.16818028927009754,
      "grad_norm": 0.7224794030189514,
      "learning_rate": 4.9159338811205615e-05,
      "loss": 0.0058,
      "step": 3500
    },
    {
      "epoch": 0.17058286483109894,
      "grad_norm": 3.212285280227661,
      "learning_rate": 4.9147325933400605e-05,
      "loss": 0.0074,
      "step": 3550
    },
    {
      "epoch": 0.17298544039210034,
      "grad_norm": 0.7348601222038269,
      "learning_rate": 4.91353130555956e-05,
      "loss": 0.0077,
      "step": 3600
    },
    {
      "epoch": 0.17538801595310172,
      "grad_norm": 2.40085768699646,
      "learning_rate": 4.9123300177790594e-05,
      "loss": 0.0079,
      "step": 3650
    },
    {
      "epoch": 0.17779059151410312,
      "grad_norm": 0.47765877842903137,
      "learning_rate": 4.9111287299985585e-05,
      "loss": 0.0057,
      "step": 3700
    },
    {
      "epoch": 0.18019316707510452,
      "grad_norm": 1.040637731552124,
      "learning_rate": 4.909927442218058e-05,
      "loss": 0.0063,
      "step": 3750
    },
    {
      "epoch": 0.1825957426361059,
      "grad_norm": 0.4997390806674957,
      "learning_rate": 4.908726154437557e-05,
      "loss": 0.0056,
      "step": 3800
    },
    {
      "epoch": 0.1849983181971073,
      "grad_norm": 1.5473697185516357,
      "learning_rate": 4.9075248666570564e-05,
      "loss": 0.006,
      "step": 3850
    },
    {
      "epoch": 0.1874008937581087,
      "grad_norm": 0.2133985012769699,
      "learning_rate": 4.906323578876556e-05,
      "loss": 0.0049,
      "step": 3900
    },
    {
      "epoch": 0.18980346931911007,
      "grad_norm": 0.6842890381813049,
      "learning_rate": 4.905122291096055e-05,
      "loss": 0.0047,
      "step": 3950
    },
    {
      "epoch": 0.19220604488011148,
      "grad_norm": 0.4622081518173218,
      "learning_rate": 4.903921003315555e-05,
      "loss": 0.0057,
      "step": 4000
    },
    {
      "epoch": 0.19460862044111288,
      "grad_norm": 0.571236252784729,
      "learning_rate": 4.902719715535054e-05,
      "loss": 0.0057,
      "step": 4050
    },
    {
      "epoch": 0.19701119600211425,
      "grad_norm": 0.3720848858356476,
      "learning_rate": 4.901518427754553e-05,
      "loss": 0.0052,
      "step": 4100
    },
    {
      "epoch": 0.19941377156311565,
      "grad_norm": 0.8233627080917358,
      "learning_rate": 4.900317139974052e-05,
      "loss": 0.0049,
      "step": 4150
    },
    {
      "epoch": 0.20181634712411706,
      "grad_norm": 1.2623599767684937,
      "learning_rate": 4.899115852193551e-05,
      "loss": 0.0042,
      "step": 4200
    },
    {
      "epoch": 0.20421892268511846,
      "grad_norm": 0.8537761569023132,
      "learning_rate": 4.897914564413051e-05,
      "loss": 0.0059,
      "step": 4250
    },
    {
      "epoch": 0.20662149824611983,
      "grad_norm": 1.2179261445999146,
      "learning_rate": 4.89671327663255e-05,
      "loss": 0.0063,
      "step": 4300
    },
    {
      "epoch": 0.20902407380712124,
      "grad_norm": 1.0948755741119385,
      "learning_rate": 4.895511988852049e-05,
      "loss": 0.0036,
      "step": 4350
    },
    {
      "epoch": 0.21142664936812264,
      "grad_norm": 0.6709845066070557,
      "learning_rate": 4.894310701071549e-05,
      "loss": 0.0037,
      "step": 4400
    },
    {
      "epoch": 0.213829224929124,
      "grad_norm": 1.072180986404419,
      "learning_rate": 4.893109413291048e-05,
      "loss": 0.0039,
      "step": 4450
    },
    {
      "epoch": 0.21623180049012541,
      "grad_norm": 0.4446156919002533,
      "learning_rate": 4.891908125510548e-05,
      "loss": 0.0036,
      "step": 4500
    },
    {
      "epoch": 0.21863437605112682,
      "grad_norm": 0.34354302287101746,
      "learning_rate": 4.890706837730047e-05,
      "loss": 0.0053,
      "step": 4550
    },
    {
      "epoch": 0.2210369516121282,
      "grad_norm": 1.032797932624817,
      "learning_rate": 4.889505549949546e-05,
      "loss": 0.0048,
      "step": 4600
    },
    {
      "epoch": 0.2234395271731296,
      "grad_norm": 1.2775157690048218,
      "learning_rate": 4.888304262169046e-05,
      "loss": 0.0041,
      "step": 4650
    },
    {
      "epoch": 0.225842102734131,
      "grad_norm": 2.3511147499084473,
      "learning_rate": 4.887102974388545e-05,
      "loss": 0.0059,
      "step": 4700
    },
    {
      "epoch": 0.22824467829513237,
      "grad_norm": 1.3098760843276978,
      "learning_rate": 4.885901686608044e-05,
      "loss": 0.0041,
      "step": 4750
    },
    {
      "epoch": 0.23064725385613377,
      "grad_norm": 0.8418120741844177,
      "learning_rate": 4.884700398827544e-05,
      "loss": 0.0051,
      "step": 4800
    },
    {
      "epoch": 0.23304982941713517,
      "grad_norm": 0.5443441271781921,
      "learning_rate": 4.883499111047043e-05,
      "loss": 0.0037,
      "step": 4850
    },
    {
      "epoch": 0.23545240497813658,
      "grad_norm": 0.490400493144989,
      "learning_rate": 4.882297823266542e-05,
      "loss": 0.0039,
      "step": 4900
    },
    {
      "epoch": 0.23785498053913795,
      "grad_norm": 1.8660248517990112,
      "learning_rate": 4.881096535486041e-05,
      "loss": 0.0044,
      "step": 4950
    },
    {
      "epoch": 0.24025755610013935,
      "grad_norm": 0.4368196427822113,
      "learning_rate": 4.879895247705541e-05,
      "loss": 0.0057,
      "step": 5000
    },
    {
      "epoch": 0.24266013166114075,
      "grad_norm": 0.6510025262832642,
      "learning_rate": 4.87869395992504e-05,
      "loss": 0.0041,
      "step": 5050
    },
    {
      "epoch": 0.24506270722214213,
      "grad_norm": 0.5581501722335815,
      "learning_rate": 4.877492672144539e-05,
      "loss": 0.0054,
      "step": 5100
    },
    {
      "epoch": 0.24746528278314353,
      "grad_norm": 0.4542526602745056,
      "learning_rate": 4.8762913843640386e-05,
      "loss": 0.0056,
      "step": 5150
    },
    {
      "epoch": 0.24986785834414493,
      "grad_norm": 1.0200222730636597,
      "learning_rate": 4.875090096583538e-05,
      "loss": 0.0038,
      "step": 5200
    },
    {
      "epoch": 0.2522704339051463,
      "grad_norm": 0.752280056476593,
      "learning_rate": 4.873888808803037e-05,
      "loss": 0.0036,
      "step": 5250
    },
    {
      "epoch": 0.25467300946614774,
      "grad_norm": 2.1212661266326904,
      "learning_rate": 4.8726875210225366e-05,
      "loss": 0.0041,
      "step": 5300
    },
    {
      "epoch": 0.2570755850271491,
      "grad_norm": 0.3203541934490204,
      "learning_rate": 4.8714862332420356e-05,
      "loss": 0.0041,
      "step": 5350
    },
    {
      "epoch": 0.2594781605881505,
      "grad_norm": 0.6307310461997986,
      "learning_rate": 4.8702849454615354e-05,
      "loss": 0.0044,
      "step": 5400
    },
    {
      "epoch": 0.2618807361491519,
      "grad_norm": 1.670941948890686,
      "learning_rate": 4.8690836576810345e-05,
      "loss": 0.0036,
      "step": 5450
    },
    {
      "epoch": 0.2642833117101533,
      "grad_norm": 0.5347387790679932,
      "learning_rate": 4.8678823699005336e-05,
      "loss": 0.0032,
      "step": 5500
    },
    {
      "epoch": 0.26668588727115466,
      "grad_norm": 1.5894818305969238,
      "learning_rate": 4.866681082120033e-05,
      "loss": 0.0037,
      "step": 5550
    },
    {
      "epoch": 0.2690884628321561,
      "grad_norm": 1.1118308305740356,
      "learning_rate": 4.865479794339532e-05,
      "loss": 0.0032,
      "step": 5600
    },
    {
      "epoch": 0.27149103839315747,
      "grad_norm": 0.8748323917388916,
      "learning_rate": 4.8642785065590315e-05,
      "loss": 0.0047,
      "step": 5650
    },
    {
      "epoch": 0.27389361395415884,
      "grad_norm": 1.6549639701843262,
      "learning_rate": 4.8630772187785306e-05,
      "loss": 0.0033,
      "step": 5700
    },
    {
      "epoch": 0.2762961895151603,
      "grad_norm": 0.8495310544967651,
      "learning_rate": 4.8618759309980297e-05,
      "loss": 0.0029,
      "step": 5750
    },
    {
      "epoch": 0.27869876507616165,
      "grad_norm": 0.6467618346214294,
      "learning_rate": 4.8606746432175294e-05,
      "loss": 0.0022,
      "step": 5800
    },
    {
      "epoch": 0.281101340637163,
      "grad_norm": 1.3068848848342896,
      "learning_rate": 4.8594733554370285e-05,
      "loss": 0.0029,
      "step": 5850
    },
    {
      "epoch": 0.28350391619816445,
      "grad_norm": 0.7159707546234131,
      "learning_rate": 4.858272067656528e-05,
      "loss": 0.0034,
      "step": 5900
    },
    {
      "epoch": 0.2859064917591658,
      "grad_norm": 1.0186398029327393,
      "learning_rate": 4.8570707798760273e-05,
      "loss": 0.0029,
      "step": 5950
    },
    {
      "epoch": 0.2883090673201672,
      "grad_norm": 1.7167072296142578,
      "learning_rate": 4.8558694920955264e-05,
      "loss": 0.0042,
      "step": 6000
    },
    {
      "epoch": 0.29071164288116863,
      "grad_norm": 1.850773811340332,
      "learning_rate": 4.854668204315026e-05,
      "loss": 0.0025,
      "step": 6050
    },
    {
      "epoch": 0.29311421844217,
      "grad_norm": 0.6071839332580566,
      "learning_rate": 4.853466916534525e-05,
      "loss": 0.0027,
      "step": 6100
    },
    {
      "epoch": 0.2955167940031714,
      "grad_norm": 0.328778475522995,
      "learning_rate": 4.8522656287540244e-05,
      "loss": 0.0029,
      "step": 6150
    },
    {
      "epoch": 0.2979193695641728,
      "grad_norm": 0.3195604979991913,
      "learning_rate": 4.851064340973524e-05,
      "loss": 0.0024,
      "step": 6200
    },
    {
      "epoch": 0.3003219451251742,
      "grad_norm": 0.5731003880500793,
      "learning_rate": 4.849863053193023e-05,
      "loss": 0.0034,
      "step": 6250
    },
    {
      "epoch": 0.30272452068617556,
      "grad_norm": 1.2235344648361206,
      "learning_rate": 4.848661765412523e-05,
      "loss": 0.003,
      "step": 6300
    },
    {
      "epoch": 0.305127096247177,
      "grad_norm": 0.7067216634750366,
      "learning_rate": 4.8474604776320214e-05,
      "loss": 0.0026,
      "step": 6350
    },
    {
      "epoch": 0.30752967180817836,
      "grad_norm": 0.8612620830535889,
      "learning_rate": 4.846259189851521e-05,
      "loss": 0.0031,
      "step": 6400
    },
    {
      "epoch": 0.30993224736917974,
      "grad_norm": 0.8397321105003357,
      "learning_rate": 4.84505790207102e-05,
      "loss": 0.0026,
      "step": 6450
    },
    {
      "epoch": 0.31233482293018117,
      "grad_norm": 1.1973375082015991,
      "learning_rate": 4.843856614290519e-05,
      "loss": 0.003,
      "step": 6500
    },
    {
      "epoch": 0.31473739849118254,
      "grad_norm": 0.2564820349216461,
      "learning_rate": 4.842655326510019e-05,
      "loss": 0.0025,
      "step": 6550
    },
    {
      "epoch": 0.3171399740521839,
      "grad_norm": 0.9526909589767456,
      "learning_rate": 4.841454038729518e-05,
      "loss": 0.0027,
      "step": 6600
    },
    {
      "epoch": 0.31954254961318534,
      "grad_norm": 0.4399867057800293,
      "learning_rate": 4.840252750949017e-05,
      "loss": 0.0024,
      "step": 6650
    },
    {
      "epoch": 0.3219451251741867,
      "grad_norm": 0.3938835561275482,
      "learning_rate": 4.839051463168517e-05,
      "loss": 0.0029,
      "step": 6700
    },
    {
      "epoch": 0.32434770073518815,
      "grad_norm": 0.30992501974105835,
      "learning_rate": 4.837850175388016e-05,
      "loss": 0.0029,
      "step": 6750
    },
    {
      "epoch": 0.3267502762961895,
      "grad_norm": 0.4631669521331787,
      "learning_rate": 4.836648887607516e-05,
      "loss": 0.0022,
      "step": 6800
    },
    {
      "epoch": 0.3291528518571909,
      "grad_norm": 0.5240834355354309,
      "learning_rate": 4.835447599827015e-05,
      "loss": 0.003,
      "step": 6850
    },
    {
      "epoch": 0.33155542741819233,
      "grad_norm": 0.538101315498352,
      "learning_rate": 4.834246312046514e-05,
      "loss": 0.0022,
      "step": 6900
    },
    {
      "epoch": 0.3339580029791937,
      "grad_norm": 0.40361467003822327,
      "learning_rate": 4.833045024266014e-05,
      "loss": 0.0016,
      "step": 6950
    },
    {
      "epoch": 0.3363605785401951,
      "grad_norm": 1.3281399011611938,
      "learning_rate": 4.831843736485513e-05,
      "loss": 0.003,
      "step": 7000
    },
    {
      "epoch": 0.3387631541011965,
      "grad_norm": 0.5347200036048889,
      "learning_rate": 4.8306424487050126e-05,
      "loss": 0.0027,
      "step": 7050
    },
    {
      "epoch": 0.3411657296621979,
      "grad_norm": 0.5260990858078003,
      "learning_rate": 4.829441160924511e-05,
      "loss": 0.0021,
      "step": 7100
    },
    {
      "epoch": 0.34356830522319926,
      "grad_norm": 0.8495813012123108,
      "learning_rate": 4.82823987314401e-05,
      "loss": 0.0022,
      "step": 7150
    },
    {
      "epoch": 0.3459708807842007,
      "grad_norm": 0.36441248655319214,
      "learning_rate": 4.82703858536351e-05,
      "loss": 0.0021,
      "step": 7200
    },
    {
      "epoch": 0.34837345634520206,
      "grad_norm": 0.2822631299495697,
      "learning_rate": 4.825837297583009e-05,
      "loss": 0.0016,
      "step": 7250
    },
    {
      "epoch": 0.35077603190620343,
      "grad_norm": 0.863128662109375,
      "learning_rate": 4.824636009802509e-05,
      "loss": 0.0022,
      "step": 7300
    },
    {
      "epoch": 0.35317860746720486,
      "grad_norm": 1.1693450212478638,
      "learning_rate": 4.823434722022008e-05,
      "loss": 0.0032,
      "step": 7350
    },
    {
      "epoch": 0.35558118302820624,
      "grad_norm": 0.9746198654174805,
      "learning_rate": 4.822233434241507e-05,
      "loss": 0.0018,
      "step": 7400
    },
    {
      "epoch": 0.3579837585892076,
      "grad_norm": 0.5209798216819763,
      "learning_rate": 4.8210321464610066e-05,
      "loss": 0.0017,
      "step": 7450
    },
    {
      "epoch": 0.36038633415020904,
      "grad_norm": 1.5360050201416016,
      "learning_rate": 4.819830858680506e-05,
      "loss": 0.002,
      "step": 7500
    },
    {
      "epoch": 0.3627889097112104,
      "grad_norm": 0.30533674359321594,
      "learning_rate": 4.8186295709000054e-05,
      "loss": 0.0017,
      "step": 7550
    },
    {
      "epoch": 0.3651914852722118,
      "grad_norm": 0.8185293078422546,
      "learning_rate": 4.8174282831195045e-05,
      "loss": 0.0015,
      "step": 7600
    },
    {
      "epoch": 0.3675940608332132,
      "grad_norm": 0.6698569655418396,
      "learning_rate": 4.8162269953390036e-05,
      "loss": 0.0029,
      "step": 7650
    },
    {
      "epoch": 0.3699966363942146,
      "grad_norm": 0.8953649401664734,
      "learning_rate": 4.8150257075585034e-05,
      "loss": 0.0024,
      "step": 7700
    },
    {
      "epoch": 0.37239921195521597,
      "grad_norm": 0.7294184565544128,
      "learning_rate": 4.8138244197780024e-05,
      "loss": 0.0016,
      "step": 7750
    },
    {
      "epoch": 0.3748017875162174,
      "grad_norm": 0.6525855660438538,
      "learning_rate": 4.8126231319975015e-05,
      "loss": 0.002,
      "step": 7800
    },
    {
      "epoch": 0.3772043630772188,
      "grad_norm": 0.7692852020263672,
      "learning_rate": 4.8114218442170006e-05,
      "loss": 0.0023,
      "step": 7850
    },
    {
      "epoch": 0.37960693863822015,
      "grad_norm": 0.5399836301803589,
      "learning_rate": 4.8102205564365e-05,
      "loss": 0.0017,
      "step": 7900
    },
    {
      "epoch": 0.3820095141992216,
      "grad_norm": 0.8558169603347778,
      "learning_rate": 4.8090192686559995e-05,
      "loss": 0.002,
      "step": 7950
    },
    {
      "epoch": 0.38441208976022295,
      "grad_norm": 0.6112403869628906,
      "learning_rate": 4.8078179808754985e-05,
      "loss": 0.0033,
      "step": 8000
    },
    {
      "epoch": 0.3868146653212243,
      "grad_norm": 0.15063396096229553,
      "learning_rate": 4.8066166930949976e-05,
      "loss": 0.0016,
      "step": 8050
    },
    {
      "epoch": 0.38921724088222576,
      "grad_norm": 0.3506585359573364,
      "learning_rate": 4.8054154053144974e-05,
      "loss": 0.0013,
      "step": 8100
    },
    {
      "epoch": 0.39161981644322713,
      "grad_norm": 0.15903370082378387,
      "learning_rate": 4.8042141175339965e-05,
      "loss": 0.0013,
      "step": 8150
    },
    {
      "epoch": 0.3940223920042285,
      "grad_norm": 0.48620983958244324,
      "learning_rate": 4.803012829753496e-05,
      "loss": 0.0015,
      "step": 8200
    },
    {
      "epoch": 0.39642496756522994,
      "grad_norm": 0.525894820690155,
      "learning_rate": 4.801811541972995e-05,
      "loss": 0.0014,
      "step": 8250
    },
    {
      "epoch": 0.3988275431262313,
      "grad_norm": 0.4839423596858978,
      "learning_rate": 4.8006102541924944e-05,
      "loss": 0.0022,
      "step": 8300
    },
    {
      "epoch": 0.40123011868723274,
      "grad_norm": 0.22425006330013275,
      "learning_rate": 4.799408966411994e-05,
      "loss": 0.0016,
      "step": 8350
    },
    {
      "epoch": 0.4036326942482341,
      "grad_norm": 0.6325817704200745,
      "learning_rate": 4.798207678631493e-05,
      "loss": 0.0016,
      "step": 8400
    },
    {
      "epoch": 0.4060352698092355,
      "grad_norm": 0.27144181728363037,
      "learning_rate": 4.797006390850993e-05,
      "loss": 0.001,
      "step": 8450
    },
    {
      "epoch": 0.4084378453702369,
      "grad_norm": 0.12167265266180038,
      "learning_rate": 4.795805103070492e-05,
      "loss": 0.0014,
      "step": 8500
    },
    {
      "epoch": 0.4108404209312383,
      "grad_norm": 0.174238920211792,
      "learning_rate": 4.794603815289991e-05,
      "loss": 0.0012,
      "step": 8550
    },
    {
      "epoch": 0.41324299649223967,
      "grad_norm": 0.5414829254150391,
      "learning_rate": 4.79340252750949e-05,
      "loss": 0.0017,
      "step": 8600
    },
    {
      "epoch": 0.4156455720532411,
      "grad_norm": 0.5067077279090881,
      "learning_rate": 4.792201239728989e-05,
      "loss": 0.0022,
      "step": 8650
    },
    {
      "epoch": 0.41804814761424247,
      "grad_norm": 0.3894350826740265,
      "learning_rate": 4.790999951948489e-05,
      "loss": 0.0016,
      "step": 8700
    },
    {
      "epoch": 0.42045072317524385,
      "grad_norm": 1.0463272333145142,
      "learning_rate": 4.789798664167988e-05,
      "loss": 0.0014,
      "step": 8750
    },
    {
      "epoch": 0.4228532987362453,
      "grad_norm": 0.4065209627151489,
      "learning_rate": 4.788597376387487e-05,
      "loss": 0.0014,
      "step": 8800
    },
    {
      "epoch": 0.42525587429724665,
      "grad_norm": 0.6080430150032043,
      "learning_rate": 4.787396088606987e-05,
      "loss": 0.0013,
      "step": 8850
    },
    {
      "epoch": 0.427658449858248,
      "grad_norm": 0.3935399353504181,
      "learning_rate": 4.786194800826486e-05,
      "loss": 0.001,
      "step": 8900
    },
    {
      "epoch": 0.43006102541924945,
      "grad_norm": 0.42689886689186096,
      "learning_rate": 4.784993513045986e-05,
      "loss": 0.0016,
      "step": 8950
    },
    {
      "epoch": 0.43246360098025083,
      "grad_norm": 0.8148540258407593,
      "learning_rate": 4.783792225265485e-05,
      "loss": 0.0014,
      "step": 9000
    },
    {
      "epoch": 0.4348661765412522,
      "grad_norm": 0.4900786280632019,
      "learning_rate": 4.782590937484984e-05,
      "loss": 0.0012,
      "step": 9050
    },
    {
      "epoch": 0.43726875210225363,
      "grad_norm": 0.19024524092674255,
      "learning_rate": 4.781389649704484e-05,
      "loss": 0.0014,
      "step": 9100
    },
    {
      "epoch": 0.439671327663255,
      "grad_norm": 0.5179347395896912,
      "learning_rate": 4.780188361923983e-05,
      "loss": 0.0012,
      "step": 9150
    },
    {
      "epoch": 0.4420739032242564,
      "grad_norm": 0.7614045739173889,
      "learning_rate": 4.778987074143482e-05,
      "loss": 0.0013,
      "step": 9200
    },
    {
      "epoch": 0.4444764787852578,
      "grad_norm": 0.1180967465043068,
      "learning_rate": 4.777785786362982e-05,
      "loss": 0.0013,
      "step": 9250
    },
    {
      "epoch": 0.4468790543462592,
      "grad_norm": 0.6155666708946228,
      "learning_rate": 4.776584498582481e-05,
      "loss": 0.0013,
      "step": 9300
    },
    {
      "epoch": 0.44928162990726056,
      "grad_norm": 0.1983119547367096,
      "learning_rate": 4.77538321080198e-05,
      "loss": 0.001,
      "step": 9350
    },
    {
      "epoch": 0.451684205468262,
      "grad_norm": 0.4868450462818146,
      "learning_rate": 4.774181923021479e-05,
      "loss": 0.0024,
      "step": 9400
    },
    {
      "epoch": 0.45408678102926336,
      "grad_norm": 1.1665343046188354,
      "learning_rate": 4.772980635240979e-05,
      "loss": 0.0012,
      "step": 9450
    },
    {
      "epoch": 0.45648935659026474,
      "grad_norm": 0.2552391588687897,
      "learning_rate": 4.771779347460478e-05,
      "loss": 0.0021,
      "step": 9500
    },
    {
      "epoch": 0.45889193215126617,
      "grad_norm": 0.14410260319709778,
      "learning_rate": 4.770578059679977e-05,
      "loss": 0.0011,
      "step": 9550
    },
    {
      "epoch": 0.46129450771226754,
      "grad_norm": 0.7896209955215454,
      "learning_rate": 4.7693767718994766e-05,
      "loss": 0.002,
      "step": 9600
    },
    {
      "epoch": 0.4636970832732689,
      "grad_norm": 0.5913751721382141,
      "learning_rate": 4.768175484118976e-05,
      "loss": 0.0014,
      "step": 9650
    },
    {
      "epoch": 0.46609965883427035,
      "grad_norm": 0.4286574423313141,
      "learning_rate": 4.766974196338475e-05,
      "loss": 0.001,
      "step": 9700
    },
    {
      "epoch": 0.4685022343952717,
      "grad_norm": 0.6623501181602478,
      "learning_rate": 4.7657729085579746e-05,
      "loss": 0.001,
      "step": 9750
    },
    {
      "epoch": 0.47090480995627315,
      "grad_norm": 0.213047057390213,
      "learning_rate": 4.7645716207774736e-05,
      "loss": 0.0012,
      "step": 9800
    },
    {
      "epoch": 0.4733073855172745,
      "grad_norm": 0.2503214478492737,
      "learning_rate": 4.7633703329969734e-05,
      "loss": 0.0011,
      "step": 9850
    },
    {
      "epoch": 0.4757099610782759,
      "grad_norm": 0.6675728559494019,
      "learning_rate": 4.7621690452164725e-05,
      "loss": 0.001,
      "step": 9900
    },
    {
      "epoch": 0.47811253663927733,
      "grad_norm": 0.27957069873809814,
      "learning_rate": 4.7609677574359716e-05,
      "loss": 0.0013,
      "step": 9950
    },
    {
      "epoch": 0.4805151122002787,
      "grad_norm": 0.584372878074646,
      "learning_rate": 4.759766469655471e-05,
      "loss": 0.001,
      "step": 10000
    },
    {
      "epoch": 0.4829176877612801,
      "grad_norm": 0.9150265455245972,
      "learning_rate": 4.7585651818749704e-05,
      "loss": 0.0011,
      "step": 10050
    },
    {
      "epoch": 0.4853202633222815,
      "grad_norm": 0.39119142293930054,
      "learning_rate": 4.7573638940944695e-05,
      "loss": 0.0021,
      "step": 10100
    },
    {
      "epoch": 0.4877228388832829,
      "grad_norm": 0.1823011338710785,
      "learning_rate": 4.7561626063139686e-05,
      "loss": 0.0008,
      "step": 10150
    },
    {
      "epoch": 0.49012541444428426,
      "grad_norm": 0.2545369863510132,
      "learning_rate": 4.7549613185334677e-05,
      "loss": 0.0013,
      "step": 10200
    },
    {
      "epoch": 0.4925279900052857,
      "grad_norm": 0.13731487095355988,
      "learning_rate": 4.7537600307529674e-05,
      "loss": 0.0011,
      "step": 10250
    },
    {
      "epoch": 0.49493056556628706,
      "grad_norm": 0.4101825952529907,
      "learning_rate": 4.7525587429724665e-05,
      "loss": 0.0009,
      "step": 10300
    },
    {
      "epoch": 0.49733314112728844,
      "grad_norm": 0.10346488654613495,
      "learning_rate": 4.751357455191966e-05,
      "loss": 0.0009,
      "step": 10350
    },
    {
      "epoch": 0.49973571668828987,
      "grad_norm": 0.35012272000312805,
      "learning_rate": 4.7501561674114653e-05,
      "loss": 0.0009,
      "step": 10400
    },
    {
      "epoch": 0.5021382922492912,
      "grad_norm": 0.28567174077033997,
      "learning_rate": 4.7489548796309644e-05,
      "loss": 0.0008,
      "step": 10450
    },
    {
      "epoch": 0.5045408678102926,
      "grad_norm": 0.2593405544757843,
      "learning_rate": 4.747753591850464e-05,
      "loss": 0.001,
      "step": 10500
    },
    {
      "epoch": 0.506943443371294,
      "grad_norm": 0.5887481570243835,
      "learning_rate": 4.746552304069963e-05,
      "loss": 0.0012,
      "step": 10550
    },
    {
      "epoch": 0.5093460189322955,
      "grad_norm": 0.2314397394657135,
      "learning_rate": 4.7453510162894623e-05,
      "loss": 0.001,
      "step": 10600
    },
    {
      "epoch": 0.5117485944932968,
      "grad_norm": 0.5902872681617737,
      "learning_rate": 4.744149728508962e-05,
      "loss": 0.0009,
      "step": 10650
    },
    {
      "epoch": 0.5141511700542982,
      "grad_norm": 0.4220179617404938,
      "learning_rate": 4.742948440728461e-05,
      "loss": 0.0009,
      "step": 10700
    },
    {
      "epoch": 0.5165537456152997,
      "grad_norm": 0.48761019110679626,
      "learning_rate": 4.741747152947961e-05,
      "loss": 0.0008,
      "step": 10750
    },
    {
      "epoch": 0.518956321176301,
      "grad_norm": 0.35265809297561646,
      "learning_rate": 4.74054586516746e-05,
      "loss": 0.0007,
      "step": 10800
    },
    {
      "epoch": 0.5213588967373024,
      "grad_norm": 0.3995193839073181,
      "learning_rate": 4.739344577386959e-05,
      "loss": 0.0006,
      "step": 10850
    },
    {
      "epoch": 0.5237614722983038,
      "grad_norm": 0.30746737122535706,
      "learning_rate": 4.738143289606458e-05,
      "loss": 0.0008,
      "step": 10900
    },
    {
      "epoch": 0.5261640478593052,
      "grad_norm": 0.28043466806411743,
      "learning_rate": 4.736942001825957e-05,
      "loss": 0.0011,
      "step": 10950
    },
    {
      "epoch": 0.5285666234203066,
      "grad_norm": 0.873360276222229,
      "learning_rate": 4.735740714045457e-05,
      "loss": 0.0012,
      "step": 11000
    },
    {
      "epoch": 0.530969198981308,
      "grad_norm": 0.2979962229728699,
      "learning_rate": 4.734539426264956e-05,
      "loss": 0.0017,
      "step": 11050
    },
    {
      "epoch": 0.5333717745423093,
      "grad_norm": 0.23389507830142975,
      "learning_rate": 4.733338138484455e-05,
      "loss": 0.0008,
      "step": 11100
    },
    {
      "epoch": 0.5357743501033108,
      "grad_norm": 0.6266472935676575,
      "learning_rate": 4.732136850703955e-05,
      "loss": 0.0012,
      "step": 11150
    },
    {
      "epoch": 0.5381769256643122,
      "grad_norm": 0.17252309620380402,
      "learning_rate": 4.730935562923454e-05,
      "loss": 0.0007,
      "step": 11200
    },
    {
      "epoch": 0.5405795012253135,
      "grad_norm": 0.5784076452255249,
      "learning_rate": 4.729734275142954e-05,
      "loss": 0.0012,
      "step": 11250
    },
    {
      "epoch": 0.5429820767863149,
      "grad_norm": 0.10108569264411926,
      "learning_rate": 4.728532987362453e-05,
      "loss": 0.0007,
      "step": 11300
    },
    {
      "epoch": 0.5453846523473164,
      "grad_norm": 0.30679675936698914,
      "learning_rate": 4.727331699581952e-05,
      "loss": 0.0009,
      "step": 11350
    },
    {
      "epoch": 0.5477872279083177,
      "grad_norm": 0.37021946907043457,
      "learning_rate": 4.726130411801452e-05,
      "loss": 0.0008,
      "step": 11400
    },
    {
      "epoch": 0.5501898034693191,
      "grad_norm": 0.4376571774482727,
      "learning_rate": 4.724929124020951e-05,
      "loss": 0.0006,
      "step": 11450
    },
    {
      "epoch": 0.5525923790303205,
      "grad_norm": 0.6061283946037292,
      "learning_rate": 4.72372783624045e-05,
      "loss": 0.0007,
      "step": 11500
    },
    {
      "epoch": 0.5549949545913219,
      "grad_norm": 0.1600957065820694,
      "learning_rate": 4.722526548459949e-05,
      "loss": 0.0009,
      "step": 11550
    },
    {
      "epoch": 0.5573975301523233,
      "grad_norm": 0.6676353812217712,
      "learning_rate": 4.721325260679448e-05,
      "loss": 0.0008,
      "step": 11600
    },
    {
      "epoch": 0.5598001057133247,
      "grad_norm": 0.15582533180713654,
      "learning_rate": 4.720123972898948e-05,
      "loss": 0.0008,
      "step": 11650
    },
    {
      "epoch": 0.562202681274326,
      "grad_norm": 0.2839638590812683,
      "learning_rate": 4.718922685118447e-05,
      "loss": 0.0015,
      "step": 11700
    },
    {
      "epoch": 0.5646052568353275,
      "grad_norm": 0.53142911195755,
      "learning_rate": 4.717721397337947e-05,
      "loss": 0.0009,
      "step": 11750
    },
    {
      "epoch": 0.5670078323963289,
      "grad_norm": 0.10237332433462143,
      "learning_rate": 4.716520109557446e-05,
      "loss": 0.0006,
      "step": 11800
    },
    {
      "epoch": 0.5694104079573302,
      "grad_norm": 0.19533409178256989,
      "learning_rate": 4.715318821776945e-05,
      "loss": 0.001,
      "step": 11850
    },
    {
      "epoch": 0.5718129835183317,
      "grad_norm": 0.43202894926071167,
      "learning_rate": 4.7141175339964446e-05,
      "loss": 0.0008,
      "step": 11900
    },
    {
      "epoch": 0.5742155590793331,
      "grad_norm": 0.4262826442718506,
      "learning_rate": 4.712916246215944e-05,
      "loss": 0.001,
      "step": 11950
    },
    {
      "epoch": 0.5766181346403344,
      "grad_norm": 0.6485825777053833,
      "learning_rate": 4.711714958435443e-05,
      "loss": 0.0007,
      "step": 12000
    },
    {
      "epoch": 0.5790207102013358,
      "grad_norm": 0.2626805007457733,
      "learning_rate": 4.7105136706549425e-05,
      "loss": 0.0009,
      "step": 12050
    },
    {
      "epoch": 0.5814232857623373,
      "grad_norm": 0.17410828173160553,
      "learning_rate": 4.7093123828744416e-05,
      "loss": 0.0005,
      "step": 12100
    },
    {
      "epoch": 0.5838258613233386,
      "grad_norm": 0.2559817433357239,
      "learning_rate": 4.7081110950939414e-05,
      "loss": 0.0007,
      "step": 12150
    },
    {
      "epoch": 0.58622843688434,
      "grad_norm": 0.5456173419952393,
      "learning_rate": 4.7069098073134404e-05,
      "loss": 0.0007,
      "step": 12200
    },
    {
      "epoch": 0.5886310124453414,
      "grad_norm": 0.41028156876564026,
      "learning_rate": 4.7057085195329395e-05,
      "loss": 0.0013,
      "step": 12250
    },
    {
      "epoch": 0.5910335880063428,
      "grad_norm": 0.1829148381948471,
      "learning_rate": 4.7045072317524386e-05,
      "loss": 0.0014,
      "step": 12300
    },
    {
      "epoch": 0.5934361635673442,
      "grad_norm": 0.6150168776512146,
      "learning_rate": 4.703305943971938e-05,
      "loss": 0.0007,
      "step": 12350
    },
    {
      "epoch": 0.5958387391283456,
      "grad_norm": 0.19091950356960297,
      "learning_rate": 4.7021046561914375e-05,
      "loss": 0.0006,
      "step": 12400
    },
    {
      "epoch": 0.5982413146893469,
      "grad_norm": 0.47362563014030457,
      "learning_rate": 4.7009033684109365e-05,
      "loss": 0.0008,
      "step": 12450
    },
    {
      "epoch": 0.6006438902503484,
      "grad_norm": 0.5363548398017883,
      "learning_rate": 4.6997020806304356e-05,
      "loss": 0.0009,
      "step": 12500
    },
    {
      "epoch": 0.6030464658113498,
      "grad_norm": 0.6264620423316956,
      "learning_rate": 4.6985007928499354e-05,
      "loss": 0.0007,
      "step": 12550
    },
    {
      "epoch": 0.6054490413723511,
      "grad_norm": 0.3643683195114136,
      "learning_rate": 4.6972995050694345e-05,
      "loss": 0.0007,
      "step": 12600
    },
    {
      "epoch": 0.6078516169333525,
      "grad_norm": 0.32921794056892395,
      "learning_rate": 4.696098217288934e-05,
      "loss": 0.0009,
      "step": 12650
    },
    {
      "epoch": 0.610254192494354,
      "grad_norm": 0.5707162022590637,
      "learning_rate": 4.694896929508433e-05,
      "loss": 0.0007,
      "step": 12700
    },
    {
      "epoch": 0.6126567680553553,
      "grad_norm": 0.1990925371646881,
      "learning_rate": 4.6936956417279324e-05,
      "loss": 0.0007,
      "step": 12750
    },
    {
      "epoch": 0.6150593436163567,
      "grad_norm": 0.38244229555130005,
      "learning_rate": 4.692494353947432e-05,
      "loss": 0.0006,
      "step": 12800
    },
    {
      "epoch": 0.6174619191773582,
      "grad_norm": 0.1939760148525238,
      "learning_rate": 4.691293066166931e-05,
      "loss": 0.0008,
      "step": 12850
    },
    {
      "epoch": 0.6198644947383595,
      "grad_norm": 0.6574060320854187,
      "learning_rate": 4.690091778386431e-05,
      "loss": 0.0009,
      "step": 12900
    },
    {
      "epoch": 0.6222670702993609,
      "grad_norm": 0.14556463062763214,
      "learning_rate": 4.68889049060593e-05,
      "loss": 0.0006,
      "step": 12950
    },
    {
      "epoch": 0.6246696458603623,
      "grad_norm": 0.11463288217782974,
      "learning_rate": 4.687689202825429e-05,
      "loss": 0.0006,
      "step": 13000
    },
    {
      "epoch": 0.6270722214213637,
      "grad_norm": 0.08979780972003937,
      "learning_rate": 4.686487915044928e-05,
      "loss": 0.0006,
      "step": 13050
    },
    {
      "epoch": 0.6294747969823651,
      "grad_norm": 0.47137269377708435,
      "learning_rate": 4.685286627264427e-05,
      "loss": 0.0007,
      "step": 13100
    },
    {
      "epoch": 0.6318773725433665,
      "grad_norm": 0.1511927992105484,
      "learning_rate": 4.684085339483927e-05,
      "loss": 0.0005,
      "step": 13150
    },
    {
      "epoch": 0.6342799481043678,
      "grad_norm": 0.6196987628936768,
      "learning_rate": 4.682884051703426e-05,
      "loss": 0.0005,
      "step": 13200
    },
    {
      "epoch": 0.6366825236653693,
      "grad_norm": 0.576296865940094,
      "learning_rate": 4.681682763922925e-05,
      "loss": 0.0007,
      "step": 13250
    },
    {
      "epoch": 0.6390850992263707,
      "grad_norm": 0.21788786351680756,
      "learning_rate": 4.680481476142425e-05,
      "loss": 0.0005,
      "step": 13300
    },
    {
      "epoch": 0.641487674787372,
      "grad_norm": 0.3903684616088867,
      "learning_rate": 4.679280188361924e-05,
      "loss": 0.0007,
      "step": 13350
    },
    {
      "epoch": 0.6438902503483734,
      "grad_norm": 0.5802015066146851,
      "learning_rate": 4.678078900581424e-05,
      "loss": 0.0005,
      "step": 13400
    },
    {
      "epoch": 0.6462928259093749,
      "grad_norm": 0.30761125683784485,
      "learning_rate": 4.676877612800923e-05,
      "loss": 0.0006,
      "step": 13450
    },
    {
      "epoch": 0.6486954014703763,
      "grad_norm": 0.19932259619235992,
      "learning_rate": 4.675676325020422e-05,
      "loss": 0.0005,
      "step": 13500
    },
    {
      "epoch": 0.6510979770313776,
      "grad_norm": 0.32391735911369324,
      "learning_rate": 4.674475037239922e-05,
      "loss": 0.0006,
      "step": 13550
    },
    {
      "epoch": 0.653500552592379,
      "grad_norm": 0.20856009423732758,
      "learning_rate": 4.673273749459421e-05,
      "loss": 0.0005,
      "step": 13600
    },
    {
      "epoch": 0.6559031281533805,
      "grad_norm": 0.1575663983821869,
      "learning_rate": 4.67207246167892e-05,
      "loss": 0.0005,
      "step": 13650
    },
    {
      "epoch": 0.6583057037143818,
      "grad_norm": 0.15541262924671173,
      "learning_rate": 4.67087117389842e-05,
      "loss": 0.0009,
      "step": 13700
    },
    {
      "epoch": 0.6607082792753832,
      "grad_norm": 0.252206414937973,
      "learning_rate": 4.669669886117919e-05,
      "loss": 0.0007,
      "step": 13750
    },
    {
      "epoch": 0.6631108548363847,
      "grad_norm": 0.2140800803899765,
      "learning_rate": 4.668468598337418e-05,
      "loss": 0.0007,
      "step": 13800
    },
    {
      "epoch": 0.665513430397386,
      "grad_norm": 0.06244887411594391,
      "learning_rate": 4.667267310556917e-05,
      "loss": 0.0006,
      "step": 13850
    },
    {
      "epoch": 0.6679160059583874,
      "grad_norm": 0.6257362961769104,
      "learning_rate": 4.666066022776416e-05,
      "loss": 0.0007,
      "step": 13900
    },
    {
      "epoch": 0.6703185815193888,
      "grad_norm": 0.3224324584007263,
      "learning_rate": 4.664864734995916e-05,
      "loss": 0.0009,
      "step": 13950
    },
    {
      "epoch": 0.6727211570803902,
      "grad_norm": 0.409361332654953,
      "learning_rate": 4.663663447215415e-05,
      "loss": 0.0013,
      "step": 14000
    },
    {
      "epoch": 0.6751237326413916,
      "grad_norm": 0.3123898506164551,
      "learning_rate": 4.6624621594349146e-05,
      "loss": 0.0005,
      "step": 14050
    },
    {
      "epoch": 0.677526308202393,
      "grad_norm": 0.08261309564113617,
      "learning_rate": 4.661260871654414e-05,
      "loss": 0.0005,
      "step": 14100
    },
    {
      "epoch": 0.6799288837633943,
      "grad_norm": 0.1544881910085678,
      "learning_rate": 4.660059583873913e-05,
      "loss": 0.0004,
      "step": 14150
    },
    {
      "epoch": 0.6823314593243958,
      "grad_norm": 0.247747540473938,
      "learning_rate": 4.6588582960934126e-05,
      "loss": 0.0006,
      "step": 14200
    },
    {
      "epoch": 0.6847340348853972,
      "grad_norm": 0.24560029804706573,
      "learning_rate": 4.6576570083129116e-05,
      "loss": 0.0005,
      "step": 14250
    },
    {
      "epoch": 0.6871366104463985,
      "grad_norm": 0.16152065992355347,
      "learning_rate": 4.6564557205324114e-05,
      "loss": 0.0005,
      "step": 14300
    },
    {
      "epoch": 0.6895391860073999,
      "grad_norm": 0.23756396770477295,
      "learning_rate": 4.6552544327519105e-05,
      "loss": 0.0005,
      "step": 14350
    },
    {
      "epoch": 0.6919417615684014,
      "grad_norm": 0.5006148815155029,
      "learning_rate": 4.6540531449714096e-05,
      "loss": 0.0005,
      "step": 14400
    },
    {
      "epoch": 0.6943443371294027,
      "grad_norm": 0.139124795794487,
      "learning_rate": 4.652851857190909e-05,
      "loss": 0.0004,
      "step": 14450
    },
    {
      "epoch": 0.6967469126904041,
      "grad_norm": 0.3240383267402649,
      "learning_rate": 4.6516505694104084e-05,
      "loss": 0.0006,
      "step": 14500
    },
    {
      "epoch": 0.6991494882514055,
      "grad_norm": 0.3627566993236542,
      "learning_rate": 4.6504492816299075e-05,
      "loss": 0.0013,
      "step": 14550
    },
    {
      "epoch": 0.7015520638124069,
      "grad_norm": 0.09867150336503983,
      "learning_rate": 4.6492479938494066e-05,
      "loss": 0.0012,
      "step": 14600
    },
    {
      "epoch": 0.7039546393734083,
      "grad_norm": 0.21332186460494995,
      "learning_rate": 4.6480467060689057e-05,
      "loss": 0.0005,
      "step": 14650
    },
    {
      "epoch": 0.7063572149344097,
      "grad_norm": 0.08542759716510773,
      "learning_rate": 4.6468454182884054e-05,
      "loss": 0.0005,
      "step": 14700
    },
    {
      "epoch": 0.708759790495411,
      "grad_norm": 0.3749917149543762,
      "learning_rate": 4.6456441305079045e-05,
      "loss": 0.0005,
      "step": 14750
    },
    {
      "epoch": 0.7111623660564125,
      "grad_norm": 0.22350670397281647,
      "learning_rate": 4.644442842727404e-05,
      "loss": 0.0004,
      "step": 14800
    },
    {
      "epoch": 0.7135649416174139,
      "grad_norm": 0.27516818046569824,
      "learning_rate": 4.643241554946903e-05,
      "loss": 0.0005,
      "step": 14850
    },
    {
      "epoch": 0.7159675171784152,
      "grad_norm": 0.42371708154678345,
      "learning_rate": 4.6420402671664024e-05,
      "loss": 0.0004,
      "step": 14900
    },
    {
      "epoch": 0.7183700927394167,
      "grad_norm": 0.17315952479839325,
      "learning_rate": 4.640838979385902e-05,
      "loss": 0.0019,
      "step": 14950
    },
    {
      "epoch": 0.7207726683004181,
      "grad_norm": 0.16796909272670746,
      "learning_rate": 4.639637691605401e-05,
      "loss": 0.0005,
      "step": 15000
    },
    {
      "epoch": 0.7231752438614194,
      "grad_norm": 0.2549312114715576,
      "learning_rate": 4.6384364038249003e-05,
      "loss": 0.0005,
      "step": 15050
    },
    {
      "epoch": 0.7255778194224208,
      "grad_norm": 0.2706032395362854,
      "learning_rate": 4.6372351160444e-05,
      "loss": 0.0005,
      "step": 15100
    },
    {
      "epoch": 0.7279803949834223,
      "grad_norm": 0.21539588272571564,
      "learning_rate": 4.636033828263899e-05,
      "loss": 0.0007,
      "step": 15150
    },
    {
      "epoch": 0.7303829705444236,
      "grad_norm": 0.2945595383644104,
      "learning_rate": 4.634832540483399e-05,
      "loss": 0.0007,
      "step": 15200
    },
    {
      "epoch": 0.732785546105425,
      "grad_norm": 0.24545596539974213,
      "learning_rate": 4.633631252702898e-05,
      "loss": 0.0006,
      "step": 15250
    },
    {
      "epoch": 0.7351881216664264,
      "grad_norm": 0.22290267050266266,
      "learning_rate": 4.632429964922397e-05,
      "loss": 0.0004,
      "step": 15300
    },
    {
      "epoch": 0.7375906972274278,
      "grad_norm": 0.20458726584911346,
      "learning_rate": 4.631228677141896e-05,
      "loss": 0.0004,
      "step": 15350
    },
    {
      "epoch": 0.7399932727884292,
      "grad_norm": 0.14345088601112366,
      "learning_rate": 4.630027389361395e-05,
      "loss": 0.0005,
      "step": 15400
    },
    {
      "epoch": 0.7423958483494306,
      "grad_norm": 0.05818941816687584,
      "learning_rate": 4.628826101580895e-05,
      "loss": 0.0006,
      "step": 15450
    },
    {
      "epoch": 0.7447984239104319,
      "grad_norm": 0.14560377597808838,
      "learning_rate": 4.627624813800394e-05,
      "loss": 0.0006,
      "step": 15500
    },
    {
      "epoch": 0.7472009994714334,
      "grad_norm": 0.1492796093225479,
      "learning_rate": 4.626423526019893e-05,
      "loss": 0.0004,
      "step": 15550
    },
    {
      "epoch": 0.7496035750324348,
      "grad_norm": 0.5840547680854797,
      "learning_rate": 4.625222238239393e-05,
      "loss": 0.0005,
      "step": 15600
    },
    {
      "epoch": 0.7520061505934361,
      "grad_norm": 0.3758610486984253,
      "learning_rate": 4.624020950458892e-05,
      "loss": 0.0006,
      "step": 15650
    },
    {
      "epoch": 0.7544087261544375,
      "grad_norm": 0.44598308205604553,
      "learning_rate": 4.622819662678392e-05,
      "loss": 0.0005,
      "step": 15700
    },
    {
      "epoch": 0.756811301715439,
      "grad_norm": 0.1542448103427887,
      "learning_rate": 4.621618374897891e-05,
      "loss": 0.0004,
      "step": 15750
    },
    {
      "epoch": 0.7592138772764403,
      "grad_norm": 0.6062233448028564,
      "learning_rate": 4.62041708711739e-05,
      "loss": 0.0004,
      "step": 15800
    },
    {
      "epoch": 0.7616164528374417,
      "grad_norm": 0.26074254512786865,
      "learning_rate": 4.61921579933689e-05,
      "loss": 0.0005,
      "step": 15850
    },
    {
      "epoch": 0.7640190283984432,
      "grad_norm": 0.2679304778575897,
      "learning_rate": 4.618014511556389e-05,
      "loss": 0.0003,
      "step": 15900
    },
    {
      "epoch": 0.7664216039594445,
      "grad_norm": 0.298103928565979,
      "learning_rate": 4.616813223775888e-05,
      "loss": 0.0005,
      "step": 15950
    },
    {
      "epoch": 0.7688241795204459,
      "grad_norm": 0.26578018069267273,
      "learning_rate": 4.6156119359953877e-05,
      "loss": 0.0012,
      "step": 16000
    },
    {
      "epoch": 0.7712267550814473,
      "grad_norm": 0.35617056488990784,
      "learning_rate": 4.614410648214886e-05,
      "loss": 0.0004,
      "step": 16050
    },
    {
      "epoch": 0.7736293306424487,
      "grad_norm": 0.20254452526569366,
      "learning_rate": 4.613209360434386e-05,
      "loss": 0.0004,
      "step": 16100
    },
    {
      "epoch": 0.7760319062034501,
      "grad_norm": 0.18166276812553406,
      "learning_rate": 4.612008072653885e-05,
      "loss": 0.0005,
      "step": 16150
    },
    {
      "epoch": 0.7784344817644515,
      "grad_norm": 0.3068163990974426,
      "learning_rate": 4.610806784873385e-05,
      "loss": 0.0003,
      "step": 16200
    },
    {
      "epoch": 0.7808370573254528,
      "grad_norm": 0.4993622899055481,
      "learning_rate": 4.609605497092884e-05,
      "loss": 0.0003,
      "step": 16250
    },
    {
      "epoch": 0.7832396328864543,
      "grad_norm": 0.26270073652267456,
      "learning_rate": 4.608404209312383e-05,
      "loss": 0.0004,
      "step": 16300
    },
    {
      "epoch": 0.7856422084474557,
      "grad_norm": 0.46297982335090637,
      "learning_rate": 4.6072029215318826e-05,
      "loss": 0.0004,
      "step": 16350
    },
    {
      "epoch": 0.788044784008457,
      "grad_norm": 0.17706994712352753,
      "learning_rate": 4.606001633751382e-05,
      "loss": 0.0005,
      "step": 16400
    },
    {
      "epoch": 0.7904473595694584,
      "grad_norm": 0.23799970746040344,
      "learning_rate": 4.604800345970881e-05,
      "loss": 0.0003,
      "step": 16450
    },
    {
      "epoch": 0.7928499351304599,
      "grad_norm": 0.3308199346065521,
      "learning_rate": 4.6035990581903805e-05,
      "loss": 0.0003,
      "step": 16500
    },
    {
      "epoch": 0.7952525106914613,
      "grad_norm": 0.2968522608280182,
      "learning_rate": 4.6023977704098796e-05,
      "loss": 0.0004,
      "step": 16550
    },
    {
      "epoch": 0.7976550862524626,
      "grad_norm": 0.3040672242641449,
      "learning_rate": 4.6011964826293794e-05,
      "loss": 0.0004,
      "step": 16600
    },
    {
      "epoch": 0.800057661813464,
      "grad_norm": 0.23504500091075897,
      "learning_rate": 4.5999951948488784e-05,
      "loss": 0.0004,
      "step": 16650
    },
    {
      "epoch": 0.8024602373744655,
      "grad_norm": 0.34778153896331787,
      "learning_rate": 4.5987939070683775e-05,
      "loss": 0.0007,
      "step": 16700
    },
    {
      "epoch": 0.8048628129354668,
      "grad_norm": 0.2425207495689392,
      "learning_rate": 4.597592619287877e-05,
      "loss": 0.0004,
      "step": 16750
    },
    {
      "epoch": 0.8072653884964682,
      "grad_norm": 0.14435888826847076,
      "learning_rate": 4.596391331507376e-05,
      "loss": 0.0006,
      "step": 16800
    },
    {
      "epoch": 0.8096679640574697,
      "grad_norm": 0.3763614892959595,
      "learning_rate": 4.5951900437268754e-05,
      "loss": 0.0004,
      "step": 16850
    },
    {
      "epoch": 0.812070539618471,
      "grad_norm": 0.2948377728462219,
      "learning_rate": 4.5939887559463745e-05,
      "loss": 0.0003,
      "step": 16900
    },
    {
      "epoch": 0.8144731151794724,
      "grad_norm": 0.18955853581428528,
      "learning_rate": 4.5927874681658736e-05,
      "loss": 0.0004,
      "step": 16950
    },
    {
      "epoch": 0.8168756907404738,
      "grad_norm": 0.1785687357187271,
      "learning_rate": 4.5915861803853734e-05,
      "loss": 0.0005,
      "step": 17000
    },
    {
      "epoch": 0.8192782663014752,
      "grad_norm": 0.062323905527591705,
      "learning_rate": 4.5903848926048725e-05,
      "loss": 0.0004,
      "step": 17050
    },
    {
      "epoch": 0.8216808418624766,
      "grad_norm": 0.19913344085216522,
      "learning_rate": 4.589183604824372e-05,
      "loss": 0.0004,
      "step": 17100
    },
    {
      "epoch": 0.824083417423478,
      "grad_norm": 0.18266446888446808,
      "learning_rate": 4.587982317043871e-05,
      "loss": 0.0004,
      "step": 17150
    },
    {
      "epoch": 0.8264859929844793,
      "grad_norm": 0.32080376148223877,
      "learning_rate": 4.5867810292633704e-05,
      "loss": 0.0004,
      "step": 17200
    },
    {
      "epoch": 0.8288885685454808,
      "grad_norm": 0.4301320016384125,
      "learning_rate": 4.58557974148287e-05,
      "loss": 0.0004,
      "step": 17250
    },
    {
      "epoch": 0.8312911441064822,
      "grad_norm": 0.20037272572517395,
      "learning_rate": 4.584378453702369e-05,
      "loss": 0.0004,
      "step": 17300
    },
    {
      "epoch": 0.8336937196674835,
      "grad_norm": 0.30121541023254395,
      "learning_rate": 4.583177165921868e-05,
      "loss": 0.0019,
      "step": 17350
    },
    {
      "epoch": 0.8360962952284849,
      "grad_norm": 0.3756600320339203,
      "learning_rate": 4.581975878141368e-05,
      "loss": 0.0009,
      "step": 17400
    },
    {
      "epoch": 0.8384988707894864,
      "grad_norm": 0.3647182583808899,
      "learning_rate": 4.580774590360867e-05,
      "loss": 0.0004,
      "step": 17450
    },
    {
      "epoch": 0.8409014463504877,
      "grad_norm": 0.5663448572158813,
      "learning_rate": 4.579573302580366e-05,
      "loss": 0.0004,
      "step": 17500
    },
    {
      "epoch": 0.8433040219114891,
      "grad_norm": 0.1661624163389206,
      "learning_rate": 4.578372014799865e-05,
      "loss": 0.0005,
      "step": 17550
    },
    {
      "epoch": 0.8457065974724906,
      "grad_norm": 0.25336793065071106,
      "learning_rate": 4.577170727019365e-05,
      "loss": 0.0003,
      "step": 17600
    },
    {
      "epoch": 0.8481091730334919,
      "grad_norm": 0.2794156074523926,
      "learning_rate": 4.575969439238864e-05,
      "loss": 0.0004,
      "step": 17650
    },
    {
      "epoch": 0.8505117485944933,
      "grad_norm": 0.3095906972885132,
      "learning_rate": 4.574768151458363e-05,
      "loss": 0.0003,
      "step": 17700
    },
    {
      "epoch": 0.8529143241554947,
      "grad_norm": 0.2904398441314697,
      "learning_rate": 4.573566863677863e-05,
      "loss": 0.0004,
      "step": 17750
    },
    {
      "epoch": 0.855316899716496,
      "grad_norm": 0.08351132273674011,
      "learning_rate": 4.572365575897362e-05,
      "loss": 0.0003,
      "step": 17800
    },
    {
      "epoch": 0.8577194752774975,
      "grad_norm": 0.2039576917886734,
      "learning_rate": 4.571164288116861e-05,
      "loss": 0.0004,
      "step": 17850
    },
    {
      "epoch": 0.8601220508384989,
      "grad_norm": 0.6028733849525452,
      "learning_rate": 4.569963000336361e-05,
      "loss": 0.0004,
      "step": 17900
    },
    {
      "epoch": 0.8625246263995002,
      "grad_norm": 0.09233266860246658,
      "learning_rate": 4.56876171255586e-05,
      "loss": 0.0003,
      "step": 17950
    },
    {
      "epoch": 0.8649272019605017,
      "grad_norm": 0.35372769832611084,
      "learning_rate": 4.56756042477536e-05,
      "loss": 0.0003,
      "step": 18000
    },
    {
      "epoch": 0.8673297775215031,
      "grad_norm": 0.3586353361606598,
      "learning_rate": 4.566359136994859e-05,
      "loss": 0.0004,
      "step": 18050
    },
    {
      "epoch": 0.8697323530825044,
      "grad_norm": 0.21224237978458405,
      "learning_rate": 4.565157849214358e-05,
      "loss": 0.0004,
      "step": 18100
    },
    {
      "epoch": 0.8721349286435058,
      "grad_norm": 0.5403316020965576,
      "learning_rate": 4.563956561433858e-05,
      "loss": 0.0004,
      "step": 18150
    },
    {
      "epoch": 0.8745375042045073,
      "grad_norm": 0.13087156414985657,
      "learning_rate": 4.562755273653357e-05,
      "loss": 0.0003,
      "step": 18200
    },
    {
      "epoch": 0.8769400797655086,
      "grad_norm": 0.3371748924255371,
      "learning_rate": 4.561553985872856e-05,
      "loss": 0.0004,
      "step": 18250
    },
    {
      "epoch": 0.87934265532651,
      "grad_norm": 0.313486784696579,
      "learning_rate": 4.560352698092355e-05,
      "loss": 0.0004,
      "step": 18300
    },
    {
      "epoch": 0.8817452308875114,
      "grad_norm": 0.3570159077644348,
      "learning_rate": 4.559151410311854e-05,
      "loss": 0.0003,
      "step": 18350
    },
    {
      "epoch": 0.8841478064485128,
      "grad_norm": 0.22551679611206055,
      "learning_rate": 4.557950122531354e-05,
      "loss": 0.0005,
      "step": 18400
    },
    {
      "epoch": 0.8865503820095142,
      "grad_norm": 0.16138939559459686,
      "learning_rate": 4.556748834750853e-05,
      "loss": 0.0004,
      "step": 18450
    },
    {
      "epoch": 0.8889529575705156,
      "grad_norm": 0.2995676100254059,
      "learning_rate": 4.5555475469703526e-05,
      "loss": 0.0004,
      "step": 18500
    },
    {
      "epoch": 0.8913555331315169,
      "grad_norm": 0.2456107884645462,
      "learning_rate": 4.554346259189852e-05,
      "loss": 0.0004,
      "step": 18550
    },
    {
      "epoch": 0.8937581086925184,
      "grad_norm": 0.24138899147510529,
      "learning_rate": 4.553144971409351e-05,
      "loss": 0.0003,
      "step": 18600
    },
    {
      "epoch": 0.8961606842535198,
      "grad_norm": 0.30477115511894226,
      "learning_rate": 4.5519436836288505e-05,
      "loss": 0.0003,
      "step": 18650
    },
    {
      "epoch": 0.8985632598145211,
      "grad_norm": 0.473041296005249,
      "learning_rate": 4.5507423958483496e-05,
      "loss": 0.0004,
      "step": 18700
    },
    {
      "epoch": 0.9009658353755226,
      "grad_norm": 0.12909618020057678,
      "learning_rate": 4.5495411080678494e-05,
      "loss": 0.0004,
      "step": 18750
    },
    {
      "epoch": 0.903368410936524,
      "grad_norm": 0.25886765122413635,
      "learning_rate": 4.5483398202873485e-05,
      "loss": 0.0005,
      "step": 18800
    },
    {
      "epoch": 0.9057709864975253,
      "grad_norm": 0.10755965858697891,
      "learning_rate": 4.5471385325068476e-05,
      "loss": 0.0004,
      "step": 18850
    },
    {
      "epoch": 0.9081735620585267,
      "grad_norm": 0.38713788986206055,
      "learning_rate": 4.545937244726347e-05,
      "loss": 0.0003,
      "step": 18900
    },
    {
      "epoch": 0.9105761376195282,
      "grad_norm": 0.12442635744810104,
      "learning_rate": 4.5447359569458464e-05,
      "loss": 0.0003,
      "step": 18950
    },
    {
      "epoch": 0.9129787131805295,
      "grad_norm": 0.41700366139411926,
      "learning_rate": 4.5435346691653455e-05,
      "loss": 0.0004,
      "step": 19000
    },
    {
      "epoch": 0.9153812887415309,
      "grad_norm": 0.288183331489563,
      "learning_rate": 4.5423333813848446e-05,
      "loss": 0.0004,
      "step": 19050
    },
    {
      "epoch": 0.9177838643025323,
      "grad_norm": 0.3088480830192566,
      "learning_rate": 4.5411320936043436e-05,
      "loss": 0.0003,
      "step": 19100
    },
    {
      "epoch": 0.9201864398635337,
      "grad_norm": 0.35970374941825867,
      "learning_rate": 4.5399308058238434e-05,
      "loss": 0.0004,
      "step": 19150
    },
    {
      "epoch": 0.9225890154245351,
      "grad_norm": 0.21858394145965576,
      "learning_rate": 4.5387295180433425e-05,
      "loss": 0.0003,
      "step": 19200
    },
    {
      "epoch": 0.9249915909855365,
      "grad_norm": 0.2796936333179474,
      "learning_rate": 4.5375282302628416e-05,
      "loss": 0.0003,
      "step": 19250
    },
    {
      "epoch": 0.9273941665465378,
      "grad_norm": 0.13891062140464783,
      "learning_rate": 4.536326942482341e-05,
      "loss": 0.0003,
      "step": 19300
    },
    {
      "epoch": 0.9297967421075393,
      "grad_norm": 0.41483160853385925,
      "learning_rate": 4.5351256547018404e-05,
      "loss": 0.0003,
      "step": 19350
    },
    {
      "epoch": 0.9321993176685407,
      "grad_norm": 0.3850933909416199,
      "learning_rate": 4.53392436692134e-05,
      "loss": 0.0003,
      "step": 19400
    },
    {
      "epoch": 0.9346018932295421,
      "grad_norm": 0.19518998265266418,
      "learning_rate": 4.532723079140839e-05,
      "loss": 0.0005,
      "step": 19450
    },
    {
      "epoch": 0.9370044687905434,
      "grad_norm": 0.4063898026943207,
      "learning_rate": 4.5315217913603383e-05,
      "loss": 0.0003,
      "step": 19500
    },
    {
      "epoch": 0.9394070443515449,
      "grad_norm": 0.3414221405982971,
      "learning_rate": 4.530320503579838e-05,
      "loss": 0.0004,
      "step": 19550
    },
    {
      "epoch": 0.9418096199125463,
      "grad_norm": 0.04500608146190643,
      "learning_rate": 4.529119215799337e-05,
      "loss": 0.0003,
      "step": 19600
    },
    {
      "epoch": 0.9442121954735476,
      "grad_norm": 0.20071594417095184,
      "learning_rate": 4.527917928018837e-05,
      "loss": 0.0005,
      "step": 19650
    },
    {
      "epoch": 0.946614771034549,
      "grad_norm": 0.751842737197876,
      "learning_rate": 4.526716640238336e-05,
      "loss": 0.0004,
      "step": 19700
    },
    {
      "epoch": 0.9490173465955505,
      "grad_norm": 0.3956319987773895,
      "learning_rate": 4.5255153524578344e-05,
      "loss": 0.0004,
      "step": 19750
    },
    {
      "epoch": 0.9514199221565518,
      "grad_norm": 0.1831003874540329,
      "learning_rate": 4.524314064677334e-05,
      "loss": 0.0004,
      "step": 19800
    },
    {
      "epoch": 0.9538224977175532,
      "grad_norm": 0.5418301224708557,
      "learning_rate": 4.523112776896833e-05,
      "loss": 0.0003,
      "step": 19850
    },
    {
      "epoch": 0.9562250732785547,
      "grad_norm": 0.38254180550575256,
      "learning_rate": 4.521911489116333e-05,
      "loss": 0.0006,
      "step": 19900
    },
    {
      "epoch": 0.958627648839556,
      "grad_norm": 0.1576739400625229,
      "learning_rate": 4.520710201335832e-05,
      "loss": 0.0009,
      "step": 19950
    },
    {
      "epoch": 0.9610302244005574,
      "grad_norm": 0.30839741230010986,
      "learning_rate": 4.519508913555331e-05,
      "loss": 0.0005,
      "step": 20000
    },
    {
      "epoch": 0.9634327999615588,
      "grad_norm": 0.30133137106895447,
      "learning_rate": 4.518307625774831e-05,
      "loss": 0.0013,
      "step": 20050
    },
    {
      "epoch": 0.9658353755225602,
      "grad_norm": 0.2090066373348236,
      "learning_rate": 4.51710633799433e-05,
      "loss": 0.0006,
      "step": 20100
    },
    {
      "epoch": 0.9682379510835616,
      "grad_norm": 0.13039985299110413,
      "learning_rate": 4.51590505021383e-05,
      "loss": 0.0011,
      "step": 20150
    },
    {
      "epoch": 0.970640526644563,
      "grad_norm": 0.1034875139594078,
      "learning_rate": 4.514703762433329e-05,
      "loss": 0.0003,
      "step": 20200
    },
    {
      "epoch": 0.9730431022055643,
      "grad_norm": 0.14955173432826996,
      "learning_rate": 4.513502474652828e-05,
      "loss": 0.0003,
      "step": 20250
    },
    {
      "epoch": 0.9754456777665658,
      "grad_norm": 0.2439357191324234,
      "learning_rate": 4.512301186872328e-05,
      "loss": 0.0003,
      "step": 20300
    },
    {
      "epoch": 0.9778482533275672,
      "grad_norm": 0.3087243139743805,
      "learning_rate": 4.511099899091827e-05,
      "loss": 0.0011,
      "step": 20350
    },
    {
      "epoch": 0.9802508288885685,
      "grad_norm": 0.10187457501888275,
      "learning_rate": 4.509898611311326e-05,
      "loss": 0.0003,
      "step": 20400
    },
    {
      "epoch": 0.98265340444957,
      "grad_norm": 0.0614391528069973,
      "learning_rate": 4.5086973235308257e-05,
      "loss": 0.0004,
      "step": 20450
    },
    {
      "epoch": 0.9850559800105714,
      "grad_norm": 0.379104346036911,
      "learning_rate": 4.507496035750324e-05,
      "loss": 0.0003,
      "step": 20500
    },
    {
      "epoch": 0.9874585555715727,
      "grad_norm": 0.33108431100845337,
      "learning_rate": 4.506294747969824e-05,
      "loss": 0.0004,
      "step": 20550
    },
    {
      "epoch": 0.9898611311325741,
      "grad_norm": 0.2668234705924988,
      "learning_rate": 4.505093460189323e-05,
      "loss": 0.0003,
      "step": 20600
    },
    {
      "epoch": 0.9922637066935756,
      "grad_norm": 0.06497212499380112,
      "learning_rate": 4.5038921724088227e-05,
      "loss": 0.0003,
      "step": 20650
    },
    {
      "epoch": 0.9946662822545769,
      "grad_norm": 0.20944145321846008,
      "learning_rate": 4.502690884628322e-05,
      "loss": 0.0003,
      "step": 20700
    },
    {
      "epoch": 0.9970688578155783,
      "grad_norm": 0.19129639863967896,
      "learning_rate": 4.501489596847821e-05,
      "loss": 0.0003,
      "step": 20750
    },
    {
      "epoch": 0.9994714333765797,
      "grad_norm": 0.08985954523086548,
      "learning_rate": 4.5002883090673206e-05,
      "loss": 0.0008,
      "step": 20800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0002766257675830275,
      "eval_runtime": 17.5343,
      "eval_samples_per_second": 541.567,
      "eval_steps_per_second": 67.696,
      "step": 20811
    }
  ],
  "logging_steps": 50,
  "max_steps": 208110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9214907416224228.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
