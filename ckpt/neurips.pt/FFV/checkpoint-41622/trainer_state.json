{
  "best_global_step": 41622,
  "best_metric": 0.0002468742895871401,
  "best_model_checkpoint": "ckpt/neurips.pt/FFV/checkpoint-41622",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 41622,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0024025755610013935,
      "grad_norm": 3.752441644668579,
      "learning_rate": 4.99882273797511e-05,
      "loss": 0.0415,
      "step": 50
    },
    {
      "epoch": 0.004805151122002787,
      "grad_norm": 1.228306770324707,
      "learning_rate": 4.997621450194609e-05,
      "loss": 0.0324,
      "step": 100
    },
    {
      "epoch": 0.00720772668300418,
      "grad_norm": 4.905325889587402,
      "learning_rate": 4.996420162414108e-05,
      "loss": 0.0344,
      "step": 150
    },
    {
      "epoch": 0.009610302244005574,
      "grad_norm": 2.193751811981201,
      "learning_rate": 4.995218874633608e-05,
      "loss": 0.0221,
      "step": 200
    },
    {
      "epoch": 0.012012877805006967,
      "grad_norm": 1.6830034255981445,
      "learning_rate": 4.994017586853107e-05,
      "loss": 0.024,
      "step": 250
    },
    {
      "epoch": 0.01441545336600836,
      "grad_norm": 3.750678062438965,
      "learning_rate": 4.9928162990726066e-05,
      "loss": 0.0215,
      "step": 300
    },
    {
      "epoch": 0.016818028927009756,
      "grad_norm": 2.535874605178833,
      "learning_rate": 4.991615011292106e-05,
      "loss": 0.0186,
      "step": 350
    },
    {
      "epoch": 0.019220604488011148,
      "grad_norm": 0.7154179811477661,
      "learning_rate": 4.990413723511604e-05,
      "loss": 0.0212,
      "step": 400
    },
    {
      "epoch": 0.021623180049012543,
      "grad_norm": 1.7365463972091675,
      "learning_rate": 4.989212435731104e-05,
      "loss": 0.0177,
      "step": 450
    },
    {
      "epoch": 0.024025755610013935,
      "grad_norm": 1.3618357181549072,
      "learning_rate": 4.988011147950603e-05,
      "loss": 0.0281,
      "step": 500
    },
    {
      "epoch": 0.02642833117101533,
      "grad_norm": 2.555677652359009,
      "learning_rate": 4.986809860170103e-05,
      "loss": 0.0164,
      "step": 550
    },
    {
      "epoch": 0.02883090673201672,
      "grad_norm": 1.0062837600708008,
      "learning_rate": 4.985608572389602e-05,
      "loss": 0.0227,
      "step": 600
    },
    {
      "epoch": 0.031233482293018117,
      "grad_norm": 5.012147903442383,
      "learning_rate": 4.984407284609101e-05,
      "loss": 0.0191,
      "step": 650
    },
    {
      "epoch": 0.03363605785401951,
      "grad_norm": 2.7845020294189453,
      "learning_rate": 4.9832059968286006e-05,
      "loss": 0.0197,
      "step": 700
    },
    {
      "epoch": 0.0360386334150209,
      "grad_norm": 1.021740436553955,
      "learning_rate": 4.9820047090481e-05,
      "loss": 0.0174,
      "step": 750
    },
    {
      "epoch": 0.038441208976022295,
      "grad_norm": 2.853013038635254,
      "learning_rate": 4.980803421267599e-05,
      "loss": 0.0123,
      "step": 800
    },
    {
      "epoch": 0.04084378453702369,
      "grad_norm": 2.1503548622131348,
      "learning_rate": 4.9796021334870986e-05,
      "loss": 0.0167,
      "step": 850
    },
    {
      "epoch": 0.043246360098025086,
      "grad_norm": 1.6684565544128418,
      "learning_rate": 4.9784008457065976e-05,
      "loss": 0.0174,
      "step": 900
    },
    {
      "epoch": 0.045648935659026474,
      "grad_norm": 1.0092157125473022,
      "learning_rate": 4.9771995579260974e-05,
      "loss": 0.016,
      "step": 950
    },
    {
      "epoch": 0.04805151122002787,
      "grad_norm": 1.232095718383789,
      "learning_rate": 4.9759982701455965e-05,
      "loss": 0.0197,
      "step": 1000
    },
    {
      "epoch": 0.050454086781029264,
      "grad_norm": 1.941278100013733,
      "learning_rate": 4.9747969823650956e-05,
      "loss": 0.0168,
      "step": 1050
    },
    {
      "epoch": 0.05285666234203066,
      "grad_norm": 3.874238967895508,
      "learning_rate": 4.973595694584595e-05,
      "loss": 0.016,
      "step": 1100
    },
    {
      "epoch": 0.05525923790303205,
      "grad_norm": 2.4047505855560303,
      "learning_rate": 4.972394406804094e-05,
      "loss": 0.0174,
      "step": 1150
    },
    {
      "epoch": 0.05766181346403344,
      "grad_norm": 4.466421127319336,
      "learning_rate": 4.9711931190235935e-05,
      "loss": 0.0176,
      "step": 1200
    },
    {
      "epoch": 0.06006438902503484,
      "grad_norm": 2.1069514751434326,
      "learning_rate": 4.9699918312430926e-05,
      "loss": 0.0136,
      "step": 1250
    },
    {
      "epoch": 0.06246696458603623,
      "grad_norm": 1.1002517938613892,
      "learning_rate": 4.968790543462592e-05,
      "loss": 0.0124,
      "step": 1300
    },
    {
      "epoch": 0.06486954014703762,
      "grad_norm": 4.937185287475586,
      "learning_rate": 4.9675892556820914e-05,
      "loss": 0.0135,
      "step": 1350
    },
    {
      "epoch": 0.06727211570803902,
      "grad_norm": 1.193574070930481,
      "learning_rate": 4.9663879679015905e-05,
      "loss": 0.0127,
      "step": 1400
    },
    {
      "epoch": 0.06967469126904041,
      "grad_norm": 1.655759334564209,
      "learning_rate": 4.96518668012109e-05,
      "loss": 0.0156,
      "step": 1450
    },
    {
      "epoch": 0.0720772668300418,
      "grad_norm": 4.090753555297852,
      "learning_rate": 4.9639853923405893e-05,
      "loss": 0.01,
      "step": 1500
    },
    {
      "epoch": 0.0744798423910432,
      "grad_norm": 1.3033610582351685,
      "learning_rate": 4.9627841045600884e-05,
      "loss": 0.0174,
      "step": 1550
    },
    {
      "epoch": 0.07688241795204459,
      "grad_norm": 2.275681495666504,
      "learning_rate": 4.961582816779588e-05,
      "loss": 0.0133,
      "step": 1600
    },
    {
      "epoch": 0.07928499351304598,
      "grad_norm": 3.1619656085968018,
      "learning_rate": 4.960381528999087e-05,
      "loss": 0.0133,
      "step": 1650
    },
    {
      "epoch": 0.08168756907404738,
      "grad_norm": 1.3176674842834473,
      "learning_rate": 4.959180241218587e-05,
      "loss": 0.0113,
      "step": 1700
    },
    {
      "epoch": 0.08409014463504877,
      "grad_norm": 3.292354106903076,
      "learning_rate": 4.957978953438086e-05,
      "loss": 0.0123,
      "step": 1750
    },
    {
      "epoch": 0.08649272019605017,
      "grad_norm": 2.5628626346588135,
      "learning_rate": 4.956777665657585e-05,
      "loss": 0.0145,
      "step": 1800
    },
    {
      "epoch": 0.08889529575705156,
      "grad_norm": 2.2514307498931885,
      "learning_rate": 4.955576377877085e-05,
      "loss": 0.0115,
      "step": 1850
    },
    {
      "epoch": 0.09129787131805295,
      "grad_norm": 2.384793758392334,
      "learning_rate": 4.9543750900965834e-05,
      "loss": 0.0108,
      "step": 1900
    },
    {
      "epoch": 0.09370044687905435,
      "grad_norm": 1.7269525527954102,
      "learning_rate": 4.953173802316083e-05,
      "loss": 0.0082,
      "step": 1950
    },
    {
      "epoch": 0.09610302244005574,
      "grad_norm": 0.5155779719352722,
      "learning_rate": 4.951972514535582e-05,
      "loss": 0.0109,
      "step": 2000
    },
    {
      "epoch": 0.09850559800105713,
      "grad_norm": 2.3599705696105957,
      "learning_rate": 4.950771226755081e-05,
      "loss": 0.0108,
      "step": 2050
    },
    {
      "epoch": 0.10090817356205853,
      "grad_norm": 0.725629448890686,
      "learning_rate": 4.949569938974581e-05,
      "loss": 0.0098,
      "step": 2100
    },
    {
      "epoch": 0.10331074912305992,
      "grad_norm": 2.286933422088623,
      "learning_rate": 4.94836865119408e-05,
      "loss": 0.0117,
      "step": 2150
    },
    {
      "epoch": 0.10571332468406132,
      "grad_norm": 0.7589529156684875,
      "learning_rate": 4.94716736341358e-05,
      "loss": 0.0094,
      "step": 2200
    },
    {
      "epoch": 0.10811590024506271,
      "grad_norm": 2.178612232208252,
      "learning_rate": 4.945966075633079e-05,
      "loss": 0.0104,
      "step": 2250
    },
    {
      "epoch": 0.1105184758060641,
      "grad_norm": 1.7792679071426392,
      "learning_rate": 4.944764787852578e-05,
      "loss": 0.0092,
      "step": 2300
    },
    {
      "epoch": 0.1129210513670655,
      "grad_norm": 1.0822863578796387,
      "learning_rate": 4.943563500072078e-05,
      "loss": 0.0125,
      "step": 2350
    },
    {
      "epoch": 0.11532362692806689,
      "grad_norm": 1.3987854719161987,
      "learning_rate": 4.942362212291577e-05,
      "loss": 0.0095,
      "step": 2400
    },
    {
      "epoch": 0.11772620248906829,
      "grad_norm": 3.6113998889923096,
      "learning_rate": 4.941160924511076e-05,
      "loss": 0.0084,
      "step": 2450
    },
    {
      "epoch": 0.12012877805006968,
      "grad_norm": 0.7678483724594116,
      "learning_rate": 4.939959636730576e-05,
      "loss": 0.0118,
      "step": 2500
    },
    {
      "epoch": 0.12253135361107106,
      "grad_norm": 2.528989315032959,
      "learning_rate": 4.938758348950075e-05,
      "loss": 0.0082,
      "step": 2550
    },
    {
      "epoch": 0.12493392917207247,
      "grad_norm": 1.3806185722351074,
      "learning_rate": 4.9375570611695746e-05,
      "loss": 0.0085,
      "step": 2600
    },
    {
      "epoch": 0.12733650473307387,
      "grad_norm": 0.7406447529792786,
      "learning_rate": 4.936355773389073e-05,
      "loss": 0.008,
      "step": 2650
    },
    {
      "epoch": 0.12973908029407524,
      "grad_norm": 0.3724974989891052,
      "learning_rate": 4.935154485608572e-05,
      "loss": 0.0093,
      "step": 2700
    },
    {
      "epoch": 0.13214165585507665,
      "grad_norm": 0.6449531316757202,
      "learning_rate": 4.933953197828072e-05,
      "loss": 0.0104,
      "step": 2750
    },
    {
      "epoch": 0.13454423141607805,
      "grad_norm": 1.2498270273208618,
      "learning_rate": 4.932751910047571e-05,
      "loss": 0.0071,
      "step": 2800
    },
    {
      "epoch": 0.13694680697707942,
      "grad_norm": 3.0012714862823486,
      "learning_rate": 4.931550622267071e-05,
      "loss": 0.0092,
      "step": 2850
    },
    {
      "epoch": 0.13934938253808082,
      "grad_norm": 2.205944776535034,
      "learning_rate": 4.93034933448657e-05,
      "loss": 0.008,
      "step": 2900
    },
    {
      "epoch": 0.14175195809908223,
      "grad_norm": 3.701625347137451,
      "learning_rate": 4.929148046706069e-05,
      "loss": 0.008,
      "step": 2950
    },
    {
      "epoch": 0.1441545336600836,
      "grad_norm": 1.0817807912826538,
      "learning_rate": 4.9279467589255686e-05,
      "loss": 0.0069,
      "step": 3000
    },
    {
      "epoch": 0.146557109221085,
      "grad_norm": 0.6617302894592285,
      "learning_rate": 4.926745471145068e-05,
      "loss": 0.0087,
      "step": 3050
    },
    {
      "epoch": 0.1489596847820864,
      "grad_norm": 2.8477492332458496,
      "learning_rate": 4.9255441833645674e-05,
      "loss": 0.0083,
      "step": 3100
    },
    {
      "epoch": 0.15136226034308778,
      "grad_norm": 2.812577962875366,
      "learning_rate": 4.9243428955840665e-05,
      "loss": 0.006,
      "step": 3150
    },
    {
      "epoch": 0.15376483590408918,
      "grad_norm": 2.5595853328704834,
      "learning_rate": 4.9231416078035656e-05,
      "loss": 0.0069,
      "step": 3200
    },
    {
      "epoch": 0.15616741146509058,
      "grad_norm": 3.8520405292510986,
      "learning_rate": 4.9219403200230654e-05,
      "loss": 0.008,
      "step": 3250
    },
    {
      "epoch": 0.15856998702609196,
      "grad_norm": 4.4749345779418945,
      "learning_rate": 4.9207390322425645e-05,
      "loss": 0.0078,
      "step": 3300
    },
    {
      "epoch": 0.16097256258709336,
      "grad_norm": 0.622660756111145,
      "learning_rate": 4.9195377444620635e-05,
      "loss": 0.0084,
      "step": 3350
    },
    {
      "epoch": 0.16337513814809476,
      "grad_norm": 1.48850417137146,
      "learning_rate": 4.9183364566815626e-05,
      "loss": 0.0089,
      "step": 3400
    },
    {
      "epoch": 0.16577771370909616,
      "grad_norm": 3.1630680561065674,
      "learning_rate": 4.917135168901062e-05,
      "loss": 0.0061,
      "step": 3450
    },
    {
      "epoch": 0.16818028927009754,
      "grad_norm": 0.7224794030189514,
      "learning_rate": 4.9159338811205615e-05,
      "loss": 0.0058,
      "step": 3500
    },
    {
      "epoch": 0.17058286483109894,
      "grad_norm": 3.212285280227661,
      "learning_rate": 4.9147325933400605e-05,
      "loss": 0.0074,
      "step": 3550
    },
    {
      "epoch": 0.17298544039210034,
      "grad_norm": 0.7348601222038269,
      "learning_rate": 4.91353130555956e-05,
      "loss": 0.0077,
      "step": 3600
    },
    {
      "epoch": 0.17538801595310172,
      "grad_norm": 2.40085768699646,
      "learning_rate": 4.9123300177790594e-05,
      "loss": 0.0079,
      "step": 3650
    },
    {
      "epoch": 0.17779059151410312,
      "grad_norm": 0.47765877842903137,
      "learning_rate": 4.9111287299985585e-05,
      "loss": 0.0057,
      "step": 3700
    },
    {
      "epoch": 0.18019316707510452,
      "grad_norm": 1.040637731552124,
      "learning_rate": 4.909927442218058e-05,
      "loss": 0.0063,
      "step": 3750
    },
    {
      "epoch": 0.1825957426361059,
      "grad_norm": 0.4997390806674957,
      "learning_rate": 4.908726154437557e-05,
      "loss": 0.0056,
      "step": 3800
    },
    {
      "epoch": 0.1849983181971073,
      "grad_norm": 1.5473697185516357,
      "learning_rate": 4.9075248666570564e-05,
      "loss": 0.006,
      "step": 3850
    },
    {
      "epoch": 0.1874008937581087,
      "grad_norm": 0.2133985012769699,
      "learning_rate": 4.906323578876556e-05,
      "loss": 0.0049,
      "step": 3900
    },
    {
      "epoch": 0.18980346931911007,
      "grad_norm": 0.6842890381813049,
      "learning_rate": 4.905122291096055e-05,
      "loss": 0.0047,
      "step": 3950
    },
    {
      "epoch": 0.19220604488011148,
      "grad_norm": 0.4622081518173218,
      "learning_rate": 4.903921003315555e-05,
      "loss": 0.0057,
      "step": 4000
    },
    {
      "epoch": 0.19460862044111288,
      "grad_norm": 0.571236252784729,
      "learning_rate": 4.902719715535054e-05,
      "loss": 0.0057,
      "step": 4050
    },
    {
      "epoch": 0.19701119600211425,
      "grad_norm": 0.3720848858356476,
      "learning_rate": 4.901518427754553e-05,
      "loss": 0.0052,
      "step": 4100
    },
    {
      "epoch": 0.19941377156311565,
      "grad_norm": 0.8233627080917358,
      "learning_rate": 4.900317139974052e-05,
      "loss": 0.0049,
      "step": 4150
    },
    {
      "epoch": 0.20181634712411706,
      "grad_norm": 1.2623599767684937,
      "learning_rate": 4.899115852193551e-05,
      "loss": 0.0042,
      "step": 4200
    },
    {
      "epoch": 0.20421892268511846,
      "grad_norm": 0.8537761569023132,
      "learning_rate": 4.897914564413051e-05,
      "loss": 0.0059,
      "step": 4250
    },
    {
      "epoch": 0.20662149824611983,
      "grad_norm": 1.2179261445999146,
      "learning_rate": 4.89671327663255e-05,
      "loss": 0.0063,
      "step": 4300
    },
    {
      "epoch": 0.20902407380712124,
      "grad_norm": 1.0948755741119385,
      "learning_rate": 4.895511988852049e-05,
      "loss": 0.0036,
      "step": 4350
    },
    {
      "epoch": 0.21142664936812264,
      "grad_norm": 0.6709845066070557,
      "learning_rate": 4.894310701071549e-05,
      "loss": 0.0037,
      "step": 4400
    },
    {
      "epoch": 0.213829224929124,
      "grad_norm": 1.072180986404419,
      "learning_rate": 4.893109413291048e-05,
      "loss": 0.0039,
      "step": 4450
    },
    {
      "epoch": 0.21623180049012541,
      "grad_norm": 0.4446156919002533,
      "learning_rate": 4.891908125510548e-05,
      "loss": 0.0036,
      "step": 4500
    },
    {
      "epoch": 0.21863437605112682,
      "grad_norm": 0.34354302287101746,
      "learning_rate": 4.890706837730047e-05,
      "loss": 0.0053,
      "step": 4550
    },
    {
      "epoch": 0.2210369516121282,
      "grad_norm": 1.032797932624817,
      "learning_rate": 4.889505549949546e-05,
      "loss": 0.0048,
      "step": 4600
    },
    {
      "epoch": 0.2234395271731296,
      "grad_norm": 1.2775157690048218,
      "learning_rate": 4.888304262169046e-05,
      "loss": 0.0041,
      "step": 4650
    },
    {
      "epoch": 0.225842102734131,
      "grad_norm": 2.3511147499084473,
      "learning_rate": 4.887102974388545e-05,
      "loss": 0.0059,
      "step": 4700
    },
    {
      "epoch": 0.22824467829513237,
      "grad_norm": 1.3098760843276978,
      "learning_rate": 4.885901686608044e-05,
      "loss": 0.0041,
      "step": 4750
    },
    {
      "epoch": 0.23064725385613377,
      "grad_norm": 0.8418120741844177,
      "learning_rate": 4.884700398827544e-05,
      "loss": 0.0051,
      "step": 4800
    },
    {
      "epoch": 0.23304982941713517,
      "grad_norm": 0.5443441271781921,
      "learning_rate": 4.883499111047043e-05,
      "loss": 0.0037,
      "step": 4850
    },
    {
      "epoch": 0.23545240497813658,
      "grad_norm": 0.490400493144989,
      "learning_rate": 4.882297823266542e-05,
      "loss": 0.0039,
      "step": 4900
    },
    {
      "epoch": 0.23785498053913795,
      "grad_norm": 1.8660248517990112,
      "learning_rate": 4.881096535486041e-05,
      "loss": 0.0044,
      "step": 4950
    },
    {
      "epoch": 0.24025755610013935,
      "grad_norm": 0.4368196427822113,
      "learning_rate": 4.879895247705541e-05,
      "loss": 0.0057,
      "step": 5000
    },
    {
      "epoch": 0.24266013166114075,
      "grad_norm": 0.6510025262832642,
      "learning_rate": 4.87869395992504e-05,
      "loss": 0.0041,
      "step": 5050
    },
    {
      "epoch": 0.24506270722214213,
      "grad_norm": 0.5581501722335815,
      "learning_rate": 4.877492672144539e-05,
      "loss": 0.0054,
      "step": 5100
    },
    {
      "epoch": 0.24746528278314353,
      "grad_norm": 0.4542526602745056,
      "learning_rate": 4.8762913843640386e-05,
      "loss": 0.0056,
      "step": 5150
    },
    {
      "epoch": 0.24986785834414493,
      "grad_norm": 1.0200222730636597,
      "learning_rate": 4.875090096583538e-05,
      "loss": 0.0038,
      "step": 5200
    },
    {
      "epoch": 0.2522704339051463,
      "grad_norm": 0.752280056476593,
      "learning_rate": 4.873888808803037e-05,
      "loss": 0.0036,
      "step": 5250
    },
    {
      "epoch": 0.25467300946614774,
      "grad_norm": 2.1212661266326904,
      "learning_rate": 4.8726875210225366e-05,
      "loss": 0.0041,
      "step": 5300
    },
    {
      "epoch": 0.2570755850271491,
      "grad_norm": 0.3203541934490204,
      "learning_rate": 4.8714862332420356e-05,
      "loss": 0.0041,
      "step": 5350
    },
    {
      "epoch": 0.2594781605881505,
      "grad_norm": 0.6307310461997986,
      "learning_rate": 4.8702849454615354e-05,
      "loss": 0.0044,
      "step": 5400
    },
    {
      "epoch": 0.2618807361491519,
      "grad_norm": 1.670941948890686,
      "learning_rate": 4.8690836576810345e-05,
      "loss": 0.0036,
      "step": 5450
    },
    {
      "epoch": 0.2642833117101533,
      "grad_norm": 0.5347387790679932,
      "learning_rate": 4.8678823699005336e-05,
      "loss": 0.0032,
      "step": 5500
    },
    {
      "epoch": 0.26668588727115466,
      "grad_norm": 1.5894818305969238,
      "learning_rate": 4.866681082120033e-05,
      "loss": 0.0037,
      "step": 5550
    },
    {
      "epoch": 0.2690884628321561,
      "grad_norm": 1.1118308305740356,
      "learning_rate": 4.865479794339532e-05,
      "loss": 0.0032,
      "step": 5600
    },
    {
      "epoch": 0.27149103839315747,
      "grad_norm": 0.8748323917388916,
      "learning_rate": 4.8642785065590315e-05,
      "loss": 0.0047,
      "step": 5650
    },
    {
      "epoch": 0.27389361395415884,
      "grad_norm": 1.6549639701843262,
      "learning_rate": 4.8630772187785306e-05,
      "loss": 0.0033,
      "step": 5700
    },
    {
      "epoch": 0.2762961895151603,
      "grad_norm": 0.8495310544967651,
      "learning_rate": 4.8618759309980297e-05,
      "loss": 0.0029,
      "step": 5750
    },
    {
      "epoch": 0.27869876507616165,
      "grad_norm": 0.6467618346214294,
      "learning_rate": 4.8606746432175294e-05,
      "loss": 0.0022,
      "step": 5800
    },
    {
      "epoch": 0.281101340637163,
      "grad_norm": 1.3068848848342896,
      "learning_rate": 4.8594733554370285e-05,
      "loss": 0.0029,
      "step": 5850
    },
    {
      "epoch": 0.28350391619816445,
      "grad_norm": 0.7159707546234131,
      "learning_rate": 4.858272067656528e-05,
      "loss": 0.0034,
      "step": 5900
    },
    {
      "epoch": 0.2859064917591658,
      "grad_norm": 1.0186398029327393,
      "learning_rate": 4.8570707798760273e-05,
      "loss": 0.0029,
      "step": 5950
    },
    {
      "epoch": 0.2883090673201672,
      "grad_norm": 1.7167072296142578,
      "learning_rate": 4.8558694920955264e-05,
      "loss": 0.0042,
      "step": 6000
    },
    {
      "epoch": 0.29071164288116863,
      "grad_norm": 1.850773811340332,
      "learning_rate": 4.854668204315026e-05,
      "loss": 0.0025,
      "step": 6050
    },
    {
      "epoch": 0.29311421844217,
      "grad_norm": 0.6071839332580566,
      "learning_rate": 4.853466916534525e-05,
      "loss": 0.0027,
      "step": 6100
    },
    {
      "epoch": 0.2955167940031714,
      "grad_norm": 0.328778475522995,
      "learning_rate": 4.8522656287540244e-05,
      "loss": 0.0029,
      "step": 6150
    },
    {
      "epoch": 0.2979193695641728,
      "grad_norm": 0.3195604979991913,
      "learning_rate": 4.851064340973524e-05,
      "loss": 0.0024,
      "step": 6200
    },
    {
      "epoch": 0.3003219451251742,
      "grad_norm": 0.5731003880500793,
      "learning_rate": 4.849863053193023e-05,
      "loss": 0.0034,
      "step": 6250
    },
    {
      "epoch": 0.30272452068617556,
      "grad_norm": 1.2235344648361206,
      "learning_rate": 4.848661765412523e-05,
      "loss": 0.003,
      "step": 6300
    },
    {
      "epoch": 0.305127096247177,
      "grad_norm": 0.7067216634750366,
      "learning_rate": 4.8474604776320214e-05,
      "loss": 0.0026,
      "step": 6350
    },
    {
      "epoch": 0.30752967180817836,
      "grad_norm": 0.8612620830535889,
      "learning_rate": 4.846259189851521e-05,
      "loss": 0.0031,
      "step": 6400
    },
    {
      "epoch": 0.30993224736917974,
      "grad_norm": 0.8397321105003357,
      "learning_rate": 4.84505790207102e-05,
      "loss": 0.0026,
      "step": 6450
    },
    {
      "epoch": 0.31233482293018117,
      "grad_norm": 1.1973375082015991,
      "learning_rate": 4.843856614290519e-05,
      "loss": 0.003,
      "step": 6500
    },
    {
      "epoch": 0.31473739849118254,
      "grad_norm": 0.2564820349216461,
      "learning_rate": 4.842655326510019e-05,
      "loss": 0.0025,
      "step": 6550
    },
    {
      "epoch": 0.3171399740521839,
      "grad_norm": 0.9526909589767456,
      "learning_rate": 4.841454038729518e-05,
      "loss": 0.0027,
      "step": 6600
    },
    {
      "epoch": 0.31954254961318534,
      "grad_norm": 0.4399867057800293,
      "learning_rate": 4.840252750949017e-05,
      "loss": 0.0024,
      "step": 6650
    },
    {
      "epoch": 0.3219451251741867,
      "grad_norm": 0.3938835561275482,
      "learning_rate": 4.839051463168517e-05,
      "loss": 0.0029,
      "step": 6700
    },
    {
      "epoch": 0.32434770073518815,
      "grad_norm": 0.30992501974105835,
      "learning_rate": 4.837850175388016e-05,
      "loss": 0.0029,
      "step": 6750
    },
    {
      "epoch": 0.3267502762961895,
      "grad_norm": 0.4631669521331787,
      "learning_rate": 4.836648887607516e-05,
      "loss": 0.0022,
      "step": 6800
    },
    {
      "epoch": 0.3291528518571909,
      "grad_norm": 0.5240834355354309,
      "learning_rate": 4.835447599827015e-05,
      "loss": 0.003,
      "step": 6850
    },
    {
      "epoch": 0.33155542741819233,
      "grad_norm": 0.538101315498352,
      "learning_rate": 4.834246312046514e-05,
      "loss": 0.0022,
      "step": 6900
    },
    {
      "epoch": 0.3339580029791937,
      "grad_norm": 0.40361467003822327,
      "learning_rate": 4.833045024266014e-05,
      "loss": 0.0016,
      "step": 6950
    },
    {
      "epoch": 0.3363605785401951,
      "grad_norm": 1.3281399011611938,
      "learning_rate": 4.831843736485513e-05,
      "loss": 0.003,
      "step": 7000
    },
    {
      "epoch": 0.3387631541011965,
      "grad_norm": 0.5347200036048889,
      "learning_rate": 4.8306424487050126e-05,
      "loss": 0.0027,
      "step": 7050
    },
    {
      "epoch": 0.3411657296621979,
      "grad_norm": 0.5260990858078003,
      "learning_rate": 4.829441160924511e-05,
      "loss": 0.0021,
      "step": 7100
    },
    {
      "epoch": 0.34356830522319926,
      "grad_norm": 0.8495813012123108,
      "learning_rate": 4.82823987314401e-05,
      "loss": 0.0022,
      "step": 7150
    },
    {
      "epoch": 0.3459708807842007,
      "grad_norm": 0.36441248655319214,
      "learning_rate": 4.82703858536351e-05,
      "loss": 0.0021,
      "step": 7200
    },
    {
      "epoch": 0.34837345634520206,
      "grad_norm": 0.2822631299495697,
      "learning_rate": 4.825837297583009e-05,
      "loss": 0.0016,
      "step": 7250
    },
    {
      "epoch": 0.35077603190620343,
      "grad_norm": 0.863128662109375,
      "learning_rate": 4.824636009802509e-05,
      "loss": 0.0022,
      "step": 7300
    },
    {
      "epoch": 0.35317860746720486,
      "grad_norm": 1.1693450212478638,
      "learning_rate": 4.823434722022008e-05,
      "loss": 0.0032,
      "step": 7350
    },
    {
      "epoch": 0.35558118302820624,
      "grad_norm": 0.9746198654174805,
      "learning_rate": 4.822233434241507e-05,
      "loss": 0.0018,
      "step": 7400
    },
    {
      "epoch": 0.3579837585892076,
      "grad_norm": 0.5209798216819763,
      "learning_rate": 4.8210321464610066e-05,
      "loss": 0.0017,
      "step": 7450
    },
    {
      "epoch": 0.36038633415020904,
      "grad_norm": 1.5360050201416016,
      "learning_rate": 4.819830858680506e-05,
      "loss": 0.002,
      "step": 7500
    },
    {
      "epoch": 0.3627889097112104,
      "grad_norm": 0.30533674359321594,
      "learning_rate": 4.8186295709000054e-05,
      "loss": 0.0017,
      "step": 7550
    },
    {
      "epoch": 0.3651914852722118,
      "grad_norm": 0.8185293078422546,
      "learning_rate": 4.8174282831195045e-05,
      "loss": 0.0015,
      "step": 7600
    },
    {
      "epoch": 0.3675940608332132,
      "grad_norm": 0.6698569655418396,
      "learning_rate": 4.8162269953390036e-05,
      "loss": 0.0029,
      "step": 7650
    },
    {
      "epoch": 0.3699966363942146,
      "grad_norm": 0.8953649401664734,
      "learning_rate": 4.8150257075585034e-05,
      "loss": 0.0024,
      "step": 7700
    },
    {
      "epoch": 0.37239921195521597,
      "grad_norm": 0.7294184565544128,
      "learning_rate": 4.8138244197780024e-05,
      "loss": 0.0016,
      "step": 7750
    },
    {
      "epoch": 0.3748017875162174,
      "grad_norm": 0.6525855660438538,
      "learning_rate": 4.8126231319975015e-05,
      "loss": 0.002,
      "step": 7800
    },
    {
      "epoch": 0.3772043630772188,
      "grad_norm": 0.7692852020263672,
      "learning_rate": 4.8114218442170006e-05,
      "loss": 0.0023,
      "step": 7850
    },
    {
      "epoch": 0.37960693863822015,
      "grad_norm": 0.5399836301803589,
      "learning_rate": 4.8102205564365e-05,
      "loss": 0.0017,
      "step": 7900
    },
    {
      "epoch": 0.3820095141992216,
      "grad_norm": 0.8558169603347778,
      "learning_rate": 4.8090192686559995e-05,
      "loss": 0.002,
      "step": 7950
    },
    {
      "epoch": 0.38441208976022295,
      "grad_norm": 0.6112403869628906,
      "learning_rate": 4.8078179808754985e-05,
      "loss": 0.0033,
      "step": 8000
    },
    {
      "epoch": 0.3868146653212243,
      "grad_norm": 0.15063396096229553,
      "learning_rate": 4.8066166930949976e-05,
      "loss": 0.0016,
      "step": 8050
    },
    {
      "epoch": 0.38921724088222576,
      "grad_norm": 0.3506585359573364,
      "learning_rate": 4.8054154053144974e-05,
      "loss": 0.0013,
      "step": 8100
    },
    {
      "epoch": 0.39161981644322713,
      "grad_norm": 0.15903370082378387,
      "learning_rate": 4.8042141175339965e-05,
      "loss": 0.0013,
      "step": 8150
    },
    {
      "epoch": 0.3940223920042285,
      "grad_norm": 0.48620983958244324,
      "learning_rate": 4.803012829753496e-05,
      "loss": 0.0015,
      "step": 8200
    },
    {
      "epoch": 0.39642496756522994,
      "grad_norm": 0.525894820690155,
      "learning_rate": 4.801811541972995e-05,
      "loss": 0.0014,
      "step": 8250
    },
    {
      "epoch": 0.3988275431262313,
      "grad_norm": 0.4839423596858978,
      "learning_rate": 4.8006102541924944e-05,
      "loss": 0.0022,
      "step": 8300
    },
    {
      "epoch": 0.40123011868723274,
      "grad_norm": 0.22425006330013275,
      "learning_rate": 4.799408966411994e-05,
      "loss": 0.0016,
      "step": 8350
    },
    {
      "epoch": 0.4036326942482341,
      "grad_norm": 0.6325817704200745,
      "learning_rate": 4.798207678631493e-05,
      "loss": 0.0016,
      "step": 8400
    },
    {
      "epoch": 0.4060352698092355,
      "grad_norm": 0.27144181728363037,
      "learning_rate": 4.797006390850993e-05,
      "loss": 0.001,
      "step": 8450
    },
    {
      "epoch": 0.4084378453702369,
      "grad_norm": 0.12167265266180038,
      "learning_rate": 4.795805103070492e-05,
      "loss": 0.0014,
      "step": 8500
    },
    {
      "epoch": 0.4108404209312383,
      "grad_norm": 0.174238920211792,
      "learning_rate": 4.794603815289991e-05,
      "loss": 0.0012,
      "step": 8550
    },
    {
      "epoch": 0.41324299649223967,
      "grad_norm": 0.5414829254150391,
      "learning_rate": 4.79340252750949e-05,
      "loss": 0.0017,
      "step": 8600
    },
    {
      "epoch": 0.4156455720532411,
      "grad_norm": 0.5067077279090881,
      "learning_rate": 4.792201239728989e-05,
      "loss": 0.0022,
      "step": 8650
    },
    {
      "epoch": 0.41804814761424247,
      "grad_norm": 0.3894350826740265,
      "learning_rate": 4.790999951948489e-05,
      "loss": 0.0016,
      "step": 8700
    },
    {
      "epoch": 0.42045072317524385,
      "grad_norm": 1.0463272333145142,
      "learning_rate": 4.789798664167988e-05,
      "loss": 0.0014,
      "step": 8750
    },
    {
      "epoch": 0.4228532987362453,
      "grad_norm": 0.4065209627151489,
      "learning_rate": 4.788597376387487e-05,
      "loss": 0.0014,
      "step": 8800
    },
    {
      "epoch": 0.42525587429724665,
      "grad_norm": 0.6080430150032043,
      "learning_rate": 4.787396088606987e-05,
      "loss": 0.0013,
      "step": 8850
    },
    {
      "epoch": 0.427658449858248,
      "grad_norm": 0.3935399353504181,
      "learning_rate": 4.786194800826486e-05,
      "loss": 0.001,
      "step": 8900
    },
    {
      "epoch": 0.43006102541924945,
      "grad_norm": 0.42689886689186096,
      "learning_rate": 4.784993513045986e-05,
      "loss": 0.0016,
      "step": 8950
    },
    {
      "epoch": 0.43246360098025083,
      "grad_norm": 0.8148540258407593,
      "learning_rate": 4.783792225265485e-05,
      "loss": 0.0014,
      "step": 9000
    },
    {
      "epoch": 0.4348661765412522,
      "grad_norm": 0.4900786280632019,
      "learning_rate": 4.782590937484984e-05,
      "loss": 0.0012,
      "step": 9050
    },
    {
      "epoch": 0.43726875210225363,
      "grad_norm": 0.19024524092674255,
      "learning_rate": 4.781389649704484e-05,
      "loss": 0.0014,
      "step": 9100
    },
    {
      "epoch": 0.439671327663255,
      "grad_norm": 0.5179347395896912,
      "learning_rate": 4.780188361923983e-05,
      "loss": 0.0012,
      "step": 9150
    },
    {
      "epoch": 0.4420739032242564,
      "grad_norm": 0.7614045739173889,
      "learning_rate": 4.778987074143482e-05,
      "loss": 0.0013,
      "step": 9200
    },
    {
      "epoch": 0.4444764787852578,
      "grad_norm": 0.1180967465043068,
      "learning_rate": 4.777785786362982e-05,
      "loss": 0.0013,
      "step": 9250
    },
    {
      "epoch": 0.4468790543462592,
      "grad_norm": 0.6155666708946228,
      "learning_rate": 4.776584498582481e-05,
      "loss": 0.0013,
      "step": 9300
    },
    {
      "epoch": 0.44928162990726056,
      "grad_norm": 0.1983119547367096,
      "learning_rate": 4.77538321080198e-05,
      "loss": 0.001,
      "step": 9350
    },
    {
      "epoch": 0.451684205468262,
      "grad_norm": 0.4868450462818146,
      "learning_rate": 4.774181923021479e-05,
      "loss": 0.0024,
      "step": 9400
    },
    {
      "epoch": 0.45408678102926336,
      "grad_norm": 1.1665343046188354,
      "learning_rate": 4.772980635240979e-05,
      "loss": 0.0012,
      "step": 9450
    },
    {
      "epoch": 0.45648935659026474,
      "grad_norm": 0.2552391588687897,
      "learning_rate": 4.771779347460478e-05,
      "loss": 0.0021,
      "step": 9500
    },
    {
      "epoch": 0.45889193215126617,
      "grad_norm": 0.14410260319709778,
      "learning_rate": 4.770578059679977e-05,
      "loss": 0.0011,
      "step": 9550
    },
    {
      "epoch": 0.46129450771226754,
      "grad_norm": 0.7896209955215454,
      "learning_rate": 4.7693767718994766e-05,
      "loss": 0.002,
      "step": 9600
    },
    {
      "epoch": 0.4636970832732689,
      "grad_norm": 0.5913751721382141,
      "learning_rate": 4.768175484118976e-05,
      "loss": 0.0014,
      "step": 9650
    },
    {
      "epoch": 0.46609965883427035,
      "grad_norm": 0.4286574423313141,
      "learning_rate": 4.766974196338475e-05,
      "loss": 0.001,
      "step": 9700
    },
    {
      "epoch": 0.4685022343952717,
      "grad_norm": 0.6623501181602478,
      "learning_rate": 4.7657729085579746e-05,
      "loss": 0.001,
      "step": 9750
    },
    {
      "epoch": 0.47090480995627315,
      "grad_norm": 0.213047057390213,
      "learning_rate": 4.7645716207774736e-05,
      "loss": 0.0012,
      "step": 9800
    },
    {
      "epoch": 0.4733073855172745,
      "grad_norm": 0.2503214478492737,
      "learning_rate": 4.7633703329969734e-05,
      "loss": 0.0011,
      "step": 9850
    },
    {
      "epoch": 0.4757099610782759,
      "grad_norm": 0.6675728559494019,
      "learning_rate": 4.7621690452164725e-05,
      "loss": 0.001,
      "step": 9900
    },
    {
      "epoch": 0.47811253663927733,
      "grad_norm": 0.27957069873809814,
      "learning_rate": 4.7609677574359716e-05,
      "loss": 0.0013,
      "step": 9950
    },
    {
      "epoch": 0.4805151122002787,
      "grad_norm": 0.584372878074646,
      "learning_rate": 4.759766469655471e-05,
      "loss": 0.001,
      "step": 10000
    },
    {
      "epoch": 0.4829176877612801,
      "grad_norm": 0.9150265455245972,
      "learning_rate": 4.7585651818749704e-05,
      "loss": 0.0011,
      "step": 10050
    },
    {
      "epoch": 0.4853202633222815,
      "grad_norm": 0.39119142293930054,
      "learning_rate": 4.7573638940944695e-05,
      "loss": 0.0021,
      "step": 10100
    },
    {
      "epoch": 0.4877228388832829,
      "grad_norm": 0.1823011338710785,
      "learning_rate": 4.7561626063139686e-05,
      "loss": 0.0008,
      "step": 10150
    },
    {
      "epoch": 0.49012541444428426,
      "grad_norm": 0.2545369863510132,
      "learning_rate": 4.7549613185334677e-05,
      "loss": 0.0013,
      "step": 10200
    },
    {
      "epoch": 0.4925279900052857,
      "grad_norm": 0.13731487095355988,
      "learning_rate": 4.7537600307529674e-05,
      "loss": 0.0011,
      "step": 10250
    },
    {
      "epoch": 0.49493056556628706,
      "grad_norm": 0.4101825952529907,
      "learning_rate": 4.7525587429724665e-05,
      "loss": 0.0009,
      "step": 10300
    },
    {
      "epoch": 0.49733314112728844,
      "grad_norm": 0.10346488654613495,
      "learning_rate": 4.751357455191966e-05,
      "loss": 0.0009,
      "step": 10350
    },
    {
      "epoch": 0.49973571668828987,
      "grad_norm": 0.35012272000312805,
      "learning_rate": 4.7501561674114653e-05,
      "loss": 0.0009,
      "step": 10400
    },
    {
      "epoch": 0.5021382922492912,
      "grad_norm": 0.28567174077033997,
      "learning_rate": 4.7489548796309644e-05,
      "loss": 0.0008,
      "step": 10450
    },
    {
      "epoch": 0.5045408678102926,
      "grad_norm": 0.2593405544757843,
      "learning_rate": 4.747753591850464e-05,
      "loss": 0.001,
      "step": 10500
    },
    {
      "epoch": 0.506943443371294,
      "grad_norm": 0.5887481570243835,
      "learning_rate": 4.746552304069963e-05,
      "loss": 0.0012,
      "step": 10550
    },
    {
      "epoch": 0.5093460189322955,
      "grad_norm": 0.2314397394657135,
      "learning_rate": 4.7453510162894623e-05,
      "loss": 0.001,
      "step": 10600
    },
    {
      "epoch": 0.5117485944932968,
      "grad_norm": 0.5902872681617737,
      "learning_rate": 4.744149728508962e-05,
      "loss": 0.0009,
      "step": 10650
    },
    {
      "epoch": 0.5141511700542982,
      "grad_norm": 0.4220179617404938,
      "learning_rate": 4.742948440728461e-05,
      "loss": 0.0009,
      "step": 10700
    },
    {
      "epoch": 0.5165537456152997,
      "grad_norm": 0.48761019110679626,
      "learning_rate": 4.741747152947961e-05,
      "loss": 0.0008,
      "step": 10750
    },
    {
      "epoch": 0.518956321176301,
      "grad_norm": 0.35265809297561646,
      "learning_rate": 4.74054586516746e-05,
      "loss": 0.0007,
      "step": 10800
    },
    {
      "epoch": 0.5213588967373024,
      "grad_norm": 0.3995193839073181,
      "learning_rate": 4.739344577386959e-05,
      "loss": 0.0006,
      "step": 10850
    },
    {
      "epoch": 0.5237614722983038,
      "grad_norm": 0.30746737122535706,
      "learning_rate": 4.738143289606458e-05,
      "loss": 0.0008,
      "step": 10900
    },
    {
      "epoch": 0.5261640478593052,
      "grad_norm": 0.28043466806411743,
      "learning_rate": 4.736942001825957e-05,
      "loss": 0.0011,
      "step": 10950
    },
    {
      "epoch": 0.5285666234203066,
      "grad_norm": 0.873360276222229,
      "learning_rate": 4.735740714045457e-05,
      "loss": 0.0012,
      "step": 11000
    },
    {
      "epoch": 0.530969198981308,
      "grad_norm": 0.2979962229728699,
      "learning_rate": 4.734539426264956e-05,
      "loss": 0.0017,
      "step": 11050
    },
    {
      "epoch": 0.5333717745423093,
      "grad_norm": 0.23389507830142975,
      "learning_rate": 4.733338138484455e-05,
      "loss": 0.0008,
      "step": 11100
    },
    {
      "epoch": 0.5357743501033108,
      "grad_norm": 0.6266472935676575,
      "learning_rate": 4.732136850703955e-05,
      "loss": 0.0012,
      "step": 11150
    },
    {
      "epoch": 0.5381769256643122,
      "grad_norm": 0.17252309620380402,
      "learning_rate": 4.730935562923454e-05,
      "loss": 0.0007,
      "step": 11200
    },
    {
      "epoch": 0.5405795012253135,
      "grad_norm": 0.5784076452255249,
      "learning_rate": 4.729734275142954e-05,
      "loss": 0.0012,
      "step": 11250
    },
    {
      "epoch": 0.5429820767863149,
      "grad_norm": 0.10108569264411926,
      "learning_rate": 4.728532987362453e-05,
      "loss": 0.0007,
      "step": 11300
    },
    {
      "epoch": 0.5453846523473164,
      "grad_norm": 0.30679675936698914,
      "learning_rate": 4.727331699581952e-05,
      "loss": 0.0009,
      "step": 11350
    },
    {
      "epoch": 0.5477872279083177,
      "grad_norm": 0.37021946907043457,
      "learning_rate": 4.726130411801452e-05,
      "loss": 0.0008,
      "step": 11400
    },
    {
      "epoch": 0.5501898034693191,
      "grad_norm": 0.4376571774482727,
      "learning_rate": 4.724929124020951e-05,
      "loss": 0.0006,
      "step": 11450
    },
    {
      "epoch": 0.5525923790303205,
      "grad_norm": 0.6061283946037292,
      "learning_rate": 4.72372783624045e-05,
      "loss": 0.0007,
      "step": 11500
    },
    {
      "epoch": 0.5549949545913219,
      "grad_norm": 0.1600957065820694,
      "learning_rate": 4.722526548459949e-05,
      "loss": 0.0009,
      "step": 11550
    },
    {
      "epoch": 0.5573975301523233,
      "grad_norm": 0.6676353812217712,
      "learning_rate": 4.721325260679448e-05,
      "loss": 0.0008,
      "step": 11600
    },
    {
      "epoch": 0.5598001057133247,
      "grad_norm": 0.15582533180713654,
      "learning_rate": 4.720123972898948e-05,
      "loss": 0.0008,
      "step": 11650
    },
    {
      "epoch": 0.562202681274326,
      "grad_norm": 0.2839638590812683,
      "learning_rate": 4.718922685118447e-05,
      "loss": 0.0015,
      "step": 11700
    },
    {
      "epoch": 0.5646052568353275,
      "grad_norm": 0.53142911195755,
      "learning_rate": 4.717721397337947e-05,
      "loss": 0.0009,
      "step": 11750
    },
    {
      "epoch": 0.5670078323963289,
      "grad_norm": 0.10237332433462143,
      "learning_rate": 4.716520109557446e-05,
      "loss": 0.0006,
      "step": 11800
    },
    {
      "epoch": 0.5694104079573302,
      "grad_norm": 0.19533409178256989,
      "learning_rate": 4.715318821776945e-05,
      "loss": 0.001,
      "step": 11850
    },
    {
      "epoch": 0.5718129835183317,
      "grad_norm": 0.43202894926071167,
      "learning_rate": 4.7141175339964446e-05,
      "loss": 0.0008,
      "step": 11900
    },
    {
      "epoch": 0.5742155590793331,
      "grad_norm": 0.4262826442718506,
      "learning_rate": 4.712916246215944e-05,
      "loss": 0.001,
      "step": 11950
    },
    {
      "epoch": 0.5766181346403344,
      "grad_norm": 0.6485825777053833,
      "learning_rate": 4.711714958435443e-05,
      "loss": 0.0007,
      "step": 12000
    },
    {
      "epoch": 0.5790207102013358,
      "grad_norm": 0.2626805007457733,
      "learning_rate": 4.7105136706549425e-05,
      "loss": 0.0009,
      "step": 12050
    },
    {
      "epoch": 0.5814232857623373,
      "grad_norm": 0.17410828173160553,
      "learning_rate": 4.7093123828744416e-05,
      "loss": 0.0005,
      "step": 12100
    },
    {
      "epoch": 0.5838258613233386,
      "grad_norm": 0.2559817433357239,
      "learning_rate": 4.7081110950939414e-05,
      "loss": 0.0007,
      "step": 12150
    },
    {
      "epoch": 0.58622843688434,
      "grad_norm": 0.5456173419952393,
      "learning_rate": 4.7069098073134404e-05,
      "loss": 0.0007,
      "step": 12200
    },
    {
      "epoch": 0.5886310124453414,
      "grad_norm": 0.41028156876564026,
      "learning_rate": 4.7057085195329395e-05,
      "loss": 0.0013,
      "step": 12250
    },
    {
      "epoch": 0.5910335880063428,
      "grad_norm": 0.1829148381948471,
      "learning_rate": 4.7045072317524386e-05,
      "loss": 0.0014,
      "step": 12300
    },
    {
      "epoch": 0.5934361635673442,
      "grad_norm": 0.6150168776512146,
      "learning_rate": 4.703305943971938e-05,
      "loss": 0.0007,
      "step": 12350
    },
    {
      "epoch": 0.5958387391283456,
      "grad_norm": 0.19091950356960297,
      "learning_rate": 4.7021046561914375e-05,
      "loss": 0.0006,
      "step": 12400
    },
    {
      "epoch": 0.5982413146893469,
      "grad_norm": 0.47362563014030457,
      "learning_rate": 4.7009033684109365e-05,
      "loss": 0.0008,
      "step": 12450
    },
    {
      "epoch": 0.6006438902503484,
      "grad_norm": 0.5363548398017883,
      "learning_rate": 4.6997020806304356e-05,
      "loss": 0.0009,
      "step": 12500
    },
    {
      "epoch": 0.6030464658113498,
      "grad_norm": 0.6264620423316956,
      "learning_rate": 4.6985007928499354e-05,
      "loss": 0.0007,
      "step": 12550
    },
    {
      "epoch": 0.6054490413723511,
      "grad_norm": 0.3643683195114136,
      "learning_rate": 4.6972995050694345e-05,
      "loss": 0.0007,
      "step": 12600
    },
    {
      "epoch": 0.6078516169333525,
      "grad_norm": 0.32921794056892395,
      "learning_rate": 4.696098217288934e-05,
      "loss": 0.0009,
      "step": 12650
    },
    {
      "epoch": 0.610254192494354,
      "grad_norm": 0.5707162022590637,
      "learning_rate": 4.694896929508433e-05,
      "loss": 0.0007,
      "step": 12700
    },
    {
      "epoch": 0.6126567680553553,
      "grad_norm": 0.1990925371646881,
      "learning_rate": 4.6936956417279324e-05,
      "loss": 0.0007,
      "step": 12750
    },
    {
      "epoch": 0.6150593436163567,
      "grad_norm": 0.38244229555130005,
      "learning_rate": 4.692494353947432e-05,
      "loss": 0.0006,
      "step": 12800
    },
    {
      "epoch": 0.6174619191773582,
      "grad_norm": 0.1939760148525238,
      "learning_rate": 4.691293066166931e-05,
      "loss": 0.0008,
      "step": 12850
    },
    {
      "epoch": 0.6198644947383595,
      "grad_norm": 0.6574060320854187,
      "learning_rate": 4.690091778386431e-05,
      "loss": 0.0009,
      "step": 12900
    },
    {
      "epoch": 0.6222670702993609,
      "grad_norm": 0.14556463062763214,
      "learning_rate": 4.68889049060593e-05,
      "loss": 0.0006,
      "step": 12950
    },
    {
      "epoch": 0.6246696458603623,
      "grad_norm": 0.11463288217782974,
      "learning_rate": 4.687689202825429e-05,
      "loss": 0.0006,
      "step": 13000
    },
    {
      "epoch": 0.6270722214213637,
      "grad_norm": 0.08979780972003937,
      "learning_rate": 4.686487915044928e-05,
      "loss": 0.0006,
      "step": 13050
    },
    {
      "epoch": 0.6294747969823651,
      "grad_norm": 0.47137269377708435,
      "learning_rate": 4.685286627264427e-05,
      "loss": 0.0007,
      "step": 13100
    },
    {
      "epoch": 0.6318773725433665,
      "grad_norm": 0.1511927992105484,
      "learning_rate": 4.684085339483927e-05,
      "loss": 0.0005,
      "step": 13150
    },
    {
      "epoch": 0.6342799481043678,
      "grad_norm": 0.6196987628936768,
      "learning_rate": 4.682884051703426e-05,
      "loss": 0.0005,
      "step": 13200
    },
    {
      "epoch": 0.6366825236653693,
      "grad_norm": 0.576296865940094,
      "learning_rate": 4.681682763922925e-05,
      "loss": 0.0007,
      "step": 13250
    },
    {
      "epoch": 0.6390850992263707,
      "grad_norm": 0.21788786351680756,
      "learning_rate": 4.680481476142425e-05,
      "loss": 0.0005,
      "step": 13300
    },
    {
      "epoch": 0.641487674787372,
      "grad_norm": 0.3903684616088867,
      "learning_rate": 4.679280188361924e-05,
      "loss": 0.0007,
      "step": 13350
    },
    {
      "epoch": 0.6438902503483734,
      "grad_norm": 0.5802015066146851,
      "learning_rate": 4.678078900581424e-05,
      "loss": 0.0005,
      "step": 13400
    },
    {
      "epoch": 0.6462928259093749,
      "grad_norm": 0.30761125683784485,
      "learning_rate": 4.676877612800923e-05,
      "loss": 0.0006,
      "step": 13450
    },
    {
      "epoch": 0.6486954014703763,
      "grad_norm": 0.19932259619235992,
      "learning_rate": 4.675676325020422e-05,
      "loss": 0.0005,
      "step": 13500
    },
    {
      "epoch": 0.6510979770313776,
      "grad_norm": 0.32391735911369324,
      "learning_rate": 4.674475037239922e-05,
      "loss": 0.0006,
      "step": 13550
    },
    {
      "epoch": 0.653500552592379,
      "grad_norm": 0.20856009423732758,
      "learning_rate": 4.673273749459421e-05,
      "loss": 0.0005,
      "step": 13600
    },
    {
      "epoch": 0.6559031281533805,
      "grad_norm": 0.1575663983821869,
      "learning_rate": 4.67207246167892e-05,
      "loss": 0.0005,
      "step": 13650
    },
    {
      "epoch": 0.6583057037143818,
      "grad_norm": 0.15541262924671173,
      "learning_rate": 4.67087117389842e-05,
      "loss": 0.0009,
      "step": 13700
    },
    {
      "epoch": 0.6607082792753832,
      "grad_norm": 0.252206414937973,
      "learning_rate": 4.669669886117919e-05,
      "loss": 0.0007,
      "step": 13750
    },
    {
      "epoch": 0.6631108548363847,
      "grad_norm": 0.2140800803899765,
      "learning_rate": 4.668468598337418e-05,
      "loss": 0.0007,
      "step": 13800
    },
    {
      "epoch": 0.665513430397386,
      "grad_norm": 0.06244887411594391,
      "learning_rate": 4.667267310556917e-05,
      "loss": 0.0006,
      "step": 13850
    },
    {
      "epoch": 0.6679160059583874,
      "grad_norm": 0.6257362961769104,
      "learning_rate": 4.666066022776416e-05,
      "loss": 0.0007,
      "step": 13900
    },
    {
      "epoch": 0.6703185815193888,
      "grad_norm": 0.3224324584007263,
      "learning_rate": 4.664864734995916e-05,
      "loss": 0.0009,
      "step": 13950
    },
    {
      "epoch": 0.6727211570803902,
      "grad_norm": 0.409361332654953,
      "learning_rate": 4.663663447215415e-05,
      "loss": 0.0013,
      "step": 14000
    },
    {
      "epoch": 0.6751237326413916,
      "grad_norm": 0.3123898506164551,
      "learning_rate": 4.6624621594349146e-05,
      "loss": 0.0005,
      "step": 14050
    },
    {
      "epoch": 0.677526308202393,
      "grad_norm": 0.08261309564113617,
      "learning_rate": 4.661260871654414e-05,
      "loss": 0.0005,
      "step": 14100
    },
    {
      "epoch": 0.6799288837633943,
      "grad_norm": 0.1544881910085678,
      "learning_rate": 4.660059583873913e-05,
      "loss": 0.0004,
      "step": 14150
    },
    {
      "epoch": 0.6823314593243958,
      "grad_norm": 0.247747540473938,
      "learning_rate": 4.6588582960934126e-05,
      "loss": 0.0006,
      "step": 14200
    },
    {
      "epoch": 0.6847340348853972,
      "grad_norm": 0.24560029804706573,
      "learning_rate": 4.6576570083129116e-05,
      "loss": 0.0005,
      "step": 14250
    },
    {
      "epoch": 0.6871366104463985,
      "grad_norm": 0.16152065992355347,
      "learning_rate": 4.6564557205324114e-05,
      "loss": 0.0005,
      "step": 14300
    },
    {
      "epoch": 0.6895391860073999,
      "grad_norm": 0.23756396770477295,
      "learning_rate": 4.6552544327519105e-05,
      "loss": 0.0005,
      "step": 14350
    },
    {
      "epoch": 0.6919417615684014,
      "grad_norm": 0.5006148815155029,
      "learning_rate": 4.6540531449714096e-05,
      "loss": 0.0005,
      "step": 14400
    },
    {
      "epoch": 0.6943443371294027,
      "grad_norm": 0.139124795794487,
      "learning_rate": 4.652851857190909e-05,
      "loss": 0.0004,
      "step": 14450
    },
    {
      "epoch": 0.6967469126904041,
      "grad_norm": 0.3240383267402649,
      "learning_rate": 4.6516505694104084e-05,
      "loss": 0.0006,
      "step": 14500
    },
    {
      "epoch": 0.6991494882514055,
      "grad_norm": 0.3627566993236542,
      "learning_rate": 4.6504492816299075e-05,
      "loss": 0.0013,
      "step": 14550
    },
    {
      "epoch": 0.7015520638124069,
      "grad_norm": 0.09867150336503983,
      "learning_rate": 4.6492479938494066e-05,
      "loss": 0.0012,
      "step": 14600
    },
    {
      "epoch": 0.7039546393734083,
      "grad_norm": 0.21332186460494995,
      "learning_rate": 4.6480467060689057e-05,
      "loss": 0.0005,
      "step": 14650
    },
    {
      "epoch": 0.7063572149344097,
      "grad_norm": 0.08542759716510773,
      "learning_rate": 4.6468454182884054e-05,
      "loss": 0.0005,
      "step": 14700
    },
    {
      "epoch": 0.708759790495411,
      "grad_norm": 0.3749917149543762,
      "learning_rate": 4.6456441305079045e-05,
      "loss": 0.0005,
      "step": 14750
    },
    {
      "epoch": 0.7111623660564125,
      "grad_norm": 0.22350670397281647,
      "learning_rate": 4.644442842727404e-05,
      "loss": 0.0004,
      "step": 14800
    },
    {
      "epoch": 0.7135649416174139,
      "grad_norm": 0.27516818046569824,
      "learning_rate": 4.643241554946903e-05,
      "loss": 0.0005,
      "step": 14850
    },
    {
      "epoch": 0.7159675171784152,
      "grad_norm": 0.42371708154678345,
      "learning_rate": 4.6420402671664024e-05,
      "loss": 0.0004,
      "step": 14900
    },
    {
      "epoch": 0.7183700927394167,
      "grad_norm": 0.17315952479839325,
      "learning_rate": 4.640838979385902e-05,
      "loss": 0.0019,
      "step": 14950
    },
    {
      "epoch": 0.7207726683004181,
      "grad_norm": 0.16796909272670746,
      "learning_rate": 4.639637691605401e-05,
      "loss": 0.0005,
      "step": 15000
    },
    {
      "epoch": 0.7231752438614194,
      "grad_norm": 0.2549312114715576,
      "learning_rate": 4.6384364038249003e-05,
      "loss": 0.0005,
      "step": 15050
    },
    {
      "epoch": 0.7255778194224208,
      "grad_norm": 0.2706032395362854,
      "learning_rate": 4.6372351160444e-05,
      "loss": 0.0005,
      "step": 15100
    },
    {
      "epoch": 0.7279803949834223,
      "grad_norm": 0.21539588272571564,
      "learning_rate": 4.636033828263899e-05,
      "loss": 0.0007,
      "step": 15150
    },
    {
      "epoch": 0.7303829705444236,
      "grad_norm": 0.2945595383644104,
      "learning_rate": 4.634832540483399e-05,
      "loss": 0.0007,
      "step": 15200
    },
    {
      "epoch": 0.732785546105425,
      "grad_norm": 0.24545596539974213,
      "learning_rate": 4.633631252702898e-05,
      "loss": 0.0006,
      "step": 15250
    },
    {
      "epoch": 0.7351881216664264,
      "grad_norm": 0.22290267050266266,
      "learning_rate": 4.632429964922397e-05,
      "loss": 0.0004,
      "step": 15300
    },
    {
      "epoch": 0.7375906972274278,
      "grad_norm": 0.20458726584911346,
      "learning_rate": 4.631228677141896e-05,
      "loss": 0.0004,
      "step": 15350
    },
    {
      "epoch": 0.7399932727884292,
      "grad_norm": 0.14345088601112366,
      "learning_rate": 4.630027389361395e-05,
      "loss": 0.0005,
      "step": 15400
    },
    {
      "epoch": 0.7423958483494306,
      "grad_norm": 0.05818941816687584,
      "learning_rate": 4.628826101580895e-05,
      "loss": 0.0006,
      "step": 15450
    },
    {
      "epoch": 0.7447984239104319,
      "grad_norm": 0.14560377597808838,
      "learning_rate": 4.627624813800394e-05,
      "loss": 0.0006,
      "step": 15500
    },
    {
      "epoch": 0.7472009994714334,
      "grad_norm": 0.1492796093225479,
      "learning_rate": 4.626423526019893e-05,
      "loss": 0.0004,
      "step": 15550
    },
    {
      "epoch": 0.7496035750324348,
      "grad_norm": 0.5840547680854797,
      "learning_rate": 4.625222238239393e-05,
      "loss": 0.0005,
      "step": 15600
    },
    {
      "epoch": 0.7520061505934361,
      "grad_norm": 0.3758610486984253,
      "learning_rate": 4.624020950458892e-05,
      "loss": 0.0006,
      "step": 15650
    },
    {
      "epoch": 0.7544087261544375,
      "grad_norm": 0.44598308205604553,
      "learning_rate": 4.622819662678392e-05,
      "loss": 0.0005,
      "step": 15700
    },
    {
      "epoch": 0.756811301715439,
      "grad_norm": 0.1542448103427887,
      "learning_rate": 4.621618374897891e-05,
      "loss": 0.0004,
      "step": 15750
    },
    {
      "epoch": 0.7592138772764403,
      "grad_norm": 0.6062233448028564,
      "learning_rate": 4.62041708711739e-05,
      "loss": 0.0004,
      "step": 15800
    },
    {
      "epoch": 0.7616164528374417,
      "grad_norm": 0.26074254512786865,
      "learning_rate": 4.61921579933689e-05,
      "loss": 0.0005,
      "step": 15850
    },
    {
      "epoch": 0.7640190283984432,
      "grad_norm": 0.2679304778575897,
      "learning_rate": 4.618014511556389e-05,
      "loss": 0.0003,
      "step": 15900
    },
    {
      "epoch": 0.7664216039594445,
      "grad_norm": 0.298103928565979,
      "learning_rate": 4.616813223775888e-05,
      "loss": 0.0005,
      "step": 15950
    },
    {
      "epoch": 0.7688241795204459,
      "grad_norm": 0.26578018069267273,
      "learning_rate": 4.6156119359953877e-05,
      "loss": 0.0012,
      "step": 16000
    },
    {
      "epoch": 0.7712267550814473,
      "grad_norm": 0.35617056488990784,
      "learning_rate": 4.614410648214886e-05,
      "loss": 0.0004,
      "step": 16050
    },
    {
      "epoch": 0.7736293306424487,
      "grad_norm": 0.20254452526569366,
      "learning_rate": 4.613209360434386e-05,
      "loss": 0.0004,
      "step": 16100
    },
    {
      "epoch": 0.7760319062034501,
      "grad_norm": 0.18166276812553406,
      "learning_rate": 4.612008072653885e-05,
      "loss": 0.0005,
      "step": 16150
    },
    {
      "epoch": 0.7784344817644515,
      "grad_norm": 0.3068163990974426,
      "learning_rate": 4.610806784873385e-05,
      "loss": 0.0003,
      "step": 16200
    },
    {
      "epoch": 0.7808370573254528,
      "grad_norm": 0.4993622899055481,
      "learning_rate": 4.609605497092884e-05,
      "loss": 0.0003,
      "step": 16250
    },
    {
      "epoch": 0.7832396328864543,
      "grad_norm": 0.26270073652267456,
      "learning_rate": 4.608404209312383e-05,
      "loss": 0.0004,
      "step": 16300
    },
    {
      "epoch": 0.7856422084474557,
      "grad_norm": 0.46297982335090637,
      "learning_rate": 4.6072029215318826e-05,
      "loss": 0.0004,
      "step": 16350
    },
    {
      "epoch": 0.788044784008457,
      "grad_norm": 0.17706994712352753,
      "learning_rate": 4.606001633751382e-05,
      "loss": 0.0005,
      "step": 16400
    },
    {
      "epoch": 0.7904473595694584,
      "grad_norm": 0.23799970746040344,
      "learning_rate": 4.604800345970881e-05,
      "loss": 0.0003,
      "step": 16450
    },
    {
      "epoch": 0.7928499351304599,
      "grad_norm": 0.3308199346065521,
      "learning_rate": 4.6035990581903805e-05,
      "loss": 0.0003,
      "step": 16500
    },
    {
      "epoch": 0.7952525106914613,
      "grad_norm": 0.2968522608280182,
      "learning_rate": 4.6023977704098796e-05,
      "loss": 0.0004,
      "step": 16550
    },
    {
      "epoch": 0.7976550862524626,
      "grad_norm": 0.3040672242641449,
      "learning_rate": 4.6011964826293794e-05,
      "loss": 0.0004,
      "step": 16600
    },
    {
      "epoch": 0.800057661813464,
      "grad_norm": 0.23504500091075897,
      "learning_rate": 4.5999951948488784e-05,
      "loss": 0.0004,
      "step": 16650
    },
    {
      "epoch": 0.8024602373744655,
      "grad_norm": 0.34778153896331787,
      "learning_rate": 4.5987939070683775e-05,
      "loss": 0.0007,
      "step": 16700
    },
    {
      "epoch": 0.8048628129354668,
      "grad_norm": 0.2425207495689392,
      "learning_rate": 4.597592619287877e-05,
      "loss": 0.0004,
      "step": 16750
    },
    {
      "epoch": 0.8072653884964682,
      "grad_norm": 0.14435888826847076,
      "learning_rate": 4.596391331507376e-05,
      "loss": 0.0006,
      "step": 16800
    },
    {
      "epoch": 0.8096679640574697,
      "grad_norm": 0.3763614892959595,
      "learning_rate": 4.5951900437268754e-05,
      "loss": 0.0004,
      "step": 16850
    },
    {
      "epoch": 0.812070539618471,
      "grad_norm": 0.2948377728462219,
      "learning_rate": 4.5939887559463745e-05,
      "loss": 0.0003,
      "step": 16900
    },
    {
      "epoch": 0.8144731151794724,
      "grad_norm": 0.18955853581428528,
      "learning_rate": 4.5927874681658736e-05,
      "loss": 0.0004,
      "step": 16950
    },
    {
      "epoch": 0.8168756907404738,
      "grad_norm": 0.1785687357187271,
      "learning_rate": 4.5915861803853734e-05,
      "loss": 0.0005,
      "step": 17000
    },
    {
      "epoch": 0.8192782663014752,
      "grad_norm": 0.062323905527591705,
      "learning_rate": 4.5903848926048725e-05,
      "loss": 0.0004,
      "step": 17050
    },
    {
      "epoch": 0.8216808418624766,
      "grad_norm": 0.19913344085216522,
      "learning_rate": 4.589183604824372e-05,
      "loss": 0.0004,
      "step": 17100
    },
    {
      "epoch": 0.824083417423478,
      "grad_norm": 0.18266446888446808,
      "learning_rate": 4.587982317043871e-05,
      "loss": 0.0004,
      "step": 17150
    },
    {
      "epoch": 0.8264859929844793,
      "grad_norm": 0.32080376148223877,
      "learning_rate": 4.5867810292633704e-05,
      "loss": 0.0004,
      "step": 17200
    },
    {
      "epoch": 0.8288885685454808,
      "grad_norm": 0.4301320016384125,
      "learning_rate": 4.58557974148287e-05,
      "loss": 0.0004,
      "step": 17250
    },
    {
      "epoch": 0.8312911441064822,
      "grad_norm": 0.20037272572517395,
      "learning_rate": 4.584378453702369e-05,
      "loss": 0.0004,
      "step": 17300
    },
    {
      "epoch": 0.8336937196674835,
      "grad_norm": 0.30121541023254395,
      "learning_rate": 4.583177165921868e-05,
      "loss": 0.0019,
      "step": 17350
    },
    {
      "epoch": 0.8360962952284849,
      "grad_norm": 0.3756600320339203,
      "learning_rate": 4.581975878141368e-05,
      "loss": 0.0009,
      "step": 17400
    },
    {
      "epoch": 0.8384988707894864,
      "grad_norm": 0.3647182583808899,
      "learning_rate": 4.580774590360867e-05,
      "loss": 0.0004,
      "step": 17450
    },
    {
      "epoch": 0.8409014463504877,
      "grad_norm": 0.5663448572158813,
      "learning_rate": 4.579573302580366e-05,
      "loss": 0.0004,
      "step": 17500
    },
    {
      "epoch": 0.8433040219114891,
      "grad_norm": 0.1661624163389206,
      "learning_rate": 4.578372014799865e-05,
      "loss": 0.0005,
      "step": 17550
    },
    {
      "epoch": 0.8457065974724906,
      "grad_norm": 0.25336793065071106,
      "learning_rate": 4.577170727019365e-05,
      "loss": 0.0003,
      "step": 17600
    },
    {
      "epoch": 0.8481091730334919,
      "grad_norm": 0.2794156074523926,
      "learning_rate": 4.575969439238864e-05,
      "loss": 0.0004,
      "step": 17650
    },
    {
      "epoch": 0.8505117485944933,
      "grad_norm": 0.3095906972885132,
      "learning_rate": 4.574768151458363e-05,
      "loss": 0.0003,
      "step": 17700
    },
    {
      "epoch": 0.8529143241554947,
      "grad_norm": 0.2904398441314697,
      "learning_rate": 4.573566863677863e-05,
      "loss": 0.0004,
      "step": 17750
    },
    {
      "epoch": 0.855316899716496,
      "grad_norm": 0.08351132273674011,
      "learning_rate": 4.572365575897362e-05,
      "loss": 0.0003,
      "step": 17800
    },
    {
      "epoch": 0.8577194752774975,
      "grad_norm": 0.2039576917886734,
      "learning_rate": 4.571164288116861e-05,
      "loss": 0.0004,
      "step": 17850
    },
    {
      "epoch": 0.8601220508384989,
      "grad_norm": 0.6028733849525452,
      "learning_rate": 4.569963000336361e-05,
      "loss": 0.0004,
      "step": 17900
    },
    {
      "epoch": 0.8625246263995002,
      "grad_norm": 0.09233266860246658,
      "learning_rate": 4.56876171255586e-05,
      "loss": 0.0003,
      "step": 17950
    },
    {
      "epoch": 0.8649272019605017,
      "grad_norm": 0.35372769832611084,
      "learning_rate": 4.56756042477536e-05,
      "loss": 0.0003,
      "step": 18000
    },
    {
      "epoch": 0.8673297775215031,
      "grad_norm": 0.3586353361606598,
      "learning_rate": 4.566359136994859e-05,
      "loss": 0.0004,
      "step": 18050
    },
    {
      "epoch": 0.8697323530825044,
      "grad_norm": 0.21224237978458405,
      "learning_rate": 4.565157849214358e-05,
      "loss": 0.0004,
      "step": 18100
    },
    {
      "epoch": 0.8721349286435058,
      "grad_norm": 0.5403316020965576,
      "learning_rate": 4.563956561433858e-05,
      "loss": 0.0004,
      "step": 18150
    },
    {
      "epoch": 0.8745375042045073,
      "grad_norm": 0.13087156414985657,
      "learning_rate": 4.562755273653357e-05,
      "loss": 0.0003,
      "step": 18200
    },
    {
      "epoch": 0.8769400797655086,
      "grad_norm": 0.3371748924255371,
      "learning_rate": 4.561553985872856e-05,
      "loss": 0.0004,
      "step": 18250
    },
    {
      "epoch": 0.87934265532651,
      "grad_norm": 0.313486784696579,
      "learning_rate": 4.560352698092355e-05,
      "loss": 0.0004,
      "step": 18300
    },
    {
      "epoch": 0.8817452308875114,
      "grad_norm": 0.3570159077644348,
      "learning_rate": 4.559151410311854e-05,
      "loss": 0.0003,
      "step": 18350
    },
    {
      "epoch": 0.8841478064485128,
      "grad_norm": 0.22551679611206055,
      "learning_rate": 4.557950122531354e-05,
      "loss": 0.0005,
      "step": 18400
    },
    {
      "epoch": 0.8865503820095142,
      "grad_norm": 0.16138939559459686,
      "learning_rate": 4.556748834750853e-05,
      "loss": 0.0004,
      "step": 18450
    },
    {
      "epoch": 0.8889529575705156,
      "grad_norm": 0.2995676100254059,
      "learning_rate": 4.5555475469703526e-05,
      "loss": 0.0004,
      "step": 18500
    },
    {
      "epoch": 0.8913555331315169,
      "grad_norm": 0.2456107884645462,
      "learning_rate": 4.554346259189852e-05,
      "loss": 0.0004,
      "step": 18550
    },
    {
      "epoch": 0.8937581086925184,
      "grad_norm": 0.24138899147510529,
      "learning_rate": 4.553144971409351e-05,
      "loss": 0.0003,
      "step": 18600
    },
    {
      "epoch": 0.8961606842535198,
      "grad_norm": 0.30477115511894226,
      "learning_rate": 4.5519436836288505e-05,
      "loss": 0.0003,
      "step": 18650
    },
    {
      "epoch": 0.8985632598145211,
      "grad_norm": 0.473041296005249,
      "learning_rate": 4.5507423958483496e-05,
      "loss": 0.0004,
      "step": 18700
    },
    {
      "epoch": 0.9009658353755226,
      "grad_norm": 0.12909618020057678,
      "learning_rate": 4.5495411080678494e-05,
      "loss": 0.0004,
      "step": 18750
    },
    {
      "epoch": 0.903368410936524,
      "grad_norm": 0.25886765122413635,
      "learning_rate": 4.5483398202873485e-05,
      "loss": 0.0005,
      "step": 18800
    },
    {
      "epoch": 0.9057709864975253,
      "grad_norm": 0.10755965858697891,
      "learning_rate": 4.5471385325068476e-05,
      "loss": 0.0004,
      "step": 18850
    },
    {
      "epoch": 0.9081735620585267,
      "grad_norm": 0.38713788986206055,
      "learning_rate": 4.545937244726347e-05,
      "loss": 0.0003,
      "step": 18900
    },
    {
      "epoch": 0.9105761376195282,
      "grad_norm": 0.12442635744810104,
      "learning_rate": 4.5447359569458464e-05,
      "loss": 0.0003,
      "step": 18950
    },
    {
      "epoch": 0.9129787131805295,
      "grad_norm": 0.41700366139411926,
      "learning_rate": 4.5435346691653455e-05,
      "loss": 0.0004,
      "step": 19000
    },
    {
      "epoch": 0.9153812887415309,
      "grad_norm": 0.288183331489563,
      "learning_rate": 4.5423333813848446e-05,
      "loss": 0.0004,
      "step": 19050
    },
    {
      "epoch": 0.9177838643025323,
      "grad_norm": 0.3088480830192566,
      "learning_rate": 4.5411320936043436e-05,
      "loss": 0.0003,
      "step": 19100
    },
    {
      "epoch": 0.9201864398635337,
      "grad_norm": 0.35970374941825867,
      "learning_rate": 4.5399308058238434e-05,
      "loss": 0.0004,
      "step": 19150
    },
    {
      "epoch": 0.9225890154245351,
      "grad_norm": 0.21858394145965576,
      "learning_rate": 4.5387295180433425e-05,
      "loss": 0.0003,
      "step": 19200
    },
    {
      "epoch": 0.9249915909855365,
      "grad_norm": 0.2796936333179474,
      "learning_rate": 4.5375282302628416e-05,
      "loss": 0.0003,
      "step": 19250
    },
    {
      "epoch": 0.9273941665465378,
      "grad_norm": 0.13891062140464783,
      "learning_rate": 4.536326942482341e-05,
      "loss": 0.0003,
      "step": 19300
    },
    {
      "epoch": 0.9297967421075393,
      "grad_norm": 0.41483160853385925,
      "learning_rate": 4.5351256547018404e-05,
      "loss": 0.0003,
      "step": 19350
    },
    {
      "epoch": 0.9321993176685407,
      "grad_norm": 0.3850933909416199,
      "learning_rate": 4.53392436692134e-05,
      "loss": 0.0003,
      "step": 19400
    },
    {
      "epoch": 0.9346018932295421,
      "grad_norm": 0.19518998265266418,
      "learning_rate": 4.532723079140839e-05,
      "loss": 0.0005,
      "step": 19450
    },
    {
      "epoch": 0.9370044687905434,
      "grad_norm": 0.4063898026943207,
      "learning_rate": 4.5315217913603383e-05,
      "loss": 0.0003,
      "step": 19500
    },
    {
      "epoch": 0.9394070443515449,
      "grad_norm": 0.3414221405982971,
      "learning_rate": 4.530320503579838e-05,
      "loss": 0.0004,
      "step": 19550
    },
    {
      "epoch": 0.9418096199125463,
      "grad_norm": 0.04500608146190643,
      "learning_rate": 4.529119215799337e-05,
      "loss": 0.0003,
      "step": 19600
    },
    {
      "epoch": 0.9442121954735476,
      "grad_norm": 0.20071594417095184,
      "learning_rate": 4.527917928018837e-05,
      "loss": 0.0005,
      "step": 19650
    },
    {
      "epoch": 0.946614771034549,
      "grad_norm": 0.751842737197876,
      "learning_rate": 4.526716640238336e-05,
      "loss": 0.0004,
      "step": 19700
    },
    {
      "epoch": 0.9490173465955505,
      "grad_norm": 0.3956319987773895,
      "learning_rate": 4.5255153524578344e-05,
      "loss": 0.0004,
      "step": 19750
    },
    {
      "epoch": 0.9514199221565518,
      "grad_norm": 0.1831003874540329,
      "learning_rate": 4.524314064677334e-05,
      "loss": 0.0004,
      "step": 19800
    },
    {
      "epoch": 0.9538224977175532,
      "grad_norm": 0.5418301224708557,
      "learning_rate": 4.523112776896833e-05,
      "loss": 0.0003,
      "step": 19850
    },
    {
      "epoch": 0.9562250732785547,
      "grad_norm": 0.38254180550575256,
      "learning_rate": 4.521911489116333e-05,
      "loss": 0.0006,
      "step": 19900
    },
    {
      "epoch": 0.958627648839556,
      "grad_norm": 0.1576739400625229,
      "learning_rate": 4.520710201335832e-05,
      "loss": 0.0009,
      "step": 19950
    },
    {
      "epoch": 0.9610302244005574,
      "grad_norm": 0.30839741230010986,
      "learning_rate": 4.519508913555331e-05,
      "loss": 0.0005,
      "step": 20000
    },
    {
      "epoch": 0.9634327999615588,
      "grad_norm": 0.30133137106895447,
      "learning_rate": 4.518307625774831e-05,
      "loss": 0.0013,
      "step": 20050
    },
    {
      "epoch": 0.9658353755225602,
      "grad_norm": 0.2090066373348236,
      "learning_rate": 4.51710633799433e-05,
      "loss": 0.0006,
      "step": 20100
    },
    {
      "epoch": 0.9682379510835616,
      "grad_norm": 0.13039985299110413,
      "learning_rate": 4.51590505021383e-05,
      "loss": 0.0011,
      "step": 20150
    },
    {
      "epoch": 0.970640526644563,
      "grad_norm": 0.1034875139594078,
      "learning_rate": 4.514703762433329e-05,
      "loss": 0.0003,
      "step": 20200
    },
    {
      "epoch": 0.9730431022055643,
      "grad_norm": 0.14955173432826996,
      "learning_rate": 4.513502474652828e-05,
      "loss": 0.0003,
      "step": 20250
    },
    {
      "epoch": 0.9754456777665658,
      "grad_norm": 0.2439357191324234,
      "learning_rate": 4.512301186872328e-05,
      "loss": 0.0003,
      "step": 20300
    },
    {
      "epoch": 0.9778482533275672,
      "grad_norm": 0.3087243139743805,
      "learning_rate": 4.511099899091827e-05,
      "loss": 0.0011,
      "step": 20350
    },
    {
      "epoch": 0.9802508288885685,
      "grad_norm": 0.10187457501888275,
      "learning_rate": 4.509898611311326e-05,
      "loss": 0.0003,
      "step": 20400
    },
    {
      "epoch": 0.98265340444957,
      "grad_norm": 0.0614391528069973,
      "learning_rate": 4.5086973235308257e-05,
      "loss": 0.0004,
      "step": 20450
    },
    {
      "epoch": 0.9850559800105714,
      "grad_norm": 0.379104346036911,
      "learning_rate": 4.507496035750324e-05,
      "loss": 0.0003,
      "step": 20500
    },
    {
      "epoch": 0.9874585555715727,
      "grad_norm": 0.33108431100845337,
      "learning_rate": 4.506294747969824e-05,
      "loss": 0.0004,
      "step": 20550
    },
    {
      "epoch": 0.9898611311325741,
      "grad_norm": 0.2668234705924988,
      "learning_rate": 4.505093460189323e-05,
      "loss": 0.0003,
      "step": 20600
    },
    {
      "epoch": 0.9922637066935756,
      "grad_norm": 0.06497212499380112,
      "learning_rate": 4.5038921724088227e-05,
      "loss": 0.0003,
      "step": 20650
    },
    {
      "epoch": 0.9946662822545769,
      "grad_norm": 0.20944145321846008,
      "learning_rate": 4.502690884628322e-05,
      "loss": 0.0003,
      "step": 20700
    },
    {
      "epoch": 0.9970688578155783,
      "grad_norm": 0.19129639863967896,
      "learning_rate": 4.501489596847821e-05,
      "loss": 0.0003,
      "step": 20750
    },
    {
      "epoch": 0.9994714333765797,
      "grad_norm": 0.08985954523086548,
      "learning_rate": 4.5002883090673206e-05,
      "loss": 0.0008,
      "step": 20800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0002766257675830275,
      "eval_runtime": 17.5343,
      "eval_samples_per_second": 541.567,
      "eval_steps_per_second": 67.696,
      "step": 20811
    },
    {
      "epoch": 1.001874008937581,
      "grad_norm": 0.4992769658565521,
      "learning_rate": 4.49908702128682e-05,
      "loss": 0.0004,
      "step": 20850
    },
    {
      "epoch": 1.0042765844985824,
      "grad_norm": 0.5707713961601257,
      "learning_rate": 4.497885733506319e-05,
      "loss": 0.0003,
      "step": 20900
    },
    {
      "epoch": 1.006679160059584,
      "grad_norm": 0.1927327960729599,
      "learning_rate": 4.4966844457258185e-05,
      "loss": 0.0003,
      "step": 20950
    },
    {
      "epoch": 1.0090817356205852,
      "grad_norm": 0.29604068398475647,
      "learning_rate": 4.4954831579453176e-05,
      "loss": 0.0003,
      "step": 21000
    },
    {
      "epoch": 1.0114843111815868,
      "grad_norm": 0.4909155070781708,
      "learning_rate": 4.4942818701648174e-05,
      "loss": 0.0003,
      "step": 21050
    },
    {
      "epoch": 1.013886886742588,
      "grad_norm": 0.4777075946331024,
      "learning_rate": 4.4930805823843164e-05,
      "loss": 0.0003,
      "step": 21100
    },
    {
      "epoch": 1.0162894623035894,
      "grad_norm": 0.18188002705574036,
      "learning_rate": 4.4918792946038155e-05,
      "loss": 0.0004,
      "step": 21150
    },
    {
      "epoch": 1.018692037864591,
      "grad_norm": 0.5257629752159119,
      "learning_rate": 4.490678006823315e-05,
      "loss": 0.0003,
      "step": 21200
    },
    {
      "epoch": 1.0210946134255923,
      "grad_norm": 0.27076274156570435,
      "learning_rate": 4.489476719042814e-05,
      "loss": 0.0003,
      "step": 21250
    },
    {
      "epoch": 1.0234971889865936,
      "grad_norm": 0.17122682929039001,
      "learning_rate": 4.4882754312623134e-05,
      "loss": 0.0004,
      "step": 21300
    },
    {
      "epoch": 1.0258997645475951,
      "grad_norm": 0.102567158639431,
      "learning_rate": 4.4870741434818125e-05,
      "loss": 0.0014,
      "step": 21350
    },
    {
      "epoch": 1.0283023401085964,
      "grad_norm": 0.17474950850009918,
      "learning_rate": 4.4858728557013116e-05,
      "loss": 0.0004,
      "step": 21400
    },
    {
      "epoch": 1.0307049156695978,
      "grad_norm": 0.20648618042469025,
      "learning_rate": 4.4846715679208114e-05,
      "loss": 0.0004,
      "step": 21450
    },
    {
      "epoch": 1.0331074912305993,
      "grad_norm": 0.22547797858715057,
      "learning_rate": 4.4834702801403105e-05,
      "loss": 0.0004,
      "step": 21500
    },
    {
      "epoch": 1.0355100667916006,
      "grad_norm": 0.19814680516719818,
      "learning_rate": 4.48226899235981e-05,
      "loss": 0.0003,
      "step": 21550
    },
    {
      "epoch": 1.037912642352602,
      "grad_norm": 0.23957034945487976,
      "learning_rate": 4.481067704579309e-05,
      "loss": 0.0002,
      "step": 21600
    },
    {
      "epoch": 1.0403152179136035,
      "grad_norm": 0.5633009076118469,
      "learning_rate": 4.4798664167988084e-05,
      "loss": 0.0003,
      "step": 21650
    },
    {
      "epoch": 1.0427177934746048,
      "grad_norm": 0.5277500748634338,
      "learning_rate": 4.478665129018308e-05,
      "loss": 0.001,
      "step": 21700
    },
    {
      "epoch": 1.0451203690356061,
      "grad_norm": 0.2841854691505432,
      "learning_rate": 4.477463841237807e-05,
      "loss": 0.0003,
      "step": 21750
    },
    {
      "epoch": 1.0475229445966077,
      "grad_norm": 0.06809019297361374,
      "learning_rate": 4.476262553457306e-05,
      "loss": 0.0004,
      "step": 21800
    },
    {
      "epoch": 1.049925520157609,
      "grad_norm": 0.09749210625886917,
      "learning_rate": 4.475061265676806e-05,
      "loss": 0.0004,
      "step": 21850
    },
    {
      "epoch": 1.0523280957186103,
      "grad_norm": 0.09508693963289261,
      "learning_rate": 4.473859977896305e-05,
      "loss": 0.0003,
      "step": 21900
    },
    {
      "epoch": 1.0547306712796118,
      "grad_norm": 0.2630667984485626,
      "learning_rate": 4.472658690115805e-05,
      "loss": 0.0005,
      "step": 21950
    },
    {
      "epoch": 1.0571332468406132,
      "grad_norm": 0.5097360014915466,
      "learning_rate": 4.471457402335303e-05,
      "loss": 0.0004,
      "step": 22000
    },
    {
      "epoch": 1.0595358224016145,
      "grad_norm": 0.35315319895744324,
      "learning_rate": 4.470256114554803e-05,
      "loss": 0.0003,
      "step": 22050
    },
    {
      "epoch": 1.061938397962616,
      "grad_norm": 0.12041237950325012,
      "learning_rate": 4.469054826774302e-05,
      "loss": 0.0004,
      "step": 22100
    },
    {
      "epoch": 1.0643409735236173,
      "grad_norm": 0.11234511435031891,
      "learning_rate": 4.467853538993801e-05,
      "loss": 0.0003,
      "step": 22150
    },
    {
      "epoch": 1.0667435490846187,
      "grad_norm": 0.06749357283115387,
      "learning_rate": 4.466652251213301e-05,
      "loss": 0.001,
      "step": 22200
    },
    {
      "epoch": 1.0691461246456202,
      "grad_norm": 0.12210679799318314,
      "learning_rate": 4.4654509634328e-05,
      "loss": 0.0004,
      "step": 22250
    },
    {
      "epoch": 1.0715487002066215,
      "grad_norm": 0.3539080321788788,
      "learning_rate": 4.464249675652299e-05,
      "loss": 0.0003,
      "step": 22300
    },
    {
      "epoch": 1.0739512757676228,
      "grad_norm": 0.10067323595285416,
      "learning_rate": 4.463048387871799e-05,
      "loss": 0.0003,
      "step": 22350
    },
    {
      "epoch": 1.0763538513286244,
      "grad_norm": 0.3240951597690582,
      "learning_rate": 4.461847100091298e-05,
      "loss": 0.0003,
      "step": 22400
    },
    {
      "epoch": 1.0787564268896257,
      "grad_norm": 0.35171443223953247,
      "learning_rate": 4.460645812310798e-05,
      "loss": 0.0004,
      "step": 22450
    },
    {
      "epoch": 1.081159002450627,
      "grad_norm": 0.347272664308548,
      "learning_rate": 4.459444524530297e-05,
      "loss": 0.0002,
      "step": 22500
    },
    {
      "epoch": 1.0835615780116286,
      "grad_norm": 0.43274781107902527,
      "learning_rate": 4.458243236749796e-05,
      "loss": 0.0003,
      "step": 22550
    },
    {
      "epoch": 1.0859641535726299,
      "grad_norm": 0.04950995370745659,
      "learning_rate": 4.457041948969296e-05,
      "loss": 0.0003,
      "step": 22600
    },
    {
      "epoch": 1.0883667291336312,
      "grad_norm": 0.04694985970854759,
      "learning_rate": 4.455840661188795e-05,
      "loss": 0.0002,
      "step": 22650
    },
    {
      "epoch": 1.0907693046946327,
      "grad_norm": 0.24858327209949493,
      "learning_rate": 4.454639373408294e-05,
      "loss": 0.0003,
      "step": 22700
    },
    {
      "epoch": 1.093171880255634,
      "grad_norm": 0.22278593480587006,
      "learning_rate": 4.453438085627793e-05,
      "loss": 0.0003,
      "step": 22750
    },
    {
      "epoch": 1.0955744558166354,
      "grad_norm": 0.14876089990139008,
      "learning_rate": 4.452236797847292e-05,
      "loss": 0.0003,
      "step": 22800
    },
    {
      "epoch": 1.097977031377637,
      "grad_norm": 0.2408357411623001,
      "learning_rate": 4.451035510066792e-05,
      "loss": 0.0008,
      "step": 22850
    },
    {
      "epoch": 1.1003796069386382,
      "grad_norm": 0.5605106949806213,
      "learning_rate": 4.449834222286291e-05,
      "loss": 0.0008,
      "step": 22900
    },
    {
      "epoch": 1.1027821824996396,
      "grad_norm": 0.2771901488304138,
      "learning_rate": 4.4486329345057906e-05,
      "loss": 0.0004,
      "step": 22950
    },
    {
      "epoch": 1.105184758060641,
      "grad_norm": 0.14125175774097443,
      "learning_rate": 4.44743164672529e-05,
      "loss": 0.0004,
      "step": 23000
    },
    {
      "epoch": 1.1075873336216424,
      "grad_norm": 0.2656981647014618,
      "learning_rate": 4.446230358944789e-05,
      "loss": 0.0003,
      "step": 23050
    },
    {
      "epoch": 1.1099899091826437,
      "grad_norm": 0.1385556310415268,
      "learning_rate": 4.4450290711642885e-05,
      "loss": 0.0004,
      "step": 23100
    },
    {
      "epoch": 1.1123924847436453,
      "grad_norm": 0.2712734639644623,
      "learning_rate": 4.4438277833837876e-05,
      "loss": 0.0003,
      "step": 23150
    },
    {
      "epoch": 1.1147950603046466,
      "grad_norm": 0.0331929549574852,
      "learning_rate": 4.442626495603287e-05,
      "loss": 0.0003,
      "step": 23200
    },
    {
      "epoch": 1.117197635865648,
      "grad_norm": 0.09687848389148712,
      "learning_rate": 4.4414252078227865e-05,
      "loss": 0.0003,
      "step": 23250
    },
    {
      "epoch": 1.1196002114266494,
      "grad_norm": 0.1281844973564148,
      "learning_rate": 4.4402239200422856e-05,
      "loss": 0.0004,
      "step": 23300
    },
    {
      "epoch": 1.1220027869876508,
      "grad_norm": 0.2856989800930023,
      "learning_rate": 4.439022632261785e-05,
      "loss": 0.0003,
      "step": 23350
    },
    {
      "epoch": 1.124405362548652,
      "grad_norm": 0.40938514471054077,
      "learning_rate": 4.4378213444812844e-05,
      "loss": 0.0003,
      "step": 23400
    },
    {
      "epoch": 1.1268079381096536,
      "grad_norm": 0.3188592791557312,
      "learning_rate": 4.4366200567007835e-05,
      "loss": 0.0004,
      "step": 23450
    },
    {
      "epoch": 1.129210513670655,
      "grad_norm": 0.5321780443191528,
      "learning_rate": 4.4354187689202826e-05,
      "loss": 0.0003,
      "step": 23500
    },
    {
      "epoch": 1.1316130892316563,
      "grad_norm": 0.29687175154685974,
      "learning_rate": 4.4342174811397816e-05,
      "loss": 0.0004,
      "step": 23550
    },
    {
      "epoch": 1.1340156647926578,
      "grad_norm": 0.1628730595111847,
      "learning_rate": 4.4330161933592814e-05,
      "loss": 0.0003,
      "step": 23600
    },
    {
      "epoch": 1.1364182403536591,
      "grad_norm": 1.0476480722427368,
      "learning_rate": 4.4318149055787805e-05,
      "loss": 0.0003,
      "step": 23650
    },
    {
      "epoch": 1.1388208159146604,
      "grad_norm": 0.23282422125339508,
      "learning_rate": 4.4306136177982796e-05,
      "loss": 0.0003,
      "step": 23700
    },
    {
      "epoch": 1.141223391475662,
      "grad_norm": 0.13655194640159607,
      "learning_rate": 4.429412330017779e-05,
      "loss": 0.0003,
      "step": 23750
    },
    {
      "epoch": 1.1436259670366633,
      "grad_norm": 0.26861560344696045,
      "learning_rate": 4.4282110422372784e-05,
      "loss": 0.0002,
      "step": 23800
    },
    {
      "epoch": 1.1460285425976646,
      "grad_norm": 0.1270122230052948,
      "learning_rate": 4.427009754456778e-05,
      "loss": 0.0002,
      "step": 23850
    },
    {
      "epoch": 1.1484311181586662,
      "grad_norm": 0.13103552162647247,
      "learning_rate": 4.425808466676277e-05,
      "loss": 0.0003,
      "step": 23900
    },
    {
      "epoch": 1.1508336937196675,
      "grad_norm": 0.11463029682636261,
      "learning_rate": 4.424607178895776e-05,
      "loss": 0.0003,
      "step": 23950
    },
    {
      "epoch": 1.1532362692806688,
      "grad_norm": 0.4563866853713989,
      "learning_rate": 4.423405891115276e-05,
      "loss": 0.0003,
      "step": 24000
    },
    {
      "epoch": 1.1556388448416703,
      "grad_norm": 0.11383373290300369,
      "learning_rate": 4.422204603334775e-05,
      "loss": 0.0004,
      "step": 24050
    },
    {
      "epoch": 1.1580414204026717,
      "grad_norm": 0.36382296681404114,
      "learning_rate": 4.421003315554275e-05,
      "loss": 0.0004,
      "step": 24100
    },
    {
      "epoch": 1.160443995963673,
      "grad_norm": 0.29843389987945557,
      "learning_rate": 4.419802027773774e-05,
      "loss": 0.0003,
      "step": 24150
    },
    {
      "epoch": 1.1628465715246745,
      "grad_norm": 0.28806403279304504,
      "learning_rate": 4.4186007399932724e-05,
      "loss": 0.0003,
      "step": 24200
    },
    {
      "epoch": 1.1652491470856758,
      "grad_norm": 0.285141259431839,
      "learning_rate": 4.417399452212772e-05,
      "loss": 0.0004,
      "step": 24250
    },
    {
      "epoch": 1.1676517226466772,
      "grad_norm": 0.25685030221939087,
      "learning_rate": 4.416198164432271e-05,
      "loss": 0.0003,
      "step": 24300
    },
    {
      "epoch": 1.1700542982076787,
      "grad_norm": 0.502432644367218,
      "learning_rate": 4.414996876651771e-05,
      "loss": 0.0003,
      "step": 24350
    },
    {
      "epoch": 1.17245687376868,
      "grad_norm": 0.3716150224208832,
      "learning_rate": 4.41379558887127e-05,
      "loss": 0.0004,
      "step": 24400
    },
    {
      "epoch": 1.1748594493296813,
      "grad_norm": 1.0119508504867554,
      "learning_rate": 4.412594301090769e-05,
      "loss": 0.0003,
      "step": 24450
    },
    {
      "epoch": 1.1772620248906829,
      "grad_norm": 0.3840879201889038,
      "learning_rate": 4.411393013310269e-05,
      "loss": 0.0004,
      "step": 24500
    },
    {
      "epoch": 1.1796646004516842,
      "grad_norm": 0.07308443635702133,
      "learning_rate": 4.410191725529768e-05,
      "loss": 0.0002,
      "step": 24550
    },
    {
      "epoch": 1.1820671760126855,
      "grad_norm": 0.5020934343338013,
      "learning_rate": 4.408990437749267e-05,
      "loss": 0.0003,
      "step": 24600
    },
    {
      "epoch": 1.184469751573687,
      "grad_norm": 0.49319320917129517,
      "learning_rate": 4.407789149968767e-05,
      "loss": 0.0003,
      "step": 24650
    },
    {
      "epoch": 1.1868723271346884,
      "grad_norm": 0.46707862615585327,
      "learning_rate": 4.406587862188266e-05,
      "loss": 0.0003,
      "step": 24700
    },
    {
      "epoch": 1.1892749026956897,
      "grad_norm": 0.25085702538490295,
      "learning_rate": 4.405386574407766e-05,
      "loss": 0.0003,
      "step": 24750
    },
    {
      "epoch": 1.1916774782566912,
      "grad_norm": 0.1559993177652359,
      "learning_rate": 4.404185286627265e-05,
      "loss": 0.0011,
      "step": 24800
    },
    {
      "epoch": 1.1940800538176926,
      "grad_norm": 0.25831112265586853,
      "learning_rate": 4.402983998846764e-05,
      "loss": 0.0003,
      "step": 24850
    },
    {
      "epoch": 1.1964826293786939,
      "grad_norm": 0.4188432991504669,
      "learning_rate": 4.4017827110662636e-05,
      "loss": 0.0002,
      "step": 24900
    },
    {
      "epoch": 1.1988852049396954,
      "grad_norm": 0.1695726066827774,
      "learning_rate": 4.400581423285762e-05,
      "loss": 0.0003,
      "step": 24950
    },
    {
      "epoch": 1.2012877805006967,
      "grad_norm": 0.1975635588169098,
      "learning_rate": 4.399380135505262e-05,
      "loss": 0.0003,
      "step": 25000
    },
    {
      "epoch": 1.203690356061698,
      "grad_norm": 0.37471795082092285,
      "learning_rate": 4.398178847724761e-05,
      "loss": 0.0003,
      "step": 25050
    },
    {
      "epoch": 1.2060929316226996,
      "grad_norm": 0.496836394071579,
      "learning_rate": 4.39697755994426e-05,
      "loss": 0.0003,
      "step": 25100
    },
    {
      "epoch": 1.208495507183701,
      "grad_norm": 0.18173544108867645,
      "learning_rate": 4.39577627216376e-05,
      "loss": 0.0003,
      "step": 25150
    },
    {
      "epoch": 1.2108980827447022,
      "grad_norm": 0.3307437598705292,
      "learning_rate": 4.394574984383259e-05,
      "loss": 0.0004,
      "step": 25200
    },
    {
      "epoch": 1.2133006583057038,
      "grad_norm": 0.1432572454214096,
      "learning_rate": 4.3933736966027586e-05,
      "loss": 0.0004,
      "step": 25250
    },
    {
      "epoch": 1.215703233866705,
      "grad_norm": 0.32035666704177856,
      "learning_rate": 4.392172408822258e-05,
      "loss": 0.0003,
      "step": 25300
    },
    {
      "epoch": 1.2181058094277064,
      "grad_norm": 0.11591293662786484,
      "learning_rate": 4.390971121041757e-05,
      "loss": 0.0002,
      "step": 25350
    },
    {
      "epoch": 1.220508384988708,
      "grad_norm": 0.11728936433792114,
      "learning_rate": 4.3897698332612565e-05,
      "loss": 0.0003,
      "step": 25400
    },
    {
      "epoch": 1.2229109605497093,
      "grad_norm": 0.07201755791902542,
      "learning_rate": 4.3885685454807556e-05,
      "loss": 0.0003,
      "step": 25450
    },
    {
      "epoch": 1.2253135361107106,
      "grad_norm": 0.5402578711509705,
      "learning_rate": 4.3873672577002553e-05,
      "loss": 0.0003,
      "step": 25500
    },
    {
      "epoch": 1.2277161116717121,
      "grad_norm": 0.4535433351993561,
      "learning_rate": 4.3861659699197544e-05,
      "loss": 0.0004,
      "step": 25550
    },
    {
      "epoch": 1.2301186872327134,
      "grad_norm": 0.242207333445549,
      "learning_rate": 4.3849646821392535e-05,
      "loss": 0.0002,
      "step": 25600
    },
    {
      "epoch": 1.2325212627937148,
      "grad_norm": 0.2785510718822479,
      "learning_rate": 4.383763394358753e-05,
      "loss": 0.0003,
      "step": 25650
    },
    {
      "epoch": 1.2349238383547163,
      "grad_norm": 0.29172492027282715,
      "learning_rate": 4.382562106578252e-05,
      "loss": 0.0002,
      "step": 25700
    },
    {
      "epoch": 1.2373264139157176,
      "grad_norm": 0.548777163028717,
      "learning_rate": 4.3813608187977514e-05,
      "loss": 0.0003,
      "step": 25750
    },
    {
      "epoch": 1.2397289894767192,
      "grad_norm": 0.10639773309230804,
      "learning_rate": 4.3801595310172505e-05,
      "loss": 0.0011,
      "step": 25800
    },
    {
      "epoch": 1.2421315650377205,
      "grad_norm": 0.8363096714019775,
      "learning_rate": 4.3789582432367496e-05,
      "loss": 0.0004,
      "step": 25850
    },
    {
      "epoch": 1.2445341405987218,
      "grad_norm": 0.1324809491634369,
      "learning_rate": 4.3777569554562494e-05,
      "loss": 0.0003,
      "step": 25900
    },
    {
      "epoch": 1.2469367161597233,
      "grad_norm": 0.1312372386455536,
      "learning_rate": 4.3765556676757484e-05,
      "loss": 0.0003,
      "step": 25950
    },
    {
      "epoch": 1.2493392917207247,
      "grad_norm": 0.3721861243247986,
      "learning_rate": 4.375354379895248e-05,
      "loss": 0.0004,
      "step": 26000
    },
    {
      "epoch": 1.251741867281726,
      "grad_norm": 0.08200420439243317,
      "learning_rate": 4.374153092114747e-05,
      "loss": 0.0003,
      "step": 26050
    },
    {
      "epoch": 1.2541444428427275,
      "grad_norm": 0.17463506758213043,
      "learning_rate": 4.3729518043342464e-05,
      "loss": 0.0003,
      "step": 26100
    },
    {
      "epoch": 1.2565470184037288,
      "grad_norm": 0.07052762806415558,
      "learning_rate": 4.371750516553746e-05,
      "loss": 0.0003,
      "step": 26150
    },
    {
      "epoch": 1.2589495939647302,
      "grad_norm": 0.292098730802536,
      "learning_rate": 4.370549228773245e-05,
      "loss": 0.0003,
      "step": 26200
    },
    {
      "epoch": 1.2613521695257317,
      "grad_norm": 0.14936472475528717,
      "learning_rate": 4.369347940992744e-05,
      "loss": 0.0004,
      "step": 26250
    },
    {
      "epoch": 1.263754745086733,
      "grad_norm": 0.06192438676953316,
      "learning_rate": 4.368146653212244e-05,
      "loss": 0.0002,
      "step": 26300
    },
    {
      "epoch": 1.2661573206477343,
      "grad_norm": 0.08184002339839935,
      "learning_rate": 4.366945365431743e-05,
      "loss": 0.0002,
      "step": 26350
    },
    {
      "epoch": 1.2685598962087359,
      "grad_norm": 0.08301490545272827,
      "learning_rate": 4.365744077651243e-05,
      "loss": 0.0002,
      "step": 26400
    },
    {
      "epoch": 1.2709624717697372,
      "grad_norm": 0.3207520842552185,
      "learning_rate": 4.364542789870741e-05,
      "loss": 0.0008,
      "step": 26450
    },
    {
      "epoch": 1.2733650473307385,
      "grad_norm": 0.15295177698135376,
      "learning_rate": 4.363341502090241e-05,
      "loss": 0.0003,
      "step": 26500
    },
    {
      "epoch": 1.27576762289174,
      "grad_norm": 0.5004488229751587,
      "learning_rate": 4.36214021430974e-05,
      "loss": 0.0004,
      "step": 26550
    },
    {
      "epoch": 1.2781701984527414,
      "grad_norm": 0.27939942479133606,
      "learning_rate": 4.360938926529239e-05,
      "loss": 0.0011,
      "step": 26600
    },
    {
      "epoch": 1.2805727740137427,
      "grad_norm": 0.518150806427002,
      "learning_rate": 4.359737638748739e-05,
      "loss": 0.0003,
      "step": 26650
    },
    {
      "epoch": 1.2829753495747442,
      "grad_norm": 0.10202443599700928,
      "learning_rate": 4.358536350968238e-05,
      "loss": 0.0002,
      "step": 26700
    },
    {
      "epoch": 1.2853779251357456,
      "grad_norm": 0.12092322111129761,
      "learning_rate": 4.357335063187737e-05,
      "loss": 0.0002,
      "step": 26750
    },
    {
      "epoch": 1.2877805006967469,
      "grad_norm": 0.3375898599624634,
      "learning_rate": 4.356133775407237e-05,
      "loss": 0.0003,
      "step": 26800
    },
    {
      "epoch": 1.2901830762577484,
      "grad_norm": 0.1371108740568161,
      "learning_rate": 4.354932487626736e-05,
      "loss": 0.0003,
      "step": 26850
    },
    {
      "epoch": 1.2925856518187497,
      "grad_norm": 0.5438352227210999,
      "learning_rate": 4.353731199846236e-05,
      "loss": 0.0002,
      "step": 26900
    },
    {
      "epoch": 1.294988227379751,
      "grad_norm": 0.49703168869018555,
      "learning_rate": 4.352529912065735e-05,
      "loss": 0.0004,
      "step": 26950
    },
    {
      "epoch": 1.2973908029407526,
      "grad_norm": 0.0926581546664238,
      "learning_rate": 4.351328624285234e-05,
      "loss": 0.0003,
      "step": 27000
    },
    {
      "epoch": 1.299793378501754,
      "grad_norm": 0.11523832380771637,
      "learning_rate": 4.350127336504734e-05,
      "loss": 0.0002,
      "step": 27050
    },
    {
      "epoch": 1.3021959540627552,
      "grad_norm": 0.24311117827892303,
      "learning_rate": 4.348926048724233e-05,
      "loss": 0.0003,
      "step": 27100
    },
    {
      "epoch": 1.3045985296237568,
      "grad_norm": 0.1388663351535797,
      "learning_rate": 4.347724760943732e-05,
      "loss": 0.0003,
      "step": 27150
    },
    {
      "epoch": 1.307001105184758,
      "grad_norm": 0.599384605884552,
      "learning_rate": 4.346523473163231e-05,
      "loss": 0.0003,
      "step": 27200
    },
    {
      "epoch": 1.3094036807457594,
      "grad_norm": 0.3037467300891876,
      "learning_rate": 4.34532218538273e-05,
      "loss": 0.0009,
      "step": 27250
    },
    {
      "epoch": 1.311806256306761,
      "grad_norm": 0.11500087380409241,
      "learning_rate": 4.34412089760223e-05,
      "loss": 0.0003,
      "step": 27300
    },
    {
      "epoch": 1.3142088318677623,
      "grad_norm": 0.08916129916906357,
      "learning_rate": 4.342919609821729e-05,
      "loss": 0.0004,
      "step": 27350
    },
    {
      "epoch": 1.3166114074287636,
      "grad_norm": 0.17197869718074799,
      "learning_rate": 4.3417183220412286e-05,
      "loss": 0.0004,
      "step": 27400
    },
    {
      "epoch": 1.3190139829897651,
      "grad_norm": 0.23490162193775177,
      "learning_rate": 4.340517034260728e-05,
      "loss": 0.0003,
      "step": 27450
    },
    {
      "epoch": 1.3214165585507665,
      "grad_norm": 0.17945760488510132,
      "learning_rate": 4.339315746480227e-05,
      "loss": 0.0002,
      "step": 27500
    },
    {
      "epoch": 1.3238191341117678,
      "grad_norm": 0.1592765748500824,
      "learning_rate": 4.3381144586997265e-05,
      "loss": 0.001,
      "step": 27550
    },
    {
      "epoch": 1.3262217096727693,
      "grad_norm": 0.24011379480361938,
      "learning_rate": 4.3369131709192256e-05,
      "loss": 0.0002,
      "step": 27600
    },
    {
      "epoch": 1.3286242852337706,
      "grad_norm": 0.3405603766441345,
      "learning_rate": 4.335711883138725e-05,
      "loss": 0.0003,
      "step": 27650
    },
    {
      "epoch": 1.331026860794772,
      "grad_norm": 0.7615110278129578,
      "learning_rate": 4.3345105953582245e-05,
      "loss": 0.0005,
      "step": 27700
    },
    {
      "epoch": 1.3334294363557735,
      "grad_norm": 0.20746034383773804,
      "learning_rate": 4.3333093075777235e-05,
      "loss": 0.0003,
      "step": 27750
    },
    {
      "epoch": 1.3358320119167748,
      "grad_norm": 0.08179829269647598,
      "learning_rate": 4.332108019797223e-05,
      "loss": 0.0002,
      "step": 27800
    },
    {
      "epoch": 1.3382345874777761,
      "grad_norm": 0.436138391494751,
      "learning_rate": 4.3309067320167224e-05,
      "loss": 0.0003,
      "step": 27850
    },
    {
      "epoch": 1.3406371630387777,
      "grad_norm": 0.3941299617290497,
      "learning_rate": 4.3297054442362215e-05,
      "loss": 0.0003,
      "step": 27900
    },
    {
      "epoch": 1.343039738599779,
      "grad_norm": 0.12981241941452026,
      "learning_rate": 4.3285041564557206e-05,
      "loss": 0.0002,
      "step": 27950
    },
    {
      "epoch": 1.3454423141607803,
      "grad_norm": 0.47842663526535034,
      "learning_rate": 4.3273028686752196e-05,
      "loss": 0.0002,
      "step": 28000
    },
    {
      "epoch": 1.3478448897217818,
      "grad_norm": 0.1500474363565445,
      "learning_rate": 4.3261015808947194e-05,
      "loss": 0.0003,
      "step": 28050
    },
    {
      "epoch": 1.3502474652827832,
      "grad_norm": 0.3616204261779785,
      "learning_rate": 4.3249002931142185e-05,
      "loss": 0.0004,
      "step": 28100
    },
    {
      "epoch": 1.3526500408437845,
      "grad_norm": 0.6762105226516724,
      "learning_rate": 4.3236990053337176e-05,
      "loss": 0.0004,
      "step": 28150
    },
    {
      "epoch": 1.355052616404786,
      "grad_norm": 0.3510049283504486,
      "learning_rate": 4.322497717553217e-05,
      "loss": 0.0011,
      "step": 28200
    },
    {
      "epoch": 1.3574551919657873,
      "grad_norm": 0.17117348313331604,
      "learning_rate": 4.3212964297727164e-05,
      "loss": 0.0003,
      "step": 28250
    },
    {
      "epoch": 1.3598577675267887,
      "grad_norm": 0.21711799502372742,
      "learning_rate": 4.320095141992216e-05,
      "loss": 0.0002,
      "step": 28300
    },
    {
      "epoch": 1.3622603430877902,
      "grad_norm": 0.08745494484901428,
      "learning_rate": 4.318893854211715e-05,
      "loss": 0.0002,
      "step": 28350
    },
    {
      "epoch": 1.3646629186487915,
      "grad_norm": 0.12792468070983887,
      "learning_rate": 4.317692566431214e-05,
      "loss": 0.0003,
      "step": 28400
    },
    {
      "epoch": 1.3670654942097928,
      "grad_norm": 0.36621537804603577,
      "learning_rate": 4.316491278650714e-05,
      "loss": 0.0003,
      "step": 28450
    },
    {
      "epoch": 1.3694680697707944,
      "grad_norm": 0.14626337587833405,
      "learning_rate": 4.315289990870213e-05,
      "loss": 0.0012,
      "step": 28500
    },
    {
      "epoch": 1.3718706453317957,
      "grad_norm": 0.4535680413246155,
      "learning_rate": 4.314088703089712e-05,
      "loss": 0.0003,
      "step": 28550
    },
    {
      "epoch": 1.374273220892797,
      "grad_norm": 0.4323645234107971,
      "learning_rate": 4.312887415309212e-05,
      "loss": 0.0003,
      "step": 28600
    },
    {
      "epoch": 1.3766757964537986,
      "grad_norm": 0.601742148399353,
      "learning_rate": 4.311686127528711e-05,
      "loss": 0.0011,
      "step": 28650
    },
    {
      "epoch": 1.3790783720147999,
      "grad_norm": 0.1767137199640274,
      "learning_rate": 4.31048483974821e-05,
      "loss": 0.0003,
      "step": 28700
    },
    {
      "epoch": 1.3814809475758012,
      "grad_norm": 0.20287391543388367,
      "learning_rate": 4.309283551967709e-05,
      "loss": 0.0002,
      "step": 28750
    },
    {
      "epoch": 1.3838835231368027,
      "grad_norm": 0.5216000080108643,
      "learning_rate": 4.308082264187209e-05,
      "loss": 0.0002,
      "step": 28800
    },
    {
      "epoch": 1.386286098697804,
      "grad_norm": 0.29561862349510193,
      "learning_rate": 4.306880976406708e-05,
      "loss": 0.0003,
      "step": 28850
    },
    {
      "epoch": 1.3886886742588054,
      "grad_norm": 0.3404546082019806,
      "learning_rate": 4.305679688626207e-05,
      "loss": 0.0003,
      "step": 28900
    },
    {
      "epoch": 1.391091249819807,
      "grad_norm": 0.11266584694385529,
      "learning_rate": 4.304478400845707e-05,
      "loss": 0.0004,
      "step": 28950
    },
    {
      "epoch": 1.3934938253808082,
      "grad_norm": 0.33060622215270996,
      "learning_rate": 4.303277113065206e-05,
      "loss": 0.0003,
      "step": 29000
    },
    {
      "epoch": 1.3958964009418096,
      "grad_norm": 0.32409390807151794,
      "learning_rate": 4.302075825284705e-05,
      "loss": 0.0003,
      "step": 29050
    },
    {
      "epoch": 1.398298976502811,
      "grad_norm": 0.09549912810325623,
      "learning_rate": 4.300874537504205e-05,
      "loss": 0.0003,
      "step": 29100
    },
    {
      "epoch": 1.4007015520638124,
      "grad_norm": 0.28782257437705994,
      "learning_rate": 4.299673249723704e-05,
      "loss": 0.0005,
      "step": 29150
    },
    {
      "epoch": 1.4031041276248137,
      "grad_norm": 0.49200430512428284,
      "learning_rate": 4.298471961943204e-05,
      "loss": 0.0002,
      "step": 29200
    },
    {
      "epoch": 1.4055067031858153,
      "grad_norm": 0.07874685525894165,
      "learning_rate": 4.297270674162703e-05,
      "loss": 0.001,
      "step": 29250
    },
    {
      "epoch": 1.4079092787468166,
      "grad_norm": 0.13831672072410583,
      "learning_rate": 4.296069386382202e-05,
      "loss": 0.0003,
      "step": 29300
    },
    {
      "epoch": 1.410311854307818,
      "grad_norm": 0.10804431885480881,
      "learning_rate": 4.2948680986017016e-05,
      "loss": 0.0003,
      "step": 29350
    },
    {
      "epoch": 1.4127144298688195,
      "grad_norm": 0.4337581694126129,
      "learning_rate": 4.2936668108212e-05,
      "loss": 0.0003,
      "step": 29400
    },
    {
      "epoch": 1.4151170054298208,
      "grad_norm": 0.11263225972652435,
      "learning_rate": 4.2924655230407e-05,
      "loss": 0.0011,
      "step": 29450
    },
    {
      "epoch": 1.417519580990822,
      "grad_norm": 0.2660137414932251,
      "learning_rate": 4.291264235260199e-05,
      "loss": 0.0003,
      "step": 29500
    },
    {
      "epoch": 1.4199221565518236,
      "grad_norm": 0.3360635042190552,
      "learning_rate": 4.290062947479698e-05,
      "loss": 0.0009,
      "step": 29550
    },
    {
      "epoch": 1.422324732112825,
      "grad_norm": 0.1136658787727356,
      "learning_rate": 4.288861659699198e-05,
      "loss": 0.0002,
      "step": 29600
    },
    {
      "epoch": 1.4247273076738263,
      "grad_norm": 0.32145658135414124,
      "learning_rate": 4.287660371918697e-05,
      "loss": 0.0003,
      "step": 29650
    },
    {
      "epoch": 1.4271298832348278,
      "grad_norm": 0.194465771317482,
      "learning_rate": 4.2864590841381966e-05,
      "loss": 0.0003,
      "step": 29700
    },
    {
      "epoch": 1.4295324587958291,
      "grad_norm": 0.3283785879611969,
      "learning_rate": 4.2852577963576957e-05,
      "loss": 0.0003,
      "step": 29750
    },
    {
      "epoch": 1.4319350343568304,
      "grad_norm": 0.576633632183075,
      "learning_rate": 4.284056508577195e-05,
      "loss": 0.0002,
      "step": 29800
    },
    {
      "epoch": 1.434337609917832,
      "grad_norm": 0.0425812192261219,
      "learning_rate": 4.2828552207966945e-05,
      "loss": 0.0003,
      "step": 29850
    },
    {
      "epoch": 1.4367401854788333,
      "grad_norm": 0.37768885493278503,
      "learning_rate": 4.2816539330161936e-05,
      "loss": 0.0012,
      "step": 29900
    },
    {
      "epoch": 1.4391427610398346,
      "grad_norm": 0.47589078545570374,
      "learning_rate": 4.280452645235693e-05,
      "loss": 0.0005,
      "step": 29950
    },
    {
      "epoch": 1.4415453366008362,
      "grad_norm": 0.164137065410614,
      "learning_rate": 4.2792513574551924e-05,
      "loss": 0.0003,
      "step": 30000
    },
    {
      "epoch": 1.4439479121618375,
      "grad_norm": 0.7602103352546692,
      "learning_rate": 4.2780500696746915e-05,
      "loss": 0.0009,
      "step": 30050
    },
    {
      "epoch": 1.4463504877228388,
      "grad_norm": 0.3185465633869171,
      "learning_rate": 4.276848781894191e-05,
      "loss": 0.0002,
      "step": 30100
    },
    {
      "epoch": 1.4487530632838403,
      "grad_norm": 0.23874111473560333,
      "learning_rate": 4.27564749411369e-05,
      "loss": 0.0003,
      "step": 30150
    },
    {
      "epoch": 1.4511556388448417,
      "grad_norm": 0.1396084576845169,
      "learning_rate": 4.2744462063331894e-05,
      "loss": 0.0003,
      "step": 30200
    },
    {
      "epoch": 1.453558214405843,
      "grad_norm": 0.2125507891178131,
      "learning_rate": 4.2732449185526885e-05,
      "loss": 0.0002,
      "step": 30250
    },
    {
      "epoch": 1.4559607899668445,
      "grad_norm": 0.35699817538261414,
      "learning_rate": 4.2720436307721876e-05,
      "loss": 0.0003,
      "step": 30300
    },
    {
      "epoch": 1.4583633655278458,
      "grad_norm": 0.25961363315582275,
      "learning_rate": 4.2708423429916874e-05,
      "loss": 0.0002,
      "step": 30350
    },
    {
      "epoch": 1.4607659410888472,
      "grad_norm": 0.29363036155700684,
      "learning_rate": 4.2696410552111864e-05,
      "loss": 0.0004,
      "step": 30400
    },
    {
      "epoch": 1.4631685166498487,
      "grad_norm": 0.1365731954574585,
      "learning_rate": 4.2684397674306855e-05,
      "loss": 0.0003,
      "step": 30450
    },
    {
      "epoch": 1.46557109221085,
      "grad_norm": 0.30721086263656616,
      "learning_rate": 4.267238479650185e-05,
      "loss": 0.0003,
      "step": 30500
    },
    {
      "epoch": 1.4679736677718513,
      "grad_norm": 0.640612781047821,
      "learning_rate": 4.2660371918696844e-05,
      "loss": 0.0008,
      "step": 30550
    },
    {
      "epoch": 1.4703762433328529,
      "grad_norm": 0.22630193829536438,
      "learning_rate": 4.264835904089184e-05,
      "loss": 0.0002,
      "step": 30600
    },
    {
      "epoch": 1.4727788188938542,
      "grad_norm": 0.6640514731407166,
      "learning_rate": 4.263634616308683e-05,
      "loss": 0.0003,
      "step": 30650
    },
    {
      "epoch": 1.4751813944548555,
      "grad_norm": 0.4187709093093872,
      "learning_rate": 4.262433328528182e-05,
      "loss": 0.0002,
      "step": 30700
    },
    {
      "epoch": 1.477583970015857,
      "grad_norm": 0.3012326955795288,
      "learning_rate": 4.261232040747682e-05,
      "loss": 0.0003,
      "step": 30750
    },
    {
      "epoch": 1.4799865455768584,
      "grad_norm": 0.4089412987232208,
      "learning_rate": 4.260030752967181e-05,
      "loss": 0.0002,
      "step": 30800
    },
    {
      "epoch": 1.4823891211378597,
      "grad_norm": 0.21691793203353882,
      "learning_rate": 4.258829465186681e-05,
      "loss": 0.0003,
      "step": 30850
    },
    {
      "epoch": 1.4847916966988612,
      "grad_norm": 0.08132248371839523,
      "learning_rate": 4.257628177406179e-05,
      "loss": 0.0002,
      "step": 30900
    },
    {
      "epoch": 1.4871942722598626,
      "grad_norm": 0.15930189192295074,
      "learning_rate": 4.2564268896256784e-05,
      "loss": 0.0003,
      "step": 30950
    },
    {
      "epoch": 1.4895968478208639,
      "grad_norm": 0.4160701036453247,
      "learning_rate": 4.255225601845178e-05,
      "loss": 0.0003,
      "step": 31000
    },
    {
      "epoch": 1.4919994233818654,
      "grad_norm": 0.5281301736831665,
      "learning_rate": 4.254024314064677e-05,
      "loss": 0.0002,
      "step": 31050
    },
    {
      "epoch": 1.4944019989428667,
      "grad_norm": 0.10806836932897568,
      "learning_rate": 4.252823026284177e-05,
      "loss": 0.0004,
      "step": 31100
    },
    {
      "epoch": 1.496804574503868,
      "grad_norm": 0.21593758463859558,
      "learning_rate": 4.251621738503676e-05,
      "loss": 0.0011,
      "step": 31150
    },
    {
      "epoch": 1.4992071500648696,
      "grad_norm": 0.1427089422941208,
      "learning_rate": 4.250420450723175e-05,
      "loss": 0.0002,
      "step": 31200
    },
    {
      "epoch": 1.501609725625871,
      "grad_norm": 0.05969393998384476,
      "learning_rate": 4.249219162942675e-05,
      "loss": 0.0003,
      "step": 31250
    },
    {
      "epoch": 1.5040123011868722,
      "grad_norm": 0.08626098185777664,
      "learning_rate": 4.248017875162174e-05,
      "loss": 0.0003,
      "step": 31300
    },
    {
      "epoch": 1.5064148767478738,
      "grad_norm": 0.026984207332134247,
      "learning_rate": 4.246816587381674e-05,
      "loss": 0.0002,
      "step": 31350
    },
    {
      "epoch": 1.508817452308875,
      "grad_norm": 0.09539730101823807,
      "learning_rate": 4.245615299601173e-05,
      "loss": 0.0002,
      "step": 31400
    },
    {
      "epoch": 1.5112200278698764,
      "grad_norm": 0.09265059977769852,
      "learning_rate": 4.244414011820672e-05,
      "loss": 0.0004,
      "step": 31450
    },
    {
      "epoch": 1.513622603430878,
      "grad_norm": 0.2843555212020874,
      "learning_rate": 4.243212724040172e-05,
      "loss": 0.001,
      "step": 31500
    },
    {
      "epoch": 1.5160251789918793,
      "grad_norm": 0.18011556565761566,
      "learning_rate": 4.242011436259671e-05,
      "loss": 0.0002,
      "step": 31550
    },
    {
      "epoch": 1.5184277545528806,
      "grad_norm": 0.3678586483001709,
      "learning_rate": 4.24081014847917e-05,
      "loss": 0.0002,
      "step": 31600
    },
    {
      "epoch": 1.5208303301138821,
      "grad_norm": 0.13767194747924805,
      "learning_rate": 4.239608860698669e-05,
      "loss": 0.0002,
      "step": 31650
    },
    {
      "epoch": 1.5232329056748835,
      "grad_norm": 0.3867296874523163,
      "learning_rate": 4.238407572918168e-05,
      "loss": 0.0003,
      "step": 31700
    },
    {
      "epoch": 1.5256354812358848,
      "grad_norm": 0.20831581950187683,
      "learning_rate": 4.237206285137668e-05,
      "loss": 0.0002,
      "step": 31750
    },
    {
      "epoch": 1.5280380567968863,
      "grad_norm": 0.07988113164901733,
      "learning_rate": 4.236004997357167e-05,
      "loss": 0.0002,
      "step": 31800
    },
    {
      "epoch": 1.5304406323578876,
      "grad_norm": 0.3909052312374115,
      "learning_rate": 4.2348037095766666e-05,
      "loss": 0.0002,
      "step": 31850
    },
    {
      "epoch": 1.532843207918889,
      "grad_norm": 0.2308759093284607,
      "learning_rate": 4.233602421796166e-05,
      "loss": 0.0002,
      "step": 31900
    },
    {
      "epoch": 1.5352457834798905,
      "grad_norm": 0.4335176348686218,
      "learning_rate": 4.232401134015665e-05,
      "loss": 0.0002,
      "step": 31950
    },
    {
      "epoch": 1.5376483590408918,
      "grad_norm": 0.16163888573646545,
      "learning_rate": 4.2311998462351645e-05,
      "loss": 0.0003,
      "step": 32000
    },
    {
      "epoch": 1.5400509346018931,
      "grad_norm": 0.5345222353935242,
      "learning_rate": 4.2299985584546636e-05,
      "loss": 0.0002,
      "step": 32050
    },
    {
      "epoch": 1.5424535101628947,
      "grad_norm": 0.237000972032547,
      "learning_rate": 4.228797270674163e-05,
      "loss": 0.0002,
      "step": 32100
    },
    {
      "epoch": 1.544856085723896,
      "grad_norm": 0.35432982444763184,
      "learning_rate": 4.2275959828936625e-05,
      "loss": 0.0004,
      "step": 32150
    },
    {
      "epoch": 1.5472586612848973,
      "grad_norm": 0.060881394892930984,
      "learning_rate": 4.2263946951131615e-05,
      "loss": 0.0003,
      "step": 32200
    },
    {
      "epoch": 1.5496612368458988,
      "grad_norm": 0.0964832603931427,
      "learning_rate": 4.225193407332661e-05,
      "loss": 0.0002,
      "step": 32250
    },
    {
      "epoch": 1.5520638124069002,
      "grad_norm": 0.5365875363349915,
      "learning_rate": 4.2239921195521604e-05,
      "loss": 0.0003,
      "step": 32300
    },
    {
      "epoch": 1.5544663879679015,
      "grad_norm": 0.2716146409511566,
      "learning_rate": 4.2227908317716595e-05,
      "loss": 0.0004,
      "step": 32350
    },
    {
      "epoch": 1.556868963528903,
      "grad_norm": 0.39388301968574524,
      "learning_rate": 4.2215895439911586e-05,
      "loss": 0.0003,
      "step": 32400
    },
    {
      "epoch": 1.5592715390899043,
      "grad_norm": 0.08570656925439835,
      "learning_rate": 4.2203882562106576e-05,
      "loss": 0.0003,
      "step": 32450
    },
    {
      "epoch": 1.5616741146509057,
      "grad_norm": 0.190058171749115,
      "learning_rate": 4.2191869684301574e-05,
      "loss": 0.0002,
      "step": 32500
    },
    {
      "epoch": 1.5640766902119072,
      "grad_norm": 0.4508114457130432,
      "learning_rate": 4.2179856806496565e-05,
      "loss": 0.0002,
      "step": 32550
    },
    {
      "epoch": 1.5664792657729085,
      "grad_norm": 0.08796123415231705,
      "learning_rate": 4.2167843928691556e-05,
      "loss": 0.0002,
      "step": 32600
    },
    {
      "epoch": 1.5688818413339098,
      "grad_norm": 0.23510205745697021,
      "learning_rate": 4.215583105088655e-05,
      "loss": 0.0002,
      "step": 32650
    },
    {
      "epoch": 1.5712844168949114,
      "grad_norm": 0.11995519697666168,
      "learning_rate": 4.2143818173081544e-05,
      "loss": 0.0002,
      "step": 32700
    },
    {
      "epoch": 1.5736869924559127,
      "grad_norm": 0.13486680388450623,
      "learning_rate": 4.213180529527654e-05,
      "loss": 0.0003,
      "step": 32750
    },
    {
      "epoch": 1.576089568016914,
      "grad_norm": 0.36394456028938293,
      "learning_rate": 4.211979241747153e-05,
      "loss": 0.0003,
      "step": 32800
    },
    {
      "epoch": 1.5784921435779156,
      "grad_norm": 0.1545395404100418,
      "learning_rate": 4.210777953966652e-05,
      "loss": 0.0011,
      "step": 32850
    },
    {
      "epoch": 1.5808947191389169,
      "grad_norm": 0.11312085390090942,
      "learning_rate": 4.209576666186152e-05,
      "loss": 0.0003,
      "step": 32900
    },
    {
      "epoch": 1.5832972946999182,
      "grad_norm": 0.3543778359889984,
      "learning_rate": 4.208375378405651e-05,
      "loss": 0.0002,
      "step": 32950
    },
    {
      "epoch": 1.5856998702609197,
      "grad_norm": 0.31481650471687317,
      "learning_rate": 4.20717409062515e-05,
      "loss": 0.0003,
      "step": 33000
    },
    {
      "epoch": 1.588102445821921,
      "grad_norm": 0.17454153299331665,
      "learning_rate": 4.20597280284465e-05,
      "loss": 0.0003,
      "step": 33050
    },
    {
      "epoch": 1.5905050213829224,
      "grad_norm": 0.5287648439407349,
      "learning_rate": 4.204771515064149e-05,
      "loss": 0.0003,
      "step": 33100
    },
    {
      "epoch": 1.592907596943924,
      "grad_norm": 0.20385953783988953,
      "learning_rate": 4.203570227283648e-05,
      "loss": 0.0003,
      "step": 33150
    },
    {
      "epoch": 1.5953101725049252,
      "grad_norm": 0.1850849688053131,
      "learning_rate": 4.202368939503147e-05,
      "loss": 0.0003,
      "step": 33200
    },
    {
      "epoch": 1.5977127480659266,
      "grad_norm": 0.16656316816806793,
      "learning_rate": 4.201167651722647e-05,
      "loss": 0.0003,
      "step": 33250
    },
    {
      "epoch": 1.600115323626928,
      "grad_norm": 0.3665350079536438,
      "learning_rate": 4.199966363942146e-05,
      "loss": 0.0003,
      "step": 33300
    },
    {
      "epoch": 1.6025178991879294,
      "grad_norm": 0.5673137903213501,
      "learning_rate": 4.198765076161645e-05,
      "loss": 0.0002,
      "step": 33350
    },
    {
      "epoch": 1.6049204747489307,
      "grad_norm": 0.04722507670521736,
      "learning_rate": 4.197563788381145e-05,
      "loss": 0.0004,
      "step": 33400
    },
    {
      "epoch": 1.6073230503099323,
      "grad_norm": 0.1257496327161789,
      "learning_rate": 4.196362500600644e-05,
      "loss": 0.0003,
      "step": 33450
    },
    {
      "epoch": 1.6097256258709336,
      "grad_norm": 0.5992549061775208,
      "learning_rate": 4.195161212820143e-05,
      "loss": 0.0002,
      "step": 33500
    },
    {
      "epoch": 1.612128201431935,
      "grad_norm": 0.14945244789123535,
      "learning_rate": 4.193959925039643e-05,
      "loss": 0.0003,
      "step": 33550
    },
    {
      "epoch": 1.6145307769929365,
      "grad_norm": 0.1723501831293106,
      "learning_rate": 4.192758637259142e-05,
      "loss": 0.0003,
      "step": 33600
    },
    {
      "epoch": 1.6169333525539378,
      "grad_norm": 0.2389804571866989,
      "learning_rate": 4.191557349478642e-05,
      "loss": 0.0003,
      "step": 33650
    },
    {
      "epoch": 1.619335928114939,
      "grad_norm": 0.33987101912498474,
      "learning_rate": 4.190356061698141e-05,
      "loss": 0.0003,
      "step": 33700
    },
    {
      "epoch": 1.6217385036759406,
      "grad_norm": 0.41195741295814514,
      "learning_rate": 4.18915477391764e-05,
      "loss": 0.0003,
      "step": 33750
    },
    {
      "epoch": 1.624141079236942,
      "grad_norm": 0.09031356126070023,
      "learning_rate": 4.1879534861371396e-05,
      "loss": 0.0002,
      "step": 33800
    },
    {
      "epoch": 1.6265436547979433,
      "grad_norm": 0.2568168044090271,
      "learning_rate": 4.186752198356639e-05,
      "loss": 0.0002,
      "step": 33850
    },
    {
      "epoch": 1.6289462303589448,
      "grad_norm": 0.18387679755687714,
      "learning_rate": 4.185550910576138e-05,
      "loss": 0.0003,
      "step": 33900
    },
    {
      "epoch": 1.6313488059199461,
      "grad_norm": 0.2915133237838745,
      "learning_rate": 4.184349622795637e-05,
      "loss": 0.0002,
      "step": 33950
    },
    {
      "epoch": 1.6337513814809475,
      "grad_norm": 0.12326949089765549,
      "learning_rate": 4.183148335015136e-05,
      "loss": 0.0002,
      "step": 34000
    },
    {
      "epoch": 1.636153957041949,
      "grad_norm": 0.3017825782299042,
      "learning_rate": 4.181947047234636e-05,
      "loss": 0.0002,
      "step": 34050
    },
    {
      "epoch": 1.6385565326029503,
      "grad_norm": 0.29881033301353455,
      "learning_rate": 4.180745759454135e-05,
      "loss": 0.0002,
      "step": 34100
    },
    {
      "epoch": 1.6409591081639516,
      "grad_norm": 0.35508668422698975,
      "learning_rate": 4.1795444716736346e-05,
      "loss": 0.0002,
      "step": 34150
    },
    {
      "epoch": 1.6433616837249532,
      "grad_norm": 0.5199384093284607,
      "learning_rate": 4.1783431838931337e-05,
      "loss": 0.0003,
      "step": 34200
    },
    {
      "epoch": 1.6457642592859545,
      "grad_norm": 0.15887679159641266,
      "learning_rate": 4.177141896112633e-05,
      "loss": 0.0008,
      "step": 34250
    },
    {
      "epoch": 1.6481668348469558,
      "grad_norm": 0.1304912120103836,
      "learning_rate": 4.1759406083321325e-05,
      "loss": 0.0003,
      "step": 34300
    },
    {
      "epoch": 1.6505694104079573,
      "grad_norm": 0.4180145561695099,
      "learning_rate": 4.1747393205516316e-05,
      "loss": 0.0003,
      "step": 34350
    },
    {
      "epoch": 1.652971985968959,
      "grad_norm": 0.10353469848632812,
      "learning_rate": 4.173538032771131e-05,
      "loss": 0.0002,
      "step": 34400
    },
    {
      "epoch": 1.65537456152996,
      "grad_norm": 0.1877821832895279,
      "learning_rate": 4.1723367449906304e-05,
      "loss": 0.0002,
      "step": 34450
    },
    {
      "epoch": 1.6577771370909615,
      "grad_norm": 0.27038851380348206,
      "learning_rate": 4.1711354572101295e-05,
      "loss": 0.0004,
      "step": 34500
    },
    {
      "epoch": 1.660179712651963,
      "grad_norm": 0.4811370372772217,
      "learning_rate": 4.169934169429629e-05,
      "loss": 0.0002,
      "step": 34550
    },
    {
      "epoch": 1.6625822882129642,
      "grad_norm": 0.729203462600708,
      "learning_rate": 4.1687328816491283e-05,
      "loss": 0.0003,
      "step": 34600
    },
    {
      "epoch": 1.6649848637739657,
      "grad_norm": 0.2977149784564972,
      "learning_rate": 4.1675315938686274e-05,
      "loss": 0.001,
      "step": 34650
    },
    {
      "epoch": 1.6673874393349672,
      "grad_norm": 0.5466206073760986,
      "learning_rate": 4.1663303060881265e-05,
      "loss": 0.0003,
      "step": 34700
    },
    {
      "epoch": 1.6697900148959683,
      "grad_norm": 0.2511705160140991,
      "learning_rate": 4.1651290183076256e-05,
      "loss": 0.0002,
      "step": 34750
    },
    {
      "epoch": 1.6721925904569699,
      "grad_norm": 0.6213825345039368,
      "learning_rate": 4.1639277305271254e-05,
      "loss": 0.0004,
      "step": 34800
    },
    {
      "epoch": 1.6745951660179714,
      "grad_norm": 0.3363088071346283,
      "learning_rate": 4.1627264427466244e-05,
      "loss": 0.0002,
      "step": 34850
    },
    {
      "epoch": 1.6769977415789725,
      "grad_norm": 0.1599172055721283,
      "learning_rate": 4.1615251549661235e-05,
      "loss": 0.0002,
      "step": 34900
    },
    {
      "epoch": 1.679400317139974,
      "grad_norm": 0.07233303040266037,
      "learning_rate": 4.160323867185623e-05,
      "loss": 0.0004,
      "step": 34950
    },
    {
      "epoch": 1.6818028927009756,
      "grad_norm": 0.3721114695072174,
      "learning_rate": 4.1591225794051224e-05,
      "loss": 0.0002,
      "step": 35000
    },
    {
      "epoch": 1.6842054682619767,
      "grad_norm": 0.24913601577281952,
      "learning_rate": 4.157921291624622e-05,
      "loss": 0.0003,
      "step": 35050
    },
    {
      "epoch": 1.6866080438229782,
      "grad_norm": 0.08896638453006744,
      "learning_rate": 4.156720003844121e-05,
      "loss": 0.0002,
      "step": 35100
    },
    {
      "epoch": 1.6890106193839798,
      "grad_norm": 0.3941357135772705,
      "learning_rate": 4.15551871606362e-05,
      "loss": 0.0003,
      "step": 35150
    },
    {
      "epoch": 1.6914131949449809,
      "grad_norm": 0.5122926235198975,
      "learning_rate": 4.15431742828312e-05,
      "loss": 0.0002,
      "step": 35200
    },
    {
      "epoch": 1.6938157705059824,
      "grad_norm": 0.30820155143737793,
      "learning_rate": 4.153116140502619e-05,
      "loss": 0.0002,
      "step": 35250
    },
    {
      "epoch": 1.696218346066984,
      "grad_norm": 0.5839250087738037,
      "learning_rate": 4.151914852722118e-05,
      "loss": 0.0003,
      "step": 35300
    },
    {
      "epoch": 1.698620921627985,
      "grad_norm": 0.13412070274353027,
      "learning_rate": 4.150713564941617e-05,
      "loss": 0.0002,
      "step": 35350
    },
    {
      "epoch": 1.7010234971889866,
      "grad_norm": 0.14241409301757812,
      "learning_rate": 4.1495122771611164e-05,
      "loss": 0.0002,
      "step": 35400
    },
    {
      "epoch": 1.7034260727499881,
      "grad_norm": 0.46300357580184937,
      "learning_rate": 4.148310989380616e-05,
      "loss": 0.0002,
      "step": 35450
    },
    {
      "epoch": 1.7058286483109892,
      "grad_norm": 0.036088261753320694,
      "learning_rate": 4.147109701600115e-05,
      "loss": 0.0011,
      "step": 35500
    },
    {
      "epoch": 1.7082312238719908,
      "grad_norm": 0.6255699396133423,
      "learning_rate": 4.145908413819615e-05,
      "loss": 0.0003,
      "step": 35550
    },
    {
      "epoch": 1.7106337994329923,
      "grad_norm": 0.1893894076347351,
      "learning_rate": 4.144707126039114e-05,
      "loss": 0.0003,
      "step": 35600
    },
    {
      "epoch": 1.7130363749939934,
      "grad_norm": 0.05650782585144043,
      "learning_rate": 4.143505838258613e-05,
      "loss": 0.0009,
      "step": 35650
    },
    {
      "epoch": 1.715438950554995,
      "grad_norm": 0.31366342306137085,
      "learning_rate": 4.142304550478113e-05,
      "loss": 0.0004,
      "step": 35700
    },
    {
      "epoch": 1.7178415261159965,
      "grad_norm": 0.28387412428855896,
      "learning_rate": 4.141103262697612e-05,
      "loss": 0.0002,
      "step": 35750
    },
    {
      "epoch": 1.7202441016769976,
      "grad_norm": 0.1361163705587387,
      "learning_rate": 4.139901974917111e-05,
      "loss": 0.0003,
      "step": 35800
    },
    {
      "epoch": 1.7226466772379991,
      "grad_norm": 0.3791709840297699,
      "learning_rate": 4.138700687136611e-05,
      "loss": 0.0002,
      "step": 35850
    },
    {
      "epoch": 1.7250492527990007,
      "grad_norm": 0.22244006395339966,
      "learning_rate": 4.13749939935611e-05,
      "loss": 0.0003,
      "step": 35900
    },
    {
      "epoch": 1.7274518283600018,
      "grad_norm": 0.3066266179084778,
      "learning_rate": 4.13629811157561e-05,
      "loss": 0.0003,
      "step": 35950
    },
    {
      "epoch": 1.7298544039210033,
      "grad_norm": 0.3854101300239563,
      "learning_rate": 4.135096823795109e-05,
      "loss": 0.0002,
      "step": 36000
    },
    {
      "epoch": 1.7322569794820049,
      "grad_norm": 0.4062853157520294,
      "learning_rate": 4.133895536014608e-05,
      "loss": 0.0003,
      "step": 36050
    },
    {
      "epoch": 1.734659555043006,
      "grad_norm": 0.5119354724884033,
      "learning_rate": 4.132694248234107e-05,
      "loss": 0.0003,
      "step": 36100
    },
    {
      "epoch": 1.7370621306040075,
      "grad_norm": 0.06919097155332565,
      "learning_rate": 4.131492960453606e-05,
      "loss": 0.0003,
      "step": 36150
    },
    {
      "epoch": 1.739464706165009,
      "grad_norm": 0.6276270151138306,
      "learning_rate": 4.130291672673106e-05,
      "loss": 0.0002,
      "step": 36200
    },
    {
      "epoch": 1.7418672817260101,
      "grad_norm": 0.14591342210769653,
      "learning_rate": 4.129090384892605e-05,
      "loss": 0.0003,
      "step": 36250
    },
    {
      "epoch": 1.7442698572870117,
      "grad_norm": 0.42434728145599365,
      "learning_rate": 4.127889097112104e-05,
      "loss": 0.0002,
      "step": 36300
    },
    {
      "epoch": 1.7466724328480132,
      "grad_norm": 0.11878709495067596,
      "learning_rate": 4.126687809331604e-05,
      "loss": 0.0002,
      "step": 36350
    },
    {
      "epoch": 1.7490750084090143,
      "grad_norm": 0.4091390371322632,
      "learning_rate": 4.125486521551103e-05,
      "loss": 0.0003,
      "step": 36400
    },
    {
      "epoch": 1.7514775839700158,
      "grad_norm": 0.1838543713092804,
      "learning_rate": 4.1242852337706025e-05,
      "loss": 0.0003,
      "step": 36450
    },
    {
      "epoch": 1.7538801595310174,
      "grad_norm": 0.47276055812835693,
      "learning_rate": 4.1230839459901016e-05,
      "loss": 0.0002,
      "step": 36500
    },
    {
      "epoch": 1.7562827350920185,
      "grad_norm": 0.08667374402284622,
      "learning_rate": 4.121882658209601e-05,
      "loss": 0.0002,
      "step": 36550
    },
    {
      "epoch": 1.75868531065302,
      "grad_norm": 0.45751887559890747,
      "learning_rate": 4.1206813704291005e-05,
      "loss": 0.0003,
      "step": 36600
    },
    {
      "epoch": 1.7610878862140216,
      "grad_norm": 0.30253908038139343,
      "learning_rate": 4.1194800826485995e-05,
      "loss": 0.0002,
      "step": 36650
    },
    {
      "epoch": 1.7634904617750227,
      "grad_norm": 0.1844957023859024,
      "learning_rate": 4.118278794868099e-05,
      "loss": 0.0003,
      "step": 36700
    },
    {
      "epoch": 1.7658930373360242,
      "grad_norm": 0.08654098212718964,
      "learning_rate": 4.1170775070875984e-05,
      "loss": 0.0007,
      "step": 36750
    },
    {
      "epoch": 1.7682956128970257,
      "grad_norm": 0.13357271254062653,
      "learning_rate": 4.1158762193070975e-05,
      "loss": 0.0002,
      "step": 36800
    },
    {
      "epoch": 1.7706981884580268,
      "grad_norm": 0.2089388221502304,
      "learning_rate": 4.1146749315265966e-05,
      "loss": 0.0003,
      "step": 36850
    },
    {
      "epoch": 1.7731007640190284,
      "grad_norm": 0.3014194965362549,
      "learning_rate": 4.1134736437460956e-05,
      "loss": 0.0003,
      "step": 36900
    },
    {
      "epoch": 1.77550333958003,
      "grad_norm": 0.12939698994159698,
      "learning_rate": 4.1122723559655954e-05,
      "loss": 0.0002,
      "step": 36950
    },
    {
      "epoch": 1.777905915141031,
      "grad_norm": 0.05046879127621651,
      "learning_rate": 4.1110710681850945e-05,
      "loss": 0.0004,
      "step": 37000
    },
    {
      "epoch": 1.7803084907020326,
      "grad_norm": 0.8090863823890686,
      "learning_rate": 4.1098697804045936e-05,
      "loss": 0.0003,
      "step": 37050
    },
    {
      "epoch": 1.782711066263034,
      "grad_norm": 0.6488982439041138,
      "learning_rate": 4.108668492624093e-05,
      "loss": 0.001,
      "step": 37100
    },
    {
      "epoch": 1.7851136418240352,
      "grad_norm": 0.6103997230529785,
      "learning_rate": 4.1074672048435924e-05,
      "loss": 0.0003,
      "step": 37150
    },
    {
      "epoch": 1.7875162173850367,
      "grad_norm": 0.29312390089035034,
      "learning_rate": 4.106265917063092e-05,
      "loss": 0.0004,
      "step": 37200
    },
    {
      "epoch": 1.7899187929460383,
      "grad_norm": 0.22249676287174225,
      "learning_rate": 4.105064629282591e-05,
      "loss": 0.0003,
      "step": 37250
    },
    {
      "epoch": 1.7923213685070394,
      "grad_norm": 0.3814830183982849,
      "learning_rate": 4.10386334150209e-05,
      "loss": 0.0008,
      "step": 37300
    },
    {
      "epoch": 1.794723944068041,
      "grad_norm": 0.12901055812835693,
      "learning_rate": 4.10266205372159e-05,
      "loss": 0.0011,
      "step": 37350
    },
    {
      "epoch": 1.7971265196290425,
      "grad_norm": 0.45699819922447205,
      "learning_rate": 4.101460765941089e-05,
      "loss": 0.0002,
      "step": 37400
    },
    {
      "epoch": 1.7995290951900438,
      "grad_norm": 0.04736136272549629,
      "learning_rate": 4.100259478160588e-05,
      "loss": 0.0002,
      "step": 37450
    },
    {
      "epoch": 1.801931670751045,
      "grad_norm": 0.1926971971988678,
      "learning_rate": 4.099058190380088e-05,
      "loss": 0.0003,
      "step": 37500
    },
    {
      "epoch": 1.8043342463120466,
      "grad_norm": 0.24196864664554596,
      "learning_rate": 4.097856902599587e-05,
      "loss": 0.0002,
      "step": 37550
    },
    {
      "epoch": 1.806736821873048,
      "grad_norm": 0.5273232460021973,
      "learning_rate": 4.096655614819086e-05,
      "loss": 0.0003,
      "step": 37600
    },
    {
      "epoch": 1.8091393974340493,
      "grad_norm": 0.23905791342258453,
      "learning_rate": 4.095454327038585e-05,
      "loss": 0.0003,
      "step": 37650
    },
    {
      "epoch": 1.8115419729950508,
      "grad_norm": 0.14021927118301392,
      "learning_rate": 4.0942530392580843e-05,
      "loss": 0.0003,
      "step": 37700
    },
    {
      "epoch": 1.8139445485560521,
      "grad_norm": 0.12785185873508453,
      "learning_rate": 4.093051751477584e-05,
      "loss": 0.0002,
      "step": 37750
    },
    {
      "epoch": 1.8163471241170535,
      "grad_norm": 0.06755917519330978,
      "learning_rate": 4.091850463697083e-05,
      "loss": 0.0003,
      "step": 37800
    },
    {
      "epoch": 1.818749699678055,
      "grad_norm": 0.7578392028808594,
      "learning_rate": 4.090649175916583e-05,
      "loss": 0.0002,
      "step": 37850
    },
    {
      "epoch": 1.8211522752390563,
      "grad_norm": 0.16468165814876556,
      "learning_rate": 4.089447888136082e-05,
      "loss": 0.0002,
      "step": 37900
    },
    {
      "epoch": 1.8235548508000576,
      "grad_norm": 0.16600404679775238,
      "learning_rate": 4.088246600355581e-05,
      "loss": 0.0002,
      "step": 37950
    },
    {
      "epoch": 1.8259574263610592,
      "grad_norm": 0.3339490294456482,
      "learning_rate": 4.087045312575081e-05,
      "loss": 0.0002,
      "step": 38000
    },
    {
      "epoch": 1.8283600019220605,
      "grad_norm": 0.08461663126945496,
      "learning_rate": 4.08584402479458e-05,
      "loss": 0.0002,
      "step": 38050
    },
    {
      "epoch": 1.8307625774830618,
      "grad_norm": 0.4593643844127655,
      "learning_rate": 4.08464273701408e-05,
      "loss": 0.0002,
      "step": 38100
    },
    {
      "epoch": 1.8331651530440634,
      "grad_norm": 0.10630622506141663,
      "learning_rate": 4.083441449233579e-05,
      "loss": 0.0003,
      "step": 38150
    },
    {
      "epoch": 1.8355677286050647,
      "grad_norm": 0.4772961735725403,
      "learning_rate": 4.082240161453078e-05,
      "loss": 0.0003,
      "step": 38200
    },
    {
      "epoch": 1.837970304166066,
      "grad_norm": 0.18055619299411774,
      "learning_rate": 4.0810388736725776e-05,
      "loss": 0.0003,
      "step": 38250
    },
    {
      "epoch": 1.8403728797270675,
      "grad_norm": 0.10408484190702438,
      "learning_rate": 4.079837585892077e-05,
      "loss": 0.0002,
      "step": 38300
    },
    {
      "epoch": 1.8427754552880689,
      "grad_norm": 0.1370144635438919,
      "learning_rate": 4.078636298111576e-05,
      "loss": 0.0008,
      "step": 38350
    },
    {
      "epoch": 1.8451780308490702,
      "grad_norm": 0.08380362391471863,
      "learning_rate": 4.077435010331075e-05,
      "loss": 0.0009,
      "step": 38400
    },
    {
      "epoch": 1.8475806064100717,
      "grad_norm": 0.3664363622665405,
      "learning_rate": 4.076233722550574e-05,
      "loss": 0.001,
      "step": 38450
    },
    {
      "epoch": 1.849983181971073,
      "grad_norm": 0.12651190161705017,
      "learning_rate": 4.075032434770074e-05,
      "loss": 0.0002,
      "step": 38500
    },
    {
      "epoch": 1.8523857575320744,
      "grad_norm": 0.16082440316677094,
      "learning_rate": 4.073831146989573e-05,
      "loss": 0.0003,
      "step": 38550
    },
    {
      "epoch": 1.854788333093076,
      "grad_norm": 0.1514846235513687,
      "learning_rate": 4.0726298592090726e-05,
      "loss": 0.0002,
      "step": 38600
    },
    {
      "epoch": 1.8571909086540772,
      "grad_norm": 0.10627486556768417,
      "learning_rate": 4.0714285714285717e-05,
      "loss": 0.0002,
      "step": 38650
    },
    {
      "epoch": 1.8595934842150785,
      "grad_norm": 0.33289259672164917,
      "learning_rate": 4.070227283648071e-05,
      "loss": 0.0002,
      "step": 38700
    },
    {
      "epoch": 1.86199605977608,
      "grad_norm": 0.13235758244991302,
      "learning_rate": 4.0690259958675705e-05,
      "loss": 0.0007,
      "step": 38750
    },
    {
      "epoch": 1.8643986353370814,
      "grad_norm": 0.07774758338928223,
      "learning_rate": 4.0678247080870696e-05,
      "loss": 0.0002,
      "step": 38800
    },
    {
      "epoch": 1.8668012108980827,
      "grad_norm": 0.09182814508676529,
      "learning_rate": 4.0666234203065687e-05,
      "loss": 0.0002,
      "step": 38850
    },
    {
      "epoch": 1.8692037864590842,
      "grad_norm": 0.2501012086868286,
      "learning_rate": 4.0654221325260684e-05,
      "loss": 0.0002,
      "step": 38900
    },
    {
      "epoch": 1.8716063620200856,
      "grad_norm": 0.19980812072753906,
      "learning_rate": 4.0642208447455675e-05,
      "loss": 0.0002,
      "step": 38950
    },
    {
      "epoch": 1.8740089375810869,
      "grad_norm": 0.35816246271133423,
      "learning_rate": 4.063019556965067e-05,
      "loss": 0.0002,
      "step": 39000
    },
    {
      "epoch": 1.8764115131420884,
      "grad_norm": 0.295459121465683,
      "learning_rate": 4.0618182691845663e-05,
      "loss": 0.0002,
      "step": 39050
    },
    {
      "epoch": 1.8788140887030897,
      "grad_norm": 0.12553173303604126,
      "learning_rate": 4.0606169814040654e-05,
      "loss": 0.0003,
      "step": 39100
    },
    {
      "epoch": 1.881216664264091,
      "grad_norm": 0.15352186560630798,
      "learning_rate": 4.0594156936235645e-05,
      "loss": 0.0002,
      "step": 39150
    },
    {
      "epoch": 1.8836192398250926,
      "grad_norm": 0.47126880288124084,
      "learning_rate": 4.0582144058430636e-05,
      "loss": 0.0002,
      "step": 39200
    },
    {
      "epoch": 1.886021815386094,
      "grad_norm": 0.7552170157432556,
      "learning_rate": 4.0570131180625634e-05,
      "loss": 0.0003,
      "step": 39250
    },
    {
      "epoch": 1.8884243909470952,
      "grad_norm": 0.42827877402305603,
      "learning_rate": 4.0558118302820624e-05,
      "loss": 0.0002,
      "step": 39300
    },
    {
      "epoch": 1.8908269665080968,
      "grad_norm": 0.12851719558238983,
      "learning_rate": 4.0546105425015615e-05,
      "loss": 0.0003,
      "step": 39350
    },
    {
      "epoch": 1.893229542069098,
      "grad_norm": 0.1253732144832611,
      "learning_rate": 4.053409254721061e-05,
      "loss": 0.0003,
      "step": 39400
    },
    {
      "epoch": 1.8956321176300994,
      "grad_norm": 0.2679625153541565,
      "learning_rate": 4.0522079669405604e-05,
      "loss": 0.0003,
      "step": 39450
    },
    {
      "epoch": 1.898034693191101,
      "grad_norm": 0.1021670252084732,
      "learning_rate": 4.05100667916006e-05,
      "loss": 0.0002,
      "step": 39500
    },
    {
      "epoch": 1.9004372687521023,
      "grad_norm": 0.3880205750465393,
      "learning_rate": 4.049805391379559e-05,
      "loss": 0.0003,
      "step": 39550
    },
    {
      "epoch": 1.9028398443131036,
      "grad_norm": 0.0788060799241066,
      "learning_rate": 4.048604103599058e-05,
      "loss": 0.0002,
      "step": 39600
    },
    {
      "epoch": 1.9052424198741051,
      "grad_norm": 1.126301884651184,
      "learning_rate": 4.047402815818558e-05,
      "loss": 0.0003,
      "step": 39650
    },
    {
      "epoch": 1.9076449954351065,
      "grad_norm": 0.15360933542251587,
      "learning_rate": 4.046201528038057e-05,
      "loss": 0.0003,
      "step": 39700
    },
    {
      "epoch": 1.9100475709961078,
      "grad_norm": 0.7412075400352478,
      "learning_rate": 4.045000240257556e-05,
      "loss": 0.0003,
      "step": 39750
    },
    {
      "epoch": 1.9124501465571093,
      "grad_norm": 0.23727621138095856,
      "learning_rate": 4.043798952477056e-05,
      "loss": 0.001,
      "step": 39800
    },
    {
      "epoch": 1.9148527221181106,
      "grad_norm": 0.4413389563560486,
      "learning_rate": 4.0425976646965544e-05,
      "loss": 0.0004,
      "step": 39850
    },
    {
      "epoch": 1.917255297679112,
      "grad_norm": 0.4333195686340332,
      "learning_rate": 4.041396376916054e-05,
      "loss": 0.0003,
      "step": 39900
    },
    {
      "epoch": 1.9196578732401135,
      "grad_norm": 0.4689060151576996,
      "learning_rate": 4.040195089135553e-05,
      "loss": 0.0003,
      "step": 39950
    },
    {
      "epoch": 1.9220604488011148,
      "grad_norm": 0.667738139629364,
      "learning_rate": 4.038993801355053e-05,
      "loss": 0.0006,
      "step": 40000
    },
    {
      "epoch": 1.9244630243621161,
      "grad_norm": 0.3019731938838959,
      "learning_rate": 4.037792513574552e-05,
      "loss": 0.0007,
      "step": 40050
    },
    {
      "epoch": 1.9268655999231177,
      "grad_norm": 0.12459761649370193,
      "learning_rate": 4.036591225794051e-05,
      "loss": 0.0002,
      "step": 40100
    },
    {
      "epoch": 1.929268175484119,
      "grad_norm": 0.39420798420906067,
      "learning_rate": 4.035389938013551e-05,
      "loss": 0.0002,
      "step": 40150
    },
    {
      "epoch": 1.9316707510451203,
      "grad_norm": 0.3314282298088074,
      "learning_rate": 4.03418865023305e-05,
      "loss": 0.0002,
      "step": 40200
    },
    {
      "epoch": 1.9340733266061219,
      "grad_norm": 0.449924498796463,
      "learning_rate": 4.032987362452549e-05,
      "loss": 0.0003,
      "step": 40250
    },
    {
      "epoch": 1.9364759021671232,
      "grad_norm": 0.1686738282442093,
      "learning_rate": 4.031786074672049e-05,
      "loss": 0.0003,
      "step": 40300
    },
    {
      "epoch": 1.9388784777281245,
      "grad_norm": 0.3901350796222687,
      "learning_rate": 4.030584786891548e-05,
      "loss": 0.0002,
      "step": 40350
    },
    {
      "epoch": 1.941281053289126,
      "grad_norm": 0.2952089309692383,
      "learning_rate": 4.029383499111048e-05,
      "loss": 0.0002,
      "step": 40400
    },
    {
      "epoch": 1.9436836288501274,
      "grad_norm": 0.2781904935836792,
      "learning_rate": 4.028182211330547e-05,
      "loss": 0.001,
      "step": 40450
    },
    {
      "epoch": 1.9460862044111287,
      "grad_norm": 0.2023051530122757,
      "learning_rate": 4.026980923550046e-05,
      "loss": 0.0003,
      "step": 40500
    },
    {
      "epoch": 1.9484887799721302,
      "grad_norm": 0.4169735014438629,
      "learning_rate": 4.0257796357695456e-05,
      "loss": 0.0009,
      "step": 40550
    },
    {
      "epoch": 1.9508913555331315,
      "grad_norm": 0.23725280165672302,
      "learning_rate": 4.024578347989044e-05,
      "loss": 0.0003,
      "step": 40600
    },
    {
      "epoch": 1.9532939310941329,
      "grad_norm": 0.8361831307411194,
      "learning_rate": 4.023377060208544e-05,
      "loss": 0.0003,
      "step": 40650
    },
    {
      "epoch": 1.9556965066551344,
      "grad_norm": 0.09725058823823929,
      "learning_rate": 4.022175772428043e-05,
      "loss": 0.0002,
      "step": 40700
    },
    {
      "epoch": 1.9580990822161357,
      "grad_norm": 0.714133083820343,
      "learning_rate": 4.020974484647542e-05,
      "loss": 0.0003,
      "step": 40750
    },
    {
      "epoch": 1.960501657777137,
      "grad_norm": 0.2784968316555023,
      "learning_rate": 4.019773196867042e-05,
      "loss": 0.0003,
      "step": 40800
    },
    {
      "epoch": 1.9629042333381386,
      "grad_norm": 0.09162421524524689,
      "learning_rate": 4.018571909086541e-05,
      "loss": 0.0002,
      "step": 40850
    },
    {
      "epoch": 1.96530680889914,
      "grad_norm": 0.6228557229042053,
      "learning_rate": 4.0173706213060405e-05,
      "loss": 0.0003,
      "step": 40900
    },
    {
      "epoch": 1.9677093844601412,
      "grad_norm": 0.257232666015625,
      "learning_rate": 4.0161693335255396e-05,
      "loss": 0.0002,
      "step": 40950
    },
    {
      "epoch": 1.9701119600211427,
      "grad_norm": 0.41313067078590393,
      "learning_rate": 4.014968045745039e-05,
      "loss": 0.0002,
      "step": 41000
    },
    {
      "epoch": 1.972514535582144,
      "grad_norm": 0.23325678706169128,
      "learning_rate": 4.0137667579645385e-05,
      "loss": 0.0002,
      "step": 41050
    },
    {
      "epoch": 1.9749171111431454,
      "grad_norm": 0.2915097773075104,
      "learning_rate": 4.0125654701840375e-05,
      "loss": 0.0002,
      "step": 41100
    },
    {
      "epoch": 1.977319686704147,
      "grad_norm": 0.29688411951065063,
      "learning_rate": 4.0113641824035366e-05,
      "loss": 0.0003,
      "step": 41150
    },
    {
      "epoch": 1.9797222622651482,
      "grad_norm": 0.1659715622663498,
      "learning_rate": 4.0101628946230364e-05,
      "loss": 0.0002,
      "step": 41200
    },
    {
      "epoch": 1.9821248378261496,
      "grad_norm": 0.1834564357995987,
      "learning_rate": 4.0089616068425355e-05,
      "loss": 0.0003,
      "step": 41250
    },
    {
      "epoch": 1.984527413387151,
      "grad_norm": 0.08409940451383591,
      "learning_rate": 4.0077603190620345e-05,
      "loss": 0.0003,
      "step": 41300
    },
    {
      "epoch": 1.9869299889481524,
      "grad_norm": 0.08858031034469604,
      "learning_rate": 4.0065590312815336e-05,
      "loss": 0.0003,
      "step": 41350
    },
    {
      "epoch": 1.9893325645091537,
      "grad_norm": 0.4038834869861603,
      "learning_rate": 4.0053577435010334e-05,
      "loss": 0.0002,
      "step": 41400
    },
    {
      "epoch": 1.9917351400701553,
      "grad_norm": 0.34925347566604614,
      "learning_rate": 4.0041564557205325e-05,
      "loss": 0.0003,
      "step": 41450
    },
    {
      "epoch": 1.9941377156311566,
      "grad_norm": 0.22997115552425385,
      "learning_rate": 4.0029551679400316e-05,
      "loss": 0.0002,
      "step": 41500
    },
    {
      "epoch": 1.996540291192158,
      "grad_norm": 0.24026137590408325,
      "learning_rate": 4.001753880159531e-05,
      "loss": 0.0002,
      "step": 41550
    },
    {
      "epoch": 1.9989428667531595,
      "grad_norm": 0.034235455095767975,
      "learning_rate": 4.0005525923790304e-05,
      "loss": 0.0002,
      "step": 41600
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0002468742895871401,
      "eval_runtime": 17.1931,
      "eval_samples_per_second": 552.316,
      "eval_steps_per_second": 69.039,
      "step": 41622
    }
  ],
  "logging_steps": 50,
  "max_steps": 208110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8429814832448456e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
