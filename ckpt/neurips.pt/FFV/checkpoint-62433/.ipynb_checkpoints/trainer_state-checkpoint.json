{
  "best_global_step": 62433,
  "best_metric": 0.00017453967302571982,
  "best_model_checkpoint": "ckpt/neurips.pt/FFV/checkpoint-62433",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 62433,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0024025755610013935,
      "grad_norm": 1.3977797031402588,
      "learning_rate": 4.99882273797511e-05,
      "loss": 0.0476,
      "step": 50
    },
    {
      "epoch": 0.004805151122002787,
      "grad_norm": 5.024441719055176,
      "learning_rate": 4.997621450194609e-05,
      "loss": 0.0289,
      "step": 100
    },
    {
      "epoch": 0.00720772668300418,
      "grad_norm": 1.565306544303894,
      "learning_rate": 4.996420162414108e-05,
      "loss": 0.0387,
      "step": 150
    },
    {
      "epoch": 0.009610302244005574,
      "grad_norm": 1.6434930562973022,
      "learning_rate": 4.995218874633608e-05,
      "loss": 0.025,
      "step": 200
    },
    {
      "epoch": 0.012012877805006967,
      "grad_norm": 4.89108943939209,
      "learning_rate": 4.994017586853107e-05,
      "loss": 0.0238,
      "step": 250
    },
    {
      "epoch": 0.01441545336600836,
      "grad_norm": 1.0357552766799927,
      "learning_rate": 4.9928162990726066e-05,
      "loss": 0.0176,
      "step": 300
    },
    {
      "epoch": 0.016818028927009756,
      "grad_norm": 2.2466228008270264,
      "learning_rate": 4.991615011292106e-05,
      "loss": 0.0212,
      "step": 350
    },
    {
      "epoch": 0.019220604488011148,
      "grad_norm": 2.003396511077881,
      "learning_rate": 4.990413723511604e-05,
      "loss": 0.0216,
      "step": 400
    },
    {
      "epoch": 0.021623180049012543,
      "grad_norm": 0.7462701797485352,
      "learning_rate": 4.989212435731104e-05,
      "loss": 0.02,
      "step": 450
    },
    {
      "epoch": 0.024025755610013935,
      "grad_norm": 1.7794575691223145,
      "learning_rate": 4.988011147950603e-05,
      "loss": 0.0175,
      "step": 500
    },
    {
      "epoch": 0.02642833117101533,
      "grad_norm": 1.3216904401779175,
      "learning_rate": 4.986809860170103e-05,
      "loss": 0.0198,
      "step": 550
    },
    {
      "epoch": 0.02883090673201672,
      "grad_norm": 3.202026128768921,
      "learning_rate": 4.985608572389602e-05,
      "loss": 0.0166,
      "step": 600
    },
    {
      "epoch": 0.031233482293018117,
      "grad_norm": 1.434770941734314,
      "learning_rate": 4.984407284609101e-05,
      "loss": 0.0162,
      "step": 650
    },
    {
      "epoch": 0.03363605785401951,
      "grad_norm": 4.874935626983643,
      "learning_rate": 4.9832059968286006e-05,
      "loss": 0.0189,
      "step": 700
    },
    {
      "epoch": 0.0360386334150209,
      "grad_norm": 4.808428764343262,
      "learning_rate": 4.9820047090481e-05,
      "loss": 0.0168,
      "step": 750
    },
    {
      "epoch": 0.038441208976022295,
      "grad_norm": 2.936591148376465,
      "learning_rate": 4.980803421267599e-05,
      "loss": 0.0208,
      "step": 800
    },
    {
      "epoch": 0.04084378453702369,
      "grad_norm": 0.6572856903076172,
      "learning_rate": 4.9796021334870986e-05,
      "loss": 0.0156,
      "step": 850
    },
    {
      "epoch": 0.043246360098025086,
      "grad_norm": 2.383610963821411,
      "learning_rate": 4.9784008457065976e-05,
      "loss": 0.0171,
      "step": 900
    },
    {
      "epoch": 0.045648935659026474,
      "grad_norm": 1.7208203077316284,
      "learning_rate": 4.9771995579260974e-05,
      "loss": 0.0178,
      "step": 950
    },
    {
      "epoch": 0.04805151122002787,
      "grad_norm": 1.8242915868759155,
      "learning_rate": 4.9759982701455965e-05,
      "loss": 0.0186,
      "step": 1000
    },
    {
      "epoch": 0.050454086781029264,
      "grad_norm": 2.109001398086548,
      "learning_rate": 4.9747969823650956e-05,
      "loss": 0.0192,
      "step": 1050
    },
    {
      "epoch": 0.05285666234203066,
      "grad_norm": 1.2478501796722412,
      "learning_rate": 4.973595694584595e-05,
      "loss": 0.0166,
      "step": 1100
    },
    {
      "epoch": 0.05525923790303205,
      "grad_norm": 1.3806898593902588,
      "learning_rate": 4.972394406804094e-05,
      "loss": 0.0172,
      "step": 1150
    },
    {
      "epoch": 0.05766181346403344,
      "grad_norm": 1.7513642311096191,
      "learning_rate": 4.9711931190235935e-05,
      "loss": 0.0124,
      "step": 1200
    },
    {
      "epoch": 0.06006438902503484,
      "grad_norm": 3.117465019226074,
      "learning_rate": 4.9699918312430926e-05,
      "loss": 0.0145,
      "step": 1250
    },
    {
      "epoch": 0.06246696458603623,
      "grad_norm": 2.624201536178589,
      "learning_rate": 4.968790543462592e-05,
      "loss": 0.0163,
      "step": 1300
    },
    {
      "epoch": 0.06486954014703762,
      "grad_norm": 2.4585120677948,
      "learning_rate": 4.9675892556820914e-05,
      "loss": 0.0181,
      "step": 1350
    },
    {
      "epoch": 0.06727211570803902,
      "grad_norm": 1.311131238937378,
      "learning_rate": 4.9663879679015905e-05,
      "loss": 0.0121,
      "step": 1400
    },
    {
      "epoch": 0.06967469126904041,
      "grad_norm": 0.9783168435096741,
      "learning_rate": 4.96518668012109e-05,
      "loss": 0.0121,
      "step": 1450
    },
    {
      "epoch": 0.0720772668300418,
      "grad_norm": 0.9726380109786987,
      "learning_rate": 4.9639853923405893e-05,
      "loss": 0.0148,
      "step": 1500
    },
    {
      "epoch": 0.0744798423910432,
      "grad_norm": 2.8475356101989746,
      "learning_rate": 4.9627841045600884e-05,
      "loss": 0.01,
      "step": 1550
    },
    {
      "epoch": 0.07688241795204459,
      "grad_norm": 0.889223575592041,
      "learning_rate": 4.961582816779588e-05,
      "loss": 0.0104,
      "step": 1600
    },
    {
      "epoch": 0.07928499351304598,
      "grad_norm": 1.589859127998352,
      "learning_rate": 4.960381528999087e-05,
      "loss": 0.0103,
      "step": 1650
    },
    {
      "epoch": 0.08168756907404738,
      "grad_norm": 0.8792979121208191,
      "learning_rate": 4.959180241218587e-05,
      "loss": 0.0136,
      "step": 1700
    },
    {
      "epoch": 0.08409014463504877,
      "grad_norm": 1.183384895324707,
      "learning_rate": 4.957978953438086e-05,
      "loss": 0.0107,
      "step": 1750
    },
    {
      "epoch": 0.08649272019605017,
      "grad_norm": 4.050797462463379,
      "learning_rate": 4.956777665657585e-05,
      "loss": 0.0128,
      "step": 1800
    },
    {
      "epoch": 0.08889529575705156,
      "grad_norm": 2.58302903175354,
      "learning_rate": 4.955576377877085e-05,
      "loss": 0.0108,
      "step": 1850
    },
    {
      "epoch": 0.09129787131805295,
      "grad_norm": 1.6763356924057007,
      "learning_rate": 4.9543750900965834e-05,
      "loss": 0.0113,
      "step": 1900
    },
    {
      "epoch": 0.09370044687905435,
      "grad_norm": 3.229660987854004,
      "learning_rate": 4.953173802316083e-05,
      "loss": 0.0111,
      "step": 1950
    },
    {
      "epoch": 0.09610302244005574,
      "grad_norm": 1.7616082429885864,
      "learning_rate": 4.951972514535582e-05,
      "loss": 0.012,
      "step": 2000
    },
    {
      "epoch": 0.09850559800105713,
      "grad_norm": 1.5646854639053345,
      "learning_rate": 4.950771226755081e-05,
      "loss": 0.0101,
      "step": 2050
    },
    {
      "epoch": 0.10090817356205853,
      "grad_norm": 4.657251834869385,
      "learning_rate": 4.949569938974581e-05,
      "loss": 0.0094,
      "step": 2100
    },
    {
      "epoch": 0.10331074912305992,
      "grad_norm": 2.1267502307891846,
      "learning_rate": 4.94836865119408e-05,
      "loss": 0.014,
      "step": 2150
    },
    {
      "epoch": 0.10571332468406132,
      "grad_norm": 5.356624126434326,
      "learning_rate": 4.94716736341358e-05,
      "loss": 0.0124,
      "step": 2200
    },
    {
      "epoch": 0.10811590024506271,
      "grad_norm": 2.064894914627075,
      "learning_rate": 4.945966075633079e-05,
      "loss": 0.0094,
      "step": 2250
    },
    {
      "epoch": 0.1105184758060641,
      "grad_norm": 2.0159528255462646,
      "learning_rate": 4.944764787852578e-05,
      "loss": 0.0099,
      "step": 2300
    },
    {
      "epoch": 0.1129210513670655,
      "grad_norm": 3.8876395225524902,
      "learning_rate": 4.943563500072078e-05,
      "loss": 0.0096,
      "step": 2350
    },
    {
      "epoch": 0.11532362692806689,
      "grad_norm": 3.4123547077178955,
      "learning_rate": 4.942362212291577e-05,
      "loss": 0.011,
      "step": 2400
    },
    {
      "epoch": 0.11772620248906829,
      "grad_norm": 2.3515970706939697,
      "learning_rate": 4.941160924511076e-05,
      "loss": 0.0101,
      "step": 2450
    },
    {
      "epoch": 0.12012877805006968,
      "grad_norm": 4.216569423675537,
      "learning_rate": 4.939959636730576e-05,
      "loss": 0.0127,
      "step": 2500
    },
    {
      "epoch": 0.12253135361107106,
      "grad_norm": 1.6170148849487305,
      "learning_rate": 4.938758348950075e-05,
      "loss": 0.0111,
      "step": 2550
    },
    {
      "epoch": 0.12493392917207247,
      "grad_norm": 0.6739742159843445,
      "learning_rate": 4.9375570611695746e-05,
      "loss": 0.0086,
      "step": 2600
    },
    {
      "epoch": 0.12733650473307387,
      "grad_norm": 2.3992059230804443,
      "learning_rate": 4.936355773389073e-05,
      "loss": 0.0123,
      "step": 2650
    },
    {
      "epoch": 0.12973908029407524,
      "grad_norm": 2.6405045986175537,
      "learning_rate": 4.935154485608572e-05,
      "loss": 0.0114,
      "step": 2700
    },
    {
      "epoch": 0.13214165585507665,
      "grad_norm": 0.3864342272281647,
      "learning_rate": 4.933953197828072e-05,
      "loss": 0.0088,
      "step": 2750
    },
    {
      "epoch": 0.13454423141607805,
      "grad_norm": 1.4979263544082642,
      "learning_rate": 4.932751910047571e-05,
      "loss": 0.008,
      "step": 2800
    },
    {
      "epoch": 0.13694680697707942,
      "grad_norm": 4.138174057006836,
      "learning_rate": 4.931550622267071e-05,
      "loss": 0.0138,
      "step": 2850
    },
    {
      "epoch": 0.13934938253808082,
      "grad_norm": 0.8691509366035461,
      "learning_rate": 4.93034933448657e-05,
      "loss": 0.0089,
      "step": 2900
    },
    {
      "epoch": 0.14175195809908223,
      "grad_norm": 2.495490312576294,
      "learning_rate": 4.929148046706069e-05,
      "loss": 0.0072,
      "step": 2950
    },
    {
      "epoch": 0.1441545336600836,
      "grad_norm": 2.8286640644073486,
      "learning_rate": 4.9279467589255686e-05,
      "loss": 0.0104,
      "step": 3000
    },
    {
      "epoch": 0.146557109221085,
      "grad_norm": 2.058450698852539,
      "learning_rate": 4.926745471145068e-05,
      "loss": 0.0116,
      "step": 3050
    },
    {
      "epoch": 0.1489596847820864,
      "grad_norm": 1.6004475355148315,
      "learning_rate": 4.9255441833645674e-05,
      "loss": 0.0079,
      "step": 3100
    },
    {
      "epoch": 0.15136226034308778,
      "grad_norm": 3.1092495918273926,
      "learning_rate": 4.9243428955840665e-05,
      "loss": 0.0098,
      "step": 3150
    },
    {
      "epoch": 0.15376483590408918,
      "grad_norm": 1.8317694664001465,
      "learning_rate": 4.9231416078035656e-05,
      "loss": 0.0094,
      "step": 3200
    },
    {
      "epoch": 0.15616741146509058,
      "grad_norm": 1.5068285465240479,
      "learning_rate": 4.9219403200230654e-05,
      "loss": 0.0073,
      "step": 3250
    },
    {
      "epoch": 0.15856998702609196,
      "grad_norm": 1.204134225845337,
      "learning_rate": 4.9207390322425645e-05,
      "loss": 0.0082,
      "step": 3300
    },
    {
      "epoch": 0.16097256258709336,
      "grad_norm": 1.2216471433639526,
      "learning_rate": 4.9195377444620635e-05,
      "loss": 0.0084,
      "step": 3350
    },
    {
      "epoch": 0.16337513814809476,
      "grad_norm": 2.2922213077545166,
      "learning_rate": 4.9183364566815626e-05,
      "loss": 0.0058,
      "step": 3400
    },
    {
      "epoch": 0.16577771370909616,
      "grad_norm": 1.4693466424942017,
      "learning_rate": 4.917135168901062e-05,
      "loss": 0.0058,
      "step": 3450
    },
    {
      "epoch": 0.16818028927009754,
      "grad_norm": 1.3643933534622192,
      "learning_rate": 4.9159338811205615e-05,
      "loss": 0.0063,
      "step": 3500
    },
    {
      "epoch": 0.17058286483109894,
      "grad_norm": 1.0520546436309814,
      "learning_rate": 4.9147325933400605e-05,
      "loss": 0.0075,
      "step": 3550
    },
    {
      "epoch": 0.17298544039210034,
      "grad_norm": 1.178865909576416,
      "learning_rate": 4.91353130555956e-05,
      "loss": 0.0083,
      "step": 3600
    },
    {
      "epoch": 0.17538801595310172,
      "grad_norm": 0.8996872305870056,
      "learning_rate": 4.9123300177790594e-05,
      "loss": 0.0067,
      "step": 3650
    },
    {
      "epoch": 0.17779059151410312,
      "grad_norm": 2.0464773178100586,
      "learning_rate": 4.9111287299985585e-05,
      "loss": 0.0067,
      "step": 3700
    },
    {
      "epoch": 0.18019316707510452,
      "grad_norm": 1.003833293914795,
      "learning_rate": 4.909927442218058e-05,
      "loss": 0.0097,
      "step": 3750
    },
    {
      "epoch": 0.1825957426361059,
      "grad_norm": 0.8388890027999878,
      "learning_rate": 4.908726154437557e-05,
      "loss": 0.0074,
      "step": 3800
    },
    {
      "epoch": 0.1849983181971073,
      "grad_norm": 0.6696130633354187,
      "learning_rate": 4.9075248666570564e-05,
      "loss": 0.006,
      "step": 3850
    },
    {
      "epoch": 0.1874008937581087,
      "grad_norm": 0.2937922179698944,
      "learning_rate": 4.906323578876556e-05,
      "loss": 0.0061,
      "step": 3900
    },
    {
      "epoch": 0.18980346931911007,
      "grad_norm": 1.0247782468795776,
      "learning_rate": 4.905122291096055e-05,
      "loss": 0.0056,
      "step": 3950
    },
    {
      "epoch": 0.19220604488011148,
      "grad_norm": 0.5409323573112488,
      "learning_rate": 4.903921003315555e-05,
      "loss": 0.0046,
      "step": 4000
    },
    {
      "epoch": 0.19460862044111288,
      "grad_norm": 0.43130701780319214,
      "learning_rate": 4.902719715535054e-05,
      "loss": 0.0059,
      "step": 4050
    },
    {
      "epoch": 0.19701119600211425,
      "grad_norm": 1.1368478536605835,
      "learning_rate": 4.901518427754553e-05,
      "loss": 0.0047,
      "step": 4100
    },
    {
      "epoch": 0.19941377156311565,
      "grad_norm": 1.3211380243301392,
      "learning_rate": 4.900317139974052e-05,
      "loss": 0.0046,
      "step": 4150
    },
    {
      "epoch": 0.20181634712411706,
      "grad_norm": 2.1333322525024414,
      "learning_rate": 4.899115852193551e-05,
      "loss": 0.0057,
      "step": 4200
    },
    {
      "epoch": 0.20421892268511846,
      "grad_norm": 0.5230908989906311,
      "learning_rate": 4.897914564413051e-05,
      "loss": 0.006,
      "step": 4250
    },
    {
      "epoch": 0.20662149824611983,
      "grad_norm": 2.048586130142212,
      "learning_rate": 4.89671327663255e-05,
      "loss": 0.0052,
      "step": 4300
    },
    {
      "epoch": 0.20902407380712124,
      "grad_norm": 1.6597139835357666,
      "learning_rate": 4.895511988852049e-05,
      "loss": 0.0045,
      "step": 4350
    },
    {
      "epoch": 0.21142664936812264,
      "grad_norm": 0.47161102294921875,
      "learning_rate": 4.894310701071549e-05,
      "loss": 0.004,
      "step": 4400
    },
    {
      "epoch": 0.213829224929124,
      "grad_norm": 0.7128011584281921,
      "learning_rate": 4.893109413291048e-05,
      "loss": 0.0038,
      "step": 4450
    },
    {
      "epoch": 0.21623180049012541,
      "grad_norm": 0.39195820689201355,
      "learning_rate": 4.891908125510548e-05,
      "loss": 0.0041,
      "step": 4500
    },
    {
      "epoch": 0.21863437605112682,
      "grad_norm": 0.352633535861969,
      "learning_rate": 4.890706837730047e-05,
      "loss": 0.0039,
      "step": 4550
    },
    {
      "epoch": 0.2210369516121282,
      "grad_norm": 0.62523353099823,
      "learning_rate": 4.889505549949546e-05,
      "loss": 0.005,
      "step": 4600
    },
    {
      "epoch": 0.2234395271731296,
      "grad_norm": 2.3909573554992676,
      "learning_rate": 4.888304262169046e-05,
      "loss": 0.0043,
      "step": 4650
    },
    {
      "epoch": 0.225842102734131,
      "grad_norm": 0.7748146057128906,
      "learning_rate": 4.887102974388545e-05,
      "loss": 0.0033,
      "step": 4700
    },
    {
      "epoch": 0.22824467829513237,
      "grad_norm": 0.3099277913570404,
      "learning_rate": 4.885901686608044e-05,
      "loss": 0.004,
      "step": 4750
    },
    {
      "epoch": 0.23064725385613377,
      "grad_norm": 1.8322608470916748,
      "learning_rate": 4.884700398827544e-05,
      "loss": 0.0042,
      "step": 4800
    },
    {
      "epoch": 0.23304982941713517,
      "grad_norm": 1.8548411130905151,
      "learning_rate": 4.883499111047043e-05,
      "loss": 0.0047,
      "step": 4850
    },
    {
      "epoch": 0.23545240497813658,
      "grad_norm": 1.062731146812439,
      "learning_rate": 4.882297823266542e-05,
      "loss": 0.0048,
      "step": 4900
    },
    {
      "epoch": 0.23785498053913795,
      "grad_norm": 1.5180546045303345,
      "learning_rate": 4.881096535486041e-05,
      "loss": 0.0039,
      "step": 4950
    },
    {
      "epoch": 0.24025755610013935,
      "grad_norm": 1.1765363216400146,
      "learning_rate": 4.879895247705541e-05,
      "loss": 0.0039,
      "step": 5000
    },
    {
      "epoch": 0.24266013166114075,
      "grad_norm": 0.455443412065506,
      "learning_rate": 4.87869395992504e-05,
      "loss": 0.0035,
      "step": 5050
    },
    {
      "epoch": 0.24506270722214213,
      "grad_norm": 1.46443772315979,
      "learning_rate": 4.877492672144539e-05,
      "loss": 0.0038,
      "step": 5100
    },
    {
      "epoch": 0.24746528278314353,
      "grad_norm": 0.5781234502792358,
      "learning_rate": 4.8762913843640386e-05,
      "loss": 0.0048,
      "step": 5150
    },
    {
      "epoch": 0.24986785834414493,
      "grad_norm": 1.2511003017425537,
      "learning_rate": 4.875090096583538e-05,
      "loss": 0.0031,
      "step": 5200
    },
    {
      "epoch": 0.2522704339051463,
      "grad_norm": 2.3380489349365234,
      "learning_rate": 4.873888808803037e-05,
      "loss": 0.004,
      "step": 5250
    },
    {
      "epoch": 0.25467300946614774,
      "grad_norm": 0.3612140417098999,
      "learning_rate": 4.8726875210225366e-05,
      "loss": 0.0054,
      "step": 5300
    },
    {
      "epoch": 0.2570755850271491,
      "grad_norm": 0.4610612988471985,
      "learning_rate": 4.8714862332420356e-05,
      "loss": 0.0035,
      "step": 5350
    },
    {
      "epoch": 0.2594781605881505,
      "grad_norm": 0.7935386300086975,
      "learning_rate": 4.8702849454615354e-05,
      "loss": 0.0037,
      "step": 5400
    },
    {
      "epoch": 0.2618807361491519,
      "grad_norm": 1.397274136543274,
      "learning_rate": 4.8690836576810345e-05,
      "loss": 0.003,
      "step": 5450
    },
    {
      "epoch": 0.2642833117101533,
      "grad_norm": 1.3162274360656738,
      "learning_rate": 4.8678823699005336e-05,
      "loss": 0.004,
      "step": 5500
    },
    {
      "epoch": 0.26668588727115466,
      "grad_norm": 1.1938406229019165,
      "learning_rate": 4.866681082120033e-05,
      "loss": 0.0046,
      "step": 5550
    },
    {
      "epoch": 0.2690884628321561,
      "grad_norm": 0.4257481098175049,
      "learning_rate": 4.865479794339532e-05,
      "loss": 0.0026,
      "step": 5600
    },
    {
      "epoch": 0.27149103839315747,
      "grad_norm": 0.567571759223938,
      "learning_rate": 4.8642785065590315e-05,
      "loss": 0.0033,
      "step": 5650
    },
    {
      "epoch": 0.27389361395415884,
      "grad_norm": 1.661132574081421,
      "learning_rate": 4.8630772187785306e-05,
      "loss": 0.0033,
      "step": 5700
    },
    {
      "epoch": 0.2762961895151603,
      "grad_norm": 1.2566858530044556,
      "learning_rate": 4.8618759309980297e-05,
      "loss": 0.0033,
      "step": 5750
    },
    {
      "epoch": 0.27869876507616165,
      "grad_norm": 1.9318197965621948,
      "learning_rate": 4.8606746432175294e-05,
      "loss": 0.0037,
      "step": 5800
    },
    {
      "epoch": 0.281101340637163,
      "grad_norm": 1.4022386074066162,
      "learning_rate": 4.8594733554370285e-05,
      "loss": 0.0033,
      "step": 5850
    },
    {
      "epoch": 0.28350391619816445,
      "grad_norm": 1.4420922994613647,
      "learning_rate": 4.858272067656528e-05,
      "loss": 0.0038,
      "step": 5900
    },
    {
      "epoch": 0.2859064917591658,
      "grad_norm": 0.5299707651138306,
      "learning_rate": 4.8570707798760273e-05,
      "loss": 0.0026,
      "step": 5950
    },
    {
      "epoch": 0.2883090673201672,
      "grad_norm": 1.218781590461731,
      "learning_rate": 4.8558694920955264e-05,
      "loss": 0.0032,
      "step": 6000
    },
    {
      "epoch": 0.29071164288116863,
      "grad_norm": 0.8099576830863953,
      "learning_rate": 4.854668204315026e-05,
      "loss": 0.0026,
      "step": 6050
    },
    {
      "epoch": 0.29311421844217,
      "grad_norm": 0.839592456817627,
      "learning_rate": 4.853466916534525e-05,
      "loss": 0.0025,
      "step": 6100
    },
    {
      "epoch": 0.2955167940031714,
      "grad_norm": 0.5667944550514221,
      "learning_rate": 4.8522656287540244e-05,
      "loss": 0.0031,
      "step": 6150
    },
    {
      "epoch": 0.2979193695641728,
      "grad_norm": 1.277574062347412,
      "learning_rate": 4.851064340973524e-05,
      "loss": 0.0022,
      "step": 6200
    },
    {
      "epoch": 0.3003219451251742,
      "grad_norm": 0.7289004921913147,
      "learning_rate": 4.849863053193023e-05,
      "loss": 0.0029,
      "step": 6250
    },
    {
      "epoch": 0.30272452068617556,
      "grad_norm": 1.75052011013031,
      "learning_rate": 4.848661765412523e-05,
      "loss": 0.003,
      "step": 6300
    },
    {
      "epoch": 0.305127096247177,
      "grad_norm": 0.8101513981819153,
      "learning_rate": 4.8474604776320214e-05,
      "loss": 0.0036,
      "step": 6350
    },
    {
      "epoch": 0.30752967180817836,
      "grad_norm": 0.625751256942749,
      "learning_rate": 4.846259189851521e-05,
      "loss": 0.0026,
      "step": 6400
    },
    {
      "epoch": 0.30993224736917974,
      "grad_norm": 0.38452669978141785,
      "learning_rate": 4.84505790207102e-05,
      "loss": 0.0019,
      "step": 6450
    },
    {
      "epoch": 0.31233482293018117,
      "grad_norm": 0.4652124047279358,
      "learning_rate": 4.843856614290519e-05,
      "loss": 0.0025,
      "step": 6500
    },
    {
      "epoch": 0.31473739849118254,
      "grad_norm": 0.2544368803501129,
      "learning_rate": 4.842655326510019e-05,
      "loss": 0.003,
      "step": 6550
    },
    {
      "epoch": 0.3171399740521839,
      "grad_norm": 0.993867039680481,
      "learning_rate": 4.841454038729518e-05,
      "loss": 0.0031,
      "step": 6600
    },
    {
      "epoch": 0.31954254961318534,
      "grad_norm": 0.8605760931968689,
      "learning_rate": 4.840252750949017e-05,
      "loss": 0.0022,
      "step": 6650
    },
    {
      "epoch": 0.3219451251741867,
      "grad_norm": 1.1287469863891602,
      "learning_rate": 4.839051463168517e-05,
      "loss": 0.0028,
      "step": 6700
    },
    {
      "epoch": 0.32434770073518815,
      "grad_norm": 1.0360721349716187,
      "learning_rate": 4.837850175388016e-05,
      "loss": 0.0031,
      "step": 6750
    },
    {
      "epoch": 0.3267502762961895,
      "grad_norm": 0.3745308816432953,
      "learning_rate": 4.836648887607516e-05,
      "loss": 0.0016,
      "step": 6800
    },
    {
      "epoch": 0.3291528518571909,
      "grad_norm": 0.42093610763549805,
      "learning_rate": 4.835447599827015e-05,
      "loss": 0.0024,
      "step": 6850
    },
    {
      "epoch": 0.33155542741819233,
      "grad_norm": 0.4041617810726166,
      "learning_rate": 4.834246312046514e-05,
      "loss": 0.0024,
      "step": 6900
    },
    {
      "epoch": 0.3339580029791937,
      "grad_norm": 0.2239319235086441,
      "learning_rate": 4.833045024266014e-05,
      "loss": 0.0024,
      "step": 6950
    },
    {
      "epoch": 0.3363605785401951,
      "grad_norm": 0.5156970620155334,
      "learning_rate": 4.831843736485513e-05,
      "loss": 0.0025,
      "step": 7000
    },
    {
      "epoch": 0.3387631541011965,
      "grad_norm": 0.589368999004364,
      "learning_rate": 4.8306424487050126e-05,
      "loss": 0.0017,
      "step": 7050
    },
    {
      "epoch": 0.3411657296621979,
      "grad_norm": 0.9890074729919434,
      "learning_rate": 4.829441160924511e-05,
      "loss": 0.0022,
      "step": 7100
    },
    {
      "epoch": 0.34356830522319926,
      "grad_norm": 0.36482352018356323,
      "learning_rate": 4.82823987314401e-05,
      "loss": 0.0017,
      "step": 7150
    },
    {
      "epoch": 0.3459708807842007,
      "grad_norm": 0.3104461133480072,
      "learning_rate": 4.82703858536351e-05,
      "loss": 0.0016,
      "step": 7200
    },
    {
      "epoch": 0.34837345634520206,
      "grad_norm": 0.5063043832778931,
      "learning_rate": 4.825837297583009e-05,
      "loss": 0.0018,
      "step": 7250
    },
    {
      "epoch": 0.35077603190620343,
      "grad_norm": 1.35908842086792,
      "learning_rate": 4.824636009802509e-05,
      "loss": 0.0019,
      "step": 7300
    },
    {
      "epoch": 0.35317860746720486,
      "grad_norm": 0.4147496521472931,
      "learning_rate": 4.823434722022008e-05,
      "loss": 0.0028,
      "step": 7350
    },
    {
      "epoch": 0.35558118302820624,
      "grad_norm": 0.6044933795928955,
      "learning_rate": 4.822233434241507e-05,
      "loss": 0.0013,
      "step": 7400
    },
    {
      "epoch": 0.3579837585892076,
      "grad_norm": 0.7975555062294006,
      "learning_rate": 4.8210321464610066e-05,
      "loss": 0.0023,
      "step": 7450
    },
    {
      "epoch": 0.36038633415020904,
      "grad_norm": 0.8660078644752502,
      "learning_rate": 4.819830858680506e-05,
      "loss": 0.0018,
      "step": 7500
    },
    {
      "epoch": 0.3627889097112104,
      "grad_norm": 0.9014655947685242,
      "learning_rate": 4.8186295709000054e-05,
      "loss": 0.0024,
      "step": 7550
    },
    {
      "epoch": 0.3651914852722118,
      "grad_norm": 0.44202256202697754,
      "learning_rate": 4.8174282831195045e-05,
      "loss": 0.0018,
      "step": 7600
    },
    {
      "epoch": 0.3675940608332132,
      "grad_norm": 0.9656853675842285,
      "learning_rate": 4.8162269953390036e-05,
      "loss": 0.0028,
      "step": 7650
    },
    {
      "epoch": 0.3699966363942146,
      "grad_norm": 0.2906738519668579,
      "learning_rate": 4.8150257075585034e-05,
      "loss": 0.0015,
      "step": 7700
    },
    {
      "epoch": 0.37239921195521597,
      "grad_norm": 1.329195261001587,
      "learning_rate": 4.8138244197780024e-05,
      "loss": 0.0016,
      "step": 7750
    },
    {
      "epoch": 0.3748017875162174,
      "grad_norm": 0.5366710424423218,
      "learning_rate": 4.8126231319975015e-05,
      "loss": 0.0016,
      "step": 7800
    },
    {
      "epoch": 0.3772043630772188,
      "grad_norm": 0.38370034098625183,
      "learning_rate": 4.8114218442170006e-05,
      "loss": 0.0017,
      "step": 7850
    },
    {
      "epoch": 0.37960693863822015,
      "grad_norm": 0.3066962957382202,
      "learning_rate": 4.8102205564365e-05,
      "loss": 0.0018,
      "step": 7900
    },
    {
      "epoch": 0.3820095141992216,
      "grad_norm": 0.2574390769004822,
      "learning_rate": 4.8090192686559995e-05,
      "loss": 0.0017,
      "step": 7950
    },
    {
      "epoch": 0.38441208976022295,
      "grad_norm": 0.1367029994726181,
      "learning_rate": 4.8078179808754985e-05,
      "loss": 0.0044,
      "step": 8000
    },
    {
      "epoch": 0.3868146653212243,
      "grad_norm": 0.29495754837989807,
      "learning_rate": 4.8066166930949976e-05,
      "loss": 0.0015,
      "step": 8050
    },
    {
      "epoch": 0.38921724088222576,
      "grad_norm": 1.0089691877365112,
      "learning_rate": 4.8054154053144974e-05,
      "loss": 0.0014,
      "step": 8100
    },
    {
      "epoch": 0.39161981644322713,
      "grad_norm": 0.9552493691444397,
      "learning_rate": 4.8042141175339965e-05,
      "loss": 0.0015,
      "step": 8150
    },
    {
      "epoch": 0.3940223920042285,
      "grad_norm": 0.5448896884918213,
      "learning_rate": 4.803012829753496e-05,
      "loss": 0.0015,
      "step": 8200
    },
    {
      "epoch": 0.39642496756522994,
      "grad_norm": 0.7121440768241882,
      "learning_rate": 4.801811541972995e-05,
      "loss": 0.0015,
      "step": 8250
    },
    {
      "epoch": 0.3988275431262313,
      "grad_norm": 1.0201919078826904,
      "learning_rate": 4.8006102541924944e-05,
      "loss": 0.0025,
      "step": 8300
    },
    {
      "epoch": 0.40123011868723274,
      "grad_norm": 0.5103296637535095,
      "learning_rate": 4.799408966411994e-05,
      "loss": 0.0014,
      "step": 8350
    },
    {
      "epoch": 0.4036326942482341,
      "grad_norm": 1.3019262552261353,
      "learning_rate": 4.798207678631493e-05,
      "loss": 0.0016,
      "step": 8400
    },
    {
      "epoch": 0.4060352698092355,
      "grad_norm": 0.853866457939148,
      "learning_rate": 4.797006390850993e-05,
      "loss": 0.0014,
      "step": 8450
    },
    {
      "epoch": 0.4084378453702369,
      "grad_norm": 0.4468635618686676,
      "learning_rate": 4.795805103070492e-05,
      "loss": 0.0014,
      "step": 8500
    },
    {
      "epoch": 0.4108404209312383,
      "grad_norm": 0.5029453635215759,
      "learning_rate": 4.794603815289991e-05,
      "loss": 0.001,
      "step": 8550
    },
    {
      "epoch": 0.41324299649223967,
      "grad_norm": 0.6873670816421509,
      "learning_rate": 4.79340252750949e-05,
      "loss": 0.0013,
      "step": 8600
    },
    {
      "epoch": 0.4156455720532411,
      "grad_norm": 0.4353700876235962,
      "learning_rate": 4.792201239728989e-05,
      "loss": 0.0016,
      "step": 8650
    },
    {
      "epoch": 0.41804814761424247,
      "grad_norm": 0.27242541313171387,
      "learning_rate": 4.790999951948489e-05,
      "loss": 0.0018,
      "step": 8700
    },
    {
      "epoch": 0.42045072317524385,
      "grad_norm": 0.6060540080070496,
      "learning_rate": 4.789798664167988e-05,
      "loss": 0.0013,
      "step": 8750
    },
    {
      "epoch": 0.4228532987362453,
      "grad_norm": 0.42970892786979675,
      "learning_rate": 4.788597376387487e-05,
      "loss": 0.0011,
      "step": 8800
    },
    {
      "epoch": 0.42525587429724665,
      "grad_norm": 0.3042391240596771,
      "learning_rate": 4.787396088606987e-05,
      "loss": 0.0016,
      "step": 8850
    },
    {
      "epoch": 0.427658449858248,
      "grad_norm": 0.7691907286643982,
      "learning_rate": 4.786194800826486e-05,
      "loss": 0.0012,
      "step": 8900
    },
    {
      "epoch": 0.43006102541924945,
      "grad_norm": 0.4786968529224396,
      "learning_rate": 4.784993513045986e-05,
      "loss": 0.0011,
      "step": 8950
    },
    {
      "epoch": 0.43246360098025083,
      "grad_norm": 0.8461541533470154,
      "learning_rate": 4.783792225265485e-05,
      "loss": 0.0011,
      "step": 9000
    },
    {
      "epoch": 0.4348661765412522,
      "grad_norm": 0.33702102303504944,
      "learning_rate": 4.782590937484984e-05,
      "loss": 0.0015,
      "step": 9050
    },
    {
      "epoch": 0.43726875210225363,
      "grad_norm": 0.6144108176231384,
      "learning_rate": 4.781389649704484e-05,
      "loss": 0.0012,
      "step": 9100
    },
    {
      "epoch": 0.439671327663255,
      "grad_norm": 0.5265894532203674,
      "learning_rate": 4.780188361923983e-05,
      "loss": 0.0011,
      "step": 9150
    },
    {
      "epoch": 0.4420739032242564,
      "grad_norm": 0.6786264181137085,
      "learning_rate": 4.778987074143482e-05,
      "loss": 0.0016,
      "step": 9200
    },
    {
      "epoch": 0.4444764787852578,
      "grad_norm": 0.39735889434814453,
      "learning_rate": 4.777785786362982e-05,
      "loss": 0.0015,
      "step": 9250
    },
    {
      "epoch": 0.4468790543462592,
      "grad_norm": 0.30964046716690063,
      "learning_rate": 4.776584498582481e-05,
      "loss": 0.001,
      "step": 9300
    },
    {
      "epoch": 0.44928162990726056,
      "grad_norm": 0.3742053806781769,
      "learning_rate": 4.77538321080198e-05,
      "loss": 0.0013,
      "step": 9350
    },
    {
      "epoch": 0.451684205468262,
      "grad_norm": 0.16615520417690277,
      "learning_rate": 4.774181923021479e-05,
      "loss": 0.0022,
      "step": 9400
    },
    {
      "epoch": 0.45408678102926336,
      "grad_norm": 1.7019116878509521,
      "learning_rate": 4.772980635240979e-05,
      "loss": 0.0018,
      "step": 9450
    },
    {
      "epoch": 0.45648935659026474,
      "grad_norm": 0.36377424001693726,
      "learning_rate": 4.771779347460478e-05,
      "loss": 0.0025,
      "step": 9500
    },
    {
      "epoch": 0.45889193215126617,
      "grad_norm": 0.26808589696884155,
      "learning_rate": 4.770578059679977e-05,
      "loss": 0.0013,
      "step": 9550
    },
    {
      "epoch": 0.46129450771226754,
      "grad_norm": 1.0855271816253662,
      "learning_rate": 4.7693767718994766e-05,
      "loss": 0.0019,
      "step": 9600
    },
    {
      "epoch": 0.4636970832732689,
      "grad_norm": 0.8001090884208679,
      "learning_rate": 4.768175484118976e-05,
      "loss": 0.0013,
      "step": 9650
    },
    {
      "epoch": 0.46609965883427035,
      "grad_norm": 0.2877447009086609,
      "learning_rate": 4.766974196338475e-05,
      "loss": 0.0013,
      "step": 9700
    },
    {
      "epoch": 0.4685022343952717,
      "grad_norm": 0.15168769657611847,
      "learning_rate": 4.7657729085579746e-05,
      "loss": 0.001,
      "step": 9750
    },
    {
      "epoch": 0.47090480995627315,
      "grad_norm": 0.13548272848129272,
      "learning_rate": 4.7645716207774736e-05,
      "loss": 0.0014,
      "step": 9800
    },
    {
      "epoch": 0.4733073855172745,
      "grad_norm": 0.2586910128593445,
      "learning_rate": 4.7633703329969734e-05,
      "loss": 0.001,
      "step": 9850
    },
    {
      "epoch": 0.4757099610782759,
      "grad_norm": 0.19806697964668274,
      "learning_rate": 4.7621690452164725e-05,
      "loss": 0.001,
      "step": 9900
    },
    {
      "epoch": 0.47811253663927733,
      "grad_norm": 0.5505807399749756,
      "learning_rate": 4.7609677574359716e-05,
      "loss": 0.0017,
      "step": 9950
    },
    {
      "epoch": 0.4805151122002787,
      "grad_norm": 0.4760282039642334,
      "learning_rate": 4.759766469655471e-05,
      "loss": 0.0009,
      "step": 10000
    },
    {
      "epoch": 0.4829176877612801,
      "grad_norm": 1.452796459197998,
      "learning_rate": 4.7585651818749704e-05,
      "loss": 0.0013,
      "step": 10050
    },
    {
      "epoch": 0.4853202633222815,
      "grad_norm": 0.21217229962348938,
      "learning_rate": 4.7573638940944695e-05,
      "loss": 0.0016,
      "step": 10100
    },
    {
      "epoch": 0.4877228388832829,
      "grad_norm": 0.1599077433347702,
      "learning_rate": 4.7561626063139686e-05,
      "loss": 0.0008,
      "step": 10150
    },
    {
      "epoch": 0.49012541444428426,
      "grad_norm": 0.2584468424320221,
      "learning_rate": 4.7549613185334677e-05,
      "loss": 0.001,
      "step": 10200
    },
    {
      "epoch": 0.4925279900052857,
      "grad_norm": 0.32612329721450806,
      "learning_rate": 4.7537600307529674e-05,
      "loss": 0.0013,
      "step": 10250
    },
    {
      "epoch": 0.49493056556628706,
      "grad_norm": 0.24040719866752625,
      "learning_rate": 4.7525587429724665e-05,
      "loss": 0.0014,
      "step": 10300
    },
    {
      "epoch": 0.49733314112728844,
      "grad_norm": 0.418674111366272,
      "learning_rate": 4.751357455191966e-05,
      "loss": 0.0007,
      "step": 10350
    },
    {
      "epoch": 0.49973571668828987,
      "grad_norm": 0.4090425670146942,
      "learning_rate": 4.7501561674114653e-05,
      "loss": 0.0009,
      "step": 10400
    },
    {
      "epoch": 0.5021382922492912,
      "grad_norm": 0.1169799342751503,
      "learning_rate": 4.7489548796309644e-05,
      "loss": 0.0009,
      "step": 10450
    },
    {
      "epoch": 0.5045408678102926,
      "grad_norm": 0.3678429126739502,
      "learning_rate": 4.747753591850464e-05,
      "loss": 0.0008,
      "step": 10500
    },
    {
      "epoch": 0.506943443371294,
      "grad_norm": 0.24571798741817474,
      "learning_rate": 4.746552304069963e-05,
      "loss": 0.0012,
      "step": 10550
    },
    {
      "epoch": 0.5093460189322955,
      "grad_norm": 0.12910117208957672,
      "learning_rate": 4.7453510162894623e-05,
      "loss": 0.0007,
      "step": 10600
    },
    {
      "epoch": 0.5117485944932968,
      "grad_norm": 0.37375181913375854,
      "learning_rate": 4.744149728508962e-05,
      "loss": 0.0007,
      "step": 10650
    },
    {
      "epoch": 0.5141511700542982,
      "grad_norm": 0.21670688688755035,
      "learning_rate": 4.742948440728461e-05,
      "loss": 0.0009,
      "step": 10700
    },
    {
      "epoch": 0.5165537456152997,
      "grad_norm": 0.9681891202926636,
      "learning_rate": 4.741747152947961e-05,
      "loss": 0.0008,
      "step": 10750
    },
    {
      "epoch": 0.518956321176301,
      "grad_norm": 0.688563346862793,
      "learning_rate": 4.74054586516746e-05,
      "loss": 0.0008,
      "step": 10800
    },
    {
      "epoch": 0.5213588967373024,
      "grad_norm": 0.45723238587379456,
      "learning_rate": 4.739344577386959e-05,
      "loss": 0.0011,
      "step": 10850
    },
    {
      "epoch": 0.5237614722983038,
      "grad_norm": 0.3736203908920288,
      "learning_rate": 4.738143289606458e-05,
      "loss": 0.0009,
      "step": 10900
    },
    {
      "epoch": 0.5261640478593052,
      "grad_norm": 0.28052544593811035,
      "learning_rate": 4.736942001825957e-05,
      "loss": 0.0007,
      "step": 10950
    },
    {
      "epoch": 0.5285666234203066,
      "grad_norm": 0.12103938311338425,
      "learning_rate": 4.735740714045457e-05,
      "loss": 0.001,
      "step": 11000
    },
    {
      "epoch": 0.530969198981308,
      "grad_norm": 0.49166709184646606,
      "learning_rate": 4.734539426264956e-05,
      "loss": 0.0017,
      "step": 11050
    },
    {
      "epoch": 0.5333717745423093,
      "grad_norm": 0.49919912219047546,
      "learning_rate": 4.733338138484455e-05,
      "loss": 0.0007,
      "step": 11100
    },
    {
      "epoch": 0.5357743501033108,
      "grad_norm": 0.7029434442520142,
      "learning_rate": 4.732136850703955e-05,
      "loss": 0.0009,
      "step": 11150
    },
    {
      "epoch": 0.5381769256643122,
      "grad_norm": 0.25718995928764343,
      "learning_rate": 4.730935562923454e-05,
      "loss": 0.0006,
      "step": 11200
    },
    {
      "epoch": 0.5405795012253135,
      "grad_norm": 0.4542209506034851,
      "learning_rate": 4.729734275142954e-05,
      "loss": 0.0015,
      "step": 11250
    },
    {
      "epoch": 0.5429820767863149,
      "grad_norm": 0.22616103291511536,
      "learning_rate": 4.728532987362453e-05,
      "loss": 0.0006,
      "step": 11300
    },
    {
      "epoch": 0.5453846523473164,
      "grad_norm": 0.4343211352825165,
      "learning_rate": 4.727331699581952e-05,
      "loss": 0.0009,
      "step": 11350
    },
    {
      "epoch": 0.5477872279083177,
      "grad_norm": 0.3514123558998108,
      "learning_rate": 4.726130411801452e-05,
      "loss": 0.001,
      "step": 11400
    },
    {
      "epoch": 0.5501898034693191,
      "grad_norm": 0.10461115837097168,
      "learning_rate": 4.724929124020951e-05,
      "loss": 0.0007,
      "step": 11450
    },
    {
      "epoch": 0.5525923790303205,
      "grad_norm": 0.7199437022209167,
      "learning_rate": 4.72372783624045e-05,
      "loss": 0.0006,
      "step": 11500
    },
    {
      "epoch": 0.5549949545913219,
      "grad_norm": 0.32292890548706055,
      "learning_rate": 4.722526548459949e-05,
      "loss": 0.0009,
      "step": 11550
    },
    {
      "epoch": 0.5573975301523233,
      "grad_norm": 0.6617770195007324,
      "learning_rate": 4.721325260679448e-05,
      "loss": 0.0007,
      "step": 11600
    },
    {
      "epoch": 0.5598001057133247,
      "grad_norm": 0.06440966576337814,
      "learning_rate": 4.720123972898948e-05,
      "loss": 0.0006,
      "step": 11650
    },
    {
      "epoch": 0.562202681274326,
      "grad_norm": 0.3029870092868805,
      "learning_rate": 4.718922685118447e-05,
      "loss": 0.0017,
      "step": 11700
    },
    {
      "epoch": 0.5646052568353275,
      "grad_norm": 0.2416248321533203,
      "learning_rate": 4.717721397337947e-05,
      "loss": 0.0008,
      "step": 11750
    },
    {
      "epoch": 0.5670078323963289,
      "grad_norm": 0.20123884081840515,
      "learning_rate": 4.716520109557446e-05,
      "loss": 0.0006,
      "step": 11800
    },
    {
      "epoch": 0.5694104079573302,
      "grad_norm": 0.3825666308403015,
      "learning_rate": 4.715318821776945e-05,
      "loss": 0.0008,
      "step": 11850
    },
    {
      "epoch": 0.5718129835183317,
      "grad_norm": 0.35742446780204773,
      "learning_rate": 4.7141175339964446e-05,
      "loss": 0.0013,
      "step": 11900
    },
    {
      "epoch": 0.5742155590793331,
      "grad_norm": 0.21975021064281464,
      "learning_rate": 4.712916246215944e-05,
      "loss": 0.0007,
      "step": 11950
    },
    {
      "epoch": 0.5766181346403344,
      "grad_norm": 0.607764482498169,
      "learning_rate": 4.711714958435443e-05,
      "loss": 0.0006,
      "step": 12000
    },
    {
      "epoch": 0.5790207102013358,
      "grad_norm": 0.2979283034801483,
      "learning_rate": 4.7105136706549425e-05,
      "loss": 0.0009,
      "step": 12050
    },
    {
      "epoch": 0.5814232857623373,
      "grad_norm": 0.22214260697364807,
      "learning_rate": 4.7093123828744416e-05,
      "loss": 0.0006,
      "step": 12100
    },
    {
      "epoch": 0.5838258613233386,
      "grad_norm": 0.2760601341724396,
      "learning_rate": 4.7081110950939414e-05,
      "loss": 0.0007,
      "step": 12150
    },
    {
      "epoch": 0.58622843688434,
      "grad_norm": 0.5125977993011475,
      "learning_rate": 4.7069098073134404e-05,
      "loss": 0.0006,
      "step": 12200
    },
    {
      "epoch": 0.5886310124453414,
      "grad_norm": 0.39274945855140686,
      "learning_rate": 4.7057085195329395e-05,
      "loss": 0.0012,
      "step": 12250
    },
    {
      "epoch": 0.5910335880063428,
      "grad_norm": 0.12645234167575836,
      "learning_rate": 4.7045072317524386e-05,
      "loss": 0.0016,
      "step": 12300
    },
    {
      "epoch": 0.5934361635673442,
      "grad_norm": 0.5217161178588867,
      "learning_rate": 4.703305943971938e-05,
      "loss": 0.0007,
      "step": 12350
    },
    {
      "epoch": 0.5958387391283456,
      "grad_norm": 0.15700966119766235,
      "learning_rate": 4.7021046561914375e-05,
      "loss": 0.0006,
      "step": 12400
    },
    {
      "epoch": 0.5982413146893469,
      "grad_norm": 0.506783127784729,
      "learning_rate": 4.7009033684109365e-05,
      "loss": 0.0007,
      "step": 12450
    },
    {
      "epoch": 0.6006438902503484,
      "grad_norm": 0.7790651917457581,
      "learning_rate": 4.6997020806304356e-05,
      "loss": 0.0007,
      "step": 12500
    },
    {
      "epoch": 0.6030464658113498,
      "grad_norm": 0.4262654185295105,
      "learning_rate": 4.6985007928499354e-05,
      "loss": 0.0007,
      "step": 12550
    },
    {
      "epoch": 0.6054490413723511,
      "grad_norm": 0.16989585757255554,
      "learning_rate": 4.6972995050694345e-05,
      "loss": 0.0006,
      "step": 12600
    },
    {
      "epoch": 0.6078516169333525,
      "grad_norm": 0.3065897226333618,
      "learning_rate": 4.696098217288934e-05,
      "loss": 0.0005,
      "step": 12650
    },
    {
      "epoch": 0.610254192494354,
      "grad_norm": 0.4384155869483948,
      "learning_rate": 4.694896929508433e-05,
      "loss": 0.0005,
      "step": 12700
    },
    {
      "epoch": 0.6126567680553553,
      "grad_norm": 0.6204643845558167,
      "learning_rate": 4.6936956417279324e-05,
      "loss": 0.0006,
      "step": 12750
    },
    {
      "epoch": 0.6150593436163567,
      "grad_norm": 0.6278405785560608,
      "learning_rate": 4.692494353947432e-05,
      "loss": 0.0006,
      "step": 12800
    },
    {
      "epoch": 0.6174619191773582,
      "grad_norm": 0.1425287276506424,
      "learning_rate": 4.691293066166931e-05,
      "loss": 0.0007,
      "step": 12850
    },
    {
      "epoch": 0.6198644947383595,
      "grad_norm": 0.5710081458091736,
      "learning_rate": 4.690091778386431e-05,
      "loss": 0.0007,
      "step": 12900
    },
    {
      "epoch": 0.6222670702993609,
      "grad_norm": 0.49438947439193726,
      "learning_rate": 4.68889049060593e-05,
      "loss": 0.0007,
      "step": 12950
    },
    {
      "epoch": 0.6246696458603623,
      "grad_norm": 0.15969662368297577,
      "learning_rate": 4.687689202825429e-05,
      "loss": 0.0005,
      "step": 13000
    },
    {
      "epoch": 0.6270722214213637,
      "grad_norm": 0.2225857973098755,
      "learning_rate": 4.686487915044928e-05,
      "loss": 0.0005,
      "step": 13050
    },
    {
      "epoch": 0.6294747969823651,
      "grad_norm": 0.24664218723773956,
      "learning_rate": 4.685286627264427e-05,
      "loss": 0.0006,
      "step": 13100
    },
    {
      "epoch": 0.6318773725433665,
      "grad_norm": 0.11504471302032471,
      "learning_rate": 4.684085339483927e-05,
      "loss": 0.0005,
      "step": 13150
    },
    {
      "epoch": 0.6342799481043678,
      "grad_norm": 0.7715178728103638,
      "learning_rate": 4.682884051703426e-05,
      "loss": 0.0007,
      "step": 13200
    },
    {
      "epoch": 0.6366825236653693,
      "grad_norm": 0.20270946621894836,
      "learning_rate": 4.681682763922925e-05,
      "loss": 0.0006,
      "step": 13250
    },
    {
      "epoch": 0.6390850992263707,
      "grad_norm": 0.21342764794826508,
      "learning_rate": 4.680481476142425e-05,
      "loss": 0.0005,
      "step": 13300
    },
    {
      "epoch": 0.641487674787372,
      "grad_norm": 0.5223425030708313,
      "learning_rate": 4.679280188361924e-05,
      "loss": 0.0005,
      "step": 13350
    },
    {
      "epoch": 0.6438902503483734,
      "grad_norm": 0.12004567682743073,
      "learning_rate": 4.678078900581424e-05,
      "loss": 0.0006,
      "step": 13400
    },
    {
      "epoch": 0.6462928259093749,
      "grad_norm": 0.42098134756088257,
      "learning_rate": 4.676877612800923e-05,
      "loss": 0.0007,
      "step": 13450
    },
    {
      "epoch": 0.6486954014703763,
      "grad_norm": 0.2151358425617218,
      "learning_rate": 4.675676325020422e-05,
      "loss": 0.0005,
      "step": 13500
    },
    {
      "epoch": 0.6510979770313776,
      "grad_norm": 0.1564132422208786,
      "learning_rate": 4.674475037239922e-05,
      "loss": 0.0006,
      "step": 13550
    },
    {
      "epoch": 0.653500552592379,
      "grad_norm": 0.34378185868263245,
      "learning_rate": 4.673273749459421e-05,
      "loss": 0.0005,
      "step": 13600
    },
    {
      "epoch": 0.6559031281533805,
      "grad_norm": 0.5846260786056519,
      "learning_rate": 4.67207246167892e-05,
      "loss": 0.0005,
      "step": 13650
    },
    {
      "epoch": 0.6583057037143818,
      "grad_norm": 0.31590744853019714,
      "learning_rate": 4.67087117389842e-05,
      "loss": 0.0009,
      "step": 13700
    },
    {
      "epoch": 0.6607082792753832,
      "grad_norm": 0.12359816581010818,
      "learning_rate": 4.669669886117919e-05,
      "loss": 0.0006,
      "step": 13750
    },
    {
      "epoch": 0.6631108548363847,
      "grad_norm": 0.3400913178920746,
      "learning_rate": 4.668468598337418e-05,
      "loss": 0.0006,
      "step": 13800
    },
    {
      "epoch": 0.665513430397386,
      "grad_norm": 0.4283086061477661,
      "learning_rate": 4.667267310556917e-05,
      "loss": 0.0006,
      "step": 13850
    },
    {
      "epoch": 0.6679160059583874,
      "grad_norm": 0.7601321935653687,
      "learning_rate": 4.666066022776416e-05,
      "loss": 0.0006,
      "step": 13900
    },
    {
      "epoch": 0.6703185815193888,
      "grad_norm": 0.3197753131389618,
      "learning_rate": 4.664864734995916e-05,
      "loss": 0.0005,
      "step": 13950
    },
    {
      "epoch": 0.6727211570803902,
      "grad_norm": 0.6270705461502075,
      "learning_rate": 4.663663447215415e-05,
      "loss": 0.0013,
      "step": 14000
    },
    {
      "epoch": 0.6751237326413916,
      "grad_norm": 0.14623108506202698,
      "learning_rate": 4.6624621594349146e-05,
      "loss": 0.0004,
      "step": 14050
    },
    {
      "epoch": 0.677526308202393,
      "grad_norm": 0.1553351879119873,
      "learning_rate": 4.661260871654414e-05,
      "loss": 0.0004,
      "step": 14100
    },
    {
      "epoch": 0.6799288837633943,
      "grad_norm": 0.4013386368751526,
      "learning_rate": 4.660059583873913e-05,
      "loss": 0.0005,
      "step": 14150
    },
    {
      "epoch": 0.6823314593243958,
      "grad_norm": 0.22471214830875397,
      "learning_rate": 4.6588582960934126e-05,
      "loss": 0.0006,
      "step": 14200
    },
    {
      "epoch": 0.6847340348853972,
      "grad_norm": 0.3483694791793823,
      "learning_rate": 4.6576570083129116e-05,
      "loss": 0.0004,
      "step": 14250
    },
    {
      "epoch": 0.6871366104463985,
      "grad_norm": 0.2009802907705307,
      "learning_rate": 4.6564557205324114e-05,
      "loss": 0.0004,
      "step": 14300
    },
    {
      "epoch": 0.6895391860073999,
      "grad_norm": 0.48448190093040466,
      "learning_rate": 4.6552544327519105e-05,
      "loss": 0.0005,
      "step": 14350
    },
    {
      "epoch": 0.6919417615684014,
      "grad_norm": 0.5146467685699463,
      "learning_rate": 4.6540531449714096e-05,
      "loss": 0.0005,
      "step": 14400
    },
    {
      "epoch": 0.6943443371294027,
      "grad_norm": 0.3616337478160858,
      "learning_rate": 4.652851857190909e-05,
      "loss": 0.0005,
      "step": 14450
    },
    {
      "epoch": 0.6967469126904041,
      "grad_norm": 0.5003799200057983,
      "learning_rate": 4.6516505694104084e-05,
      "loss": 0.0006,
      "step": 14500
    },
    {
      "epoch": 0.6991494882514055,
      "grad_norm": 0.14854463934898376,
      "learning_rate": 4.6504492816299075e-05,
      "loss": 0.0012,
      "step": 14550
    },
    {
      "epoch": 0.7015520638124069,
      "grad_norm": 0.21859683096408844,
      "learning_rate": 4.6492479938494066e-05,
      "loss": 0.0013,
      "step": 14600
    },
    {
      "epoch": 0.7039546393734083,
      "grad_norm": 0.1741461604833603,
      "learning_rate": 4.6480467060689057e-05,
      "loss": 0.0004,
      "step": 14650
    },
    {
      "epoch": 0.7063572149344097,
      "grad_norm": 0.051883917301893234,
      "learning_rate": 4.6468454182884054e-05,
      "loss": 0.0004,
      "step": 14700
    },
    {
      "epoch": 0.708759790495411,
      "grad_norm": 0.5903456211090088,
      "learning_rate": 4.6456441305079045e-05,
      "loss": 0.0004,
      "step": 14750
    },
    {
      "epoch": 0.7111623660564125,
      "grad_norm": 0.22995281219482422,
      "learning_rate": 4.644442842727404e-05,
      "loss": 0.0004,
      "step": 14800
    },
    {
      "epoch": 0.7135649416174139,
      "grad_norm": 0.04761036857962608,
      "learning_rate": 4.643241554946903e-05,
      "loss": 0.0004,
      "step": 14850
    },
    {
      "epoch": 0.7159675171784152,
      "grad_norm": 0.5436388254165649,
      "learning_rate": 4.6420402671664024e-05,
      "loss": 0.0003,
      "step": 14900
    },
    {
      "epoch": 0.7183700927394167,
      "grad_norm": 0.15185348689556122,
      "learning_rate": 4.640838979385902e-05,
      "loss": 0.0018,
      "step": 14950
    },
    {
      "epoch": 0.7207726683004181,
      "grad_norm": 0.1837403029203415,
      "learning_rate": 4.639637691605401e-05,
      "loss": 0.0005,
      "step": 15000
    },
    {
      "epoch": 0.7231752438614194,
      "grad_norm": 0.23922692239284515,
      "learning_rate": 4.6384364038249003e-05,
      "loss": 0.0004,
      "step": 15050
    },
    {
      "epoch": 0.7255778194224208,
      "grad_norm": 0.15882593393325806,
      "learning_rate": 4.6372351160444e-05,
      "loss": 0.0003,
      "step": 15100
    },
    {
      "epoch": 0.7279803949834223,
      "grad_norm": 0.09423285722732544,
      "learning_rate": 4.636033828263899e-05,
      "loss": 0.0007,
      "step": 15150
    },
    {
      "epoch": 0.7303829705444236,
      "grad_norm": 0.260184645652771,
      "learning_rate": 4.634832540483399e-05,
      "loss": 0.0005,
      "step": 15200
    },
    {
      "epoch": 0.732785546105425,
      "grad_norm": 0.20817090570926666,
      "learning_rate": 4.633631252702898e-05,
      "loss": 0.0006,
      "step": 15250
    },
    {
      "epoch": 0.7351881216664264,
      "grad_norm": 0.17084501683712006,
      "learning_rate": 4.632429964922397e-05,
      "loss": 0.0004,
      "step": 15300
    },
    {
      "epoch": 0.7375906972274278,
      "grad_norm": 0.193682000041008,
      "learning_rate": 4.631228677141896e-05,
      "loss": 0.0004,
      "step": 15350
    },
    {
      "epoch": 0.7399932727884292,
      "grad_norm": 0.15719152987003326,
      "learning_rate": 4.630027389361395e-05,
      "loss": 0.0005,
      "step": 15400
    },
    {
      "epoch": 0.7423958483494306,
      "grad_norm": 0.1569463014602661,
      "learning_rate": 4.628826101580895e-05,
      "loss": 0.0005,
      "step": 15450
    },
    {
      "epoch": 0.7447984239104319,
      "grad_norm": 0.17209003865718842,
      "learning_rate": 4.627624813800394e-05,
      "loss": 0.0004,
      "step": 15500
    },
    {
      "epoch": 0.7472009994714334,
      "grad_norm": 0.1934378743171692,
      "learning_rate": 4.626423526019893e-05,
      "loss": 0.0004,
      "step": 15550
    },
    {
      "epoch": 0.7496035750324348,
      "grad_norm": 0.10144836455583572,
      "learning_rate": 4.625222238239393e-05,
      "loss": 0.0004,
      "step": 15600
    },
    {
      "epoch": 0.7520061505934361,
      "grad_norm": 0.5811201333999634,
      "learning_rate": 4.624020950458892e-05,
      "loss": 0.0004,
      "step": 15650
    },
    {
      "epoch": 0.7544087261544375,
      "grad_norm": 0.3101181089878082,
      "learning_rate": 4.622819662678392e-05,
      "loss": 0.0004,
      "step": 15700
    },
    {
      "epoch": 0.756811301715439,
      "grad_norm": 0.3473042845726013,
      "learning_rate": 4.621618374897891e-05,
      "loss": 0.0003,
      "step": 15750
    },
    {
      "epoch": 0.7592138772764403,
      "grad_norm": 0.8602665066719055,
      "learning_rate": 4.62041708711739e-05,
      "loss": 0.0005,
      "step": 15800
    },
    {
      "epoch": 0.7616164528374417,
      "grad_norm": 0.16456608474254608,
      "learning_rate": 4.61921579933689e-05,
      "loss": 0.0006,
      "step": 15850
    },
    {
      "epoch": 0.7640190283984432,
      "grad_norm": 0.17578771710395813,
      "learning_rate": 4.618014511556389e-05,
      "loss": 0.0004,
      "step": 15900
    },
    {
      "epoch": 0.7664216039594445,
      "grad_norm": 0.443629652261734,
      "learning_rate": 4.616813223775888e-05,
      "loss": 0.0005,
      "step": 15950
    },
    {
      "epoch": 0.7688241795204459,
      "grad_norm": 0.06637255847454071,
      "learning_rate": 4.6156119359953877e-05,
      "loss": 0.0012,
      "step": 16000
    },
    {
      "epoch": 0.7712267550814473,
      "grad_norm": 0.4256909489631653,
      "learning_rate": 4.614410648214886e-05,
      "loss": 0.0004,
      "step": 16050
    },
    {
      "epoch": 0.7736293306424487,
      "grad_norm": 0.17608195543289185,
      "learning_rate": 4.613209360434386e-05,
      "loss": 0.0004,
      "step": 16100
    },
    {
      "epoch": 0.7760319062034501,
      "grad_norm": 0.06355367600917816,
      "learning_rate": 4.612008072653885e-05,
      "loss": 0.0004,
      "step": 16150
    },
    {
      "epoch": 0.7784344817644515,
      "grad_norm": 0.21487824618816376,
      "learning_rate": 4.610806784873385e-05,
      "loss": 0.0004,
      "step": 16200
    },
    {
      "epoch": 0.7808370573254528,
      "grad_norm": 0.4879235327243805,
      "learning_rate": 4.609605497092884e-05,
      "loss": 0.0003,
      "step": 16250
    },
    {
      "epoch": 0.7832396328864543,
      "grad_norm": 0.47245651483535767,
      "learning_rate": 4.608404209312383e-05,
      "loss": 0.0004,
      "step": 16300
    },
    {
      "epoch": 0.7856422084474557,
      "grad_norm": 0.27663683891296387,
      "learning_rate": 4.6072029215318826e-05,
      "loss": 0.0004,
      "step": 16350
    },
    {
      "epoch": 0.788044784008457,
      "grad_norm": 0.10262192040681839,
      "learning_rate": 4.606001633751382e-05,
      "loss": 0.0005,
      "step": 16400
    },
    {
      "epoch": 0.7904473595694584,
      "grad_norm": 0.18882723152637482,
      "learning_rate": 4.604800345970881e-05,
      "loss": 0.0003,
      "step": 16450
    },
    {
      "epoch": 0.7928499351304599,
      "grad_norm": 0.3279273808002472,
      "learning_rate": 4.6035990581903805e-05,
      "loss": 0.0003,
      "step": 16500
    },
    {
      "epoch": 0.7952525106914613,
      "grad_norm": 0.23209944367408752,
      "learning_rate": 4.6023977704098796e-05,
      "loss": 0.0003,
      "step": 16550
    },
    {
      "epoch": 0.7976550862524626,
      "grad_norm": 0.29151651263237,
      "learning_rate": 4.6011964826293794e-05,
      "loss": 0.0004,
      "step": 16600
    },
    {
      "epoch": 0.800057661813464,
      "grad_norm": 0.23741181194782257,
      "learning_rate": 4.5999951948488784e-05,
      "loss": 0.0004,
      "step": 16650
    },
    {
      "epoch": 0.8024602373744655,
      "grad_norm": 0.1282050758600235,
      "learning_rate": 4.5987939070683775e-05,
      "loss": 0.0006,
      "step": 16700
    },
    {
      "epoch": 0.8048628129354668,
      "grad_norm": 0.5281004309654236,
      "learning_rate": 4.597592619287877e-05,
      "loss": 0.0003,
      "step": 16750
    },
    {
      "epoch": 0.8072653884964682,
      "grad_norm": 0.105466328561306,
      "learning_rate": 4.596391331507376e-05,
      "loss": 0.0006,
      "step": 16800
    },
    {
      "epoch": 0.8096679640574697,
      "grad_norm": 0.33728885650634766,
      "learning_rate": 4.5951900437268754e-05,
      "loss": 0.0003,
      "step": 16850
    },
    {
      "epoch": 0.812070539618471,
      "grad_norm": 0.3270459473133087,
      "learning_rate": 4.5939887559463745e-05,
      "loss": 0.0003,
      "step": 16900
    },
    {
      "epoch": 0.8144731151794724,
      "grad_norm": 0.39197736978530884,
      "learning_rate": 4.5927874681658736e-05,
      "loss": 0.0004,
      "step": 16950
    },
    {
      "epoch": 0.8168756907404738,
      "grad_norm": 0.2630337178707123,
      "learning_rate": 4.5915861803853734e-05,
      "loss": 0.0005,
      "step": 17000
    },
    {
      "epoch": 0.8192782663014752,
      "grad_norm": 0.12100967764854431,
      "learning_rate": 4.5903848926048725e-05,
      "loss": 0.0004,
      "step": 17050
    },
    {
      "epoch": 0.8216808418624766,
      "grad_norm": 0.30437594652175903,
      "learning_rate": 4.589183604824372e-05,
      "loss": 0.0004,
      "step": 17100
    },
    {
      "epoch": 0.824083417423478,
      "grad_norm": 0.23258104920387268,
      "learning_rate": 4.587982317043871e-05,
      "loss": 0.0004,
      "step": 17150
    },
    {
      "epoch": 0.8264859929844793,
      "grad_norm": 0.26034241914749146,
      "learning_rate": 4.5867810292633704e-05,
      "loss": 0.0004,
      "step": 17200
    },
    {
      "epoch": 0.8288885685454808,
      "grad_norm": 0.6104981303215027,
      "learning_rate": 4.58557974148287e-05,
      "loss": 0.0003,
      "step": 17250
    },
    {
      "epoch": 0.8312911441064822,
      "grad_norm": 0.1092868521809578,
      "learning_rate": 4.584378453702369e-05,
      "loss": 0.0003,
      "step": 17300
    },
    {
      "epoch": 0.8336937196674835,
      "grad_norm": 0.3565486669540405,
      "learning_rate": 4.583177165921868e-05,
      "loss": 0.0019,
      "step": 17350
    },
    {
      "epoch": 0.8360962952284849,
      "grad_norm": 0.039763398468494415,
      "learning_rate": 4.581975878141368e-05,
      "loss": 0.001,
      "step": 17400
    },
    {
      "epoch": 0.8384988707894864,
      "grad_norm": 0.22541488707065582,
      "learning_rate": 4.580774590360867e-05,
      "loss": 0.0004,
      "step": 17450
    },
    {
      "epoch": 0.8409014463504877,
      "grad_norm": 0.4568646550178528,
      "learning_rate": 4.579573302580366e-05,
      "loss": 0.0003,
      "step": 17500
    },
    {
      "epoch": 0.8433040219114891,
      "grad_norm": 0.210551917552948,
      "learning_rate": 4.578372014799865e-05,
      "loss": 0.0004,
      "step": 17550
    },
    {
      "epoch": 0.8457065974724906,
      "grad_norm": 0.09916633367538452,
      "learning_rate": 4.577170727019365e-05,
      "loss": 0.0003,
      "step": 17600
    },
    {
      "epoch": 0.8481091730334919,
      "grad_norm": 0.0883723720908165,
      "learning_rate": 4.575969439238864e-05,
      "loss": 0.0003,
      "step": 17650
    },
    {
      "epoch": 0.8505117485944933,
      "grad_norm": 0.2823579013347626,
      "learning_rate": 4.574768151458363e-05,
      "loss": 0.0003,
      "step": 17700
    },
    {
      "epoch": 0.8529143241554947,
      "grad_norm": 0.33642271161079407,
      "learning_rate": 4.573566863677863e-05,
      "loss": 0.0003,
      "step": 17750
    },
    {
      "epoch": 0.855316899716496,
      "grad_norm": 0.3782644271850586,
      "learning_rate": 4.572365575897362e-05,
      "loss": 0.0004,
      "step": 17800
    },
    {
      "epoch": 0.8577194752774975,
      "grad_norm": 0.1584354192018509,
      "learning_rate": 4.571164288116861e-05,
      "loss": 0.0004,
      "step": 17850
    },
    {
      "epoch": 0.8601220508384989,
      "grad_norm": 0.37643149495124817,
      "learning_rate": 4.569963000336361e-05,
      "loss": 0.0004,
      "step": 17900
    },
    {
      "epoch": 0.8625246263995002,
      "grad_norm": 0.32858750224113464,
      "learning_rate": 4.56876171255586e-05,
      "loss": 0.0003,
      "step": 17950
    },
    {
      "epoch": 0.8649272019605017,
      "grad_norm": 0.2948163151741028,
      "learning_rate": 4.56756042477536e-05,
      "loss": 0.0002,
      "step": 18000
    },
    {
      "epoch": 0.8673297775215031,
      "grad_norm": 0.344052255153656,
      "learning_rate": 4.566359136994859e-05,
      "loss": 0.0004,
      "step": 18050
    },
    {
      "epoch": 0.8697323530825044,
      "grad_norm": 0.12947531044483185,
      "learning_rate": 4.565157849214358e-05,
      "loss": 0.0004,
      "step": 18100
    },
    {
      "epoch": 0.8721349286435058,
      "grad_norm": 0.1878499984741211,
      "learning_rate": 4.563956561433858e-05,
      "loss": 0.0003,
      "step": 18150
    },
    {
      "epoch": 0.8745375042045073,
      "grad_norm": 0.13571342825889587,
      "learning_rate": 4.562755273653357e-05,
      "loss": 0.0004,
      "step": 18200
    },
    {
      "epoch": 0.8769400797655086,
      "grad_norm": 0.2651681900024414,
      "learning_rate": 4.561553985872856e-05,
      "loss": 0.0003,
      "step": 18250
    },
    {
      "epoch": 0.87934265532651,
      "grad_norm": 0.49337679147720337,
      "learning_rate": 4.560352698092355e-05,
      "loss": 0.0003,
      "step": 18300
    },
    {
      "epoch": 0.8817452308875114,
      "grad_norm": 0.17957456409931183,
      "learning_rate": 4.559151410311854e-05,
      "loss": 0.0003,
      "step": 18350
    },
    {
      "epoch": 0.8841478064485128,
      "grad_norm": 0.23218616843223572,
      "learning_rate": 4.557950122531354e-05,
      "loss": 0.0004,
      "step": 18400
    },
    {
      "epoch": 0.8865503820095142,
      "grad_norm": 0.3005669414997101,
      "learning_rate": 4.556748834750853e-05,
      "loss": 0.0004,
      "step": 18450
    },
    {
      "epoch": 0.8889529575705156,
      "grad_norm": 0.22637823224067688,
      "learning_rate": 4.5555475469703526e-05,
      "loss": 0.0004,
      "step": 18500
    },
    {
      "epoch": 0.8913555331315169,
      "grad_norm": 0.10558310896158218,
      "learning_rate": 4.554346259189852e-05,
      "loss": 0.0003,
      "step": 18550
    },
    {
      "epoch": 0.8937581086925184,
      "grad_norm": 0.22686965763568878,
      "learning_rate": 4.553144971409351e-05,
      "loss": 0.0003,
      "step": 18600
    },
    {
      "epoch": 0.8961606842535198,
      "grad_norm": 0.18179915845394135,
      "learning_rate": 4.5519436836288505e-05,
      "loss": 0.0003,
      "step": 18650
    },
    {
      "epoch": 0.8985632598145211,
      "grad_norm": 0.4425230026245117,
      "learning_rate": 4.5507423958483496e-05,
      "loss": 0.0004,
      "step": 18700
    },
    {
      "epoch": 0.9009658353755226,
      "grad_norm": 0.28177642822265625,
      "learning_rate": 4.5495411080678494e-05,
      "loss": 0.0004,
      "step": 18750
    },
    {
      "epoch": 0.903368410936524,
      "grad_norm": 0.22463539242744446,
      "learning_rate": 4.5483398202873485e-05,
      "loss": 0.0004,
      "step": 18800
    },
    {
      "epoch": 0.9057709864975253,
      "grad_norm": 0.07656191289424896,
      "learning_rate": 4.5471385325068476e-05,
      "loss": 0.0004,
      "step": 18850
    },
    {
      "epoch": 0.9081735620585267,
      "grad_norm": 0.5765153765678406,
      "learning_rate": 4.545937244726347e-05,
      "loss": 0.0003,
      "step": 18900
    },
    {
      "epoch": 0.9105761376195282,
      "grad_norm": 0.28534284234046936,
      "learning_rate": 4.5447359569458464e-05,
      "loss": 0.0003,
      "step": 18950
    },
    {
      "epoch": 0.9129787131805295,
      "grad_norm": 0.3234435021877289,
      "learning_rate": 4.5435346691653455e-05,
      "loss": 0.0003,
      "step": 19000
    },
    {
      "epoch": 0.9153812887415309,
      "grad_norm": 0.3263469934463501,
      "learning_rate": 4.5423333813848446e-05,
      "loss": 0.0003,
      "step": 19050
    },
    {
      "epoch": 0.9177838643025323,
      "grad_norm": 0.39933428168296814,
      "learning_rate": 4.5411320936043436e-05,
      "loss": 0.0003,
      "step": 19100
    },
    {
      "epoch": 0.9201864398635337,
      "grad_norm": 0.2768672704696655,
      "learning_rate": 4.5399308058238434e-05,
      "loss": 0.0004,
      "step": 19150
    },
    {
      "epoch": 0.9225890154245351,
      "grad_norm": 0.2994152307510376,
      "learning_rate": 4.5387295180433425e-05,
      "loss": 0.0003,
      "step": 19200
    },
    {
      "epoch": 0.9249915909855365,
      "grad_norm": 0.5419884920120239,
      "learning_rate": 4.5375282302628416e-05,
      "loss": 0.0003,
      "step": 19250
    },
    {
      "epoch": 0.9273941665465378,
      "grad_norm": 0.26611900329589844,
      "learning_rate": 4.536326942482341e-05,
      "loss": 0.0002,
      "step": 19300
    },
    {
      "epoch": 0.9297967421075393,
      "grad_norm": 0.26324787735939026,
      "learning_rate": 4.5351256547018404e-05,
      "loss": 0.0003,
      "step": 19350
    },
    {
      "epoch": 0.9321993176685407,
      "grad_norm": 0.18422597646713257,
      "learning_rate": 4.53392436692134e-05,
      "loss": 0.0003,
      "step": 19400
    },
    {
      "epoch": 0.9346018932295421,
      "grad_norm": 0.2393866926431656,
      "learning_rate": 4.532723079140839e-05,
      "loss": 0.0004,
      "step": 19450
    },
    {
      "epoch": 0.9370044687905434,
      "grad_norm": 0.11371919512748718,
      "learning_rate": 4.5315217913603383e-05,
      "loss": 0.0003,
      "step": 19500
    },
    {
      "epoch": 0.9394070443515449,
      "grad_norm": 0.1446971893310547,
      "learning_rate": 4.530320503579838e-05,
      "loss": 0.0003,
      "step": 19550
    },
    {
      "epoch": 0.9418096199125463,
      "grad_norm": 0.2577582895755768,
      "learning_rate": 4.529119215799337e-05,
      "loss": 0.0003,
      "step": 19600
    },
    {
      "epoch": 0.9442121954735476,
      "grad_norm": 0.33768004179000854,
      "learning_rate": 4.527917928018837e-05,
      "loss": 0.0005,
      "step": 19650
    },
    {
      "epoch": 0.946614771034549,
      "grad_norm": 0.4355790615081787,
      "learning_rate": 4.526716640238336e-05,
      "loss": 0.0003,
      "step": 19700
    },
    {
      "epoch": 0.9490173465955505,
      "grad_norm": 0.8038241267204285,
      "learning_rate": 4.5255153524578344e-05,
      "loss": 0.0004,
      "step": 19750
    },
    {
      "epoch": 0.9514199221565518,
      "grad_norm": 0.08516258746385574,
      "learning_rate": 4.524314064677334e-05,
      "loss": 0.0003,
      "step": 19800
    },
    {
      "epoch": 0.9538224977175532,
      "grad_norm": 0.6796096563339233,
      "learning_rate": 4.523112776896833e-05,
      "loss": 0.0003,
      "step": 19850
    },
    {
      "epoch": 0.9562250732785547,
      "grad_norm": 0.1397419571876526,
      "learning_rate": 4.521911489116333e-05,
      "loss": 0.0006,
      "step": 19900
    },
    {
      "epoch": 0.958627648839556,
      "grad_norm": 0.05650286376476288,
      "learning_rate": 4.520710201335832e-05,
      "loss": 0.0009,
      "step": 19950
    },
    {
      "epoch": 0.9610302244005574,
      "grad_norm": 0.1624632030725479,
      "learning_rate": 4.519508913555331e-05,
      "loss": 0.0004,
      "step": 20000
    },
    {
      "epoch": 0.9634327999615588,
      "grad_norm": 0.39822089672088623,
      "learning_rate": 4.518307625774831e-05,
      "loss": 0.0013,
      "step": 20050
    },
    {
      "epoch": 0.9658353755225602,
      "grad_norm": 0.09939216077327728,
      "learning_rate": 4.51710633799433e-05,
      "loss": 0.0006,
      "step": 20100
    },
    {
      "epoch": 0.9682379510835616,
      "grad_norm": 0.24893417954444885,
      "learning_rate": 4.51590505021383e-05,
      "loss": 0.001,
      "step": 20150
    },
    {
      "epoch": 0.970640526644563,
      "grad_norm": 0.49658769369125366,
      "learning_rate": 4.514703762433329e-05,
      "loss": 0.0003,
      "step": 20200
    },
    {
      "epoch": 0.9730431022055643,
      "grad_norm": 0.2812676727771759,
      "learning_rate": 4.513502474652828e-05,
      "loss": 0.0004,
      "step": 20250
    },
    {
      "epoch": 0.9754456777665658,
      "grad_norm": 0.09896504133939743,
      "learning_rate": 4.512301186872328e-05,
      "loss": 0.0002,
      "step": 20300
    },
    {
      "epoch": 0.9778482533275672,
      "grad_norm": 0.35569944977760315,
      "learning_rate": 4.511099899091827e-05,
      "loss": 0.0009,
      "step": 20350
    },
    {
      "epoch": 0.9802508288885685,
      "grad_norm": 0.3320241868495941,
      "learning_rate": 4.509898611311326e-05,
      "loss": 0.0002,
      "step": 20400
    },
    {
      "epoch": 0.98265340444957,
      "grad_norm": 0.14085736870765686,
      "learning_rate": 4.5086973235308257e-05,
      "loss": 0.0004,
      "step": 20450
    },
    {
      "epoch": 0.9850559800105714,
      "grad_norm": 0.39604371786117554,
      "learning_rate": 4.507496035750324e-05,
      "loss": 0.0003,
      "step": 20500
    },
    {
      "epoch": 0.9874585555715727,
      "grad_norm": 0.27979251742362976,
      "learning_rate": 4.506294747969824e-05,
      "loss": 0.0004,
      "step": 20550
    },
    {
      "epoch": 0.9898611311325741,
      "grad_norm": 0.5717251300811768,
      "learning_rate": 4.505093460189323e-05,
      "loss": 0.0004,
      "step": 20600
    },
    {
      "epoch": 0.9922637066935756,
      "grad_norm": 0.08681616932153702,
      "learning_rate": 4.5038921724088227e-05,
      "loss": 0.0003,
      "step": 20650
    },
    {
      "epoch": 0.9946662822545769,
      "grad_norm": 0.14518681168556213,
      "learning_rate": 4.502690884628322e-05,
      "loss": 0.0003,
      "step": 20700
    },
    {
      "epoch": 0.9970688578155783,
      "grad_norm": 0.20828211307525635,
      "learning_rate": 4.501489596847821e-05,
      "loss": 0.0003,
      "step": 20750
    },
    {
      "epoch": 0.9994714333765797,
      "grad_norm": 0.13671663403511047,
      "learning_rate": 4.5002883090673206e-05,
      "loss": 0.0008,
      "step": 20800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0003530265821609646,
      "eval_runtime": 17.3519,
      "eval_samples_per_second": 547.261,
      "eval_steps_per_second": 68.408,
      "step": 20811
    },
    {
      "epoch": 1.001874008937581,
      "grad_norm": 0.22540220618247986,
      "learning_rate": 4.49908702128682e-05,
      "loss": 0.0003,
      "step": 20850
    },
    {
      "epoch": 1.0042765844985824,
      "grad_norm": 0.17521248757839203,
      "learning_rate": 4.497885733506319e-05,
      "loss": 0.0002,
      "step": 20900
    },
    {
      "epoch": 1.006679160059584,
      "grad_norm": 0.34575599431991577,
      "learning_rate": 4.4966844457258185e-05,
      "loss": 0.0003,
      "step": 20950
    },
    {
      "epoch": 1.0090817356205852,
      "grad_norm": 0.4357072710990906,
      "learning_rate": 4.4954831579453176e-05,
      "loss": 0.0004,
      "step": 21000
    },
    {
      "epoch": 1.0114843111815868,
      "grad_norm": 0.3030729293823242,
      "learning_rate": 4.4942818701648174e-05,
      "loss": 0.0003,
      "step": 21050
    },
    {
      "epoch": 1.013886886742588,
      "grad_norm": 0.34333086013793945,
      "learning_rate": 4.4930805823843164e-05,
      "loss": 0.0003,
      "step": 21100
    },
    {
      "epoch": 1.0162894623035894,
      "grad_norm": 0.4592636227607727,
      "learning_rate": 4.4918792946038155e-05,
      "loss": 0.0004,
      "step": 21150
    },
    {
      "epoch": 1.018692037864591,
      "grad_norm": 0.19810563325881958,
      "learning_rate": 4.490678006823315e-05,
      "loss": 0.0003,
      "step": 21200
    },
    {
      "epoch": 1.0210946134255923,
      "grad_norm": 0.1706208437681198,
      "learning_rate": 4.489476719042814e-05,
      "loss": 0.0003,
      "step": 21250
    },
    {
      "epoch": 1.0234971889865936,
      "grad_norm": 0.3281797170639038,
      "learning_rate": 4.4882754312623134e-05,
      "loss": 0.0003,
      "step": 21300
    },
    {
      "epoch": 1.0258997645475951,
      "grad_norm": 0.15446533262729645,
      "learning_rate": 4.4870741434818125e-05,
      "loss": 0.0012,
      "step": 21350
    },
    {
      "epoch": 1.0283023401085964,
      "grad_norm": 0.10693914443254471,
      "learning_rate": 4.4858728557013116e-05,
      "loss": 0.0003,
      "step": 21400
    },
    {
      "epoch": 1.0307049156695978,
      "grad_norm": 0.5950049161911011,
      "learning_rate": 4.4846715679208114e-05,
      "loss": 0.0003,
      "step": 21450
    },
    {
      "epoch": 1.0331074912305993,
      "grad_norm": 0.4693148136138916,
      "learning_rate": 4.4834702801403105e-05,
      "loss": 0.0004,
      "step": 21500
    },
    {
      "epoch": 1.0355100667916006,
      "grad_norm": 0.09751024842262268,
      "learning_rate": 4.48226899235981e-05,
      "loss": 0.0003,
      "step": 21550
    },
    {
      "epoch": 1.037912642352602,
      "grad_norm": 0.11516804993152618,
      "learning_rate": 4.481067704579309e-05,
      "loss": 0.0002,
      "step": 21600
    },
    {
      "epoch": 1.0403152179136035,
      "grad_norm": 0.2428678423166275,
      "learning_rate": 4.4798664167988084e-05,
      "loss": 0.0002,
      "step": 21650
    },
    {
      "epoch": 1.0427177934746048,
      "grad_norm": 0.4114397466182709,
      "learning_rate": 4.478665129018308e-05,
      "loss": 0.001,
      "step": 21700
    },
    {
      "epoch": 1.0451203690356061,
      "grad_norm": 0.04575972259044647,
      "learning_rate": 4.477463841237807e-05,
      "loss": 0.0003,
      "step": 21750
    },
    {
      "epoch": 1.0475229445966077,
      "grad_norm": 0.08430736511945724,
      "learning_rate": 4.476262553457306e-05,
      "loss": 0.0003,
      "step": 21800
    },
    {
      "epoch": 1.049925520157609,
      "grad_norm": 0.5151498913764954,
      "learning_rate": 4.475061265676806e-05,
      "loss": 0.0003,
      "step": 21850
    },
    {
      "epoch": 1.0523280957186103,
      "grad_norm": 0.22281554341316223,
      "learning_rate": 4.473859977896305e-05,
      "loss": 0.0003,
      "step": 21900
    },
    {
      "epoch": 1.0547306712796118,
      "grad_norm": 0.1993546336889267,
      "learning_rate": 4.472658690115805e-05,
      "loss": 0.0005,
      "step": 21950
    },
    {
      "epoch": 1.0571332468406132,
      "grad_norm": 0.42535659670829773,
      "learning_rate": 4.471457402335303e-05,
      "loss": 0.0003,
      "step": 22000
    },
    {
      "epoch": 1.0595358224016145,
      "grad_norm": 0.20583006739616394,
      "learning_rate": 4.470256114554803e-05,
      "loss": 0.0003,
      "step": 22050
    },
    {
      "epoch": 1.061938397962616,
      "grad_norm": 0.2296852171421051,
      "learning_rate": 4.469054826774302e-05,
      "loss": 0.0004,
      "step": 22100
    },
    {
      "epoch": 1.0643409735236173,
      "grad_norm": 0.1629859358072281,
      "learning_rate": 4.467853538993801e-05,
      "loss": 0.0004,
      "step": 22150
    },
    {
      "epoch": 1.0667435490846187,
      "grad_norm": 0.19747678935527802,
      "learning_rate": 4.466652251213301e-05,
      "loss": 0.001,
      "step": 22200
    },
    {
      "epoch": 1.0691461246456202,
      "grad_norm": 0.1763625591993332,
      "learning_rate": 4.4654509634328e-05,
      "loss": 0.0004,
      "step": 22250
    },
    {
      "epoch": 1.0715487002066215,
      "grad_norm": 0.6522377133369446,
      "learning_rate": 4.464249675652299e-05,
      "loss": 0.0003,
      "step": 22300
    },
    {
      "epoch": 1.0739512757676228,
      "grad_norm": 0.1864190548658371,
      "learning_rate": 4.463048387871799e-05,
      "loss": 0.0003,
      "step": 22350
    },
    {
      "epoch": 1.0763538513286244,
      "grad_norm": 0.33472567796707153,
      "learning_rate": 4.461847100091298e-05,
      "loss": 0.0002,
      "step": 22400
    },
    {
      "epoch": 1.0787564268896257,
      "grad_norm": 0.17470186948776245,
      "learning_rate": 4.460645812310798e-05,
      "loss": 0.0003,
      "step": 22450
    },
    {
      "epoch": 1.081159002450627,
      "grad_norm": 0.4215323328971863,
      "learning_rate": 4.459444524530297e-05,
      "loss": 0.0002,
      "step": 22500
    },
    {
      "epoch": 1.0835615780116286,
      "grad_norm": 0.5166991353034973,
      "learning_rate": 4.458243236749796e-05,
      "loss": 0.0003,
      "step": 22550
    },
    {
      "epoch": 1.0859641535726299,
      "grad_norm": 0.11394623667001724,
      "learning_rate": 4.457041948969296e-05,
      "loss": 0.0003,
      "step": 22600
    },
    {
      "epoch": 1.0883667291336312,
      "grad_norm": 0.14962774515151978,
      "learning_rate": 4.455840661188795e-05,
      "loss": 0.0003,
      "step": 22650
    },
    {
      "epoch": 1.0907693046946327,
      "grad_norm": 0.3520509898662567,
      "learning_rate": 4.454639373408294e-05,
      "loss": 0.0003,
      "step": 22700
    },
    {
      "epoch": 1.093171880255634,
      "grad_norm": 0.5232177376747131,
      "learning_rate": 4.453438085627793e-05,
      "loss": 0.0002,
      "step": 22750
    },
    {
      "epoch": 1.0955744558166354,
      "grad_norm": 0.06873255223035812,
      "learning_rate": 4.452236797847292e-05,
      "loss": 0.0003,
      "step": 22800
    },
    {
      "epoch": 1.097977031377637,
      "grad_norm": 0.3874242901802063,
      "learning_rate": 4.451035510066792e-05,
      "loss": 0.0008,
      "step": 22850
    },
    {
      "epoch": 1.1003796069386382,
      "grad_norm": 0.4742075204849243,
      "learning_rate": 4.449834222286291e-05,
      "loss": 0.0008,
      "step": 22900
    },
    {
      "epoch": 1.1027821824996396,
      "grad_norm": 0.2640048861503601,
      "learning_rate": 4.4486329345057906e-05,
      "loss": 0.0003,
      "step": 22950
    },
    {
      "epoch": 1.105184758060641,
      "grad_norm": 0.1475822776556015,
      "learning_rate": 4.44743164672529e-05,
      "loss": 0.0004,
      "step": 23000
    },
    {
      "epoch": 1.1075873336216424,
      "grad_norm": 0.2007630616426468,
      "learning_rate": 4.446230358944789e-05,
      "loss": 0.0003,
      "step": 23050
    },
    {
      "epoch": 1.1099899091826437,
      "grad_norm": 0.15685276687145233,
      "learning_rate": 4.4450290711642885e-05,
      "loss": 0.0004,
      "step": 23100
    },
    {
      "epoch": 1.1123924847436453,
      "grad_norm": 0.14636199176311493,
      "learning_rate": 4.4438277833837876e-05,
      "loss": 0.0003,
      "step": 23150
    },
    {
      "epoch": 1.1147950603046466,
      "grad_norm": 0.06379241496324539,
      "learning_rate": 4.442626495603287e-05,
      "loss": 0.0003,
      "step": 23200
    },
    {
      "epoch": 1.117197635865648,
      "grad_norm": 0.2551630139350891,
      "learning_rate": 4.4414252078227865e-05,
      "loss": 0.0003,
      "step": 23250
    },
    {
      "epoch": 1.1196002114266494,
      "grad_norm": 0.28994572162628174,
      "learning_rate": 4.4402239200422856e-05,
      "loss": 0.0003,
      "step": 23300
    },
    {
      "epoch": 1.1220027869876508,
      "grad_norm": 0.19802938401699066,
      "learning_rate": 4.439022632261785e-05,
      "loss": 0.0003,
      "step": 23350
    },
    {
      "epoch": 1.124405362548652,
      "grad_norm": 0.39090368151664734,
      "learning_rate": 4.4378213444812844e-05,
      "loss": 0.0003,
      "step": 23400
    },
    {
      "epoch": 1.1268079381096536,
      "grad_norm": 0.49735113978385925,
      "learning_rate": 4.4366200567007835e-05,
      "loss": 0.0004,
      "step": 23450
    },
    {
      "epoch": 1.129210513670655,
      "grad_norm": 0.8266732692718506,
      "learning_rate": 4.4354187689202826e-05,
      "loss": 0.0003,
      "step": 23500
    },
    {
      "epoch": 1.1316130892316563,
      "grad_norm": 0.2538958489894867,
      "learning_rate": 4.4342174811397816e-05,
      "loss": 0.0003,
      "step": 23550
    },
    {
      "epoch": 1.1340156647926578,
      "grad_norm": 0.3303684592247009,
      "learning_rate": 4.4330161933592814e-05,
      "loss": 0.0003,
      "step": 23600
    },
    {
      "epoch": 1.1364182403536591,
      "grad_norm": 0.37454894185066223,
      "learning_rate": 4.4318149055787805e-05,
      "loss": 0.0002,
      "step": 23650
    },
    {
      "epoch": 1.1388208159146604,
      "grad_norm": 0.4981617331504822,
      "learning_rate": 4.4306136177982796e-05,
      "loss": 0.0003,
      "step": 23700
    },
    {
      "epoch": 1.141223391475662,
      "grad_norm": 0.2646760046482086,
      "learning_rate": 4.429412330017779e-05,
      "loss": 0.0004,
      "step": 23750
    },
    {
      "epoch": 1.1436259670366633,
      "grad_norm": 0.3911683261394501,
      "learning_rate": 4.4282110422372784e-05,
      "loss": 0.0002,
      "step": 23800
    },
    {
      "epoch": 1.1460285425976646,
      "grad_norm": 0.07793959975242615,
      "learning_rate": 4.427009754456778e-05,
      "loss": 0.0003,
      "step": 23850
    },
    {
      "epoch": 1.1484311181586662,
      "grad_norm": 0.1454523354768753,
      "learning_rate": 4.425808466676277e-05,
      "loss": 0.0003,
      "step": 23900
    },
    {
      "epoch": 1.1508336937196675,
      "grad_norm": 0.10990884155035019,
      "learning_rate": 4.424607178895776e-05,
      "loss": 0.0002,
      "step": 23950
    },
    {
      "epoch": 1.1532362692806688,
      "grad_norm": 0.41821932792663574,
      "learning_rate": 4.423405891115276e-05,
      "loss": 0.0003,
      "step": 24000
    },
    {
      "epoch": 1.1556388448416703,
      "grad_norm": 0.12840847671031952,
      "learning_rate": 4.422204603334775e-05,
      "loss": 0.0004,
      "step": 24050
    },
    {
      "epoch": 1.1580414204026717,
      "grad_norm": 0.35294532775878906,
      "learning_rate": 4.421003315554275e-05,
      "loss": 0.0004,
      "step": 24100
    },
    {
      "epoch": 1.160443995963673,
      "grad_norm": 0.06491407006978989,
      "learning_rate": 4.419802027773774e-05,
      "loss": 0.0003,
      "step": 24150
    },
    {
      "epoch": 1.1628465715246745,
      "grad_norm": 0.542722225189209,
      "learning_rate": 4.4186007399932724e-05,
      "loss": 0.0003,
      "step": 24200
    },
    {
      "epoch": 1.1652491470856758,
      "grad_norm": 0.11047433316707611,
      "learning_rate": 4.417399452212772e-05,
      "loss": 0.0005,
      "step": 24250
    },
    {
      "epoch": 1.1676517226466772,
      "grad_norm": 0.23749899864196777,
      "learning_rate": 4.416198164432271e-05,
      "loss": 0.0003,
      "step": 24300
    },
    {
      "epoch": 1.1700542982076787,
      "grad_norm": 0.12467671930789948,
      "learning_rate": 4.414996876651771e-05,
      "loss": 0.0003,
      "step": 24350
    },
    {
      "epoch": 1.17245687376868,
      "grad_norm": 0.38840043544769287,
      "learning_rate": 4.41379558887127e-05,
      "loss": 0.0004,
      "step": 24400
    },
    {
      "epoch": 1.1748594493296813,
      "grad_norm": 0.7796114087104797,
      "learning_rate": 4.412594301090769e-05,
      "loss": 0.0003,
      "step": 24450
    },
    {
      "epoch": 1.1772620248906829,
      "grad_norm": 0.09689223021268845,
      "learning_rate": 4.411393013310269e-05,
      "loss": 0.0003,
      "step": 24500
    },
    {
      "epoch": 1.1796646004516842,
      "grad_norm": 0.0818643569946289,
      "learning_rate": 4.410191725529768e-05,
      "loss": 0.0002,
      "step": 24550
    },
    {
      "epoch": 1.1820671760126855,
      "grad_norm": 0.22777143120765686,
      "learning_rate": 4.408990437749267e-05,
      "loss": 0.0003,
      "step": 24600
    },
    {
      "epoch": 1.184469751573687,
      "grad_norm": 0.0813300833106041,
      "learning_rate": 4.407789149968767e-05,
      "loss": 0.0002,
      "step": 24650
    },
    {
      "epoch": 1.1868723271346884,
      "grad_norm": 0.18326666951179504,
      "learning_rate": 4.406587862188266e-05,
      "loss": 0.0002,
      "step": 24700
    },
    {
      "epoch": 1.1892749026956897,
      "grad_norm": 0.24781355261802673,
      "learning_rate": 4.405386574407766e-05,
      "loss": 0.0003,
      "step": 24750
    },
    {
      "epoch": 1.1916774782566912,
      "grad_norm": 0.2731446623802185,
      "learning_rate": 4.404185286627265e-05,
      "loss": 0.0012,
      "step": 24800
    },
    {
      "epoch": 1.1940800538176926,
      "grad_norm": 0.43218833208084106,
      "learning_rate": 4.402983998846764e-05,
      "loss": 0.0003,
      "step": 24850
    },
    {
      "epoch": 1.1964826293786939,
      "grad_norm": 0.09094101190567017,
      "learning_rate": 4.4017827110662636e-05,
      "loss": 0.0002,
      "step": 24900
    },
    {
      "epoch": 1.1988852049396954,
      "grad_norm": 0.1054728552699089,
      "learning_rate": 4.400581423285762e-05,
      "loss": 0.0003,
      "step": 24950
    },
    {
      "epoch": 1.2012877805006967,
      "grad_norm": 0.12798510491847992,
      "learning_rate": 4.399380135505262e-05,
      "loss": 0.0003,
      "step": 25000
    },
    {
      "epoch": 1.203690356061698,
      "grad_norm": 0.2525150775909424,
      "learning_rate": 4.398178847724761e-05,
      "loss": 0.0002,
      "step": 25050
    },
    {
      "epoch": 1.2060929316226996,
      "grad_norm": 0.11612164974212646,
      "learning_rate": 4.39697755994426e-05,
      "loss": 0.0002,
      "step": 25100
    },
    {
      "epoch": 1.208495507183701,
      "grad_norm": 0.10086524486541748,
      "learning_rate": 4.39577627216376e-05,
      "loss": 0.0003,
      "step": 25150
    },
    {
      "epoch": 1.2108980827447022,
      "grad_norm": 0.3510166108608246,
      "learning_rate": 4.394574984383259e-05,
      "loss": 0.0003,
      "step": 25200
    },
    {
      "epoch": 1.2133006583057038,
      "grad_norm": 0.05989383906126022,
      "learning_rate": 4.3933736966027586e-05,
      "loss": 0.0003,
      "step": 25250
    },
    {
      "epoch": 1.215703233866705,
      "grad_norm": 0.7809902429580688,
      "learning_rate": 4.392172408822258e-05,
      "loss": 0.0003,
      "step": 25300
    },
    {
      "epoch": 1.2181058094277064,
      "grad_norm": 0.1777988225221634,
      "learning_rate": 4.390971121041757e-05,
      "loss": 0.0002,
      "step": 25350
    },
    {
      "epoch": 1.220508384988708,
      "grad_norm": 0.17214445769786835,
      "learning_rate": 4.3897698332612565e-05,
      "loss": 0.0003,
      "step": 25400
    },
    {
      "epoch": 1.2229109605497093,
      "grad_norm": 0.22019743919372559,
      "learning_rate": 4.3885685454807556e-05,
      "loss": 0.0003,
      "step": 25450
    },
    {
      "epoch": 1.2253135361107106,
      "grad_norm": 0.055477503687143326,
      "learning_rate": 4.3873672577002553e-05,
      "loss": 0.0003,
      "step": 25500
    },
    {
      "epoch": 1.2277161116717121,
      "grad_norm": 0.48270079493522644,
      "learning_rate": 4.3861659699197544e-05,
      "loss": 0.0004,
      "step": 25550
    },
    {
      "epoch": 1.2301186872327134,
      "grad_norm": 0.12254415452480316,
      "learning_rate": 4.3849646821392535e-05,
      "loss": 0.0002,
      "step": 25600
    },
    {
      "epoch": 1.2325212627937148,
      "grad_norm": 0.21984973549842834,
      "learning_rate": 4.383763394358753e-05,
      "loss": 0.0003,
      "step": 25650
    },
    {
      "epoch": 1.2349238383547163,
      "grad_norm": 0.36357057094573975,
      "learning_rate": 4.382562106578252e-05,
      "loss": 0.0003,
      "step": 25700
    },
    {
      "epoch": 1.2373264139157176,
      "grad_norm": 0.0739065408706665,
      "learning_rate": 4.3813608187977514e-05,
      "loss": 0.0003,
      "step": 25750
    },
    {
      "epoch": 1.2397289894767192,
      "grad_norm": 0.1947525143623352,
      "learning_rate": 4.3801595310172505e-05,
      "loss": 0.001,
      "step": 25800
    },
    {
      "epoch": 1.2421315650377205,
      "grad_norm": 0.7525554895401001,
      "learning_rate": 4.3789582432367496e-05,
      "loss": 0.0004,
      "step": 25850
    },
    {
      "epoch": 1.2445341405987218,
      "grad_norm": 0.16971996426582336,
      "learning_rate": 4.3777569554562494e-05,
      "loss": 0.0003,
      "step": 25900
    },
    {
      "epoch": 1.2469367161597233,
      "grad_norm": 0.1761680245399475,
      "learning_rate": 4.3765556676757484e-05,
      "loss": 0.0003,
      "step": 25950
    },
    {
      "epoch": 1.2493392917207247,
      "grad_norm": 0.19751451909542084,
      "learning_rate": 4.375354379895248e-05,
      "loss": 0.0003,
      "step": 26000
    },
    {
      "epoch": 1.251741867281726,
      "grad_norm": 0.09128549695014954,
      "learning_rate": 4.374153092114747e-05,
      "loss": 0.0004,
      "step": 26050
    },
    {
      "epoch": 1.2541444428427275,
      "grad_norm": 0.10404949635267258,
      "learning_rate": 4.3729518043342464e-05,
      "loss": 0.0003,
      "step": 26100
    },
    {
      "epoch": 1.2565470184037288,
      "grad_norm": 0.12468400597572327,
      "learning_rate": 4.371750516553746e-05,
      "loss": 0.0002,
      "step": 26150
    },
    {
      "epoch": 1.2589495939647302,
      "grad_norm": 0.4903065264225006,
      "learning_rate": 4.370549228773245e-05,
      "loss": 0.0002,
      "step": 26200
    },
    {
      "epoch": 1.2613521695257317,
      "grad_norm": 0.1683279275894165,
      "learning_rate": 4.369347940992744e-05,
      "loss": 0.0004,
      "step": 26250
    },
    {
      "epoch": 1.263754745086733,
      "grad_norm": 0.35741129517555237,
      "learning_rate": 4.368146653212244e-05,
      "loss": 0.0002,
      "step": 26300
    },
    {
      "epoch": 1.2661573206477343,
      "grad_norm": 0.14142781496047974,
      "learning_rate": 4.366945365431743e-05,
      "loss": 0.0003,
      "step": 26350
    },
    {
      "epoch": 1.2685598962087359,
      "grad_norm": 0.12414663285017014,
      "learning_rate": 4.365744077651243e-05,
      "loss": 0.0002,
      "step": 26400
    },
    {
      "epoch": 1.2709624717697372,
      "grad_norm": 0.32479989528656006,
      "learning_rate": 4.364542789870741e-05,
      "loss": 0.0009,
      "step": 26450
    },
    {
      "epoch": 1.2733650473307385,
      "grad_norm": 0.05397210642695427,
      "learning_rate": 4.363341502090241e-05,
      "loss": 0.0003,
      "step": 26500
    },
    {
      "epoch": 1.27576762289174,
      "grad_norm": 0.42768874764442444,
      "learning_rate": 4.36214021430974e-05,
      "loss": 0.0003,
      "step": 26550
    },
    {
      "epoch": 1.2781701984527414,
      "grad_norm": 0.3232393264770508,
      "learning_rate": 4.360938926529239e-05,
      "loss": 0.0011,
      "step": 26600
    },
    {
      "epoch": 1.2805727740137427,
      "grad_norm": 0.49348294734954834,
      "learning_rate": 4.359737638748739e-05,
      "loss": 0.0002,
      "step": 26650
    },
    {
      "epoch": 1.2829753495747442,
      "grad_norm": 0.23353737592697144,
      "learning_rate": 4.358536350968238e-05,
      "loss": 0.0003,
      "step": 26700
    },
    {
      "epoch": 1.2853779251357456,
      "grad_norm": 0.1937100887298584,
      "learning_rate": 4.357335063187737e-05,
      "loss": 0.0002,
      "step": 26750
    },
    {
      "epoch": 1.2877805006967469,
      "grad_norm": 0.3648567497730255,
      "learning_rate": 4.356133775407237e-05,
      "loss": 0.0003,
      "step": 26800
    },
    {
      "epoch": 1.2901830762577484,
      "grad_norm": 0.412325918674469,
      "learning_rate": 4.354932487626736e-05,
      "loss": 0.0003,
      "step": 26850
    },
    {
      "epoch": 1.2925856518187497,
      "grad_norm": 0.33980223536491394,
      "learning_rate": 4.353731199846236e-05,
      "loss": 0.0002,
      "step": 26900
    },
    {
      "epoch": 1.294988227379751,
      "grad_norm": 0.3690638840198517,
      "learning_rate": 4.352529912065735e-05,
      "loss": 0.0004,
      "step": 26950
    },
    {
      "epoch": 1.2973908029407526,
      "grad_norm": 0.3232174217700958,
      "learning_rate": 4.351328624285234e-05,
      "loss": 0.0003,
      "step": 27000
    },
    {
      "epoch": 1.299793378501754,
      "grad_norm": 0.21832674741744995,
      "learning_rate": 4.350127336504734e-05,
      "loss": 0.0002,
      "step": 27050
    },
    {
      "epoch": 1.3021959540627552,
      "grad_norm": 0.23820875585079193,
      "learning_rate": 4.348926048724233e-05,
      "loss": 0.0003,
      "step": 27100
    },
    {
      "epoch": 1.3045985296237568,
      "grad_norm": 0.11215326935052872,
      "learning_rate": 4.347724760943732e-05,
      "loss": 0.0003,
      "step": 27150
    },
    {
      "epoch": 1.307001105184758,
      "grad_norm": 0.328054815530777,
      "learning_rate": 4.346523473163231e-05,
      "loss": 0.0003,
      "step": 27200
    },
    {
      "epoch": 1.3094036807457594,
      "grad_norm": 0.2628526985645294,
      "learning_rate": 4.34532218538273e-05,
      "loss": 0.0009,
      "step": 27250
    },
    {
      "epoch": 1.311806256306761,
      "grad_norm": 0.13341212272644043,
      "learning_rate": 4.34412089760223e-05,
      "loss": 0.0003,
      "step": 27300
    },
    {
      "epoch": 1.3142088318677623,
      "grad_norm": 0.42439204454421997,
      "learning_rate": 4.342919609821729e-05,
      "loss": 0.0004,
      "step": 27350
    },
    {
      "epoch": 1.3166114074287636,
      "grad_norm": 0.36442503333091736,
      "learning_rate": 4.3417183220412286e-05,
      "loss": 0.0003,
      "step": 27400
    },
    {
      "epoch": 1.3190139829897651,
      "grad_norm": 0.08520469814538956,
      "learning_rate": 4.340517034260728e-05,
      "loss": 0.0002,
      "step": 27450
    },
    {
      "epoch": 1.3214165585507665,
      "grad_norm": 0.21118131279945374,
      "learning_rate": 4.339315746480227e-05,
      "loss": 0.0003,
      "step": 27500
    },
    {
      "epoch": 1.3238191341117678,
      "grad_norm": 0.2895908057689667,
      "learning_rate": 4.3381144586997265e-05,
      "loss": 0.0011,
      "step": 27550
    },
    {
      "epoch": 1.3262217096727693,
      "grad_norm": 0.3116430640220642,
      "learning_rate": 4.3369131709192256e-05,
      "loss": 0.0002,
      "step": 27600
    },
    {
      "epoch": 1.3286242852337706,
      "grad_norm": 0.3218556344509125,
      "learning_rate": 4.335711883138725e-05,
      "loss": 0.0002,
      "step": 27650
    },
    {
      "epoch": 1.331026860794772,
      "grad_norm": 0.34517741203308105,
      "learning_rate": 4.3345105953582245e-05,
      "loss": 0.0004,
      "step": 27700
    },
    {
      "epoch": 1.3334294363557735,
      "grad_norm": 0.11780449748039246,
      "learning_rate": 4.3333093075777235e-05,
      "loss": 0.0003,
      "step": 27750
    },
    {
      "epoch": 1.3358320119167748,
      "grad_norm": 0.2060290277004242,
      "learning_rate": 4.332108019797223e-05,
      "loss": 0.0003,
      "step": 27800
    },
    {
      "epoch": 1.3382345874777761,
      "grad_norm": 0.15089669823646545,
      "learning_rate": 4.3309067320167224e-05,
      "loss": 0.0003,
      "step": 27850
    },
    {
      "epoch": 1.3406371630387777,
      "grad_norm": 0.6104974150657654,
      "learning_rate": 4.3297054442362215e-05,
      "loss": 0.0002,
      "step": 27900
    },
    {
      "epoch": 1.343039738599779,
      "grad_norm": 0.16999709606170654,
      "learning_rate": 4.3285041564557206e-05,
      "loss": 0.0002,
      "step": 27950
    },
    {
      "epoch": 1.3454423141607803,
      "grad_norm": 0.6748199462890625,
      "learning_rate": 4.3273028686752196e-05,
      "loss": 0.0002,
      "step": 28000
    },
    {
      "epoch": 1.3478448897217818,
      "grad_norm": 0.31880801916122437,
      "learning_rate": 4.3261015808947194e-05,
      "loss": 0.0003,
      "step": 28050
    },
    {
      "epoch": 1.3502474652827832,
      "grad_norm": 0.3120270371437073,
      "learning_rate": 4.3249002931142185e-05,
      "loss": 0.0003,
      "step": 28100
    },
    {
      "epoch": 1.3526500408437845,
      "grad_norm": 0.8276293873786926,
      "learning_rate": 4.3236990053337176e-05,
      "loss": 0.0004,
      "step": 28150
    },
    {
      "epoch": 1.355052616404786,
      "grad_norm": 0.19405165314674377,
      "learning_rate": 4.322497717553217e-05,
      "loss": 0.0011,
      "step": 28200
    },
    {
      "epoch": 1.3574551919657873,
      "grad_norm": 0.1786317676305771,
      "learning_rate": 4.3212964297727164e-05,
      "loss": 0.0003,
      "step": 28250
    },
    {
      "epoch": 1.3598577675267887,
      "grad_norm": 0.27192577719688416,
      "learning_rate": 4.320095141992216e-05,
      "loss": 0.0003,
      "step": 28300
    },
    {
      "epoch": 1.3622603430877902,
      "grad_norm": 0.23895537853240967,
      "learning_rate": 4.318893854211715e-05,
      "loss": 0.0002,
      "step": 28350
    },
    {
      "epoch": 1.3646629186487915,
      "grad_norm": 0.2393680214881897,
      "learning_rate": 4.317692566431214e-05,
      "loss": 0.0003,
      "step": 28400
    },
    {
      "epoch": 1.3670654942097928,
      "grad_norm": 0.44740843772888184,
      "learning_rate": 4.316491278650714e-05,
      "loss": 0.0003,
      "step": 28450
    },
    {
      "epoch": 1.3694680697707944,
      "grad_norm": 0.29198649525642395,
      "learning_rate": 4.315289990870213e-05,
      "loss": 0.0011,
      "step": 28500
    },
    {
      "epoch": 1.3718706453317957,
      "grad_norm": 0.3590756952762604,
      "learning_rate": 4.314088703089712e-05,
      "loss": 0.0003,
      "step": 28550
    },
    {
      "epoch": 1.374273220892797,
      "grad_norm": 0.07434433698654175,
      "learning_rate": 4.312887415309212e-05,
      "loss": 0.0003,
      "step": 28600
    },
    {
      "epoch": 1.3766757964537986,
      "grad_norm": 0.4305468499660492,
      "learning_rate": 4.311686127528711e-05,
      "loss": 0.001,
      "step": 28650
    },
    {
      "epoch": 1.3790783720147999,
      "grad_norm": 0.21685373783111572,
      "learning_rate": 4.31048483974821e-05,
      "loss": 0.0003,
      "step": 28700
    },
    {
      "epoch": 1.3814809475758012,
      "grad_norm": 0.14424994587898254,
      "learning_rate": 4.309283551967709e-05,
      "loss": 0.0002,
      "step": 28750
    },
    {
      "epoch": 1.3838835231368027,
      "grad_norm": 0.19152240455150604,
      "learning_rate": 4.308082264187209e-05,
      "loss": 0.0003,
      "step": 28800
    },
    {
      "epoch": 1.386286098697804,
      "grad_norm": 0.22449995577335358,
      "learning_rate": 4.306880976406708e-05,
      "loss": 0.0002,
      "step": 28850
    },
    {
      "epoch": 1.3886886742588054,
      "grad_norm": 0.13369537889957428,
      "learning_rate": 4.305679688626207e-05,
      "loss": 0.0003,
      "step": 28900
    },
    {
      "epoch": 1.391091249819807,
      "grad_norm": 0.26843833923339844,
      "learning_rate": 4.304478400845707e-05,
      "loss": 0.0004,
      "step": 28950
    },
    {
      "epoch": 1.3934938253808082,
      "grad_norm": 0.15522386133670807,
      "learning_rate": 4.303277113065206e-05,
      "loss": 0.0002,
      "step": 29000
    },
    {
      "epoch": 1.3958964009418096,
      "grad_norm": 0.11702471226453781,
      "learning_rate": 4.302075825284705e-05,
      "loss": 0.0002,
      "step": 29050
    },
    {
      "epoch": 1.398298976502811,
      "grad_norm": 0.11432593315839767,
      "learning_rate": 4.300874537504205e-05,
      "loss": 0.0002,
      "step": 29100
    },
    {
      "epoch": 1.4007015520638124,
      "grad_norm": 0.11245197802782059,
      "learning_rate": 4.299673249723704e-05,
      "loss": 0.0005,
      "step": 29150
    },
    {
      "epoch": 1.4031041276248137,
      "grad_norm": 0.663247287273407,
      "learning_rate": 4.298471961943204e-05,
      "loss": 0.0003,
      "step": 29200
    },
    {
      "epoch": 1.4055067031858153,
      "grad_norm": 0.10814060270786285,
      "learning_rate": 4.297270674162703e-05,
      "loss": 0.001,
      "step": 29250
    },
    {
      "epoch": 1.4079092787468166,
      "grad_norm": 0.15442101657390594,
      "learning_rate": 4.296069386382202e-05,
      "loss": 0.0003,
      "step": 29300
    },
    {
      "epoch": 1.410311854307818,
      "grad_norm": 0.04019853472709656,
      "learning_rate": 4.2948680986017016e-05,
      "loss": 0.0003,
      "step": 29350
    },
    {
      "epoch": 1.4127144298688195,
      "grad_norm": 0.7454224228858948,
      "learning_rate": 4.2936668108212e-05,
      "loss": 0.0003,
      "step": 29400
    },
    {
      "epoch": 1.4151170054298208,
      "grad_norm": 0.2245170921087265,
      "learning_rate": 4.2924655230407e-05,
      "loss": 0.0011,
      "step": 29450
    },
    {
      "epoch": 1.417519580990822,
      "grad_norm": 0.2962872087955475,
      "learning_rate": 4.291264235260199e-05,
      "loss": 0.0002,
      "step": 29500
    },
    {
      "epoch": 1.4199221565518236,
      "grad_norm": 0.2970970869064331,
      "learning_rate": 4.290062947479698e-05,
      "loss": 0.0009,
      "step": 29550
    },
    {
      "epoch": 1.422324732112825,
      "grad_norm": 0.17883600294589996,
      "learning_rate": 4.288861659699198e-05,
      "loss": 0.0002,
      "step": 29600
    },
    {
      "epoch": 1.4247273076738263,
      "grad_norm": 0.25738051533699036,
      "learning_rate": 4.287660371918697e-05,
      "loss": 0.0002,
      "step": 29650
    },
    {
      "epoch": 1.4271298832348278,
      "grad_norm": 0.1192416399717331,
      "learning_rate": 4.2864590841381966e-05,
      "loss": 0.0003,
      "step": 29700
    },
    {
      "epoch": 1.4295324587958291,
      "grad_norm": 0.07386375218629837,
      "learning_rate": 4.2852577963576957e-05,
      "loss": 0.0002,
      "step": 29750
    },
    {
      "epoch": 1.4319350343568304,
      "grad_norm": 0.8805044889450073,
      "learning_rate": 4.284056508577195e-05,
      "loss": 0.0002,
      "step": 29800
    },
    {
      "epoch": 1.434337609917832,
      "grad_norm": 0.20008942484855652,
      "learning_rate": 4.2828552207966945e-05,
      "loss": 0.0003,
      "step": 29850
    },
    {
      "epoch": 1.4367401854788333,
      "grad_norm": 0.219995379447937,
      "learning_rate": 4.2816539330161936e-05,
      "loss": 0.0011,
      "step": 29900
    },
    {
      "epoch": 1.4391427610398346,
      "grad_norm": 0.372771292924881,
      "learning_rate": 4.280452645235693e-05,
      "loss": 0.0004,
      "step": 29950
    },
    {
      "epoch": 1.4415453366008362,
      "grad_norm": 0.15069404244422913,
      "learning_rate": 4.2792513574551924e-05,
      "loss": 0.0004,
      "step": 30000
    },
    {
      "epoch": 1.4439479121618375,
      "grad_norm": 0.28731629252433777,
      "learning_rate": 4.2780500696746915e-05,
      "loss": 0.0008,
      "step": 30050
    },
    {
      "epoch": 1.4463504877228388,
      "grad_norm": 0.12150480598211288,
      "learning_rate": 4.276848781894191e-05,
      "loss": 0.0002,
      "step": 30100
    },
    {
      "epoch": 1.4487530632838403,
      "grad_norm": 0.14776886999607086,
      "learning_rate": 4.27564749411369e-05,
      "loss": 0.0002,
      "step": 30150
    },
    {
      "epoch": 1.4511556388448417,
      "grad_norm": 0.13559316098690033,
      "learning_rate": 4.2744462063331894e-05,
      "loss": 0.0003,
      "step": 30200
    },
    {
      "epoch": 1.453558214405843,
      "grad_norm": 0.22673942148685455,
      "learning_rate": 4.2732449185526885e-05,
      "loss": 0.0002,
      "step": 30250
    },
    {
      "epoch": 1.4559607899668445,
      "grad_norm": 0.672328770160675,
      "learning_rate": 4.2720436307721876e-05,
      "loss": 0.0003,
      "step": 30300
    },
    {
      "epoch": 1.4583633655278458,
      "grad_norm": 0.2725568413734436,
      "learning_rate": 4.2708423429916874e-05,
      "loss": 0.0002,
      "step": 30350
    },
    {
      "epoch": 1.4607659410888472,
      "grad_norm": 0.2033998817205429,
      "learning_rate": 4.2696410552111864e-05,
      "loss": 0.0003,
      "step": 30400
    },
    {
      "epoch": 1.4631685166498487,
      "grad_norm": 0.17975066602230072,
      "learning_rate": 4.2684397674306855e-05,
      "loss": 0.0003,
      "step": 30450
    },
    {
      "epoch": 1.46557109221085,
      "grad_norm": 0.13251477479934692,
      "learning_rate": 4.267238479650185e-05,
      "loss": 0.0004,
      "step": 30500
    },
    {
      "epoch": 1.4679736677718513,
      "grad_norm": 0.5413303375244141,
      "learning_rate": 4.2660371918696844e-05,
      "loss": 0.0007,
      "step": 30550
    },
    {
      "epoch": 1.4703762433328529,
      "grad_norm": 0.18467338383197784,
      "learning_rate": 4.264835904089184e-05,
      "loss": 0.0002,
      "step": 30600
    },
    {
      "epoch": 1.4727788188938542,
      "grad_norm": 0.7437682151794434,
      "learning_rate": 4.263634616308683e-05,
      "loss": 0.0003,
      "step": 30650
    },
    {
      "epoch": 1.4751813944548555,
      "grad_norm": 0.42032256722450256,
      "learning_rate": 4.262433328528182e-05,
      "loss": 0.0002,
      "step": 30700
    },
    {
      "epoch": 1.477583970015857,
      "grad_norm": 0.11056716740131378,
      "learning_rate": 4.261232040747682e-05,
      "loss": 0.0003,
      "step": 30750
    },
    {
      "epoch": 1.4799865455768584,
      "grad_norm": 0.10462573915719986,
      "learning_rate": 4.260030752967181e-05,
      "loss": 0.0003,
      "step": 30800
    },
    {
      "epoch": 1.4823891211378597,
      "grad_norm": 0.38394370675086975,
      "learning_rate": 4.258829465186681e-05,
      "loss": 0.0003,
      "step": 30850
    },
    {
      "epoch": 1.4847916966988612,
      "grad_norm": 0.035092949867248535,
      "learning_rate": 4.257628177406179e-05,
      "loss": 0.0003,
      "step": 30900
    },
    {
      "epoch": 1.4871942722598626,
      "grad_norm": 0.19610510766506195,
      "learning_rate": 4.2564268896256784e-05,
      "loss": 0.0003,
      "step": 30950
    },
    {
      "epoch": 1.4895968478208639,
      "grad_norm": 0.8693848848342896,
      "learning_rate": 4.255225601845178e-05,
      "loss": 0.0003,
      "step": 31000
    },
    {
      "epoch": 1.4919994233818654,
      "grad_norm": 0.6300873756408691,
      "learning_rate": 4.254024314064677e-05,
      "loss": 0.0002,
      "step": 31050
    },
    {
      "epoch": 1.4944019989428667,
      "grad_norm": 0.36822792887687683,
      "learning_rate": 4.252823026284177e-05,
      "loss": 0.0002,
      "step": 31100
    },
    {
      "epoch": 1.496804574503868,
      "grad_norm": 0.043827272951602936,
      "learning_rate": 4.251621738503676e-05,
      "loss": 0.001,
      "step": 31150
    },
    {
      "epoch": 1.4992071500648696,
      "grad_norm": 0.14807382225990295,
      "learning_rate": 4.250420450723175e-05,
      "loss": 0.0002,
      "step": 31200
    },
    {
      "epoch": 1.501609725625871,
      "grad_norm": 0.0684456005692482,
      "learning_rate": 4.249219162942675e-05,
      "loss": 0.0002,
      "step": 31250
    },
    {
      "epoch": 1.5040123011868722,
      "grad_norm": 0.15899288654327393,
      "learning_rate": 4.248017875162174e-05,
      "loss": 0.0002,
      "step": 31300
    },
    {
      "epoch": 1.5064148767478738,
      "grad_norm": 0.20659296214580536,
      "learning_rate": 4.246816587381674e-05,
      "loss": 0.0002,
      "step": 31350
    },
    {
      "epoch": 1.508817452308875,
      "grad_norm": 0.09227947145700455,
      "learning_rate": 4.245615299601173e-05,
      "loss": 0.0002,
      "step": 31400
    },
    {
      "epoch": 1.5112200278698764,
      "grad_norm": 0.3237651288509369,
      "learning_rate": 4.244414011820672e-05,
      "loss": 0.0003,
      "step": 31450
    },
    {
      "epoch": 1.513622603430878,
      "grad_norm": 0.3557889461517334,
      "learning_rate": 4.243212724040172e-05,
      "loss": 0.0009,
      "step": 31500
    },
    {
      "epoch": 1.5160251789918793,
      "grad_norm": 0.4606798589229584,
      "learning_rate": 4.242011436259671e-05,
      "loss": 0.0002,
      "step": 31550
    },
    {
      "epoch": 1.5184277545528806,
      "grad_norm": 0.18892212212085724,
      "learning_rate": 4.24081014847917e-05,
      "loss": 0.0002,
      "step": 31600
    },
    {
      "epoch": 1.5208303301138821,
      "grad_norm": 0.12459063529968262,
      "learning_rate": 4.239608860698669e-05,
      "loss": 0.0003,
      "step": 31650
    },
    {
      "epoch": 1.5232329056748835,
      "grad_norm": 0.3235798478126526,
      "learning_rate": 4.238407572918168e-05,
      "loss": 0.0002,
      "step": 31700
    },
    {
      "epoch": 1.5256354812358848,
      "grad_norm": 0.1728474497795105,
      "learning_rate": 4.237206285137668e-05,
      "loss": 0.0002,
      "step": 31750
    },
    {
      "epoch": 1.5280380567968863,
      "grad_norm": 0.41164910793304443,
      "learning_rate": 4.236004997357167e-05,
      "loss": 0.0002,
      "step": 31800
    },
    {
      "epoch": 1.5304406323578876,
      "grad_norm": 0.24431683123111725,
      "learning_rate": 4.2348037095766666e-05,
      "loss": 0.0002,
      "step": 31850
    },
    {
      "epoch": 1.532843207918889,
      "grad_norm": 0.11089986562728882,
      "learning_rate": 4.233602421796166e-05,
      "loss": 0.0003,
      "step": 31900
    },
    {
      "epoch": 1.5352457834798905,
      "grad_norm": 0.4052330553531647,
      "learning_rate": 4.232401134015665e-05,
      "loss": 0.0002,
      "step": 31950
    },
    {
      "epoch": 1.5376483590408918,
      "grad_norm": 0.2550998628139496,
      "learning_rate": 4.2311998462351645e-05,
      "loss": 0.0002,
      "step": 32000
    },
    {
      "epoch": 1.5400509346018931,
      "grad_norm": 0.6465194821357727,
      "learning_rate": 4.2299985584546636e-05,
      "loss": 0.0003,
      "step": 32050
    },
    {
      "epoch": 1.5424535101628947,
      "grad_norm": 0.22474415600299835,
      "learning_rate": 4.228797270674163e-05,
      "loss": 0.0003,
      "step": 32100
    },
    {
      "epoch": 1.544856085723896,
      "grad_norm": 0.3989250957965851,
      "learning_rate": 4.2275959828936625e-05,
      "loss": 0.0003,
      "step": 32150
    },
    {
      "epoch": 1.5472586612848973,
      "grad_norm": 0.23539304733276367,
      "learning_rate": 4.2263946951131615e-05,
      "loss": 0.0003,
      "step": 32200
    },
    {
      "epoch": 1.5496612368458988,
      "grad_norm": 0.1350019872188568,
      "learning_rate": 4.225193407332661e-05,
      "loss": 0.0002,
      "step": 32250
    },
    {
      "epoch": 1.5520638124069002,
      "grad_norm": 0.4558686912059784,
      "learning_rate": 4.2239921195521604e-05,
      "loss": 0.0003,
      "step": 32300
    },
    {
      "epoch": 1.5544663879679015,
      "grad_norm": 0.33590906858444214,
      "learning_rate": 4.2227908317716595e-05,
      "loss": 0.0004,
      "step": 32350
    },
    {
      "epoch": 1.556868963528903,
      "grad_norm": 0.33438244462013245,
      "learning_rate": 4.2215895439911586e-05,
      "loss": 0.0003,
      "step": 32400
    },
    {
      "epoch": 1.5592715390899043,
      "grad_norm": 0.14033210277557373,
      "learning_rate": 4.2203882562106576e-05,
      "loss": 0.0003,
      "step": 32450
    },
    {
      "epoch": 1.5616741146509057,
      "grad_norm": 0.45333635807037354,
      "learning_rate": 4.2191869684301574e-05,
      "loss": 0.0003,
      "step": 32500
    },
    {
      "epoch": 1.5640766902119072,
      "grad_norm": 0.09055788069963455,
      "learning_rate": 4.2179856806496565e-05,
      "loss": 0.0003,
      "step": 32550
    },
    {
      "epoch": 1.5664792657729085,
      "grad_norm": 0.20395782589912415,
      "learning_rate": 4.2167843928691556e-05,
      "loss": 0.0002,
      "step": 32600
    },
    {
      "epoch": 1.5688818413339098,
      "grad_norm": 0.28211912512779236,
      "learning_rate": 4.215583105088655e-05,
      "loss": 0.0002,
      "step": 32650
    },
    {
      "epoch": 1.5712844168949114,
      "grad_norm": 0.13319727778434753,
      "learning_rate": 4.2143818173081544e-05,
      "loss": 0.0002,
      "step": 32700
    },
    {
      "epoch": 1.5736869924559127,
      "grad_norm": 0.17236214876174927,
      "learning_rate": 4.213180529527654e-05,
      "loss": 0.0003,
      "step": 32750
    },
    {
      "epoch": 1.576089568016914,
      "grad_norm": 0.1800520122051239,
      "learning_rate": 4.211979241747153e-05,
      "loss": 0.0003,
      "step": 32800
    },
    {
      "epoch": 1.5784921435779156,
      "grad_norm": 0.23782365024089813,
      "learning_rate": 4.210777953966652e-05,
      "loss": 0.0011,
      "step": 32850
    },
    {
      "epoch": 1.5808947191389169,
      "grad_norm": 0.12825006246566772,
      "learning_rate": 4.209576666186152e-05,
      "loss": 0.0003,
      "step": 32900
    },
    {
      "epoch": 1.5832972946999182,
      "grad_norm": 0.33154141902923584,
      "learning_rate": 4.208375378405651e-05,
      "loss": 0.0002,
      "step": 32950
    },
    {
      "epoch": 1.5856998702609197,
      "grad_norm": 0.5304999351501465,
      "learning_rate": 4.20717409062515e-05,
      "loss": 0.0003,
      "step": 33000
    },
    {
      "epoch": 1.588102445821921,
      "grad_norm": 0.07255654782056808,
      "learning_rate": 4.20597280284465e-05,
      "loss": 0.0002,
      "step": 33050
    },
    {
      "epoch": 1.5905050213829224,
      "grad_norm": 0.2847059667110443,
      "learning_rate": 4.204771515064149e-05,
      "loss": 0.0003,
      "step": 33100
    },
    {
      "epoch": 1.592907596943924,
      "grad_norm": 0.2079170048236847,
      "learning_rate": 4.203570227283648e-05,
      "loss": 0.0003,
      "step": 33150
    },
    {
      "epoch": 1.5953101725049252,
      "grad_norm": 0.27134114503860474,
      "learning_rate": 4.202368939503147e-05,
      "loss": 0.0003,
      "step": 33200
    },
    {
      "epoch": 1.5977127480659266,
      "grad_norm": 0.1582970917224884,
      "learning_rate": 4.201167651722647e-05,
      "loss": 0.0003,
      "step": 33250
    },
    {
      "epoch": 1.600115323626928,
      "grad_norm": 0.8561494946479797,
      "learning_rate": 4.199966363942146e-05,
      "loss": 0.0003,
      "step": 33300
    },
    {
      "epoch": 1.6025178991879294,
      "grad_norm": 0.463461697101593,
      "learning_rate": 4.198765076161645e-05,
      "loss": 0.0003,
      "step": 33350
    },
    {
      "epoch": 1.6049204747489307,
      "grad_norm": 0.266195148229599,
      "learning_rate": 4.197563788381145e-05,
      "loss": 0.0003,
      "step": 33400
    },
    {
      "epoch": 1.6073230503099323,
      "grad_norm": 0.09070646017789841,
      "learning_rate": 4.196362500600644e-05,
      "loss": 0.0004,
      "step": 33450
    },
    {
      "epoch": 1.6097256258709336,
      "grad_norm": 0.45898815989494324,
      "learning_rate": 4.195161212820143e-05,
      "loss": 0.0002,
      "step": 33500
    },
    {
      "epoch": 1.612128201431935,
      "grad_norm": 0.20257209241390228,
      "learning_rate": 4.193959925039643e-05,
      "loss": 0.0003,
      "step": 33550
    },
    {
      "epoch": 1.6145307769929365,
      "grad_norm": 0.47046637535095215,
      "learning_rate": 4.192758637259142e-05,
      "loss": 0.0003,
      "step": 33600
    },
    {
      "epoch": 1.6169333525539378,
      "grad_norm": 0.2542521059513092,
      "learning_rate": 4.191557349478642e-05,
      "loss": 0.0003,
      "step": 33650
    },
    {
      "epoch": 1.619335928114939,
      "grad_norm": 0.2721390724182129,
      "learning_rate": 4.190356061698141e-05,
      "loss": 0.0002,
      "step": 33700
    },
    {
      "epoch": 1.6217385036759406,
      "grad_norm": 0.37919747829437256,
      "learning_rate": 4.18915477391764e-05,
      "loss": 0.0003,
      "step": 33750
    },
    {
      "epoch": 1.624141079236942,
      "grad_norm": 0.12643925845623016,
      "learning_rate": 4.1879534861371396e-05,
      "loss": 0.0002,
      "step": 33800
    },
    {
      "epoch": 1.6265436547979433,
      "grad_norm": 0.0738300010561943,
      "learning_rate": 4.186752198356639e-05,
      "loss": 0.0002,
      "step": 33850
    },
    {
      "epoch": 1.6289462303589448,
      "grad_norm": 0.09816901385784149,
      "learning_rate": 4.185550910576138e-05,
      "loss": 0.0002,
      "step": 33900
    },
    {
      "epoch": 1.6313488059199461,
      "grad_norm": 0.24783416092395782,
      "learning_rate": 4.184349622795637e-05,
      "loss": 0.0002,
      "step": 33950
    },
    {
      "epoch": 1.6337513814809475,
      "grad_norm": 0.21759486198425293,
      "learning_rate": 4.183148335015136e-05,
      "loss": 0.0003,
      "step": 34000
    },
    {
      "epoch": 1.636153957041949,
      "grad_norm": 0.43999671936035156,
      "learning_rate": 4.181947047234636e-05,
      "loss": 0.0002,
      "step": 34050
    },
    {
      "epoch": 1.6385565326029503,
      "grad_norm": 0.3262476325035095,
      "learning_rate": 4.180745759454135e-05,
      "loss": 0.0003,
      "step": 34100
    },
    {
      "epoch": 1.6409591081639516,
      "grad_norm": 0.17994782328605652,
      "learning_rate": 4.1795444716736346e-05,
      "loss": 0.0002,
      "step": 34150
    },
    {
      "epoch": 1.6433616837249532,
      "grad_norm": 0.1471857726573944,
      "learning_rate": 4.1783431838931337e-05,
      "loss": 0.0002,
      "step": 34200
    },
    {
      "epoch": 1.6457642592859545,
      "grad_norm": 0.12955158948898315,
      "learning_rate": 4.177141896112633e-05,
      "loss": 0.0008,
      "step": 34250
    },
    {
      "epoch": 1.6481668348469558,
      "grad_norm": 0.3867940604686737,
      "learning_rate": 4.1759406083321325e-05,
      "loss": 0.0002,
      "step": 34300
    },
    {
      "epoch": 1.6505694104079573,
      "grad_norm": 0.16320562362670898,
      "learning_rate": 4.1747393205516316e-05,
      "loss": 0.0003,
      "step": 34350
    },
    {
      "epoch": 1.652971985968959,
      "grad_norm": 0.14085564017295837,
      "learning_rate": 4.173538032771131e-05,
      "loss": 0.0002,
      "step": 34400
    },
    {
      "epoch": 1.65537456152996,
      "grad_norm": 0.0970633402466774,
      "learning_rate": 4.1723367449906304e-05,
      "loss": 0.0002,
      "step": 34450
    },
    {
      "epoch": 1.6577771370909615,
      "grad_norm": 0.18491235375404358,
      "learning_rate": 4.1711354572101295e-05,
      "loss": 0.0003,
      "step": 34500
    },
    {
      "epoch": 1.660179712651963,
      "grad_norm": 0.7057790756225586,
      "learning_rate": 4.169934169429629e-05,
      "loss": 0.0002,
      "step": 34550
    },
    {
      "epoch": 1.6625822882129642,
      "grad_norm": 0.3401336073875427,
      "learning_rate": 4.1687328816491283e-05,
      "loss": 0.0002,
      "step": 34600
    },
    {
      "epoch": 1.6649848637739657,
      "grad_norm": 0.43774518370628357,
      "learning_rate": 4.1675315938686274e-05,
      "loss": 0.0008,
      "step": 34650
    },
    {
      "epoch": 1.6673874393349672,
      "grad_norm": 0.4826618731021881,
      "learning_rate": 4.1663303060881265e-05,
      "loss": 0.0003,
      "step": 34700
    },
    {
      "epoch": 1.6697900148959683,
      "grad_norm": 0.35428979992866516,
      "learning_rate": 4.1651290183076256e-05,
      "loss": 0.0002,
      "step": 34750
    },
    {
      "epoch": 1.6721925904569699,
      "grad_norm": 0.45400145649909973,
      "learning_rate": 4.1639277305271254e-05,
      "loss": 0.0004,
      "step": 34800
    },
    {
      "epoch": 1.6745951660179714,
      "grad_norm": 0.6183383464813232,
      "learning_rate": 4.1627264427466244e-05,
      "loss": 0.0002,
      "step": 34850
    },
    {
      "epoch": 1.6769977415789725,
      "grad_norm": 0.18359826505184174,
      "learning_rate": 4.1615251549661235e-05,
      "loss": 0.0002,
      "step": 34900
    },
    {
      "epoch": 1.679400317139974,
      "grad_norm": 0.5307702422142029,
      "learning_rate": 4.160323867185623e-05,
      "loss": 0.0003,
      "step": 34950
    },
    {
      "epoch": 1.6818028927009756,
      "grad_norm": 0.8450655341148376,
      "learning_rate": 4.1591225794051224e-05,
      "loss": 0.0002,
      "step": 35000
    },
    {
      "epoch": 1.6842054682619767,
      "grad_norm": 0.18549148738384247,
      "learning_rate": 4.157921291624622e-05,
      "loss": 0.0003,
      "step": 35050
    },
    {
      "epoch": 1.6866080438229782,
      "grad_norm": 0.15533490478992462,
      "learning_rate": 4.156720003844121e-05,
      "loss": 0.0002,
      "step": 35100
    },
    {
      "epoch": 1.6890106193839798,
      "grad_norm": 0.25791415572166443,
      "learning_rate": 4.15551871606362e-05,
      "loss": 0.0002,
      "step": 35150
    },
    {
      "epoch": 1.6914131949449809,
      "grad_norm": 0.4275081157684326,
      "learning_rate": 4.15431742828312e-05,
      "loss": 0.0002,
      "step": 35200
    },
    {
      "epoch": 1.6938157705059824,
      "grad_norm": 0.1651061475276947,
      "learning_rate": 4.153116140502619e-05,
      "loss": 0.0002,
      "step": 35250
    },
    {
      "epoch": 1.696218346066984,
      "grad_norm": 0.2553761601448059,
      "learning_rate": 4.151914852722118e-05,
      "loss": 0.0003,
      "step": 35300
    },
    {
      "epoch": 1.698620921627985,
      "grad_norm": 0.4721601903438568,
      "learning_rate": 4.150713564941617e-05,
      "loss": 0.0002,
      "step": 35350
    },
    {
      "epoch": 1.7010234971889866,
      "grad_norm": 0.14721561968326569,
      "learning_rate": 4.1495122771611164e-05,
      "loss": 0.0002,
      "step": 35400
    },
    {
      "epoch": 1.7034260727499881,
      "grad_norm": 0.21328556537628174,
      "learning_rate": 4.148310989380616e-05,
      "loss": 0.0002,
      "step": 35450
    },
    {
      "epoch": 1.7058286483109892,
      "grad_norm": 0.11222446709871292,
      "learning_rate": 4.147109701600115e-05,
      "loss": 0.001,
      "step": 35500
    },
    {
      "epoch": 1.7082312238719908,
      "grad_norm": 0.6405584216117859,
      "learning_rate": 4.145908413819615e-05,
      "loss": 0.0002,
      "step": 35550
    },
    {
      "epoch": 1.7106337994329923,
      "grad_norm": 0.24844861030578613,
      "learning_rate": 4.144707126039114e-05,
      "loss": 0.0003,
      "step": 35600
    },
    {
      "epoch": 1.7130363749939934,
      "grad_norm": 0.29185599088668823,
      "learning_rate": 4.143505838258613e-05,
      "loss": 0.0008,
      "step": 35650
    },
    {
      "epoch": 1.715438950554995,
      "grad_norm": 0.36590927839279175,
      "learning_rate": 4.142304550478113e-05,
      "loss": 0.0003,
      "step": 35700
    },
    {
      "epoch": 1.7178415261159965,
      "grad_norm": 0.09468801319599152,
      "learning_rate": 4.141103262697612e-05,
      "loss": 0.0002,
      "step": 35750
    },
    {
      "epoch": 1.7202441016769976,
      "grad_norm": 0.12199579924345016,
      "learning_rate": 4.139901974917111e-05,
      "loss": 0.0002,
      "step": 35800
    },
    {
      "epoch": 1.7226466772379991,
      "grad_norm": 0.06447631865739822,
      "learning_rate": 4.138700687136611e-05,
      "loss": 0.0002,
      "step": 35850
    },
    {
      "epoch": 1.7250492527990007,
      "grad_norm": 0.19833149015903473,
      "learning_rate": 4.13749939935611e-05,
      "loss": 0.0002,
      "step": 35900
    },
    {
      "epoch": 1.7274518283600018,
      "grad_norm": 0.4246577024459839,
      "learning_rate": 4.13629811157561e-05,
      "loss": 0.0002,
      "step": 35950
    },
    {
      "epoch": 1.7298544039210033,
      "grad_norm": 0.1874566525220871,
      "learning_rate": 4.135096823795109e-05,
      "loss": 0.0002,
      "step": 36000
    },
    {
      "epoch": 1.7322569794820049,
      "grad_norm": 0.26788824796676636,
      "learning_rate": 4.133895536014608e-05,
      "loss": 0.0002,
      "step": 36050
    },
    {
      "epoch": 1.734659555043006,
      "grad_norm": 0.6963486671447754,
      "learning_rate": 4.132694248234107e-05,
      "loss": 0.0003,
      "step": 36100
    },
    {
      "epoch": 1.7370621306040075,
      "grad_norm": 0.15076227486133575,
      "learning_rate": 4.131492960453606e-05,
      "loss": 0.0003,
      "step": 36150
    },
    {
      "epoch": 1.739464706165009,
      "grad_norm": 0.38748452067375183,
      "learning_rate": 4.130291672673106e-05,
      "loss": 0.0002,
      "step": 36200
    },
    {
      "epoch": 1.7418672817260101,
      "grad_norm": 0.13390500843524933,
      "learning_rate": 4.129090384892605e-05,
      "loss": 0.0002,
      "step": 36250
    },
    {
      "epoch": 1.7442698572870117,
      "grad_norm": 0.2015000879764557,
      "learning_rate": 4.127889097112104e-05,
      "loss": 0.0002,
      "step": 36300
    },
    {
      "epoch": 1.7466724328480132,
      "grad_norm": 0.09324540197849274,
      "learning_rate": 4.126687809331604e-05,
      "loss": 0.0002,
      "step": 36350
    },
    {
      "epoch": 1.7490750084090143,
      "grad_norm": 0.412992388010025,
      "learning_rate": 4.125486521551103e-05,
      "loss": 0.0002,
      "step": 36400
    },
    {
      "epoch": 1.7514775839700158,
      "grad_norm": 0.16915886104106903,
      "learning_rate": 4.1242852337706025e-05,
      "loss": 0.0003,
      "step": 36450
    },
    {
      "epoch": 1.7538801595310174,
      "grad_norm": 0.31476983428001404,
      "learning_rate": 4.1230839459901016e-05,
      "loss": 0.0003,
      "step": 36500
    },
    {
      "epoch": 1.7562827350920185,
      "grad_norm": 0.08235328644514084,
      "learning_rate": 4.121882658209601e-05,
      "loss": 0.0002,
      "step": 36550
    },
    {
      "epoch": 1.75868531065302,
      "grad_norm": 0.08773431926965714,
      "learning_rate": 4.1206813704291005e-05,
      "loss": 0.0003,
      "step": 36600
    },
    {
      "epoch": 1.7610878862140216,
      "grad_norm": 0.09232397377490997,
      "learning_rate": 4.1194800826485995e-05,
      "loss": 0.0002,
      "step": 36650
    },
    {
      "epoch": 1.7634904617750227,
      "grad_norm": 0.2044745832681656,
      "learning_rate": 4.118278794868099e-05,
      "loss": 0.0003,
      "step": 36700
    },
    {
      "epoch": 1.7658930373360242,
      "grad_norm": 0.08803584426641464,
      "learning_rate": 4.1170775070875984e-05,
      "loss": 0.0008,
      "step": 36750
    },
    {
      "epoch": 1.7682956128970257,
      "grad_norm": 0.114043228328228,
      "learning_rate": 4.1158762193070975e-05,
      "loss": 0.0003,
      "step": 36800
    },
    {
      "epoch": 1.7706981884580268,
      "grad_norm": 0.4338945150375366,
      "learning_rate": 4.1146749315265966e-05,
      "loss": 0.0003,
      "step": 36850
    },
    {
      "epoch": 1.7731007640190284,
      "grad_norm": 0.20248040556907654,
      "learning_rate": 4.1134736437460956e-05,
      "loss": 0.0003,
      "step": 36900
    },
    {
      "epoch": 1.77550333958003,
      "grad_norm": 0.06265722960233688,
      "learning_rate": 4.1122723559655954e-05,
      "loss": 0.0003,
      "step": 36950
    },
    {
      "epoch": 1.777905915141031,
      "grad_norm": 0.16323912143707275,
      "learning_rate": 4.1110710681850945e-05,
      "loss": 0.0003,
      "step": 37000
    },
    {
      "epoch": 1.7803084907020326,
      "grad_norm": 0.5365154147148132,
      "learning_rate": 4.1098697804045936e-05,
      "loss": 0.0002,
      "step": 37050
    },
    {
      "epoch": 1.782711066263034,
      "grad_norm": 0.7045608162879944,
      "learning_rate": 4.108668492624093e-05,
      "loss": 0.001,
      "step": 37100
    },
    {
      "epoch": 1.7851136418240352,
      "grad_norm": 0.8131425976753235,
      "learning_rate": 4.1074672048435924e-05,
      "loss": 0.0003,
      "step": 37150
    },
    {
      "epoch": 1.7875162173850367,
      "grad_norm": 0.24689048528671265,
      "learning_rate": 4.106265917063092e-05,
      "loss": 0.0003,
      "step": 37200
    },
    {
      "epoch": 1.7899187929460383,
      "grad_norm": 0.2619660496711731,
      "learning_rate": 4.105064629282591e-05,
      "loss": 0.0002,
      "step": 37250
    },
    {
      "epoch": 1.7923213685070394,
      "grad_norm": 0.40229669213294983,
      "learning_rate": 4.10386334150209e-05,
      "loss": 0.0007,
      "step": 37300
    },
    {
      "epoch": 1.794723944068041,
      "grad_norm": 0.11309698224067688,
      "learning_rate": 4.10266205372159e-05,
      "loss": 0.0011,
      "step": 37350
    },
    {
      "epoch": 1.7971265196290425,
      "grad_norm": 0.07678728550672531,
      "learning_rate": 4.101460765941089e-05,
      "loss": 0.0002,
      "step": 37400
    },
    {
      "epoch": 1.7995290951900438,
      "grad_norm": 0.21264715492725372,
      "learning_rate": 4.100259478160588e-05,
      "loss": 0.0002,
      "step": 37450
    },
    {
      "epoch": 1.801931670751045,
      "grad_norm": 0.31567075848579407,
      "learning_rate": 4.099058190380088e-05,
      "loss": 0.0003,
      "step": 37500
    },
    {
      "epoch": 1.8043342463120466,
      "grad_norm": 0.29525548219680786,
      "learning_rate": 4.097856902599587e-05,
      "loss": 0.0002,
      "step": 37550
    },
    {
      "epoch": 1.806736821873048,
      "grad_norm": 0.5452392101287842,
      "learning_rate": 4.096655614819086e-05,
      "loss": 0.0003,
      "step": 37600
    },
    {
      "epoch": 1.8091393974340493,
      "grad_norm": 0.16134491562843323,
      "learning_rate": 4.095454327038585e-05,
      "loss": 0.0003,
      "step": 37650
    },
    {
      "epoch": 1.8115419729950508,
      "grad_norm": 0.32096895575523376,
      "learning_rate": 4.0942530392580843e-05,
      "loss": 0.0003,
      "step": 37700
    },
    {
      "epoch": 1.8139445485560521,
      "grad_norm": 0.15027493238449097,
      "learning_rate": 4.093051751477584e-05,
      "loss": 0.0002,
      "step": 37750
    },
    {
      "epoch": 1.8163471241170535,
      "grad_norm": 0.3023838400840759,
      "learning_rate": 4.091850463697083e-05,
      "loss": 0.0003,
      "step": 37800
    },
    {
      "epoch": 1.818749699678055,
      "grad_norm": 0.41469046473503113,
      "learning_rate": 4.090649175916583e-05,
      "loss": 0.0002,
      "step": 37850
    },
    {
      "epoch": 1.8211522752390563,
      "grad_norm": 0.23867616057395935,
      "learning_rate": 4.089447888136082e-05,
      "loss": 0.0003,
      "step": 37900
    },
    {
      "epoch": 1.8235548508000576,
      "grad_norm": 0.07255494594573975,
      "learning_rate": 4.088246600355581e-05,
      "loss": 0.0002,
      "step": 37950
    },
    {
      "epoch": 1.8259574263610592,
      "grad_norm": 0.07782449573278427,
      "learning_rate": 4.087045312575081e-05,
      "loss": 0.0002,
      "step": 38000
    },
    {
      "epoch": 1.8283600019220605,
      "grad_norm": 0.1636013686656952,
      "learning_rate": 4.08584402479458e-05,
      "loss": 0.0003,
      "step": 38050
    },
    {
      "epoch": 1.8307625774830618,
      "grad_norm": 0.689122200012207,
      "learning_rate": 4.08464273701408e-05,
      "loss": 0.0002,
      "step": 38100
    },
    {
      "epoch": 1.8331651530440634,
      "grad_norm": 0.1736898422241211,
      "learning_rate": 4.083441449233579e-05,
      "loss": 0.0003,
      "step": 38150
    },
    {
      "epoch": 1.8355677286050647,
      "grad_norm": 0.18008658289909363,
      "learning_rate": 4.082240161453078e-05,
      "loss": 0.0003,
      "step": 38200
    },
    {
      "epoch": 1.837970304166066,
      "grad_norm": 0.1963019222021103,
      "learning_rate": 4.0810388736725776e-05,
      "loss": 0.0002,
      "step": 38250
    },
    {
      "epoch": 1.8403728797270675,
      "grad_norm": 0.5127596259117126,
      "learning_rate": 4.079837585892077e-05,
      "loss": 0.0002,
      "step": 38300
    },
    {
      "epoch": 1.8427754552880689,
      "grad_norm": 0.136821448802948,
      "learning_rate": 4.078636298111576e-05,
      "loss": 0.0008,
      "step": 38350
    },
    {
      "epoch": 1.8451780308490702,
      "grad_norm": 0.07697301357984543,
      "learning_rate": 4.077435010331075e-05,
      "loss": 0.0008,
      "step": 38400
    },
    {
      "epoch": 1.8475806064100717,
      "grad_norm": 0.10008389502763748,
      "learning_rate": 4.076233722550574e-05,
      "loss": 0.0008,
      "step": 38450
    },
    {
      "epoch": 1.849983181971073,
      "grad_norm": 0.14770640432834625,
      "learning_rate": 4.075032434770074e-05,
      "loss": 0.0002,
      "step": 38500
    },
    {
      "epoch": 1.8523857575320744,
      "grad_norm": 0.08176736533641815,
      "learning_rate": 4.073831146989573e-05,
      "loss": 0.0003,
      "step": 38550
    },
    {
      "epoch": 1.854788333093076,
      "grad_norm": 0.2156451940536499,
      "learning_rate": 4.0726298592090726e-05,
      "loss": 0.0002,
      "step": 38600
    },
    {
      "epoch": 1.8571909086540772,
      "grad_norm": 0.2562948167324066,
      "learning_rate": 4.0714285714285717e-05,
      "loss": 0.0003,
      "step": 38650
    },
    {
      "epoch": 1.8595934842150785,
      "grad_norm": 0.13238941133022308,
      "learning_rate": 4.070227283648071e-05,
      "loss": 0.0002,
      "step": 38700
    },
    {
      "epoch": 1.86199605977608,
      "grad_norm": 0.09398754686117172,
      "learning_rate": 4.0690259958675705e-05,
      "loss": 0.0007,
      "step": 38750
    },
    {
      "epoch": 1.8643986353370814,
      "grad_norm": 0.08275090157985687,
      "learning_rate": 4.0678247080870696e-05,
      "loss": 0.0002,
      "step": 38800
    },
    {
      "epoch": 1.8668012108980827,
      "grad_norm": 0.22755911946296692,
      "learning_rate": 4.0666234203065687e-05,
      "loss": 0.0002,
      "step": 38850
    },
    {
      "epoch": 1.8692037864590842,
      "grad_norm": 0.16153565049171448,
      "learning_rate": 4.0654221325260684e-05,
      "loss": 0.0002,
      "step": 38900
    },
    {
      "epoch": 1.8716063620200856,
      "grad_norm": 0.3047083020210266,
      "learning_rate": 4.0642208447455675e-05,
      "loss": 0.0002,
      "step": 38950
    },
    {
      "epoch": 1.8740089375810869,
      "grad_norm": 0.2566756308078766,
      "learning_rate": 4.063019556965067e-05,
      "loss": 0.0002,
      "step": 39000
    },
    {
      "epoch": 1.8764115131420884,
      "grad_norm": 0.4551422894001007,
      "learning_rate": 4.0618182691845663e-05,
      "loss": 0.0002,
      "step": 39050
    },
    {
      "epoch": 1.8788140887030897,
      "grad_norm": 0.1672452688217163,
      "learning_rate": 4.0606169814040654e-05,
      "loss": 0.0003,
      "step": 39100
    },
    {
      "epoch": 1.881216664264091,
      "grad_norm": 0.09239187091588974,
      "learning_rate": 4.0594156936235645e-05,
      "loss": 0.0002,
      "step": 39150
    },
    {
      "epoch": 1.8836192398250926,
      "grad_norm": 0.3127364218235016,
      "learning_rate": 4.0582144058430636e-05,
      "loss": 0.0002,
      "step": 39200
    },
    {
      "epoch": 1.886021815386094,
      "grad_norm": 0.5557047724723816,
      "learning_rate": 4.0570131180625634e-05,
      "loss": 0.0003,
      "step": 39250
    },
    {
      "epoch": 1.8884243909470952,
      "grad_norm": 0.7202554941177368,
      "learning_rate": 4.0558118302820624e-05,
      "loss": 0.0002,
      "step": 39300
    },
    {
      "epoch": 1.8908269665080968,
      "grad_norm": 0.4443577229976654,
      "learning_rate": 4.0546105425015615e-05,
      "loss": 0.0003,
      "step": 39350
    },
    {
      "epoch": 1.893229542069098,
      "grad_norm": 0.12409486621618271,
      "learning_rate": 4.053409254721061e-05,
      "loss": 0.0003,
      "step": 39400
    },
    {
      "epoch": 1.8956321176300994,
      "grad_norm": 0.15730981528759003,
      "learning_rate": 4.0522079669405604e-05,
      "loss": 0.0003,
      "step": 39450
    },
    {
      "epoch": 1.898034693191101,
      "grad_norm": 0.13762803375720978,
      "learning_rate": 4.05100667916006e-05,
      "loss": 0.0002,
      "step": 39500
    },
    {
      "epoch": 1.9004372687521023,
      "grad_norm": 0.06918915361166,
      "learning_rate": 4.049805391379559e-05,
      "loss": 0.0002,
      "step": 39550
    },
    {
      "epoch": 1.9028398443131036,
      "grad_norm": 0.095029816031456,
      "learning_rate": 4.048604103599058e-05,
      "loss": 0.0002,
      "step": 39600
    },
    {
      "epoch": 1.9052424198741051,
      "grad_norm": 0.8787901997566223,
      "learning_rate": 4.047402815818558e-05,
      "loss": 0.0003,
      "step": 39650
    },
    {
      "epoch": 1.9076449954351065,
      "grad_norm": 0.22174261510372162,
      "learning_rate": 4.046201528038057e-05,
      "loss": 0.0002,
      "step": 39700
    },
    {
      "epoch": 1.9100475709961078,
      "grad_norm": 0.9846295714378357,
      "learning_rate": 4.045000240257556e-05,
      "loss": 0.0004,
      "step": 39750
    },
    {
      "epoch": 1.9124501465571093,
      "grad_norm": 0.28958871960639954,
      "learning_rate": 4.043798952477056e-05,
      "loss": 0.0009,
      "step": 39800
    },
    {
      "epoch": 1.9148527221181106,
      "grad_norm": 0.25380077958106995,
      "learning_rate": 4.0425976646965544e-05,
      "loss": 0.0003,
      "step": 39850
    },
    {
      "epoch": 1.917255297679112,
      "grad_norm": 0.6349695920944214,
      "learning_rate": 4.041396376916054e-05,
      "loss": 0.0004,
      "step": 39900
    },
    {
      "epoch": 1.9196578732401135,
      "grad_norm": 0.5172313451766968,
      "learning_rate": 4.040195089135553e-05,
      "loss": 0.0003,
      "step": 39950
    },
    {
      "epoch": 1.9220604488011148,
      "grad_norm": 0.3594399392604828,
      "learning_rate": 4.038993801355053e-05,
      "loss": 0.0005,
      "step": 40000
    },
    {
      "epoch": 1.9244630243621161,
      "grad_norm": 0.3230490982532501,
      "learning_rate": 4.037792513574552e-05,
      "loss": 0.0006,
      "step": 40050
    },
    {
      "epoch": 1.9268655999231177,
      "grad_norm": 0.1389443278312683,
      "learning_rate": 4.036591225794051e-05,
      "loss": 0.0002,
      "step": 40100
    },
    {
      "epoch": 1.929268175484119,
      "grad_norm": 0.21225394308567047,
      "learning_rate": 4.035389938013551e-05,
      "loss": 0.0003,
      "step": 40150
    },
    {
      "epoch": 1.9316707510451203,
      "grad_norm": 0.13024713099002838,
      "learning_rate": 4.03418865023305e-05,
      "loss": 0.0002,
      "step": 40200
    },
    {
      "epoch": 1.9340733266061219,
      "grad_norm": 0.028152640908956528,
      "learning_rate": 4.032987362452549e-05,
      "loss": 0.0003,
      "step": 40250
    },
    {
      "epoch": 1.9364759021671232,
      "grad_norm": 0.21460124850273132,
      "learning_rate": 4.031786074672049e-05,
      "loss": 0.0002,
      "step": 40300
    },
    {
      "epoch": 1.9388784777281245,
      "grad_norm": 0.5409828424453735,
      "learning_rate": 4.030584786891548e-05,
      "loss": 0.0002,
      "step": 40350
    },
    {
      "epoch": 1.941281053289126,
      "grad_norm": 0.34937793016433716,
      "learning_rate": 4.029383499111048e-05,
      "loss": 0.0002,
      "step": 40400
    },
    {
      "epoch": 1.9436836288501274,
      "grad_norm": 0.400411456823349,
      "learning_rate": 4.028182211330547e-05,
      "loss": 0.0009,
      "step": 40450
    },
    {
      "epoch": 1.9460862044111287,
      "grad_norm": 0.45208704471588135,
      "learning_rate": 4.026980923550046e-05,
      "loss": 0.0003,
      "step": 40500
    },
    {
      "epoch": 1.9484887799721302,
      "grad_norm": 0.6281006932258606,
      "learning_rate": 4.0257796357695456e-05,
      "loss": 0.0008,
      "step": 40550
    },
    {
      "epoch": 1.9508913555331315,
      "grad_norm": 0.4969312846660614,
      "learning_rate": 4.024578347989044e-05,
      "loss": 0.0003,
      "step": 40600
    },
    {
      "epoch": 1.9532939310941329,
      "grad_norm": 0.697885274887085,
      "learning_rate": 4.023377060208544e-05,
      "loss": 0.0002,
      "step": 40650
    },
    {
      "epoch": 1.9556965066551344,
      "grad_norm": 0.22011986374855042,
      "learning_rate": 4.022175772428043e-05,
      "loss": 0.0003,
      "step": 40700
    },
    {
      "epoch": 1.9580990822161357,
      "grad_norm": 0.7306181192398071,
      "learning_rate": 4.020974484647542e-05,
      "loss": 0.0003,
      "step": 40750
    },
    {
      "epoch": 1.960501657777137,
      "grad_norm": 0.42067334055900574,
      "learning_rate": 4.019773196867042e-05,
      "loss": 0.0002,
      "step": 40800
    },
    {
      "epoch": 1.9629042333381386,
      "grad_norm": 0.18050532042980194,
      "learning_rate": 4.018571909086541e-05,
      "loss": 0.0002,
      "step": 40850
    },
    {
      "epoch": 1.96530680889914,
      "grad_norm": 0.17288242280483246,
      "learning_rate": 4.0173706213060405e-05,
      "loss": 0.0003,
      "step": 40900
    },
    {
      "epoch": 1.9677093844601412,
      "grad_norm": 0.0862312838435173,
      "learning_rate": 4.0161693335255396e-05,
      "loss": 0.0002,
      "step": 40950
    },
    {
      "epoch": 1.9701119600211427,
      "grad_norm": 0.07700788974761963,
      "learning_rate": 4.014968045745039e-05,
      "loss": 0.0002,
      "step": 41000
    },
    {
      "epoch": 1.972514535582144,
      "grad_norm": 0.14234140515327454,
      "learning_rate": 4.0137667579645385e-05,
      "loss": 0.0001,
      "step": 41050
    },
    {
      "epoch": 1.9749171111431454,
      "grad_norm": 0.2475491464138031,
      "learning_rate": 4.0125654701840375e-05,
      "loss": 0.0002,
      "step": 41100
    },
    {
      "epoch": 1.977319686704147,
      "grad_norm": 0.1126495823264122,
      "learning_rate": 4.0113641824035366e-05,
      "loss": 0.0002,
      "step": 41150
    },
    {
      "epoch": 1.9797222622651482,
      "grad_norm": 0.09397350251674652,
      "learning_rate": 4.0101628946230364e-05,
      "loss": 0.0002,
      "step": 41200
    },
    {
      "epoch": 1.9821248378261496,
      "grad_norm": 0.20789746940135956,
      "learning_rate": 4.0089616068425355e-05,
      "loss": 0.0002,
      "step": 41250
    },
    {
      "epoch": 1.984527413387151,
      "grad_norm": 0.10199245065450668,
      "learning_rate": 4.0077603190620345e-05,
      "loss": 0.0002,
      "step": 41300
    },
    {
      "epoch": 1.9869299889481524,
      "grad_norm": 0.14259858429431915,
      "learning_rate": 4.0065590312815336e-05,
      "loss": 0.0003,
      "step": 41350
    },
    {
      "epoch": 1.9893325645091537,
      "grad_norm": 0.6657786965370178,
      "learning_rate": 4.0053577435010334e-05,
      "loss": 0.0003,
      "step": 41400
    },
    {
      "epoch": 1.9917351400701553,
      "grad_norm": 0.2767373025417328,
      "learning_rate": 4.0041564557205325e-05,
      "loss": 0.0004,
      "step": 41450
    },
    {
      "epoch": 1.9941377156311566,
      "grad_norm": 0.08530121296644211,
      "learning_rate": 4.0029551679400316e-05,
      "loss": 0.0002,
      "step": 41500
    },
    {
      "epoch": 1.996540291192158,
      "grad_norm": 0.2888677716255188,
      "learning_rate": 4.001753880159531e-05,
      "loss": 0.0002,
      "step": 41550
    },
    {
      "epoch": 1.9989428667531595,
      "grad_norm": 0.19722571969032288,
      "learning_rate": 4.0005525923790304e-05,
      "loss": 0.0002,
      "step": 41600
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.00041477978811599314,
      "eval_runtime": 17.339,
      "eval_samples_per_second": 547.667,
      "eval_steps_per_second": 68.458,
      "step": 41622
    },
    {
      "epoch": 2.0013454423141606,
      "grad_norm": 0.4078594148159027,
      "learning_rate": 3.9993513045985295e-05,
      "loss": 0.0003,
      "step": 41650
    },
    {
      "epoch": 2.003748017875162,
      "grad_norm": 0.09417311102151871,
      "learning_rate": 3.998150016818029e-05,
      "loss": 0.0005,
      "step": 41700
    },
    {
      "epoch": 2.0061505934361636,
      "grad_norm": 0.1892285794019699,
      "learning_rate": 3.996948729037528e-05,
      "loss": 0.0002,
      "step": 41750
    },
    {
      "epoch": 2.0085531689971647,
      "grad_norm": 0.2531404495239258,
      "learning_rate": 3.995747441257028e-05,
      "loss": 0.0003,
      "step": 41800
    },
    {
      "epoch": 2.0109557445581663,
      "grad_norm": 0.37840038537979126,
      "learning_rate": 3.994546153476527e-05,
      "loss": 0.0002,
      "step": 41850
    },
    {
      "epoch": 2.013358320119168,
      "grad_norm": 0.4291863441467285,
      "learning_rate": 3.993344865696026e-05,
      "loss": 0.0002,
      "step": 41900
    },
    {
      "epoch": 2.0157608956801694,
      "grad_norm": 0.2395341694355011,
      "learning_rate": 3.992143577915526e-05,
      "loss": 0.0003,
      "step": 41950
    },
    {
      "epoch": 2.0181634712411705,
      "grad_norm": 0.10924787819385529,
      "learning_rate": 3.990942290135025e-05,
      "loss": 0.0003,
      "step": 42000
    },
    {
      "epoch": 2.020566046802172,
      "grad_norm": 0.4266636371612549,
      "learning_rate": 3.989741002354524e-05,
      "loss": 0.0002,
      "step": 42050
    },
    {
      "epoch": 2.0229686223631735,
      "grad_norm": 0.5219449996948242,
      "learning_rate": 3.988539714574023e-05,
      "loss": 0.0003,
      "step": 42100
    },
    {
      "epoch": 2.0253711979241746,
      "grad_norm": 0.07837063819169998,
      "learning_rate": 3.987338426793522e-05,
      "loss": 0.0007,
      "step": 42150
    },
    {
      "epoch": 2.027773773485176,
      "grad_norm": 0.35692065954208374,
      "learning_rate": 3.986137139013022e-05,
      "loss": 0.0002,
      "step": 42200
    },
    {
      "epoch": 2.0301763490461777,
      "grad_norm": 0.23009900748729706,
      "learning_rate": 3.984935851232521e-05,
      "loss": 0.0003,
      "step": 42250
    },
    {
      "epoch": 2.032578924607179,
      "grad_norm": 0.11324174702167511,
      "learning_rate": 3.983734563452021e-05,
      "loss": 0.0002,
      "step": 42300
    },
    {
      "epoch": 2.0349815001681804,
      "grad_norm": 0.23768924176692963,
      "learning_rate": 3.98253327567152e-05,
      "loss": 0.0002,
      "step": 42350
    },
    {
      "epoch": 2.037384075729182,
      "grad_norm": 0.09557679295539856,
      "learning_rate": 3.981331987891019e-05,
      "loss": 0.0008,
      "step": 42400
    },
    {
      "epoch": 2.039786651290183,
      "grad_norm": 0.22740799188613892,
      "learning_rate": 3.980130700110519e-05,
      "loss": 0.0002,
      "step": 42450
    },
    {
      "epoch": 2.0421892268511845,
      "grad_norm": 0.4276053309440613,
      "learning_rate": 3.978929412330018e-05,
      "loss": 0.0002,
      "step": 42500
    },
    {
      "epoch": 2.044591802412186,
      "grad_norm": 0.10858376324176788,
      "learning_rate": 3.977728124549518e-05,
      "loss": 0.0002,
      "step": 42550
    },
    {
      "epoch": 2.046994377973187,
      "grad_norm": 0.3802545368671417,
      "learning_rate": 3.976526836769017e-05,
      "loss": 0.0002,
      "step": 42600
    },
    {
      "epoch": 2.0493969535341887,
      "grad_norm": 0.21693751215934753,
      "learning_rate": 3.975325548988516e-05,
      "loss": 0.0002,
      "step": 42650
    },
    {
      "epoch": 2.0517995290951903,
      "grad_norm": 0.5908257365226746,
      "learning_rate": 3.9741242612080156e-05,
      "loss": 0.0002,
      "step": 42700
    },
    {
      "epoch": 2.0542021046561914,
      "grad_norm": 0.3555893003940582,
      "learning_rate": 3.972922973427515e-05,
      "loss": 0.0002,
      "step": 42750
    },
    {
      "epoch": 2.056604680217193,
      "grad_norm": 0.5087557435035706,
      "learning_rate": 3.971721685647014e-05,
      "loss": 0.0003,
      "step": 42800
    },
    {
      "epoch": 2.0590072557781944,
      "grad_norm": 0.29824212193489075,
      "learning_rate": 3.970520397866513e-05,
      "loss": 0.0002,
      "step": 42850
    },
    {
      "epoch": 2.0614098313391955,
      "grad_norm": 0.2062930017709732,
      "learning_rate": 3.969319110086012e-05,
      "loss": 0.0002,
      "step": 42900
    },
    {
      "epoch": 2.063812406900197,
      "grad_norm": 0.1900385171175003,
      "learning_rate": 3.968117822305512e-05,
      "loss": 0.0003,
      "step": 42950
    },
    {
      "epoch": 2.0662149824611986,
      "grad_norm": 0.14308713376522064,
      "learning_rate": 3.966916534525011e-05,
      "loss": 0.0002,
      "step": 43000
    },
    {
      "epoch": 2.0686175580221997,
      "grad_norm": 0.27370452880859375,
      "learning_rate": 3.96571524674451e-05,
      "loss": 0.0002,
      "step": 43050
    },
    {
      "epoch": 2.0710201335832013,
      "grad_norm": 0.07704731822013855,
      "learning_rate": 3.9645139589640096e-05,
      "loss": 0.0002,
      "step": 43100
    },
    {
      "epoch": 2.073422709144203,
      "grad_norm": 0.12204141914844513,
      "learning_rate": 3.963312671183509e-05,
      "loss": 0.0002,
      "step": 43150
    },
    {
      "epoch": 2.075825284705204,
      "grad_norm": 0.07381021231412888,
      "learning_rate": 3.9621113834030085e-05,
      "loss": 0.0002,
      "step": 43200
    },
    {
      "epoch": 2.0782278602662054,
      "grad_norm": 0.13078095018863678,
      "learning_rate": 3.9609100956225076e-05,
      "loss": 0.0003,
      "step": 43250
    },
    {
      "epoch": 2.080630435827207,
      "grad_norm": 0.1355329006910324,
      "learning_rate": 3.9597088078420067e-05,
      "loss": 0.0002,
      "step": 43300
    },
    {
      "epoch": 2.083033011388208,
      "grad_norm": 0.4654593765735626,
      "learning_rate": 3.9585075200615064e-05,
      "loss": 0.0003,
      "step": 43350
    },
    {
      "epoch": 2.0854355869492096,
      "grad_norm": 0.09904686361551285,
      "learning_rate": 3.9573062322810055e-05,
      "loss": 0.0002,
      "step": 43400
    },
    {
      "epoch": 2.087838162510211,
      "grad_norm": 0.3813920319080353,
      "learning_rate": 3.956104944500505e-05,
      "loss": 0.0003,
      "step": 43450
    },
    {
      "epoch": 2.0902407380712122,
      "grad_norm": 0.1884661465883255,
      "learning_rate": 3.9549036567200043e-05,
      "loss": 0.0004,
      "step": 43500
    },
    {
      "epoch": 2.092643313632214,
      "grad_norm": 0.8692275881767273,
      "learning_rate": 3.953702368939503e-05,
      "loss": 0.0002,
      "step": 43550
    },
    {
      "epoch": 2.0950458891932153,
      "grad_norm": 0.30245694518089294,
      "learning_rate": 3.9525010811590025e-05,
      "loss": 0.0002,
      "step": 43600
    },
    {
      "epoch": 2.0974484647542164,
      "grad_norm": 0.15237732231616974,
      "learning_rate": 3.9512997933785016e-05,
      "loss": 0.0002,
      "step": 43650
    },
    {
      "epoch": 2.099851040315218,
      "grad_norm": 0.11840136349201202,
      "learning_rate": 3.9500985055980013e-05,
      "loss": 0.0002,
      "step": 43700
    },
    {
      "epoch": 2.1022536158762195,
      "grad_norm": 0.5983670353889465,
      "learning_rate": 3.9488972178175004e-05,
      "loss": 0.0002,
      "step": 43750
    },
    {
      "epoch": 2.1046561914372206,
      "grad_norm": 0.10474897921085358,
      "learning_rate": 3.9476959300369995e-05,
      "loss": 0.0002,
      "step": 43800
    },
    {
      "epoch": 2.107058766998222,
      "grad_norm": 0.12732872366905212,
      "learning_rate": 3.946494642256499e-05,
      "loss": 0.0002,
      "step": 43850
    },
    {
      "epoch": 2.1094613425592237,
      "grad_norm": 0.25148463249206543,
      "learning_rate": 3.9452933544759984e-05,
      "loss": 0.0002,
      "step": 43900
    },
    {
      "epoch": 2.111863918120225,
      "grad_norm": 0.12611350417137146,
      "learning_rate": 3.944092066695498e-05,
      "loss": 0.0002,
      "step": 43950
    },
    {
      "epoch": 2.1142664936812263,
      "grad_norm": 0.6145294308662415,
      "learning_rate": 3.942890778914997e-05,
      "loss": 0.0009,
      "step": 44000
    },
    {
      "epoch": 2.116669069242228,
      "grad_norm": 0.11901931464672089,
      "learning_rate": 3.941689491134496e-05,
      "loss": 0.0003,
      "step": 44050
    },
    {
      "epoch": 2.119071644803229,
      "grad_norm": 0.3787572979927063,
      "learning_rate": 3.940488203353996e-05,
      "loss": 0.0002,
      "step": 44100
    },
    {
      "epoch": 2.1214742203642305,
      "grad_norm": 0.320324182510376,
      "learning_rate": 3.939286915573495e-05,
      "loss": 0.0002,
      "step": 44150
    },
    {
      "epoch": 2.123876795925232,
      "grad_norm": 0.06515423953533173,
      "learning_rate": 3.938085627792994e-05,
      "loss": 0.0003,
      "step": 44200
    },
    {
      "epoch": 2.126279371486233,
      "grad_norm": 0.4431802034378052,
      "learning_rate": 3.936884340012494e-05,
      "loss": 0.0003,
      "step": 44250
    },
    {
      "epoch": 2.1286819470472347,
      "grad_norm": 0.32982543110847473,
      "learning_rate": 3.9356830522319924e-05,
      "loss": 0.0002,
      "step": 44300
    },
    {
      "epoch": 2.131084522608236,
      "grad_norm": 0.16348347067832947,
      "learning_rate": 3.934481764451492e-05,
      "loss": 0.0003,
      "step": 44350
    },
    {
      "epoch": 2.1334870981692373,
      "grad_norm": 0.30105143785476685,
      "learning_rate": 3.933280476670991e-05,
      "loss": 0.0002,
      "step": 44400
    },
    {
      "epoch": 2.135889673730239,
      "grad_norm": 0.20925304293632507,
      "learning_rate": 3.932079188890491e-05,
      "loss": 0.0003,
      "step": 44450
    },
    {
      "epoch": 2.1382922492912404,
      "grad_norm": 0.1591317504644394,
      "learning_rate": 3.93087790110999e-05,
      "loss": 0.0002,
      "step": 44500
    },
    {
      "epoch": 2.1406948248522415,
      "grad_norm": 0.4116123914718628,
      "learning_rate": 3.929676613329489e-05,
      "loss": 0.0002,
      "step": 44550
    },
    {
      "epoch": 2.143097400413243,
      "grad_norm": 0.08643001317977905,
      "learning_rate": 3.928475325548989e-05,
      "loss": 0.0009,
      "step": 44600
    },
    {
      "epoch": 2.1454999759742446,
      "grad_norm": 0.5124751925468445,
      "learning_rate": 3.927274037768488e-05,
      "loss": 0.0003,
      "step": 44650
    },
    {
      "epoch": 2.1479025515352457,
      "grad_norm": 0.5514990091323853,
      "learning_rate": 3.926072749987987e-05,
      "loss": 0.0002,
      "step": 44700
    },
    {
      "epoch": 2.150305127096247,
      "grad_norm": 0.17131681740283966,
      "learning_rate": 3.924871462207487e-05,
      "loss": 0.0002,
      "step": 44750
    },
    {
      "epoch": 2.1527077026572488,
      "grad_norm": 0.05676263943314552,
      "learning_rate": 3.923670174426986e-05,
      "loss": 0.0002,
      "step": 44800
    },
    {
      "epoch": 2.15511027821825,
      "grad_norm": 0.3651449382305145,
      "learning_rate": 3.922468886646486e-05,
      "loss": 0.0002,
      "step": 44850
    },
    {
      "epoch": 2.1575128537792514,
      "grad_norm": 0.44127926230430603,
      "learning_rate": 3.921267598865985e-05,
      "loss": 0.0002,
      "step": 44900
    },
    {
      "epoch": 2.159915429340253,
      "grad_norm": 0.36059561371803284,
      "learning_rate": 3.920066311085484e-05,
      "loss": 0.0002,
      "step": 44950
    },
    {
      "epoch": 2.162318004901254,
      "grad_norm": 0.15205572545528412,
      "learning_rate": 3.9188650233049836e-05,
      "loss": 0.0003,
      "step": 45000
    },
    {
      "epoch": 2.1647205804622556,
      "grad_norm": 0.4725603759288788,
      "learning_rate": 3.917663735524482e-05,
      "loss": 0.0002,
      "step": 45050
    },
    {
      "epoch": 2.167123156023257,
      "grad_norm": 0.5876015424728394,
      "learning_rate": 3.916462447743982e-05,
      "loss": 0.0002,
      "step": 45100
    },
    {
      "epoch": 2.169525731584258,
      "grad_norm": 0.1580255627632141,
      "learning_rate": 3.915261159963481e-05,
      "loss": 0.0002,
      "step": 45150
    },
    {
      "epoch": 2.1719283071452598,
      "grad_norm": 0.09138262271881104,
      "learning_rate": 3.91405987218298e-05,
      "loss": 0.0002,
      "step": 45200
    },
    {
      "epoch": 2.1743308827062613,
      "grad_norm": 0.19796280562877655,
      "learning_rate": 3.91285858440248e-05,
      "loss": 0.0003,
      "step": 45250
    },
    {
      "epoch": 2.1767334582672624,
      "grad_norm": 0.5064794421195984,
      "learning_rate": 3.911657296621979e-05,
      "loss": 0.0002,
      "step": 45300
    },
    {
      "epoch": 2.179136033828264,
      "grad_norm": 0.2916278839111328,
      "learning_rate": 3.9104560088414785e-05,
      "loss": 0.0009,
      "step": 45350
    },
    {
      "epoch": 2.1815386093892655,
      "grad_norm": 0.10986433923244476,
      "learning_rate": 3.9092547210609776e-05,
      "loss": 0.0002,
      "step": 45400
    },
    {
      "epoch": 2.1839411849502666,
      "grad_norm": 0.5489683151245117,
      "learning_rate": 3.908053433280477e-05,
      "loss": 0.0002,
      "step": 45450
    },
    {
      "epoch": 2.186343760511268,
      "grad_norm": 0.5680423378944397,
      "learning_rate": 3.9068521454999765e-05,
      "loss": 0.0004,
      "step": 45500
    },
    {
      "epoch": 2.1887463360722696,
      "grad_norm": 0.07656465470790863,
      "learning_rate": 3.9056508577194755e-05,
      "loss": 0.0003,
      "step": 45550
    },
    {
      "epoch": 2.1911489116332707,
      "grad_norm": 0.3107885718345642,
      "learning_rate": 3.9044495699389746e-05,
      "loss": 0.0009,
      "step": 45600
    },
    {
      "epoch": 2.1935514871942723,
      "grad_norm": 0.23937538266181946,
      "learning_rate": 3.9032482821584744e-05,
      "loss": 0.0002,
      "step": 45650
    },
    {
      "epoch": 2.195954062755274,
      "grad_norm": 0.10356176644563675,
      "learning_rate": 3.9020469943779735e-05,
      "loss": 0.0008,
      "step": 45700
    },
    {
      "epoch": 2.198356638316275,
      "grad_norm": 0.1298723965883255,
      "learning_rate": 3.900845706597473e-05,
      "loss": 0.0002,
      "step": 45750
    },
    {
      "epoch": 2.2007592138772765,
      "grad_norm": 0.0958421528339386,
      "learning_rate": 3.8996444188169716e-05,
      "loss": 0.0002,
      "step": 45800
    },
    {
      "epoch": 2.203161789438278,
      "grad_norm": 0.19107003509998322,
      "learning_rate": 3.8984431310364714e-05,
      "loss": 0.0002,
      "step": 45850
    },
    {
      "epoch": 2.205564364999279,
      "grad_norm": 0.197743758559227,
      "learning_rate": 3.8972418432559705e-05,
      "loss": 0.0002,
      "step": 45900
    },
    {
      "epoch": 2.2079669405602806,
      "grad_norm": 0.24558481574058533,
      "learning_rate": 3.8960405554754696e-05,
      "loss": 0.0004,
      "step": 45950
    },
    {
      "epoch": 2.210369516121282,
      "grad_norm": 0.1751820594072342,
      "learning_rate": 3.894839267694969e-05,
      "loss": 0.0002,
      "step": 46000
    },
    {
      "epoch": 2.2127720916822833,
      "grad_norm": 0.11247367411851883,
      "learning_rate": 3.8936379799144684e-05,
      "loss": 0.0002,
      "step": 46050
    },
    {
      "epoch": 2.215174667243285,
      "grad_norm": 0.2853730022907257,
      "learning_rate": 3.8924366921339675e-05,
      "loss": 0.0002,
      "step": 46100
    },
    {
      "epoch": 2.2175772428042864,
      "grad_norm": 0.09567580372095108,
      "learning_rate": 3.891235404353467e-05,
      "loss": 0.0002,
      "step": 46150
    },
    {
      "epoch": 2.2199798183652875,
      "grad_norm": 0.39147040247917175,
      "learning_rate": 3.890034116572966e-05,
      "loss": 0.0002,
      "step": 46200
    },
    {
      "epoch": 2.222382393926289,
      "grad_norm": 0.4635055363178253,
      "learning_rate": 3.888832828792466e-05,
      "loss": 0.0002,
      "step": 46250
    },
    {
      "epoch": 2.2247849694872905,
      "grad_norm": 0.38999322056770325,
      "learning_rate": 3.887631541011965e-05,
      "loss": 0.0002,
      "step": 46300
    },
    {
      "epoch": 2.2271875450482916,
      "grad_norm": 0.12246672809123993,
      "learning_rate": 3.886430253231464e-05,
      "loss": 0.0002,
      "step": 46350
    },
    {
      "epoch": 2.229590120609293,
      "grad_norm": 0.17675887048244476,
      "learning_rate": 3.885228965450964e-05,
      "loss": 0.0002,
      "step": 46400
    },
    {
      "epoch": 2.2319926961702947,
      "grad_norm": 0.1821049302816391,
      "learning_rate": 3.884027677670463e-05,
      "loss": 0.0003,
      "step": 46450
    },
    {
      "epoch": 2.234395271731296,
      "grad_norm": 0.13072609901428223,
      "learning_rate": 3.882826389889962e-05,
      "loss": 0.0004,
      "step": 46500
    },
    {
      "epoch": 2.2367978472922974,
      "grad_norm": 0.09296075254678726,
      "learning_rate": 3.881625102109461e-05,
      "loss": 0.0002,
      "step": 46550
    },
    {
      "epoch": 2.239200422853299,
      "grad_norm": 0.4073535203933716,
      "learning_rate": 3.88042381432896e-05,
      "loss": 0.0002,
      "step": 46600
    },
    {
      "epoch": 2.2416029984143,
      "grad_norm": 0.09300295263528824,
      "learning_rate": 3.87922252654846e-05,
      "loss": 0.0002,
      "step": 46650
    },
    {
      "epoch": 2.2440055739753015,
      "grad_norm": 0.4531802833080292,
      "learning_rate": 3.878021238767959e-05,
      "loss": 0.0002,
      "step": 46700
    },
    {
      "epoch": 2.246408149536303,
      "grad_norm": 0.34606680274009705,
      "learning_rate": 3.876819950987459e-05,
      "loss": 0.0002,
      "step": 46750
    },
    {
      "epoch": 2.248810725097304,
      "grad_norm": 0.1436464935541153,
      "learning_rate": 3.875618663206958e-05,
      "loss": 0.0002,
      "step": 46800
    },
    {
      "epoch": 2.2512133006583057,
      "grad_norm": 0.40555405616760254,
      "learning_rate": 3.874417375426457e-05,
      "loss": 0.0002,
      "step": 46850
    },
    {
      "epoch": 2.2536158762193073,
      "grad_norm": 0.43795648217201233,
      "learning_rate": 3.873216087645957e-05,
      "loss": 0.0002,
      "step": 46900
    },
    {
      "epoch": 2.2560184517803084,
      "grad_norm": 0.1046232357621193,
      "learning_rate": 3.872014799865456e-05,
      "loss": 0.0002,
      "step": 46950
    },
    {
      "epoch": 2.25842102734131,
      "grad_norm": 0.24463315308094025,
      "learning_rate": 3.870813512084955e-05,
      "loss": 0.0002,
      "step": 47000
    },
    {
      "epoch": 2.2608236029023114,
      "grad_norm": 0.05556382238864899,
      "learning_rate": 3.869612224304455e-05,
      "loss": 0.0002,
      "step": 47050
    },
    {
      "epoch": 2.2632261784633125,
      "grad_norm": 0.227471262216568,
      "learning_rate": 3.868410936523954e-05,
      "loss": 0.0006,
      "step": 47100
    },
    {
      "epoch": 2.265628754024314,
      "grad_norm": 0.4110322892665863,
      "learning_rate": 3.8672096487434536e-05,
      "loss": 0.0002,
      "step": 47150
    },
    {
      "epoch": 2.2680313295853156,
      "grad_norm": 0.21994423866271973,
      "learning_rate": 3.866008360962953e-05,
      "loss": 0.0002,
      "step": 47200
    },
    {
      "epoch": 2.2704339051463167,
      "grad_norm": 0.09547950327396393,
      "learning_rate": 3.864807073182452e-05,
      "loss": 0.0002,
      "step": 47250
    },
    {
      "epoch": 2.2728364807073183,
      "grad_norm": 0.12142513692378998,
      "learning_rate": 3.863605785401951e-05,
      "loss": 0.0002,
      "step": 47300
    },
    {
      "epoch": 2.27523905626832,
      "grad_norm": 0.6295325756072998,
      "learning_rate": 3.86240449762145e-05,
      "loss": 0.0002,
      "step": 47350
    },
    {
      "epoch": 2.277641631829321,
      "grad_norm": 0.6719062328338623,
      "learning_rate": 3.86120320984095e-05,
      "loss": 0.0002,
      "step": 47400
    },
    {
      "epoch": 2.2800442073903224,
      "grad_norm": 0.12468872219324112,
      "learning_rate": 3.860001922060449e-05,
      "loss": 0.0007,
      "step": 47450
    },
    {
      "epoch": 2.282446782951324,
      "grad_norm": 0.11861356347799301,
      "learning_rate": 3.858800634279948e-05,
      "loss": 0.0002,
      "step": 47500
    },
    {
      "epoch": 2.284849358512325,
      "grad_norm": 0.2106127142906189,
      "learning_rate": 3.8575993464994476e-05,
      "loss": 0.0003,
      "step": 47550
    },
    {
      "epoch": 2.2872519340733266,
      "grad_norm": 0.4300028681755066,
      "learning_rate": 3.856398058718947e-05,
      "loss": 0.0002,
      "step": 47600
    },
    {
      "epoch": 2.289654509634328,
      "grad_norm": 0.10016258805990219,
      "learning_rate": 3.8551967709384465e-05,
      "loss": 0.0007,
      "step": 47650
    },
    {
      "epoch": 2.2920570851953292,
      "grad_norm": 0.48838913440704346,
      "learning_rate": 3.8539954831579456e-05,
      "loss": 0.0002,
      "step": 47700
    },
    {
      "epoch": 2.294459660756331,
      "grad_norm": 0.1635732352733612,
      "learning_rate": 3.8527941953774447e-05,
      "loss": 0.0003,
      "step": 47750
    },
    {
      "epoch": 2.2968622363173323,
      "grad_norm": 0.1319694072008133,
      "learning_rate": 3.8515929075969444e-05,
      "loss": 0.0004,
      "step": 47800
    },
    {
      "epoch": 2.2992648118783334,
      "grad_norm": 0.04599343240261078,
      "learning_rate": 3.8503916198164435e-05,
      "loss": 0.0003,
      "step": 47850
    },
    {
      "epoch": 2.301667387439335,
      "grad_norm": 0.09006187319755554,
      "learning_rate": 3.849190332035943e-05,
      "loss": 0.0002,
      "step": 47900
    },
    {
      "epoch": 2.3040699630003365,
      "grad_norm": 0.2344038337469101,
      "learning_rate": 3.847989044255442e-05,
      "loss": 0.0002,
      "step": 47950
    },
    {
      "epoch": 2.3064725385613376,
      "grad_norm": 0.38019007444381714,
      "learning_rate": 3.846787756474941e-05,
      "loss": 0.0005,
      "step": 48000
    },
    {
      "epoch": 2.308875114122339,
      "grad_norm": 0.3635117709636688,
      "learning_rate": 3.8455864686944405e-05,
      "loss": 0.0002,
      "step": 48050
    },
    {
      "epoch": 2.3112776896833407,
      "grad_norm": 0.07384950667619705,
      "learning_rate": 3.8443851809139396e-05,
      "loss": 0.0002,
      "step": 48100
    },
    {
      "epoch": 2.313680265244342,
      "grad_norm": 0.4024459719657898,
      "learning_rate": 3.8431838931334393e-05,
      "loss": 0.0002,
      "step": 48150
    },
    {
      "epoch": 2.3160828408053433,
      "grad_norm": 0.08477889001369476,
      "learning_rate": 3.8419826053529384e-05,
      "loss": 0.0008,
      "step": 48200
    },
    {
      "epoch": 2.318485416366345,
      "grad_norm": 0.1254250705242157,
      "learning_rate": 3.8407813175724375e-05,
      "loss": 0.0002,
      "step": 48250
    },
    {
      "epoch": 2.320887991927346,
      "grad_norm": 0.17924603819847107,
      "learning_rate": 3.839580029791937e-05,
      "loss": 0.0003,
      "step": 48300
    },
    {
      "epoch": 2.3232905674883475,
      "grad_norm": 0.2117638885974884,
      "learning_rate": 3.8383787420114364e-05,
      "loss": 0.0002,
      "step": 48350
    },
    {
      "epoch": 2.325693143049349,
      "grad_norm": 0.28624579310417175,
      "learning_rate": 3.837177454230936e-05,
      "loss": 0.0002,
      "step": 48400
    },
    {
      "epoch": 2.32809571861035,
      "grad_norm": 0.08892606198787689,
      "learning_rate": 3.835976166450435e-05,
      "loss": 0.0002,
      "step": 48450
    },
    {
      "epoch": 2.3304982941713517,
      "grad_norm": 0.0941028967499733,
      "learning_rate": 3.834774878669934e-05,
      "loss": 0.0002,
      "step": 48500
    },
    {
      "epoch": 2.332900869732353,
      "grad_norm": 0.18067900836467743,
      "learning_rate": 3.833573590889434e-05,
      "loss": 0.0002,
      "step": 48550
    },
    {
      "epoch": 2.3353034452933543,
      "grad_norm": 0.20226265490055084,
      "learning_rate": 3.832372303108933e-05,
      "loss": 0.0002,
      "step": 48600
    },
    {
      "epoch": 2.337706020854356,
      "grad_norm": 0.13538451492786407,
      "learning_rate": 3.831171015328432e-05,
      "loss": 0.0002,
      "step": 48650
    },
    {
      "epoch": 2.3401085964153574,
      "grad_norm": 0.08994276821613312,
      "learning_rate": 3.829969727547932e-05,
      "loss": 0.0002,
      "step": 48700
    },
    {
      "epoch": 2.3425111719763585,
      "grad_norm": 0.1354120373725891,
      "learning_rate": 3.8287684397674304e-05,
      "loss": 0.0002,
      "step": 48750
    },
    {
      "epoch": 2.34491374753736,
      "grad_norm": 0.24066859483718872,
      "learning_rate": 3.82756715198693e-05,
      "loss": 0.0002,
      "step": 48800
    },
    {
      "epoch": 2.3473163230983616,
      "grad_norm": 0.10691478848457336,
      "learning_rate": 3.826365864206429e-05,
      "loss": 0.0007,
      "step": 48850
    },
    {
      "epoch": 2.3497188986593627,
      "grad_norm": 0.0874600037932396,
      "learning_rate": 3.825164576425928e-05,
      "loss": 0.0002,
      "step": 48900
    },
    {
      "epoch": 2.352121474220364,
      "grad_norm": 0.31997138261795044,
      "learning_rate": 3.823963288645428e-05,
      "loss": 0.0002,
      "step": 48950
    },
    {
      "epoch": 2.3545240497813658,
      "grad_norm": 0.2814038395881653,
      "learning_rate": 3.822762000864927e-05,
      "loss": 0.0008,
      "step": 49000
    },
    {
      "epoch": 2.356926625342367,
      "grad_norm": 0.36560970544815063,
      "learning_rate": 3.821560713084427e-05,
      "loss": 0.0003,
      "step": 49050
    },
    {
      "epoch": 2.3593292009033684,
      "grad_norm": 0.25672438740730286,
      "learning_rate": 3.820359425303926e-05,
      "loss": 0.0002,
      "step": 49100
    },
    {
      "epoch": 2.36173177646437,
      "grad_norm": 0.23986707627773285,
      "learning_rate": 3.819158137523425e-05,
      "loss": 0.0002,
      "step": 49150
    },
    {
      "epoch": 2.364134352025371,
      "grad_norm": 0.3090210258960724,
      "learning_rate": 3.817956849742925e-05,
      "loss": 0.0002,
      "step": 49200
    },
    {
      "epoch": 2.3665369275863726,
      "grad_norm": 0.4023008346557617,
      "learning_rate": 3.816755561962424e-05,
      "loss": 0.0001,
      "step": 49250
    },
    {
      "epoch": 2.368939503147374,
      "grad_norm": 0.31471356749534607,
      "learning_rate": 3.815554274181924e-05,
      "loss": 0.0008,
      "step": 49300
    },
    {
      "epoch": 2.371342078708375,
      "grad_norm": 0.11113991588354111,
      "learning_rate": 3.814352986401423e-05,
      "loss": 0.0002,
      "step": 49350
    },
    {
      "epoch": 2.3737446542693768,
      "grad_norm": 0.05126139149069786,
      "learning_rate": 3.813151698620922e-05,
      "loss": 0.0002,
      "step": 49400
    },
    {
      "epoch": 2.3761472298303783,
      "grad_norm": 0.1446407288312912,
      "learning_rate": 3.8119504108404216e-05,
      "loss": 0.0003,
      "step": 49450
    },
    {
      "epoch": 2.3785498053913794,
      "grad_norm": 0.10285584628582001,
      "learning_rate": 3.81074912305992e-05,
      "loss": 0.0003,
      "step": 49500
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.043738093227148056,
      "learning_rate": 3.80954783527942e-05,
      "loss": 0.0002,
      "step": 49550
    },
    {
      "epoch": 2.3833549565133825,
      "grad_norm": 0.2358756959438324,
      "learning_rate": 3.808346547498919e-05,
      "loss": 0.0002,
      "step": 49600
    },
    {
      "epoch": 2.3857575320743836,
      "grad_norm": 0.3792881369590759,
      "learning_rate": 3.807145259718418e-05,
      "loss": 0.0002,
      "step": 49650
    },
    {
      "epoch": 2.388160107635385,
      "grad_norm": 0.08486293256282806,
      "learning_rate": 3.805943971937918e-05,
      "loss": 0.0002,
      "step": 49700
    },
    {
      "epoch": 2.3905626831963867,
      "grad_norm": 0.39307117462158203,
      "learning_rate": 3.804742684157417e-05,
      "loss": 0.0002,
      "step": 49750
    },
    {
      "epoch": 2.3929652587573877,
      "grad_norm": 0.1099986657500267,
      "learning_rate": 3.8035413963769165e-05,
      "loss": 0.0002,
      "step": 49800
    },
    {
      "epoch": 2.3953678343183893,
      "grad_norm": 0.7376587390899658,
      "learning_rate": 3.8023401085964156e-05,
      "loss": 0.0001,
      "step": 49850
    },
    {
      "epoch": 2.397770409879391,
      "grad_norm": 0.15547412633895874,
      "learning_rate": 3.801138820815915e-05,
      "loss": 0.0002,
      "step": 49900
    },
    {
      "epoch": 2.400172985440392,
      "grad_norm": 0.14255261421203613,
      "learning_rate": 3.7999375330354144e-05,
      "loss": 0.0002,
      "step": 49950
    },
    {
      "epoch": 2.4025755610013935,
      "grad_norm": 0.1653076559305191,
      "learning_rate": 3.7987362452549135e-05,
      "loss": 0.0002,
      "step": 50000
    },
    {
      "epoch": 2.404978136562395,
      "grad_norm": 0.12228445708751678,
      "learning_rate": 3.7975349574744126e-05,
      "loss": 0.0002,
      "step": 50050
    },
    {
      "epoch": 2.407380712123396,
      "grad_norm": 0.4376882314682007,
      "learning_rate": 3.7963336696939124e-05,
      "loss": 0.0007,
      "step": 50100
    },
    {
      "epoch": 2.4097832876843976,
      "grad_norm": 0.46222320199012756,
      "learning_rate": 3.7951323819134115e-05,
      "loss": 0.0008,
      "step": 50150
    },
    {
      "epoch": 2.412185863245399,
      "grad_norm": 0.10343153774738312,
      "learning_rate": 3.793931094132911e-05,
      "loss": 0.0003,
      "step": 50200
    },
    {
      "epoch": 2.4145884388064003,
      "grad_norm": 0.03602554649114609,
      "learning_rate": 3.7927298063524096e-05,
      "loss": 0.0002,
      "step": 50250
    },
    {
      "epoch": 2.416991014367402,
      "grad_norm": 0.10716433078050613,
      "learning_rate": 3.7915285185719094e-05,
      "loss": 0.0002,
      "step": 50300
    },
    {
      "epoch": 2.4193935899284034,
      "grad_norm": 0.19749261438846588,
      "learning_rate": 3.7903272307914085e-05,
      "loss": 0.0008,
      "step": 50350
    },
    {
      "epoch": 2.4217961654894045,
      "grad_norm": 0.1452750414609909,
      "learning_rate": 3.7891259430109075e-05,
      "loss": 0.0002,
      "step": 50400
    },
    {
      "epoch": 2.424198741050406,
      "grad_norm": 0.37786754965782166,
      "learning_rate": 3.787924655230407e-05,
      "loss": 0.0008,
      "step": 50450
    },
    {
      "epoch": 2.4266013166114075,
      "grad_norm": 0.2393411546945572,
      "learning_rate": 3.7867233674499064e-05,
      "loss": 0.0002,
      "step": 50500
    },
    {
      "epoch": 2.4290038921724086,
      "grad_norm": 0.29843002557754517,
      "learning_rate": 3.7855220796694055e-05,
      "loss": 0.0001,
      "step": 50550
    },
    {
      "epoch": 2.43140646773341,
      "grad_norm": 0.184634730219841,
      "learning_rate": 3.784320791888905e-05,
      "loss": 0.0002,
      "step": 50600
    },
    {
      "epoch": 2.4338090432944117,
      "grad_norm": 0.45991194248199463,
      "learning_rate": 3.783119504108404e-05,
      "loss": 0.0003,
      "step": 50650
    },
    {
      "epoch": 2.436211618855413,
      "grad_norm": 0.6050354242324829,
      "learning_rate": 3.781918216327904e-05,
      "loss": 0.0002,
      "step": 50700
    },
    {
      "epoch": 2.4386141944164144,
      "grad_norm": 0.09481147676706314,
      "learning_rate": 3.780716928547403e-05,
      "loss": 0.0002,
      "step": 50750
    },
    {
      "epoch": 2.441016769977416,
      "grad_norm": 0.3847770392894745,
      "learning_rate": 3.779515640766902e-05,
      "loss": 0.0002,
      "step": 50800
    },
    {
      "epoch": 2.443419345538417,
      "grad_norm": 0.10233603417873383,
      "learning_rate": 3.778314352986402e-05,
      "loss": 0.0009,
      "step": 50850
    },
    {
      "epoch": 2.4458219210994185,
      "grad_norm": 0.37040889263153076,
      "learning_rate": 3.777113065205901e-05,
      "loss": 0.0002,
      "step": 50900
    },
    {
      "epoch": 2.44822449666042,
      "grad_norm": 0.218481183052063,
      "learning_rate": 3.7759117774254e-05,
      "loss": 0.0008,
      "step": 50950
    },
    {
      "epoch": 2.450627072221421,
      "grad_norm": 0.5414186716079712,
      "learning_rate": 3.774710489644899e-05,
      "loss": 0.0002,
      "step": 51000
    },
    {
      "epoch": 2.4530296477824227,
      "grad_norm": 0.23799927532672882,
      "learning_rate": 3.773509201864398e-05,
      "loss": 0.0002,
      "step": 51050
    },
    {
      "epoch": 2.4554322233434243,
      "grad_norm": 0.25309744477272034,
      "learning_rate": 3.772307914083898e-05,
      "loss": 0.0002,
      "step": 51100
    },
    {
      "epoch": 2.4578347989044254,
      "grad_norm": 0.3381919264793396,
      "learning_rate": 3.771106626303397e-05,
      "loss": 0.0002,
      "step": 51150
    },
    {
      "epoch": 2.460237374465427,
      "grad_norm": 0.12927356362342834,
      "learning_rate": 3.769905338522897e-05,
      "loss": 0.0002,
      "step": 51200
    },
    {
      "epoch": 2.4626399500264284,
      "grad_norm": 0.2930889129638672,
      "learning_rate": 3.768704050742396e-05,
      "loss": 0.0007,
      "step": 51250
    },
    {
      "epoch": 2.4650425255874295,
      "grad_norm": 0.3558719754219055,
      "learning_rate": 3.767502762961895e-05,
      "loss": 0.0003,
      "step": 51300
    },
    {
      "epoch": 2.467445101148431,
      "grad_norm": 0.28757622838020325,
      "learning_rate": 3.766301475181395e-05,
      "loss": 0.0002,
      "step": 51350
    },
    {
      "epoch": 2.4698476767094326,
      "grad_norm": 0.11288436502218246,
      "learning_rate": 3.765100187400894e-05,
      "loss": 0.0002,
      "step": 51400
    },
    {
      "epoch": 2.4722502522704337,
      "grad_norm": 0.4627736210823059,
      "learning_rate": 3.763898899620393e-05,
      "loss": 0.0003,
      "step": 51450
    },
    {
      "epoch": 2.4746528278314353,
      "grad_norm": 0.5505245923995972,
      "learning_rate": 3.762697611839893e-05,
      "loss": 0.0002,
      "step": 51500
    },
    {
      "epoch": 2.477055403392437,
      "grad_norm": 0.3267301619052887,
      "learning_rate": 3.761496324059392e-05,
      "loss": 0.0002,
      "step": 51550
    },
    {
      "epoch": 2.4794579789534383,
      "grad_norm": 0.1997688263654709,
      "learning_rate": 3.7602950362788916e-05,
      "loss": 0.0002,
      "step": 51600
    },
    {
      "epoch": 2.4818605545144394,
      "grad_norm": 0.4149623513221741,
      "learning_rate": 3.759093748498391e-05,
      "loss": 0.0002,
      "step": 51650
    },
    {
      "epoch": 2.484263130075441,
      "grad_norm": 0.18498247861862183,
      "learning_rate": 3.75789246071789e-05,
      "loss": 0.0002,
      "step": 51700
    },
    {
      "epoch": 2.486665705636442,
      "grad_norm": 0.24773864448070526,
      "learning_rate": 3.756691172937389e-05,
      "loss": 0.0003,
      "step": 51750
    },
    {
      "epoch": 2.4890682811974436,
      "grad_norm": 0.7102482318878174,
      "learning_rate": 3.755489885156888e-05,
      "loss": 0.0002,
      "step": 51800
    },
    {
      "epoch": 2.491470856758445,
      "grad_norm": 0.10710954666137695,
      "learning_rate": 3.754288597376388e-05,
      "loss": 0.0002,
      "step": 51850
    },
    {
      "epoch": 2.4938734323194467,
      "grad_norm": 0.09799814224243164,
      "learning_rate": 3.753087309595887e-05,
      "loss": 0.0003,
      "step": 51900
    },
    {
      "epoch": 2.496276007880448,
      "grad_norm": 0.2386482059955597,
      "learning_rate": 3.751886021815386e-05,
      "loss": 0.0002,
      "step": 51950
    },
    {
      "epoch": 2.4986785834414493,
      "grad_norm": 0.3243923783302307,
      "learning_rate": 3.7506847340348856e-05,
      "loss": 0.0002,
      "step": 52000
    },
    {
      "epoch": 2.5010811590024504,
      "grad_norm": 0.07943504303693771,
      "learning_rate": 3.749483446254385e-05,
      "loss": 0.0001,
      "step": 52050
    },
    {
      "epoch": 2.503483734563452,
      "grad_norm": 0.30110156536102295,
      "learning_rate": 3.7482821584738845e-05,
      "loss": 0.0002,
      "step": 52100
    },
    {
      "epoch": 2.5058863101244535,
      "grad_norm": 0.1590431183576584,
      "learning_rate": 3.7470808706933836e-05,
      "loss": 0.0002,
      "step": 52150
    },
    {
      "epoch": 2.508288885685455,
      "grad_norm": 0.5003302693367004,
      "learning_rate": 3.7458795829128826e-05,
      "loss": 0.0002,
      "step": 52200
    },
    {
      "epoch": 2.510691461246456,
      "grad_norm": 0.5206578373908997,
      "learning_rate": 3.7446782951323824e-05,
      "loss": 0.0004,
      "step": 52250
    },
    {
      "epoch": 2.5130940368074577,
      "grad_norm": 0.06755098700523376,
      "learning_rate": 3.7434770073518815e-05,
      "loss": 0.0003,
      "step": 52300
    },
    {
      "epoch": 2.515496612368459,
      "grad_norm": 0.21326224505901337,
      "learning_rate": 3.7422757195713806e-05,
      "loss": 0.0002,
      "step": 52350
    },
    {
      "epoch": 2.5178991879294603,
      "grad_norm": 0.09875672310590744,
      "learning_rate": 3.74107443179088e-05,
      "loss": 0.0002,
      "step": 52400
    },
    {
      "epoch": 2.520301763490462,
      "grad_norm": 0.6611276865005493,
      "learning_rate": 3.7398731440103794e-05,
      "loss": 0.0003,
      "step": 52450
    },
    {
      "epoch": 2.5227043390514634,
      "grad_norm": 0.23391130566596985,
      "learning_rate": 3.7386718562298785e-05,
      "loss": 0.0002,
      "step": 52500
    },
    {
      "epoch": 2.5251069146124645,
      "grad_norm": 0.14441046118736267,
      "learning_rate": 3.7374705684493776e-05,
      "loss": 0.0003,
      "step": 52550
    },
    {
      "epoch": 2.527509490173466,
      "grad_norm": 0.563559889793396,
      "learning_rate": 3.7362692806688773e-05,
      "loss": 0.0002,
      "step": 52600
    },
    {
      "epoch": 2.529912065734467,
      "grad_norm": 0.23592722415924072,
      "learning_rate": 3.7350679928883764e-05,
      "loss": 0.0003,
      "step": 52650
    },
    {
      "epoch": 2.5323146412954687,
      "grad_norm": 0.07672334462404251,
      "learning_rate": 3.7338667051078755e-05,
      "loss": 0.0002,
      "step": 52700
    },
    {
      "epoch": 2.5347172168564702,
      "grad_norm": 0.0799083411693573,
      "learning_rate": 3.732665417327375e-05,
      "loss": 0.0002,
      "step": 52750
    },
    {
      "epoch": 2.5371197924174718,
      "grad_norm": 0.5809189081192017,
      "learning_rate": 3.7314641295468744e-05,
      "loss": 0.0002,
      "step": 52800
    },
    {
      "epoch": 2.539522367978473,
      "grad_norm": 0.08100728690624237,
      "learning_rate": 3.7302628417663734e-05,
      "loss": 0.0002,
      "step": 52850
    },
    {
      "epoch": 2.5419249435394744,
      "grad_norm": 0.09180594235658646,
      "learning_rate": 3.729061553985873e-05,
      "loss": 0.0002,
      "step": 52900
    },
    {
      "epoch": 2.5443275191004755,
      "grad_norm": 0.44057005643844604,
      "learning_rate": 3.727860266205372e-05,
      "loss": 0.0002,
      "step": 52950
    },
    {
      "epoch": 2.546730094661477,
      "grad_norm": 0.10486789047718048,
      "learning_rate": 3.726658978424872e-05,
      "loss": 0.0002,
      "step": 53000
    },
    {
      "epoch": 2.5491326702224786,
      "grad_norm": 0.14027944207191467,
      "learning_rate": 3.725457690644371e-05,
      "loss": 0.0002,
      "step": 53050
    },
    {
      "epoch": 2.55153524578348,
      "grad_norm": 0.278820276260376,
      "learning_rate": 3.72425640286387e-05,
      "loss": 0.0002,
      "step": 53100
    },
    {
      "epoch": 2.553937821344481,
      "grad_norm": 0.644394040107727,
      "learning_rate": 3.72305511508337e-05,
      "loss": 0.0002,
      "step": 53150
    },
    {
      "epoch": 2.5563403969054828,
      "grad_norm": 0.1784939020872116,
      "learning_rate": 3.7218538273028684e-05,
      "loss": 0.0002,
      "step": 53200
    },
    {
      "epoch": 2.558742972466484,
      "grad_norm": 0.10272198170423508,
      "learning_rate": 3.720652539522368e-05,
      "loss": 0.0008,
      "step": 53250
    },
    {
      "epoch": 2.5611455480274854,
      "grad_norm": 0.3645307421684265,
      "learning_rate": 3.719451251741867e-05,
      "loss": 0.0002,
      "step": 53300
    },
    {
      "epoch": 2.563548123588487,
      "grad_norm": 0.34352564811706543,
      "learning_rate": 3.718249963961366e-05,
      "loss": 0.0002,
      "step": 53350
    },
    {
      "epoch": 2.5659506991494885,
      "grad_norm": 0.5890789031982422,
      "learning_rate": 3.717048676180866e-05,
      "loss": 0.0003,
      "step": 53400
    },
    {
      "epoch": 2.5683532747104896,
      "grad_norm": 0.5944074988365173,
      "learning_rate": 3.715847388400365e-05,
      "loss": 0.0001,
      "step": 53450
    },
    {
      "epoch": 2.570755850271491,
      "grad_norm": 0.1127852126955986,
      "learning_rate": 3.714646100619865e-05,
      "loss": 0.0002,
      "step": 53500
    },
    {
      "epoch": 2.573158425832492,
      "grad_norm": 0.14454250037670135,
      "learning_rate": 3.713444812839364e-05,
      "loss": 0.0002,
      "step": 53550
    },
    {
      "epoch": 2.5755610013934938,
      "grad_norm": 0.32969504594802856,
      "learning_rate": 3.712243525058863e-05,
      "loss": 0.0002,
      "step": 53600
    },
    {
      "epoch": 2.5779635769544953,
      "grad_norm": 0.4719448387622833,
      "learning_rate": 3.711042237278363e-05,
      "loss": 0.0003,
      "step": 53650
    },
    {
      "epoch": 2.580366152515497,
      "grad_norm": 0.4764336943626404,
      "learning_rate": 3.709840949497862e-05,
      "loss": 0.0003,
      "step": 53700
    },
    {
      "epoch": 2.582768728076498,
      "grad_norm": 0.5071412324905396,
      "learning_rate": 3.708639661717362e-05,
      "loss": 0.0003,
      "step": 53750
    },
    {
      "epoch": 2.5851713036374995,
      "grad_norm": 0.1504550278186798,
      "learning_rate": 3.707438373936861e-05,
      "loss": 0.0002,
      "step": 53800
    },
    {
      "epoch": 2.5875738791985006,
      "grad_norm": 0.29794004559516907,
      "learning_rate": 3.70623708615636e-05,
      "loss": 0.0002,
      "step": 53850
    },
    {
      "epoch": 2.589976454759502,
      "grad_norm": 0.21987727284431458,
      "learning_rate": 3.7050357983758596e-05,
      "loss": 0.0002,
      "step": 53900
    },
    {
      "epoch": 2.5923790303205037,
      "grad_norm": 0.10939463973045349,
      "learning_rate": 3.703834510595358e-05,
      "loss": 0.0002,
      "step": 53950
    },
    {
      "epoch": 2.594781605881505,
      "grad_norm": 0.0334487222135067,
      "learning_rate": 3.702633222814858e-05,
      "loss": 0.0002,
      "step": 54000
    },
    {
      "epoch": 2.5971841814425063,
      "grad_norm": 0.3566013276576996,
      "learning_rate": 3.701431935034357e-05,
      "loss": 0.0002,
      "step": 54050
    },
    {
      "epoch": 2.599586757003508,
      "grad_norm": 0.09371530264616013,
      "learning_rate": 3.700230647253856e-05,
      "loss": 0.0002,
      "step": 54100
    },
    {
      "epoch": 2.601989332564509,
      "grad_norm": 0.18808642029762268,
      "learning_rate": 3.699029359473356e-05,
      "loss": 0.0002,
      "step": 54150
    },
    {
      "epoch": 2.6043919081255105,
      "grad_norm": 0.19455450773239136,
      "learning_rate": 3.697828071692855e-05,
      "loss": 0.0002,
      "step": 54200
    },
    {
      "epoch": 2.606794483686512,
      "grad_norm": 0.4825668931007385,
      "learning_rate": 3.696626783912354e-05,
      "loss": 0.0002,
      "step": 54250
    },
    {
      "epoch": 2.6091970592475136,
      "grad_norm": 0.13681963086128235,
      "learning_rate": 3.6954254961318536e-05,
      "loss": 0.0003,
      "step": 54300
    },
    {
      "epoch": 2.6115996348085146,
      "grad_norm": 0.21227465569972992,
      "learning_rate": 3.694224208351353e-05,
      "loss": 0.0007,
      "step": 54350
    },
    {
      "epoch": 2.614002210369516,
      "grad_norm": 0.18882183730602264,
      "learning_rate": 3.6930229205708524e-05,
      "loss": 0.0002,
      "step": 54400
    },
    {
      "epoch": 2.6164047859305173,
      "grad_norm": 0.18025356531143188,
      "learning_rate": 3.6918216327903515e-05,
      "loss": 0.0002,
      "step": 54450
    },
    {
      "epoch": 2.618807361491519,
      "grad_norm": 0.10352884232997894,
      "learning_rate": 3.6906203450098506e-05,
      "loss": 0.0002,
      "step": 54500
    },
    {
      "epoch": 2.6212099370525204,
      "grad_norm": 0.24329593777656555,
      "learning_rate": 3.6894190572293504e-05,
      "loss": 0.0003,
      "step": 54550
    },
    {
      "epoch": 2.623612512613522,
      "grad_norm": 0.5418544411659241,
      "learning_rate": 3.6882177694488495e-05,
      "loss": 0.0006,
      "step": 54600
    },
    {
      "epoch": 2.626015088174523,
      "grad_norm": 0.2904028296470642,
      "learning_rate": 3.687016481668349e-05,
      "loss": 0.0003,
      "step": 54650
    },
    {
      "epoch": 2.6284176637355245,
      "grad_norm": 0.09099164605140686,
      "learning_rate": 3.6858151938878476e-05,
      "loss": 0.0002,
      "step": 54700
    },
    {
      "epoch": 2.6308202392965256,
      "grad_norm": 0.4799121022224426,
      "learning_rate": 3.684613906107347e-05,
      "loss": 0.0002,
      "step": 54750
    },
    {
      "epoch": 2.633222814857527,
      "grad_norm": 0.10769116133451462,
      "learning_rate": 3.6834126183268465e-05,
      "loss": 0.0002,
      "step": 54800
    },
    {
      "epoch": 2.6356253904185287,
      "grad_norm": 0.1403190791606903,
      "learning_rate": 3.6822113305463455e-05,
      "loss": 0.0002,
      "step": 54850
    },
    {
      "epoch": 2.6380279659795303,
      "grad_norm": 0.3074534237384796,
      "learning_rate": 3.681010042765845e-05,
      "loss": 0.0007,
      "step": 54900
    },
    {
      "epoch": 2.6404305415405314,
      "grad_norm": 0.24213957786560059,
      "learning_rate": 3.6798087549853444e-05,
      "loss": 0.0002,
      "step": 54950
    },
    {
      "epoch": 2.642833117101533,
      "grad_norm": 0.43051019310951233,
      "learning_rate": 3.6786074672048435e-05,
      "loss": 0.0002,
      "step": 55000
    },
    {
      "epoch": 2.645235692662534,
      "grad_norm": 0.4454003870487213,
      "learning_rate": 3.677406179424343e-05,
      "loss": 0.0003,
      "step": 55050
    },
    {
      "epoch": 2.6476382682235355,
      "grad_norm": 0.5818271636962891,
      "learning_rate": 3.676204891643842e-05,
      "loss": 0.0002,
      "step": 55100
    },
    {
      "epoch": 2.650040843784537,
      "grad_norm": 0.05976928025484085,
      "learning_rate": 3.675003603863342e-05,
      "loss": 0.0002,
      "step": 55150
    },
    {
      "epoch": 2.6524434193455386,
      "grad_norm": 0.5529000163078308,
      "learning_rate": 3.673802316082841e-05,
      "loss": 0.0002,
      "step": 55200
    },
    {
      "epoch": 2.6548459949065397,
      "grad_norm": 0.0501321479678154,
      "learning_rate": 3.67260102830234e-05,
      "loss": 0.0002,
      "step": 55250
    },
    {
      "epoch": 2.6572485704675413,
      "grad_norm": 0.11596418917179108,
      "learning_rate": 3.67139974052184e-05,
      "loss": 0.0001,
      "step": 55300
    },
    {
      "epoch": 2.6596511460285424,
      "grad_norm": 0.045816678553819656,
      "learning_rate": 3.670198452741339e-05,
      "loss": 0.0001,
      "step": 55350
    },
    {
      "epoch": 2.662053721589544,
      "grad_norm": 0.23397061228752136,
      "learning_rate": 3.668997164960838e-05,
      "loss": 0.0002,
      "step": 55400
    },
    {
      "epoch": 2.6644562971505454,
      "grad_norm": 0.2910882830619812,
      "learning_rate": 3.667795877180337e-05,
      "loss": 0.0002,
      "step": 55450
    },
    {
      "epoch": 2.666858872711547,
      "grad_norm": 0.2043473720550537,
      "learning_rate": 3.666594589399836e-05,
      "loss": 0.0003,
      "step": 55500
    },
    {
      "epoch": 2.669261448272548,
      "grad_norm": 0.42666324973106384,
      "learning_rate": 3.665393301619336e-05,
      "loss": 0.0002,
      "step": 55550
    },
    {
      "epoch": 2.6716640238335496,
      "grad_norm": 0.31649118661880493,
      "learning_rate": 3.664192013838835e-05,
      "loss": 0.0002,
      "step": 55600
    },
    {
      "epoch": 2.6740665993945507,
      "grad_norm": 0.16380822658538818,
      "learning_rate": 3.662990726058335e-05,
      "loss": 0.0003,
      "step": 55650
    },
    {
      "epoch": 2.6764691749555523,
      "grad_norm": 0.5037558674812317,
      "learning_rate": 3.661789438277834e-05,
      "loss": 0.0002,
      "step": 55700
    },
    {
      "epoch": 2.678871750516554,
      "grad_norm": 0.21932528913021088,
      "learning_rate": 3.660588150497333e-05,
      "loss": 0.0002,
      "step": 55750
    },
    {
      "epoch": 2.6812743260775553,
      "grad_norm": 0.35026466846466064,
      "learning_rate": 3.659386862716833e-05,
      "loss": 0.0002,
      "step": 55800
    },
    {
      "epoch": 2.6836769016385564,
      "grad_norm": 0.1334972381591797,
      "learning_rate": 3.658185574936332e-05,
      "loss": 0.0001,
      "step": 55850
    },
    {
      "epoch": 2.686079477199558,
      "grad_norm": 0.3458475172519684,
      "learning_rate": 3.656984287155831e-05,
      "loss": 0.0003,
      "step": 55900
    },
    {
      "epoch": 2.688482052760559,
      "grad_norm": 0.20839186012744904,
      "learning_rate": 3.655782999375331e-05,
      "loss": 0.0002,
      "step": 55950
    },
    {
      "epoch": 2.6908846283215606,
      "grad_norm": 0.28267744183540344,
      "learning_rate": 3.65458171159483e-05,
      "loss": 0.0002,
      "step": 56000
    },
    {
      "epoch": 2.693287203882562,
      "grad_norm": 0.3657265603542328,
      "learning_rate": 3.6533804238143296e-05,
      "loss": 0.0002,
      "step": 56050
    },
    {
      "epoch": 2.6956897794435637,
      "grad_norm": 0.5480307340621948,
      "learning_rate": 3.652179136033829e-05,
      "loss": 0.0002,
      "step": 56100
    },
    {
      "epoch": 2.698092355004565,
      "grad_norm": 0.06647542864084244,
      "learning_rate": 3.650977848253328e-05,
      "loss": 0.0002,
      "step": 56150
    },
    {
      "epoch": 2.7004949305655663,
      "grad_norm": 0.2355244904756546,
      "learning_rate": 3.649776560472827e-05,
      "loss": 0.0002,
      "step": 56200
    },
    {
      "epoch": 2.7028975061265674,
      "grad_norm": 0.121815986931324,
      "learning_rate": 3.648575272692326e-05,
      "loss": 0.0005,
      "step": 56250
    },
    {
      "epoch": 2.705300081687569,
      "grad_norm": 0.333484411239624,
      "learning_rate": 3.647373984911826e-05,
      "loss": 0.0002,
      "step": 56300
    },
    {
      "epoch": 2.7077026572485705,
      "grad_norm": 0.5949151515960693,
      "learning_rate": 3.646172697131325e-05,
      "loss": 0.0002,
      "step": 56350
    },
    {
      "epoch": 2.710105232809572,
      "grad_norm": 0.30611780285835266,
      "learning_rate": 3.644971409350824e-05,
      "loss": 0.0002,
      "step": 56400
    },
    {
      "epoch": 2.712507808370573,
      "grad_norm": 0.3236773908138275,
      "learning_rate": 3.6437701215703236e-05,
      "loss": 0.0002,
      "step": 56450
    },
    {
      "epoch": 2.7149103839315747,
      "grad_norm": 0.08755000680685043,
      "learning_rate": 3.642568833789823e-05,
      "loss": 0.0002,
      "step": 56500
    },
    {
      "epoch": 2.717312959492576,
      "grad_norm": 0.054948482662439346,
      "learning_rate": 3.6413675460093225e-05,
      "loss": 0.0002,
      "step": 56550
    },
    {
      "epoch": 2.7197155350535773,
      "grad_norm": 0.3389332592487335,
      "learning_rate": 3.6401662582288216e-05,
      "loss": 0.0003,
      "step": 56600
    },
    {
      "epoch": 2.722118110614579,
      "grad_norm": 0.32162198424339294,
      "learning_rate": 3.6389649704483206e-05,
      "loss": 0.0002,
      "step": 56650
    },
    {
      "epoch": 2.7245206861755804,
      "grad_norm": 0.34189268946647644,
      "learning_rate": 3.6377636826678204e-05,
      "loss": 0.0003,
      "step": 56700
    },
    {
      "epoch": 2.7269232617365815,
      "grad_norm": 0.19701164960861206,
      "learning_rate": 3.6365623948873195e-05,
      "loss": 0.0002,
      "step": 56750
    },
    {
      "epoch": 2.729325837297583,
      "grad_norm": 0.1230122372508049,
      "learning_rate": 3.6353611071068186e-05,
      "loss": 0.0002,
      "step": 56800
    },
    {
      "epoch": 2.731728412858584,
      "grad_norm": 0.08125215768814087,
      "learning_rate": 3.634159819326318e-05,
      "loss": 0.0002,
      "step": 56850
    },
    {
      "epoch": 2.7341309884195857,
      "grad_norm": 0.20897063612937927,
      "learning_rate": 3.6329585315458174e-05,
      "loss": 0.0002,
      "step": 56900
    },
    {
      "epoch": 2.7365335639805872,
      "grad_norm": 0.1144193708896637,
      "learning_rate": 3.6317572437653165e-05,
      "loss": 0.0002,
      "step": 56950
    },
    {
      "epoch": 2.7389361395415888,
      "grad_norm": 0.7413998246192932,
      "learning_rate": 3.6305559559848156e-05,
      "loss": 0.0002,
      "step": 57000
    },
    {
      "epoch": 2.74133871510259,
      "grad_norm": 0.3722517192363739,
      "learning_rate": 3.6293546682043153e-05,
      "loss": 0.0002,
      "step": 57050
    },
    {
      "epoch": 2.7437412906635914,
      "grad_norm": 0.15225309133529663,
      "learning_rate": 3.6281533804238144e-05,
      "loss": 0.0002,
      "step": 57100
    },
    {
      "epoch": 2.7461438662245925,
      "grad_norm": 0.3325161337852478,
      "learning_rate": 3.6269520926433135e-05,
      "loss": 0.0008,
      "step": 57150
    },
    {
      "epoch": 2.748546441785594,
      "grad_norm": 0.10239283740520477,
      "learning_rate": 3.625750804862813e-05,
      "loss": 0.0002,
      "step": 57200
    },
    {
      "epoch": 2.7509490173465956,
      "grad_norm": 0.16658906638622284,
      "learning_rate": 3.6245495170823123e-05,
      "loss": 0.0003,
      "step": 57250
    },
    {
      "epoch": 2.753351592907597,
      "grad_norm": 0.12313847243785858,
      "learning_rate": 3.6233482293018114e-05,
      "loss": 0.0002,
      "step": 57300
    },
    {
      "epoch": 2.755754168468598,
      "grad_norm": 0.3002023696899414,
      "learning_rate": 3.622146941521311e-05,
      "loss": 0.0003,
      "step": 57350
    },
    {
      "epoch": 2.7581567440295998,
      "grad_norm": 0.37435582280158997,
      "learning_rate": 3.62094565374081e-05,
      "loss": 0.0003,
      "step": 57400
    },
    {
      "epoch": 2.760559319590601,
      "grad_norm": 0.17905960977077484,
      "learning_rate": 3.61974436596031e-05,
      "loss": 0.0002,
      "step": 57450
    },
    {
      "epoch": 2.7629618951516024,
      "grad_norm": 0.1008433848619461,
      "learning_rate": 3.618543078179809e-05,
      "loss": 0.0002,
      "step": 57500
    },
    {
      "epoch": 2.765364470712604,
      "grad_norm": 0.03774898871779442,
      "learning_rate": 3.617341790399308e-05,
      "loss": 0.0002,
      "step": 57550
    },
    {
      "epoch": 2.7677670462736055,
      "grad_norm": 0.3929581642150879,
      "learning_rate": 3.616140502618808e-05,
      "loss": 0.0008,
      "step": 57600
    },
    {
      "epoch": 2.7701696218346066,
      "grad_norm": 0.47515854239463806,
      "learning_rate": 3.614939214838307e-05,
      "loss": 0.0002,
      "step": 57650
    },
    {
      "epoch": 2.772572197395608,
      "grad_norm": 0.26311033964157104,
      "learning_rate": 3.613737927057806e-05,
      "loss": 0.0002,
      "step": 57700
    },
    {
      "epoch": 2.774974772956609,
      "grad_norm": 0.4156136214733124,
      "learning_rate": 3.612536639277305e-05,
      "loss": 0.0002,
      "step": 57750
    },
    {
      "epoch": 2.7773773485176108,
      "grad_norm": 0.11442884802818298,
      "learning_rate": 3.611335351496804e-05,
      "loss": 0.0002,
      "step": 57800
    },
    {
      "epoch": 2.7797799240786123,
      "grad_norm": 0.19366896152496338,
      "learning_rate": 3.610134063716304e-05,
      "loss": 0.0002,
      "step": 57850
    },
    {
      "epoch": 2.782182499639614,
      "grad_norm": 0.5582253336906433,
      "learning_rate": 3.608932775935803e-05,
      "loss": 0.0002,
      "step": 57900
    },
    {
      "epoch": 2.784585075200615,
      "grad_norm": 0.20676252245903015,
      "learning_rate": 3.607731488155303e-05,
      "loss": 0.0002,
      "step": 57950
    },
    {
      "epoch": 2.7869876507616165,
      "grad_norm": 0.11378257721662521,
      "learning_rate": 3.606530200374802e-05,
      "loss": 0.0002,
      "step": 58000
    },
    {
      "epoch": 2.7893902263226176,
      "grad_norm": 0.2739375829696655,
      "learning_rate": 3.605328912594301e-05,
      "loss": 0.0002,
      "step": 58050
    },
    {
      "epoch": 2.791792801883619,
      "grad_norm": 0.03912493586540222,
      "learning_rate": 3.604127624813801e-05,
      "loss": 0.0002,
      "step": 58100
    },
    {
      "epoch": 2.7941953774446207,
      "grad_norm": 0.07764041423797607,
      "learning_rate": 3.6029263370333e-05,
      "loss": 0.0001,
      "step": 58150
    },
    {
      "epoch": 2.796597953005622,
      "grad_norm": 0.19964757561683655,
      "learning_rate": 3.601725049252799e-05,
      "loss": 0.0002,
      "step": 58200
    },
    {
      "epoch": 2.7990005285666233,
      "grad_norm": 0.1482921838760376,
      "learning_rate": 3.600523761472299e-05,
      "loss": 0.0003,
      "step": 58250
    },
    {
      "epoch": 2.801403104127625,
      "grad_norm": 0.06824938952922821,
      "learning_rate": 3.599322473691798e-05,
      "loss": 0.0002,
      "step": 58300
    },
    {
      "epoch": 2.8038056796886264,
      "grad_norm": 0.6796367764472961,
      "learning_rate": 3.5981211859112976e-05,
      "loss": 0.0009,
      "step": 58350
    },
    {
      "epoch": 2.8062082552496275,
      "grad_norm": 0.13461710512638092,
      "learning_rate": 3.596919898130797e-05,
      "loss": 0.0001,
      "step": 58400
    },
    {
      "epoch": 2.808610830810629,
      "grad_norm": 0.11619693040847778,
      "learning_rate": 3.595718610350296e-05,
      "loss": 0.0002,
      "step": 58450
    },
    {
      "epoch": 2.8110134063716306,
      "grad_norm": 0.21817775070667267,
      "learning_rate": 3.594517322569795e-05,
      "loss": 0.0002,
      "step": 58500
    },
    {
      "epoch": 2.8134159819326316,
      "grad_norm": 0.02314259298145771,
      "learning_rate": 3.593316034789294e-05,
      "loss": 0.0001,
      "step": 58550
    },
    {
      "epoch": 2.815818557493633,
      "grad_norm": 0.1844898909330368,
      "learning_rate": 3.592114747008794e-05,
      "loss": 0.0002,
      "step": 58600
    },
    {
      "epoch": 2.8182211330546347,
      "grad_norm": 0.35868319869041443,
      "learning_rate": 3.590913459228293e-05,
      "loss": 0.0003,
      "step": 58650
    },
    {
      "epoch": 2.820623708615636,
      "grad_norm": 0.18236452341079712,
      "learning_rate": 3.589712171447792e-05,
      "loss": 0.0002,
      "step": 58700
    },
    {
      "epoch": 2.8230262841766374,
      "grad_norm": 0.18539007008075714,
      "learning_rate": 3.5885108836672916e-05,
      "loss": 0.0002,
      "step": 58750
    },
    {
      "epoch": 2.825428859737639,
      "grad_norm": 0.16778327524662018,
      "learning_rate": 3.587309595886791e-05,
      "loss": 0.0002,
      "step": 58800
    },
    {
      "epoch": 2.82783143529864,
      "grad_norm": 0.09882999956607819,
      "learning_rate": 3.5861083081062904e-05,
      "loss": 0.0003,
      "step": 58850
    },
    {
      "epoch": 2.8302340108596415,
      "grad_norm": 0.3526502251625061,
      "learning_rate": 3.5849070203257895e-05,
      "loss": 0.0002,
      "step": 58900
    },
    {
      "epoch": 2.832636586420643,
      "grad_norm": 0.5128737092018127,
      "learning_rate": 3.5837057325452886e-05,
      "loss": 0.0002,
      "step": 58950
    },
    {
      "epoch": 2.835039161981644,
      "grad_norm": 0.42156311869621277,
      "learning_rate": 3.5825044447647884e-05,
      "loss": 0.0002,
      "step": 59000
    },
    {
      "epoch": 2.8374417375426457,
      "grad_norm": 0.10498709231615067,
      "learning_rate": 3.5813031569842874e-05,
      "loss": 0.0002,
      "step": 59050
    },
    {
      "epoch": 2.8398443131036473,
      "grad_norm": 0.39232662320137024,
      "learning_rate": 3.580101869203787e-05,
      "loss": 0.0002,
      "step": 59100
    },
    {
      "epoch": 2.8422468886646484,
      "grad_norm": 0.2909398674964905,
      "learning_rate": 3.5789005814232856e-05,
      "loss": 0.0002,
      "step": 59150
    },
    {
      "epoch": 2.84464946422565,
      "grad_norm": 0.41267070174217224,
      "learning_rate": 3.577699293642785e-05,
      "loss": 0.0008,
      "step": 59200
    },
    {
      "epoch": 2.8470520397866514,
      "grad_norm": 0.19003894925117493,
      "learning_rate": 3.5764980058622845e-05,
      "loss": 0.0002,
      "step": 59250
    },
    {
      "epoch": 2.8494546153476525,
      "grad_norm": 0.1729961633682251,
      "learning_rate": 3.5752967180817835e-05,
      "loss": 0.0002,
      "step": 59300
    },
    {
      "epoch": 2.851857190908654,
      "grad_norm": 0.0991135910153389,
      "learning_rate": 3.574095430301283e-05,
      "loss": 0.0002,
      "step": 59350
    },
    {
      "epoch": 2.8542597664696556,
      "grad_norm": 0.2991063594818115,
      "learning_rate": 3.5728941425207824e-05,
      "loss": 0.0002,
      "step": 59400
    },
    {
      "epoch": 2.8566623420306567,
      "grad_norm": 0.27183738350868225,
      "learning_rate": 3.5716928547402815e-05,
      "loss": 0.0002,
      "step": 59450
    },
    {
      "epoch": 2.8590649175916583,
      "grad_norm": 0.10398653149604797,
      "learning_rate": 3.570491566959781e-05,
      "loss": 0.001,
      "step": 59500
    },
    {
      "epoch": 2.86146749315266,
      "grad_norm": 0.06490115076303482,
      "learning_rate": 3.56929027917928e-05,
      "loss": 0.0002,
      "step": 59550
    },
    {
      "epoch": 2.863870068713661,
      "grad_norm": 0.1650303602218628,
      "learning_rate": 3.5680889913987794e-05,
      "loss": 0.0002,
      "step": 59600
    },
    {
      "epoch": 2.8662726442746624,
      "grad_norm": 0.3314896821975708,
      "learning_rate": 3.566887703618279e-05,
      "loss": 0.0002,
      "step": 59650
    },
    {
      "epoch": 2.868675219835664,
      "grad_norm": 0.18532614409923553,
      "learning_rate": 3.565686415837778e-05,
      "loss": 0.0002,
      "step": 59700
    },
    {
      "epoch": 2.871077795396665,
      "grad_norm": 0.15212838351726532,
      "learning_rate": 3.564485128057278e-05,
      "loss": 0.0006,
      "step": 59750
    },
    {
      "epoch": 2.8734803709576666,
      "grad_norm": 0.05817463994026184,
      "learning_rate": 3.563283840276777e-05,
      "loss": 0.0002,
      "step": 59800
    },
    {
      "epoch": 2.875882946518668,
      "grad_norm": 0.34050053358078003,
      "learning_rate": 3.562082552496276e-05,
      "loss": 0.0002,
      "step": 59850
    },
    {
      "epoch": 2.8782855220796693,
      "grad_norm": 0.11819195747375488,
      "learning_rate": 3.560881264715775e-05,
      "loss": 0.0002,
      "step": 59900
    },
    {
      "epoch": 2.880688097640671,
      "grad_norm": 0.11120191961526871,
      "learning_rate": 3.559679976935274e-05,
      "loss": 0.0002,
      "step": 59950
    },
    {
      "epoch": 2.8830906732016723,
      "grad_norm": 0.04768827557563782,
      "learning_rate": 3.558478689154774e-05,
      "loss": 0.0002,
      "step": 60000
    },
    {
      "epoch": 2.8854932487626734,
      "grad_norm": 0.38898152112960815,
      "learning_rate": 3.557277401374273e-05,
      "loss": 0.0002,
      "step": 60050
    },
    {
      "epoch": 2.887895824323675,
      "grad_norm": 0.11094263195991516,
      "learning_rate": 3.556076113593772e-05,
      "loss": 0.0002,
      "step": 60100
    },
    {
      "epoch": 2.8902983998846765,
      "grad_norm": 0.1352359801530838,
      "learning_rate": 3.554874825813272e-05,
      "loss": 0.0002,
      "step": 60150
    },
    {
      "epoch": 2.8927009754456776,
      "grad_norm": 0.04517177492380142,
      "learning_rate": 3.553673538032771e-05,
      "loss": 0.0002,
      "step": 60200
    },
    {
      "epoch": 2.895103551006679,
      "grad_norm": 0.15952475368976593,
      "learning_rate": 3.552472250252271e-05,
      "loss": 0.0002,
      "step": 60250
    },
    {
      "epoch": 2.8975061265676807,
      "grad_norm": 0.07224258780479431,
      "learning_rate": 3.55127096247177e-05,
      "loss": 0.0007,
      "step": 60300
    },
    {
      "epoch": 2.899908702128682,
      "grad_norm": 0.19418704509735107,
      "learning_rate": 3.550069674691269e-05,
      "loss": 0.0001,
      "step": 60350
    },
    {
      "epoch": 2.9023112776896833,
      "grad_norm": 0.09567680209875107,
      "learning_rate": 3.548868386910769e-05,
      "loss": 0.0001,
      "step": 60400
    },
    {
      "epoch": 2.904713853250685,
      "grad_norm": 0.05984300747513771,
      "learning_rate": 3.547667099130268e-05,
      "loss": 0.0002,
      "step": 60450
    },
    {
      "epoch": 2.907116428811686,
      "grad_norm": 0.144274041056633,
      "learning_rate": 3.5464658113497676e-05,
      "loss": 0.0002,
      "step": 60500
    },
    {
      "epoch": 2.9095190043726875,
      "grad_norm": 0.3115510046482086,
      "learning_rate": 3.545264523569267e-05,
      "loss": 0.0002,
      "step": 60550
    },
    {
      "epoch": 2.911921579933689,
      "grad_norm": 0.4361084997653961,
      "learning_rate": 3.544063235788766e-05,
      "loss": 0.0002,
      "step": 60600
    },
    {
      "epoch": 2.91432415549469,
      "grad_norm": 0.28926002979278564,
      "learning_rate": 3.542861948008265e-05,
      "loss": 0.0002,
      "step": 60650
    },
    {
      "epoch": 2.9167267310556917,
      "grad_norm": 0.036608271300792694,
      "learning_rate": 3.541660660227764e-05,
      "loss": 0.0002,
      "step": 60700
    },
    {
      "epoch": 2.9191293066166932,
      "grad_norm": 0.10046043992042542,
      "learning_rate": 3.540459372447264e-05,
      "loss": 0.0002,
      "step": 60750
    },
    {
      "epoch": 2.9215318821776943,
      "grad_norm": 0.11741819977760315,
      "learning_rate": 3.539258084666763e-05,
      "loss": 0.0001,
      "step": 60800
    },
    {
      "epoch": 2.923934457738696,
      "grad_norm": 0.22390423715114594,
      "learning_rate": 3.538056796886262e-05,
      "loss": 0.0001,
      "step": 60850
    },
    {
      "epoch": 2.9263370332996974,
      "grad_norm": 0.2683485448360443,
      "learning_rate": 3.5368555091057616e-05,
      "loss": 0.0006,
      "step": 60900
    },
    {
      "epoch": 2.9287396088606985,
      "grad_norm": 0.47045350074768066,
      "learning_rate": 3.535654221325261e-05,
      "loss": 0.0002,
      "step": 60950
    },
    {
      "epoch": 2.9311421844217,
      "grad_norm": 0.3407745063304901,
      "learning_rate": 3.5344529335447605e-05,
      "loss": 0.0005,
      "step": 61000
    },
    {
      "epoch": 2.9335447599827016,
      "grad_norm": 0.32275888323783875,
      "learning_rate": 3.5332516457642596e-05,
      "loss": 0.0003,
      "step": 61050
    },
    {
      "epoch": 2.9359473355437027,
      "grad_norm": 0.10359703749418259,
      "learning_rate": 3.5320503579837586e-05,
      "loss": 0.0002,
      "step": 61100
    },
    {
      "epoch": 2.9383499111047042,
      "grad_norm": 0.49825775623321533,
      "learning_rate": 3.5308490702032584e-05,
      "loss": 0.0002,
      "step": 61150
    },
    {
      "epoch": 2.9407524866657058,
      "grad_norm": 0.22796961665153503,
      "learning_rate": 3.5296477824227575e-05,
      "loss": 0.0003,
      "step": 61200
    },
    {
      "epoch": 2.943155062226707,
      "grad_norm": 0.32840263843536377,
      "learning_rate": 3.5284464946422566e-05,
      "loss": 0.0002,
      "step": 61250
    },
    {
      "epoch": 2.9455576377877084,
      "grad_norm": 0.3766448497772217,
      "learning_rate": 3.527245206861756e-05,
      "loss": 0.0002,
      "step": 61300
    },
    {
      "epoch": 2.94796021334871,
      "grad_norm": 0.16223010420799255,
      "learning_rate": 3.5260439190812554e-05,
      "loss": 0.0002,
      "step": 61350
    },
    {
      "epoch": 2.950362788909711,
      "grad_norm": 0.07983006536960602,
      "learning_rate": 3.5248426313007545e-05,
      "loss": 0.0002,
      "step": 61400
    },
    {
      "epoch": 2.9527653644707126,
      "grad_norm": 0.14405551552772522,
      "learning_rate": 3.5236413435202536e-05,
      "loss": 0.0002,
      "step": 61450
    },
    {
      "epoch": 2.955167940031714,
      "grad_norm": 0.28594332933425903,
      "learning_rate": 3.522440055739753e-05,
      "loss": 0.0002,
      "step": 61500
    },
    {
      "epoch": 2.9575705155927157,
      "grad_norm": 0.24533632397651672,
      "learning_rate": 3.5212387679592524e-05,
      "loss": 0.0002,
      "step": 61550
    },
    {
      "epoch": 2.9599730911537168,
      "grad_norm": 0.2371990978717804,
      "learning_rate": 3.5200374801787515e-05,
      "loss": 0.0006,
      "step": 61600
    },
    {
      "epoch": 2.9623756667147183,
      "grad_norm": 0.19623209536075592,
      "learning_rate": 3.518836192398251e-05,
      "loss": 0.0002,
      "step": 61650
    },
    {
      "epoch": 2.9647782422757194,
      "grad_norm": 0.2915506660938263,
      "learning_rate": 3.5176349046177503e-05,
      "loss": 0.0002,
      "step": 61700
    },
    {
      "epoch": 2.967180817836721,
      "grad_norm": 0.15550512075424194,
      "learning_rate": 3.5164336168372494e-05,
      "loss": 0.0002,
      "step": 61750
    },
    {
      "epoch": 2.9695833933977225,
      "grad_norm": 0.4311997890472412,
      "learning_rate": 3.515232329056749e-05,
      "loss": 0.0002,
      "step": 61800
    },
    {
      "epoch": 2.971985968958724,
      "grad_norm": 0.3411620855331421,
      "learning_rate": 3.514031041276248e-05,
      "loss": 0.0002,
      "step": 61850
    },
    {
      "epoch": 2.974388544519725,
      "grad_norm": 0.6989138722419739,
      "learning_rate": 3.512829753495748e-05,
      "loss": 0.0002,
      "step": 61900
    },
    {
      "epoch": 2.9767911200807267,
      "grad_norm": 0.20192819833755493,
      "learning_rate": 3.511628465715247e-05,
      "loss": 0.0002,
      "step": 61950
    },
    {
      "epoch": 2.9791936956417278,
      "grad_norm": 0.34365227818489075,
      "learning_rate": 3.510427177934746e-05,
      "loss": 0.0002,
      "step": 62000
    },
    {
      "epoch": 2.9815962712027293,
      "grad_norm": 0.2635134160518646,
      "learning_rate": 3.509225890154246e-05,
      "loss": 0.0009,
      "step": 62050
    },
    {
      "epoch": 2.983998846763731,
      "grad_norm": 0.4244785010814667,
      "learning_rate": 3.508024602373745e-05,
      "loss": 0.0002,
      "step": 62100
    },
    {
      "epoch": 2.9864014223247324,
      "grad_norm": 0.12263031303882599,
      "learning_rate": 3.506823314593244e-05,
      "loss": 0.0001,
      "step": 62150
    },
    {
      "epoch": 2.9888039978857335,
      "grad_norm": 0.13430309295654297,
      "learning_rate": 3.505622026812743e-05,
      "loss": 0.0002,
      "step": 62200
    },
    {
      "epoch": 2.991206573446735,
      "grad_norm": 0.6797611117362976,
      "learning_rate": 3.504420739032242e-05,
      "loss": 0.0002,
      "step": 62250
    },
    {
      "epoch": 2.993609149007736,
      "grad_norm": 0.4418310225009918,
      "learning_rate": 3.503219451251742e-05,
      "loss": 0.0002,
      "step": 62300
    },
    {
      "epoch": 2.9960117245687377,
      "grad_norm": 0.28278228640556335,
      "learning_rate": 3.502018163471241e-05,
      "loss": 0.0002,
      "step": 62350
    },
    {
      "epoch": 2.998414300129739,
      "grad_norm": 0.2721526026725769,
      "learning_rate": 3.500816875690741e-05,
      "loss": 0.0007,
      "step": 62400
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.00017453967302571982,
      "eval_runtime": 17.3099,
      "eval_samples_per_second": 548.589,
      "eval_steps_per_second": 68.574,
      "step": 62433
    }
  ],
  "logging_steps": 50,
  "max_steps": 208110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7009080952448428e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
