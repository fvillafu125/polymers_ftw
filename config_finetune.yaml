# Necessary paths, libraries, and flags for fine-tuning with LoRA

lora_flag: True                                  # whether to use LoRA
train_file: 'data/neurips_augmented_train_Tc.csv'      # train file path
test_file: 'data/neurips_augmented_test_Tc.csv'        # test file path if cross-validation is not used
model_path: 'ckpt/pretrain.pt'                      # pretrain model path
save_path: 'ckpt/neurips.pt/Tc'                     # checkpoint path
# best_model_path: f"{save_path}/Rg1"          # best model save path
log_path: 'ckpt/neurips.pt/logs'                    # log path 
blocksize: 411                                      # max length of sequences after tokenization

# LoRA parameters

lora_args:
  r: 64                                              # rank
  lora_alpha: 16                                     # LoRA alpha
  lora_dropout: 0.05                                  # LoRA dropout
  target_modules: ["query", "value"]                  # target modules to apply LoRA
  bias: "none"                                       # bias type
  task_type: "SEQ_CLS"                               # task type

# Training parameters

training_args:                                    # training arguments for HuggingFace Trainer
  output_dir: 'ckpt/neurips.pt/Tc'                   # output directory
  num_train_epochs: 10                               # number of training epochs
  per_device_train_batch_size: 4                     # batch size per device during training
  eval_strategy: 'steps'                             # evaluation strategy
  save_strategy: 'steps'                             # save strategy
  save_total_limit: 2                                # maximum number of checkpoints to save
  load_best_model_at_end: True                       # whether to load the best model at the end of training
  metric_for_best_model: 'eval_loss'                # metric for best model
  logging_steps: 50                                  # logging steps
  logging_dir: 'ckpt/neurips.pt/logs'               # logging directory
  fp16: True                                        # whether to use fp16

# Callback parameters                            

tolerance: 2                          # arguments for callbacks
                       




